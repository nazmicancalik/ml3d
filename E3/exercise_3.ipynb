{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exercise 3: Shape Reconstruction\n",
    "\n",
    "**Submission Deadline**: 09.06.2021, 23:55\n",
    "\n",
    "We will take a look at two major approaches for 3D shape reconstruction in this last exercise.\n",
    "\n",
    "Like in exercise 2, you can run all trainings either locally or on Google Colab. Just follow the instructions below. \n",
    "\n",
    "Note that training reconstruction methods generally takes relatively long, even for simple shape completion. Training the generalization will take a few hours. *Thus, please make sure to start training well before the submission deadline.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0. Running this notebook\n",
    "We recommend running this notebook on a cuda compatible local gpu. You can also run training on cpu, it will just take longer.\n",
    "\n",
    "We describe two options for executing the training parts of this exercise below: Using Google Colab or running it locally on your machine. If you are not planning on using Colab, just skip forward to Local Execution.\n",
    "\n",
    "### Google Colab\n",
    "\n",
    "If you don't have access to gpu and don't wish to train on CPU, you can use Google Colab. However, we experienced the issue that inline visualization of shapes or inline images didn't work on colab, so just keep that in mind.\n",
    "What you can also do is only train networks on colab, download the checkpoint, and visualize inference locally.\n",
    "\n",
    "In case you're using Google Colab, you can upload the exercise folder (containing `exercise_3.ipynb`, directory `exercise_3` and the file `requirements.txt`) as `3d-machine-learning` to google drive (make sure you don't upload extracted datasets files).\n",
    "Additionally you'd need to open the notebook `exercise_3.ipynb` in Colab using `File > Open Notebook > Upload`.\n",
    "\n",
    "Next you'll need to run these two cells for setting up the environment. Before you do that make sure your instance has a GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport os\\nfrom google.colab import drive\\ndrive.mount('/content/drive', force_remount=True)\\n\\n# We assume you uploaded the exercise folder in root Google Drive folder\\n\\n!cp -r /content/drive/MyDrive/3d-machine-learning 3d-machine-learning/\\nos.chdir('/content/3d-machine-learning/')\\nprint('Installing requirements')\\n!pip install -r requirements.txt\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import os\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "# We assume you uploaded the exercise folder in root Google Drive folder\n",
    "\n",
    "!cp -r /content/drive/MyDrive/3d-machine-learning 3d-machine-learning/\n",
    "os.chdir('/content/3d-machine-learning/')\n",
    "print('Installing requirements')\n",
    "!pip install -r requirements.txt\n",
    "'''\n",
    "# Make sure you restart runtime when directed by Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this cell after restarting your colab runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport os\\nimport sys\\nimport torch\\nos.chdir(\\'/content/3d-machine-learning/\\')\\nsys.path.insert(1, \"/content/3d-machine-learning/\")\\nprint(\\'CUDA availability:\\', torch.cuda.is_available())\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "os.chdir('/content/3d-machine-learning/')\n",
    "sys.path.insert(1, \"/content/3d-machine-learning/\")\n",
    "print('CUDA availability:', torch.cuda.is_available())\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Execution\n",
    "\n",
    "If you run this notebook locally, you have to first install the python dependiencies again. They are the same as for exercise 1 so you can re-use the environment you used last time. If you use [poetry](https://python-poetry.org), you can also simply re-install everything (`poetry install`) and then run this notebook via `poetry run jupyter notebook`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "The following imports should work regardless of whether you are using Colab or local execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import k3d\n",
    "import trimesh\n",
    "import torch\n",
    "import skimage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the next cell to test whether a GPU was detected by pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Shape Reconstruction from 3D SDF grids with 3D-EPN\n",
    "\n",
    "In the first part of this exercise, we will take a look at shape complation using [3D-EPN](https://arxiv.org/abs/1612.00101). This approach was also introduced in the lecture.\n",
    "\n",
    "The visualization below shows an overview of the method: From an incomplete shape observation (which you would get when scanning an object with a depth sensor for example), we use a 3D encoder-predictor network that first encodes the incomplete shapes into a common latent space using several 3D convolution layers and then decodes them again using multiple 3D transpose convolutions.\n",
    "\n",
    "This way, we get from a 32^3 SDF voxel grid to a 32^3 DF (unsigned) voxel grid that represents the completed shape. We only focus on this part here; in the original implementation, this 32^3 completed prediction would then be further improved (in an offline step after inference) by sampling parts from a shape database to get the final resolution to 128^3.\n",
    "\n",
    "<img src=\"exercise_3/images/3depn_teaser.png\" alt=\"3D-EPN Teaser\" style=\"width: 800px;\"/>\n",
    "\n",
    "The next steps will follow the structure we established in exercise 2: Taking a look at the dataset structure and downloading the data; then, implementing dataset, model, and training loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Downloading the data\n",
    "We will use the original dataset used in the official implementation. It consists of SDF and DF grids (representing incomplete input data and complete target data) with a resolution of 32^3 each. Each input-target pair is generated from a ShapeNet shape.\n",
    "\n",
    "The incomplete SDF data are generated by sampling virtual camera trajectories around every object. Each trajectory is assigned an ID which is part of the file names (see below). The camera views for each trajectory are combined into a common SDF grid by volumetric fusion. It is easy to generate an SDF here since we know both camera location and object surface: Everything between camera and surface is known free space and outside the object, leading to a positive SDF sign. Everything behind the surface has a negative sign. For the complete shapes, however, deciding whether a voxel in the DF grid is inside or outside an object is not a trivial problem. This is why we use unsigned distance fields as target and prediction representation instead. This still encodes the distance to the closest surface but does not contain explicit information about the inside/outside location.\n",
    "\n",
    "In terms of dataset layout, we follow the ShapeNet directory structure as seen in the last exercise:\n",
    "Each folder in the `exercise_3/data/shapenet_dim32_sdf` and `exercise_3/data/shapenet_dim32_df` directories contains one shape category represented by a number, e.g. `02691156`.\n",
    "We provide the mapping between these numbers and the corresponding names in `exercise_3/data/shape_info.json`. Each of these shape category folders contains lots of shapes in sdf or df format. In addition to that, every shape now also contains multiple trajectories: 0 to 7, encoded as `__0__` to `__7__`. These 8 files are just different input representations, meaning they vary in the level of completeness and location of missing parts; they all map to the `.df` file with corresponding shape ID and `__0__` at the end.\n",
    "\n",
    "```\n",
    "# contents of exercise_2/data/shapenet_dim32_sdf\n",
    "02691156/                                           # Shape category folder with all its shapes\n",
    "    ├── 10155655850468db78d106ce0a280f87__0__.sdf   # Trajectory 0 for a shape of the category\n",
    "    ├── 10155655850468db78d106ce0a280f87__1__.sdf   # Trajectory 1 for the same shape\n",
    "    ├── :                                      \n",
    "    ├── 10155655850468db78d106ce0a280f87__7__.sdf   # Trajectory 7 for the same shape\n",
    "    ├── 1021a0914a7207aff927ed529ad90a11__0__.sdf   # Trajectory 0 for another shape\n",
    "    ├── :                                           # And so on ...\n",
    "02933112/                                           # Another shape category folder\n",
    "02958343/                                           # In total you should have 8 shape category folders\n",
    ":\n",
    "\n",
    "# contents of exercise_2/data/shapenet_dim32_df\n",
    "02691156/                                           # Shape category folder with all its shapes\n",
    "    ├── 10155655850468db78d106ce0a280f87__0__.df    # A single shape of the category\n",
    "    ├── 1021a0914a7207aff927ed529ad90a11__0__.df    # Another shape of the category\n",
    "    ├── :                                           # And so on ...\n",
    "02933112/                                           # Another shape category folder\n",
    "02958343/                                           # In total you should have 55 shape category folders\n",
    ":\n",
    "```\n",
    "\n",
    "Download and extract the data with the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nprint('Downloading ...')\\n# File sizes: 11GB for shapenet_dim32_sdf.zip (incomplete scans), 4GB for shapenet_dim32_df.zip (target shapes)\\n!wget http://kaldir.vc.in.tum.de/adai/CNNComplete/shapenet_dim32_sdf.zip -P ~/datasets/e3\\n!wget http://kaldir.vc.in.tum.de/adai/CNNComplete/shapenet_dim32_df.zip -P ~/datasets/e3\\nprint('Extracting ...')\\n!unzip -q ~/datasets/e3/shapenet_dim32_sdf.zip -d ~/datasets/e3\\n!unzip -q ~/datasets/e3/shapenet_dim32_df.zip -d ~/datasets/e3\\n!rm ~/datasets/e3/shapenet_dim32_sdf.zip\\n!rm ~/datasets/e3/shapenet_dim32_df.zip\\nprint('Done.')\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "print('Downloading ...')\n",
    "# File sizes: 11GB for shapenet_dim32_sdf.zip (incomplete scans), 4GB for shapenet_dim32_df.zip (target shapes)\n",
    "!wget http://kaldir.vc.in.tum.de/adai/CNNComplete/shapenet_dim32_sdf.zip -P ~/datasets/e3\n",
    "!wget http://kaldir.vc.in.tum.de/adai/CNNComplete/shapenet_dim32_df.zip -P ~/datasets/e3\n",
    "print('Extracting ...')\n",
    "!unzip -q ~/datasets/e3/shapenet_dim32_sdf.zip -d ~/datasets/e3\n",
    "!unzip -q ~/datasets/e3/shapenet_dim32_df.zip -d ~/datasets/e3\n",
    "!rm ~/datasets/e3/shapenet_dim32_sdf.zip\n",
    "!rm ~/datasets/e3/shapenet_dim32_df.zip\n",
    "print('Done.')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Dataset\n",
    "\n",
    "The dataset implementation follows the same general structure as in exercise 2. We prepared an initial implementation already in `exercise_3/data/shapenet.py`; your task is to resolve all TODOs there.\n",
    "\n",
    "The data for SDFs and DFs in `.sdf`/`.df` files are stored in binary form as follows:\n",
    "```\n",
    "dimX    #uint64 \n",
    "dimY    #uint64 \n",
    "dimZ    #uint64 \n",
    "data    #(dimX*dimY*dimZ) floats for sdf/df values\n",
    "```\n",
    "The SDF values stored per-voxel represent the distance to the closest surface *in voxels*.\n",
    "\n",
    "You have to take care of three important steps before returning the SDF and DF for the corresponding `index` in `__getitem__`:\n",
    "1. **Truncation**: 3D-EPN uses a truncated SDF which means that for each voxel, the distance to the closest surface will be clamped to a max absolute value. This is helpful since we do not care about longer distances (Marching Cubes only cares about distances close to the surface). It allows us to focus our predictions on the voxels near the surface. We use a `truncation_distance` of 3 (voxels) which means we expect to get an SDF with values between -3 and 3 as input to the model.\n",
    "2. **Separation** of distances and sign: 3D-EPN uses as input a 2x32x32x32 SDF grid, with absolute distance values of the SDF in channel 0 and the signs (-1 or 1) in channel 1.\n",
    "3. **Log** scaling: We scale targets and prediction with a log operation to further guide predictions to focus on the surface voxels. Therefore, you should return target DFs as `log(df + 1)`.\n",
    "\n",
    "**Hint**: An easy way to load the data from `.sdf` and `.df` files is to use `np.fromfile`. First, load the dimensions, then the data, then reshape everything into the shape you loaded in the beginning. Make sure you get the datatypes and byte offsets right!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train set: 153540\n",
      "Length of val set: 32304\n",
      "Length of overfit set: 64\n"
     ]
    }
   ],
   "source": [
    "from exercise_3.data.shapenet import ShapeNet\n",
    "\n",
    "# Create a dataset with train split\n",
    "train_dataset = ShapeNet('train')\n",
    "val_dataset = ShapeNet('val')\n",
    "overfit_dataset = ShapeNet('overfit')\n",
    "\n",
    "# Get length, which is a call to __len__ function\n",
    "print(f'Length of train set: {len(train_dataset)}')  # expected output: 153540\n",
    "# Get length, which is a call to __len__ function\n",
    "print(f'Length of val set: {len(val_dataset)}')  # expected output: 32304\n",
    "# Get length, which is a call to __len__ function\n",
    "print(f'Length of overfit set: {len(overfit_dataset)}')  # expected output: 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: 03001627/798a46965d9e0edfcea003eff0268278__3__-03001627/798a46965d9e0edfcea003eff0268278__0__\n",
      "Input SDF: (2, 32, 32, 32)\n",
      "Target DF: (32, 32, 32)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbfc0cd40a6246aab3748d68aa058d54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize some shapes\n",
    "from exercise_3.util.visualization import visualize_mesh\n",
    "from skimage.measure import marching_cubes\n",
    "\n",
    "train_sample = train_dataset[1]\n",
    "print(f'Name: {train_sample[\"name\"]}')  # expected output: 03001627/798a46965d9e0edfcea003eff0268278__3__-03001627/798a46965d9e0edfcea003eff0268278__0__\n",
    "print(f'Input SDF: {train_sample[\"input_sdf\"].shape}')  # expected output: (2, 32, 32, 32)\n",
    "print(f'Target DF: {train_sample[\"target_df\"].shape}')  # expected output: (32, 32, 32)\n",
    "\n",
    "input_mesh = marching_cubes(train_sample['input_sdf'][0], level=1)\n",
    "visualize_mesh(input_mesh[0], input_mesh[1], flip_axes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntrain_sample = train_dataset[223]\\nprint(f\\'Name: {train_sample[\"name\"]}\\')  # expected output: 04379243/a1be21c9a71d133dc5beea20858a99d5__5__-04379243/a1be21c9a71d133dc5beea20858a99d5__0__\\nprint(f\\'Input SDF: {train_sample[\"input_sdf\"].shape}\\')  # expected output: (2, 32, 32, 32)\\nprint(f\\'Target DF: {train_sample[\"target_df\"].shape}\\')  # expected output: (32, 32, 32)\\n\\ninput_mesh = marching_cubes(train_sample[\\'input_sdf\\'][0], level=1)\\nvisualize_mesh(input_mesh[0], input_mesh[1], flip_axes=True)\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "train_sample = train_dataset[223]\n",
    "print(f'Name: {train_sample[\"name\"]}')  # expected output: 04379243/a1be21c9a71d133dc5beea20858a99d5__5__-04379243/a1be21c9a71d133dc5beea20858a99d5__0__\n",
    "print(f'Input SDF: {train_sample[\"input_sdf\"].shape}')  # expected output: (2, 32, 32, 32)\n",
    "print(f'Target DF: {train_sample[\"target_df\"].shape}')  # expected output: (32, 32, 32)\n",
    "\n",
    "input_mesh = marching_cubes(train_sample['input_sdf'][0], level=1)\n",
    "visualize_mesh(input_mesh[0], input_mesh[1], flip_axes=True)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntrain_sample = train_dataset[95]\\nprint(f\\'Name: {train_sample[\"name\"]}\\')  # expected output: 03636649/3889631e42a84b0f51f77a6d7299806__2__-03636649/3889631e42a84b0f51f77a6d7299806__0__\\nprint(f\\'Input SDF: {train_sample[\"input_sdf\"].shape}\\')  # expected output: (2, 32, 32, 32)\\nprint(f\\'Target DF: {train_sample[\"target_df\"].shape}\\')  # expected output: (32, 32, 32)\\n\\ninput_mesh = marching_cubes(train_sample[\\'input_sdf\\'][0], level=1)\\nvisualize_mesh(input_mesh[0], input_mesh[1], flip_axes=True)\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "train_sample = train_dataset[95]\n",
    "print(f'Name: {train_sample[\"name\"]}')  # expected output: 03636649/3889631e42a84b0f51f77a6d7299806__2__-03636649/3889631e42a84b0f51f77a6d7299806__0__\n",
    "print(f'Input SDF: {train_sample[\"input_sdf\"].shape}')  # expected output: (2, 32, 32, 32)\n",
    "print(f'Target DF: {train_sample[\"target_df\"].shape}')  # expected output: (32, 32, 32)\n",
    "\n",
    "input_mesh = marching_cubes(train_sample['input_sdf'][0], level=1)\n",
    "visualize_mesh(input_mesh[0], input_mesh[1], flip_axes=True)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Model\n",
    "\n",
    "The model architecture of 3D-EPN is visualized below:\n",
    "\n",
    "<img src=\"exercise_3/images/3depn.png\" alt=\"3D-EPN Architecture\" style=\"width: 800px;\"/>\n",
    "\n",
    "For this exercise, we simplify the model by omitting the classification part - this will not have a big impact since most of the shape completion performance comes from the 3D encoder-decoder unet.\n",
    "\n",
    "The model consists of three parts: The encoder, the bottleneck, and the decoder. Encoder and decoder are constructed with the same architecture, just mirrored.\n",
    "\n",
    "The details of each part are:\n",
    "- **Encoder**: 4 layers, each one containing a 3D convolution (with kernel size 4, as seen in the visualization), a 3D batch norm (except the very first layer), and a leaky ReLU with a negative slope of 0.2. Our goal is to reduce the spatial dimension from 32x32x32 to 1x1x1 and to get the feature dimension from 2 (absolute values and sign) to `num_features * 8`. We do this by using a stride of 2 and padding of 1 for all convolutions except for the last one where we use a stride of 1 and no padding. The feature channels are increased from 2 to `num_features` in the first layer and then doubled with every subsequent layer.\n",
    "- **Decoder**: Same architecture as encoder, just mirrored: Going from `num_features * 8 * 2` (the 2 will be explained later) to 1 (the DF values). The spatial dimensions go from 1x1x1 to 32x32x32. Each layer use a 3D Transpose convolution now, together with 3D batch norm and ReLU (no leaky ReLUs anymore). Note that the last layer uses neither Batch Norms nor a ReLU since we do not want to constrain the range of possible values for the prediction.\n",
    "- **Bottleneck**: This is realized with 2 fully connected layers, each one going from a vector of size 640 (which is `num_features * 8`) to a vector of size 640. Each such layer is followed by a ReLU activation.\n",
    "\n",
    "Some minor details:\n",
    "- **Skip connections** allow the decoder to use information from the encoder and also improve gradient flow. We use it here to connect the output of encoder layer 1 to decoder layer 4, the output of encoder layer 2 to decoder layer 3, and so on. This means that the input to a decoder layer is the concatenation of the previous decoder output with the corresponding encoder output, along the feature dimension. Hence, the number of input features for each decoder layer are twice those of the encoder layers, as mentioned above.\n",
    "- **Log scaling**: You also need to scale the final outputs of the network logarithmically: `out = log(out + 1)`. This is the same transformation you applied to the target shapes in the dataloader before and ensures that prediction and target volumes are comparable.\n",
    "\n",
    "With this in mind, implement the network architecture and `forward()` function in `exercise_3/model/threedepn.py`. You can check your architecture with the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   | Name         | Type            | Params  \n",
      "----------------------------------------------------\n",
      "0  | conv1        | Conv3d          | 10320   \n",
      "1  | conv2        | Conv3d          | 819360  \n",
      "2  | conv3        | Conv3d          | 3277120 \n",
      "3  | conv4        | Conv3d          | 13107840\n",
      "4  | bn1          | BatchNorm3d     | 320     \n",
      "5  | bn2          | BatchNorm3d     | 640     \n",
      "6  | bn3          | BatchNorm3d     | 1280    \n",
      "7  | leaky_relu   | LeakyReLU       | 0       \n",
      "8  | bottleneck   | Sequential      | 820480  \n",
      "9  | bottleneck.0 | Linear          | 410240  \n",
      "10 | bottleneck.1 | ReLU            | 0       \n",
      "11 | bottleneck.2 | Linear          | 410240  \n",
      "12 | bottleneck.3 | ReLU            | 0       \n",
      "13 | tconv1       | ConvTranspose3d | 26214720\n",
      "14 | tconv2       | ConvTranspose3d | 6553760 \n",
      "15 | tconv3       | ConvTranspose3d | 1638480 \n",
      "16 | tconv4       | ConvTranspose3d | 10241   \n",
      "17 | bn4          | BatchNorm3d     | 640     \n",
      "18 | bn5          | BatchNorm3d     | 320     \n",
      "19 | bn6          | BatchNorm3d     | 160     \n",
      "20 | relu         | ReLU            | 0       \n",
      "21 | TOTAL        | ThreeDEPN       | 52455681\n",
      "Output tensor shape:  torch.Size([4, 32, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "from exercise_3.model.threedepn import ThreeDEPN\n",
    "from exercise_3.util.model import summarize_model\n",
    "\n",
    "threedepn = ThreeDEPN()\n",
    "print(summarize_model(threedepn))  # Expected: Rows 0-34 and TOTAL = 52455681\n",
    "\n",
    "sdf = torch.randn(4, 1, 32, 32, 32) * 2. - 1.\n",
    "input_tensor = torch.cat([torch.abs(sdf), torch.sign(sdf)], dim=1)\n",
    "predictions = threedepn(input_tensor)\n",
    "\n",
    "print('Output tensor shape: ', predictions.shape)  # Expected: torch.Size([4, 32, 32, 32])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) Training script and overfitting to a single shape reconstruction\n",
    "\n",
    "You can now go to the train script in `exercise_3/training/train_3depn.py` and fill in the missing pieces as you did for exercise 2. Then, verify that your training work by overfitting to a few samples below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "[004/00001] train_loss: 0.070432\n",
      "[009/00001] train_loss: 0.022295\n",
      "[012/00000] val_loss: 0.527366 | best_loss_val: 0.527366\n",
      "[014/00001] train_loss: 0.013221\n",
      "[019/00001] train_loss: 0.008615\n",
      "[024/00001] train_loss: 0.006580\n",
      "[024/00001] val_loss: 0.203785 | best_loss_val: 0.203785\n",
      "[029/00001] train_loss: 0.005581\n",
      "[034/00001] train_loss: 0.004817\n",
      "[037/00000] val_loss: 0.159729 | best_loss_val: 0.159729\n",
      "[039/00001] train_loss: 0.004245\n",
      "[044/00001] train_loss: 0.003877\n",
      "[049/00001] train_loss: 0.003666\n",
      "[049/00001] val_loss: 0.142577 | best_loss_val: 0.142577\n",
      "[054/00001] train_loss: 0.003449\n",
      "[059/00001] train_loss: 0.003286\n",
      "[062/00000] val_loss: 0.131892 | best_loss_val: 0.131892\n",
      "[064/00001] train_loss: 0.003148\n",
      "[069/00001] train_loss: 0.003061\n",
      "[074/00001] train_loss: 0.002986\n",
      "[074/00001] val_loss: 0.126460 | best_loss_val: 0.126460\n",
      "[079/00001] train_loss: 0.002917\n",
      "[084/00001] train_loss: 0.002839\n",
      "[087/00000] val_loss: 0.122761 | best_loss_val: 0.122761\n",
      "[089/00001] train_loss: 0.002806\n",
      "[094/00001] train_loss: 0.002769\n",
      "[099/00001] train_loss: 0.002710\n",
      "[099/00001] val_loss: 0.120128 | best_loss_val: 0.120128\n",
      "[104/00001] train_loss: 0.002670\n",
      "[109/00001] train_loss: 0.002666\n",
      "[112/00000] val_loss: 0.118830 | best_loss_val: 0.118830\n",
      "[114/00001] train_loss: 0.002632\n",
      "[119/00001] train_loss: 0.002609\n",
      "[124/00001] train_loss: 0.002608\n",
      "[124/00001] val_loss: 0.117721 | best_loss_val: 0.117721\n",
      "[129/00001] train_loss: 0.002606\n",
      "[134/00001] train_loss: 0.002580\n",
      "[137/00000] val_loss: 0.117003 | best_loss_val: 0.117003\n",
      "[139/00001] train_loss: 0.002564\n",
      "[144/00001] train_loss: 0.002582\n",
      "[149/00001] train_loss: 0.002551\n",
      "[149/00001] val_loss: 0.116566 | best_loss_val: 0.116566\n",
      "[154/00001] train_loss: 0.002553\n",
      "[159/00001] train_loss: 0.002548\n",
      "[162/00000] val_loss: 0.116209 | best_loss_val: 0.116209\n",
      "[164/00001] train_loss: 0.002544\n",
      "[169/00001] train_loss: 0.002539\n",
      "[174/00001] train_loss: 0.002531\n",
      "[174/00001] val_loss: 0.116019 | best_loss_val: 0.116019\n",
      "[179/00001] train_loss: 0.002540\n",
      "[184/00001] train_loss: 0.002517\n",
      "[187/00000] val_loss: 0.115867 | best_loss_val: 0.115867\n",
      "[189/00001] train_loss: 0.002528\n",
      "[194/00001] train_loss: 0.002519\n",
      "[199/00001] train_loss: 0.002515\n",
      "[199/00001] val_loss: 0.115774 | best_loss_val: 0.115774\n",
      "[204/00001] train_loss: 0.002517\n",
      "[209/00001] train_loss: 0.002519\n",
      "[212/00000] val_loss: 0.115750 | best_loss_val: 0.115750\n",
      "[214/00001] train_loss: 0.002528\n",
      "[219/00001] train_loss: 0.002513\n",
      "[224/00001] train_loss: 0.002514\n",
      "[224/00001] val_loss: 0.115674 | best_loss_val: 0.115674\n",
      "[229/00001] train_loss: 0.002515\n",
      "[234/00001] train_loss: 0.002510\n",
      "[237/00000] val_loss: 0.115655 | best_loss_val: 0.115655\n",
      "[239/00001] train_loss: 0.002515\n",
      "[244/00001] train_loss: 0.002527\n",
      "[249/00001] train_loss: 0.002507\n",
      "[249/00001] val_loss: 0.115623 | best_loss_val: 0.115623\n"
     ]
    }
   ],
   "source": [
    "from exercise_3.training import train_3depn\n",
    "config = {\n",
    "    'experiment_name': '3_1_3depn_overfitting',\n",
    "    'device': 'cuda:0',  # change this to cpu if you do not have a GPU\n",
    "    'is_overfit': True,\n",
    "    'batch_size': 32,\n",
    "    'resume_ckpt': None,\n",
    "    'learning_rate': 0.001,\n",
    "    'max_epochs': 250,\n",
    "    'print_every_n': 10,\n",
    "    'validate_every_n': 25,\n",
    "}\n",
    "#train_3depn.main(config)  # should be able to get <0.0025 train_loss and <0.13 val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (e) Training over the entire training set\n",
    "If the overfitting works, we can go ahead with training on the entire dataset.\n",
    "\n",
    "**Note**: As is the case with most reconstruction networks and considering the size of the model (> 50M parameters), this training will take a few hours on a GPU. *Please make sure to start training early enough before the submission deadline.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "[000/00049] train_loss: 0.033006\n",
      "[000/00099] train_loss: 0.014199\n",
      "[000/00149] train_loss: 0.011504\n",
      "[000/00199] train_loss: 0.010343\n",
      "[000/00249] train_loss: 0.009146\n",
      "[000/00299] train_loss: 0.008594\n",
      "[000/00349] train_loss: 0.008901\n",
      "[000/00399] train_loss: 0.008294\n",
      "[000/00449] train_loss: 0.008185\n",
      "[000/00499] train_loss: 0.007624\n",
      "[000/00549] train_loss: 0.007329\n",
      "[000/00599] train_loss: 0.007106\n",
      "[000/00649] train_loss: 0.007092\n",
      "[000/00699] train_loss: 0.007133\n",
      "[000/00749] train_loss: 0.006871\n",
      "[000/00799] train_loss: 0.006601\n",
      "[000/00849] train_loss: 0.006673\n",
      "[000/00899] train_loss: 0.006765\n",
      "[000/00949] train_loss: 0.006230\n",
      "[000/00999] train_loss: 0.006361\n",
      "[000/00999] val_loss: 0.365919 | best_loss_val: 0.365919\n",
      "[000/01049] train_loss: 0.006302\n",
      "[000/01099] train_loss: 0.005775\n",
      "[000/01149] train_loss: 0.006159\n",
      "[000/01199] train_loss: 0.006223\n",
      "[000/01249] train_loss: 0.006039\n",
      "[000/01299] train_loss: 0.005752\n",
      "[000/01349] train_loss: 0.005842\n",
      "[000/01399] train_loss: 0.005596\n",
      "[000/01449] train_loss: 0.005498\n",
      "[000/01499] train_loss: 0.005998\n",
      "[000/01549] train_loss: 0.005745\n",
      "[000/01599] train_loss: 0.005687\n",
      "[000/01649] train_loss: 0.005744\n",
      "[000/01699] train_loss: 0.005316\n",
      "[000/01749] train_loss: 0.005929\n",
      "[000/01799] train_loss: 0.005592\n",
      "[000/01849] train_loss: 0.005460\n",
      "[000/01899] train_loss: 0.005267\n",
      "[000/01949] train_loss: 0.005157\n",
      "[000/01999] train_loss: 0.005405\n",
      "[000/01999] val_loss: 0.145307 | best_loss_val: 0.145307\n",
      "[000/02049] train_loss: 0.005345\n",
      "[000/02099] train_loss: 0.005629\n",
      "[000/02149] train_loss: 0.005353\n",
      "[000/02199] train_loss: 0.005485\n",
      "[000/02249] train_loss: 0.005500\n",
      "[000/02299] train_loss: 0.005139\n",
      "[000/02349] train_loss: 0.005421\n",
      "[000/02399] train_loss: 0.005363\n",
      "[000/02449] train_loss: 0.005016\n",
      "[000/02499] train_loss: 0.005185\n",
      "[000/02549] train_loss: 0.005014\n",
      "[000/02599] train_loss: 0.005379\n",
      "[000/02649] train_loss: 0.005396\n",
      "[000/02699] train_loss: 0.005208\n",
      "[000/02749] train_loss: 0.005079\n",
      "[000/02799] train_loss: 0.005240\n",
      "[000/02849] train_loss: 0.005074\n",
      "[000/02899] train_loss: 0.005073\n",
      "[000/02949] train_loss: 0.004896\n",
      "[000/02999] train_loss: 0.005316\n",
      "[000/02999] val_loss: 0.211973 | best_loss_val: 0.145307\n",
      "[000/03049] train_loss: 0.004495\n",
      "[000/03099] train_loss: 0.004963\n",
      "[000/03149] train_loss: 0.004768\n",
      "[000/03199] train_loss: 0.005101\n",
      "[000/03249] train_loss: 0.004933\n",
      "[000/03299] train_loss: 0.005073\n",
      "[000/03349] train_loss: 0.004701\n",
      "[000/03399] train_loss: 0.004718\n",
      "[000/03449] train_loss: 0.004748\n",
      "[000/03499] train_loss: 0.005113\n",
      "[000/03549] train_loss: 0.004656\n",
      "[000/03599] train_loss: 0.004434\n",
      "[000/03649] train_loss: 0.004505\n",
      "[000/03699] train_loss: 0.004569\n",
      "[000/03749] train_loss: 0.004628\n",
      "[000/03799] train_loss: 0.004694\n",
      "[000/03849] train_loss: 0.004804\n",
      "[000/03899] train_loss: 0.004450\n",
      "[000/03949] train_loss: 0.004764\n",
      "[000/03999] train_loss: 0.004645\n",
      "[000/03999] val_loss: 0.151839 | best_loss_val: 0.145307\n",
      "[000/04049] train_loss: 0.004598\n",
      "[000/04099] train_loss: 0.004531\n",
      "[000/04149] train_loss: 0.004523\n",
      "[000/04199] train_loss: 0.004328\n",
      "[000/04249] train_loss: 0.004699\n",
      "[000/04299] train_loss: 0.004394\n",
      "[000/04349] train_loss: 0.005074\n",
      "[000/04399] train_loss: 0.004719\n",
      "[000/04449] train_loss: 0.004579\n",
      "[000/04499] train_loss: 0.004230\n",
      "[000/04549] train_loss: 0.004437\n",
      "[000/04599] train_loss: 0.004543\n",
      "[000/04649] train_loss: 0.004699\n",
      "[000/04699] train_loss: 0.004758\n",
      "[000/04749] train_loss: 0.004470\n",
      "[001/00000] train_loss: 0.004330\n",
      "[001/00050] train_loss: 0.004467\n",
      "[001/00100] train_loss: 0.004456\n",
      "[001/00150] train_loss: 0.004042\n",
      "[001/00200] train_loss: 0.004299\n",
      "[001/00200] val_loss: 0.228449 | best_loss_val: 0.145307\n",
      "[001/00250] train_loss: 0.004143\n",
      "[001/00300] train_loss: 0.004172\n",
      "[001/00350] train_loss: 0.004050\n",
      "[001/00400] train_loss: 0.004144\n",
      "[001/00450] train_loss: 0.004419\n",
      "[001/00500] train_loss: 0.004045\n",
      "[001/00550] train_loss: 0.004382\n",
      "[001/00600] train_loss: 0.004402\n",
      "[001/00650] train_loss: 0.004032\n",
      "[001/00700] train_loss: 0.004301\n",
      "[001/00750] train_loss: 0.004383\n",
      "[001/00800] train_loss: 0.004411\n",
      "[001/00850] train_loss: 0.004430\n",
      "[001/00900] train_loss: 0.004168\n",
      "[001/00950] train_loss: 0.004083\n",
      "[001/01000] train_loss: 0.004131\n",
      "[001/01050] train_loss: 0.003942\n",
      "[001/01100] train_loss: 0.004186\n",
      "[001/01150] train_loss: 0.004431\n",
      "[001/01200] train_loss: 0.004154\n",
      "[001/01200] val_loss: 0.120674 | best_loss_val: 0.120674\n",
      "[001/01250] train_loss: 0.004173\n",
      "[001/01300] train_loss: 0.004328\n",
      "[001/01350] train_loss: 0.004223\n",
      "[001/01400] train_loss: 0.003853\n",
      "[001/01450] train_loss: 0.004166\n",
      "[001/01500] train_loss: 0.004081\n",
      "[001/01550] train_loss: 0.004143\n",
      "[001/01600] train_loss: 0.004145\n",
      "[001/01650] train_loss: 0.003869\n",
      "[001/01700] train_loss: 0.003938\n",
      "[001/01750] train_loss: 0.003923\n",
      "[001/01800] train_loss: 0.004022\n",
      "[001/01850] train_loss: 0.003915\n",
      "[001/01900] train_loss: 0.004112\n",
      "[001/01950] train_loss: 0.004076\n",
      "[001/02000] train_loss: 0.004295\n",
      "[001/02050] train_loss: 0.004127\n",
      "[001/02100] train_loss: 0.003990\n",
      "[001/02150] train_loss: 0.004050\n",
      "[001/02200] train_loss: 0.004034\n",
      "[001/02200] val_loss: 0.490976 | best_loss_val: 0.120674\n",
      "[001/02250] train_loss: 0.003976\n",
      "[001/02300] train_loss: 0.004136\n",
      "[001/02350] train_loss: 0.004039\n",
      "[001/02400] train_loss: 0.004088\n",
      "[001/02450] train_loss: 0.004120\n",
      "[001/02500] train_loss: 0.003863\n",
      "[001/02550] train_loss: 0.003855\n",
      "[001/02600] train_loss: 0.003796\n",
      "[001/02650] train_loss: 0.003845\n",
      "[001/02700] train_loss: 0.004033\n",
      "[001/02750] train_loss: 0.004131\n",
      "[001/02800] train_loss: 0.003769\n",
      "[001/02850] train_loss: 0.003953\n",
      "[001/02900] train_loss: 0.003985\n",
      "[001/02950] train_loss: 0.003744\n",
      "[001/03000] train_loss: 0.003997\n",
      "[001/03050] train_loss: 0.003912\n",
      "[001/03100] train_loss: 0.003960\n",
      "[001/03150] train_loss: 0.003647\n",
      "[001/03200] train_loss: 0.003662\n",
      "[001/03200] val_loss: 0.137618 | best_loss_val: 0.120674\n",
      "[001/03250] train_loss: 0.003838\n",
      "[001/03300] train_loss: 0.004106\n",
      "[001/03350] train_loss: 0.004180\n",
      "[001/03400] train_loss: 0.003842\n",
      "[001/03450] train_loss: 0.004220\n",
      "[001/03500] train_loss: 0.004226\n",
      "[001/03550] train_loss: 0.003828\n",
      "[001/03600] train_loss: 0.003809\n",
      "[001/03650] train_loss: 0.003712\n",
      "[001/03700] train_loss: 0.003893\n",
      "[001/03750] train_loss: 0.004180\n",
      "[001/03800] train_loss: 0.003880\n",
      "[001/03850] train_loss: 0.004031\n",
      "[001/03900] train_loss: 0.003938\n",
      "[001/03950] train_loss: 0.003904\n",
      "[001/04000] train_loss: 0.003951\n",
      "[001/04050] train_loss: 0.003895\n",
      "[001/04100] train_loss: 0.004424\n",
      "[001/04150] train_loss: 0.003838\n",
      "[001/04200] train_loss: 0.003642\n",
      "[001/04200] val_loss: 0.141467 | best_loss_val: 0.120674\n",
      "[001/04250] train_loss: 0.003887\n",
      "[001/04300] train_loss: 0.003753\n",
      "[001/04350] train_loss: 0.003990\n",
      "[001/04400] train_loss: 0.004075\n",
      "[001/04450] train_loss: 0.003695\n",
      "[001/04500] train_loss: 0.003883\n",
      "[001/04550] train_loss: 0.003785\n",
      "[001/04600] train_loss: 0.003755\n",
      "[001/04650] train_loss: 0.003553\n",
      "[001/04700] train_loss: 0.003573\n",
      "[001/04750] train_loss: 0.003561\n",
      "[002/00001] train_loss: 0.003591\n",
      "[002/00051] train_loss: 0.003616\n",
      "[002/00101] train_loss: 0.003568\n",
      "[002/00151] train_loss: 0.003675\n",
      "[002/00201] train_loss: 0.003719\n",
      "[002/00251] train_loss: 0.003535\n",
      "[002/00301] train_loss: 0.003492\n",
      "[002/00351] train_loss: 0.003403\n",
      "[002/00401] train_loss: 0.003682\n",
      "[002/00401] val_loss: 0.112165 | best_loss_val: 0.112165\n",
      "[002/00451] train_loss: 0.003607\n",
      "[002/00501] train_loss: 0.003479\n",
      "[002/00551] train_loss: 0.003512\n",
      "[002/00601] train_loss: 0.003654\n",
      "[002/00651] train_loss: 0.003642\n",
      "[002/00701] train_loss: 0.003459\n",
      "[002/00751] train_loss: 0.003673\n",
      "[002/00801] train_loss: 0.003617\n",
      "[002/00851] train_loss: 0.003610\n",
      "[002/00901] train_loss: 0.003578\n",
      "[002/00951] train_loss: 0.003531\n",
      "[002/01001] train_loss: 0.003423\n",
      "[002/01051] train_loss: 0.003716\n",
      "[002/01101] train_loss: 0.003467\n",
      "[002/01151] train_loss: 0.003446\n",
      "[002/01201] train_loss: 0.003630\n",
      "[002/01251] train_loss: 0.003509\n",
      "[002/01301] train_loss: 0.003277\n",
      "[002/01351] train_loss: 0.003601\n",
      "[002/01401] train_loss: 0.003524\n",
      "[002/01401] val_loss: 0.129513 | best_loss_val: 0.112165\n",
      "[002/01451] train_loss: 0.003699\n",
      "[002/01501] train_loss: 0.003406\n",
      "[002/01551] train_loss: 0.003534\n",
      "[002/01601] train_loss: 0.003399\n",
      "[002/01651] train_loss: 0.003345\n",
      "[002/01701] train_loss: 0.003724\n",
      "[002/01751] train_loss: 0.003666\n",
      "[002/01801] train_loss: 0.003710\n",
      "[002/01851] train_loss: 0.003486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[002/01901] train_loss: 0.003525\n",
      "[002/01951] train_loss: 0.003596\n",
      "[002/02001] train_loss: 0.003570\n",
      "[002/02051] train_loss: 0.003497\n",
      "[002/02101] train_loss: 0.003525\n",
      "[002/02151] train_loss: 0.003466\n",
      "[002/02201] train_loss: 0.003572\n",
      "[002/02251] train_loss: 0.003199\n",
      "[002/02301] train_loss: 0.003400\n",
      "[002/02351] train_loss: 0.003530\n",
      "[002/02401] train_loss: 0.003337\n",
      "[002/02401] val_loss: 0.215063 | best_loss_val: 0.112165\n",
      "[002/02451] train_loss: 0.003497\n",
      "[002/02501] train_loss: 0.003403\n",
      "[002/02551] train_loss: 0.003382\n",
      "[002/02601] train_loss: 0.003385\n",
      "[002/02651] train_loss: 0.003300\n",
      "[002/02701] train_loss: 0.003205\n",
      "[002/02751] train_loss: 0.003369\n",
      "[002/02801] train_loss: 0.003430\n",
      "[002/02851] train_loss: 0.003423\n",
      "[002/02901] train_loss: 0.003450\n",
      "[002/02951] train_loss: 0.003288\n",
      "[002/03001] train_loss: 0.003474\n",
      "[002/03051] train_loss: 0.003316\n",
      "[002/03101] train_loss: 0.003530\n",
      "[002/03151] train_loss: 0.003473\n",
      "[002/03201] train_loss: 0.003279\n",
      "[002/03251] train_loss: 0.003571\n",
      "[002/03301] train_loss: 0.003440\n",
      "[002/03351] train_loss: 0.003483\n",
      "[002/03401] train_loss: 0.003358\n",
      "[002/03401] val_loss: 0.249064 | best_loss_val: 0.112165\n",
      "[002/03451] train_loss: 0.003231\n",
      "[002/03501] train_loss: 0.003502\n",
      "[002/03551] train_loss: 0.003293\n",
      "[002/03601] train_loss: 0.003454\n",
      "[002/03651] train_loss: 0.003386\n",
      "[002/03701] train_loss: 0.003338\n",
      "[002/03751] train_loss: 0.003321\n",
      "[002/03801] train_loss: 0.003377\n",
      "[002/03851] train_loss: 0.003250\n",
      "[002/03901] train_loss: 0.003374\n",
      "[002/03951] train_loss: 0.003147\n",
      "[002/04001] train_loss: 0.003255\n",
      "[002/04051] train_loss: 0.003205\n",
      "[002/04101] train_loss: 0.003135\n",
      "[002/04151] train_loss: 0.003359\n",
      "[002/04201] train_loss: 0.003369\n",
      "[002/04251] train_loss: 0.003440\n",
      "[002/04301] train_loss: 0.003127\n",
      "[002/04351] train_loss: 0.003357\n",
      "[002/04401] train_loss: 0.003387\n",
      "[002/04401] val_loss: 0.107891 | best_loss_val: 0.107891\n",
      "[002/04451] train_loss: 0.003458\n",
      "[002/04501] train_loss: 0.003430\n",
      "[002/04551] train_loss: 0.003252\n",
      "[002/04601] train_loss: 0.003412\n",
      "[002/04651] train_loss: 0.003369\n",
      "[002/04701] train_loss: 0.003416\n",
      "[002/04751] train_loss: 0.003518\n",
      "[003/00002] train_loss: 0.003296\n",
      "[003/00052] train_loss: 0.003239\n",
      "[003/00102] train_loss: 0.003106\n",
      "[003/00152] train_loss: 0.003132\n",
      "[003/00202] train_loss: 0.003177\n",
      "[003/00252] train_loss: 0.003131\n",
      "[003/00302] train_loss: 0.003067\n",
      "[003/00352] train_loss: 0.003209\n",
      "[003/00402] train_loss: 0.003227\n",
      "[003/00452] train_loss: 0.003202\n",
      "[003/00502] train_loss: 0.003160\n",
      "[003/00552] train_loss: 0.003333\n",
      "[003/00602] train_loss: 0.003329\n",
      "[003/00602] val_loss: 0.787819 | best_loss_val: 0.107891\n",
      "[003/00652] train_loss: 0.003016\n",
      "[003/00702] train_loss: 0.003077\n",
      "[003/00752] train_loss: 0.003223\n",
      "[003/00802] train_loss: 0.003129\n",
      "[003/00852] train_loss: 0.003016\n",
      "[003/00902] train_loss: 0.003086\n",
      "[003/00952] train_loss: 0.003120\n",
      "[003/01002] train_loss: 0.003163\n",
      "[003/01052] train_loss: 0.003236\n",
      "[003/01102] train_loss: 0.003121\n",
      "[003/01152] train_loss: 0.003163\n",
      "[003/01202] train_loss: 0.002942\n",
      "[003/01252] train_loss: 0.002977\n",
      "[003/01302] train_loss: 0.003032\n",
      "[003/01352] train_loss: 0.002986\n",
      "[003/01402] train_loss: 0.003220\n",
      "[003/01452] train_loss: 0.003175\n",
      "[003/01502] train_loss: 0.003196\n",
      "[003/01552] train_loss: 0.003032\n",
      "[003/01602] train_loss: 0.003245\n",
      "[003/01602] val_loss: 0.103948 | best_loss_val: 0.103948\n",
      "[003/01652] train_loss: 0.003120\n",
      "[003/01702] train_loss: 0.003001\n",
      "[003/01752] train_loss: 0.003018\n",
      "[003/01802] train_loss: 0.003207\n",
      "[003/01852] train_loss: 0.003223\n",
      "[003/01902] train_loss: 0.003017\n",
      "[003/01952] train_loss: 0.003070\n",
      "[003/02002] train_loss: 0.003111\n",
      "[003/02052] train_loss: 0.002989\n",
      "[003/02102] train_loss: 0.003118\n",
      "[003/02152] train_loss: 0.003032\n",
      "[003/02202] train_loss: 0.003031\n",
      "[003/02252] train_loss: 0.002929\n",
      "[003/02302] train_loss: 0.002904\n",
      "[003/02352] train_loss: 0.002890\n",
      "[003/02402] train_loss: 0.003048\n",
      "[003/02452] train_loss: 0.003093\n",
      "[003/02502] train_loss: 0.003013\n",
      "[003/02552] train_loss: 0.003160\n",
      "[003/02602] train_loss: 0.003048\n",
      "[003/02602] val_loss: 0.128195 | best_loss_val: 0.103948\n",
      "[003/02652] train_loss: 0.003177\n",
      "[003/02702] train_loss: 0.003429\n",
      "[003/02752] train_loss: 0.003145\n",
      "[003/02802] train_loss: 0.002970\n",
      "[003/02852] train_loss: 0.002988\n",
      "[003/02902] train_loss: 0.002961\n",
      "[003/02952] train_loss: 0.003168\n",
      "[003/03002] train_loss: 0.003189\n",
      "[003/03052] train_loss: 0.002983\n",
      "[003/03102] train_loss: 0.003153\n",
      "[003/03152] train_loss: 0.002931\n",
      "[003/03202] train_loss: 0.002973\n",
      "[003/03252] train_loss: 0.002920\n",
      "[003/03302] train_loss: 0.003128\n",
      "[003/03352] train_loss: 0.002989\n",
      "[003/03402] train_loss: 0.003067\n",
      "[003/03452] train_loss: 0.003034\n",
      "[003/03502] train_loss: 0.002929\n",
      "[003/03552] train_loss: 0.003189\n",
      "[003/03602] train_loss: 0.003046\n",
      "[003/03602] val_loss: 0.123101 | best_loss_val: 0.103948\n",
      "[003/03652] train_loss: 0.003266\n",
      "[003/03702] train_loss: 0.003064\n",
      "[003/03752] train_loss: 0.002934\n",
      "[003/03802] train_loss: 0.002957\n",
      "[003/03852] train_loss: 0.003147\n",
      "[003/03902] train_loss: 0.003187\n",
      "[003/03952] train_loss: 0.002853\n",
      "[003/04002] train_loss: 0.002945\n",
      "[003/04052] train_loss: 0.002856\n",
      "[003/04102] train_loss: 0.002979\n",
      "[003/04152] train_loss: 0.002877\n",
      "[003/04202] train_loss: 0.002993\n",
      "[003/04252] train_loss: 0.003011\n",
      "[003/04302] train_loss: 0.002992\n",
      "[003/04352] train_loss: 0.003020\n",
      "[003/04402] train_loss: 0.003093\n",
      "[003/04452] train_loss: 0.002886\n",
      "[003/04502] train_loss: 0.003057\n",
      "[003/04552] train_loss: 0.002905\n",
      "[003/04602] train_loss: 0.002913\n",
      "[003/04602] val_loss: 0.097932 | best_loss_val: 0.097932\n",
      "[003/04652] train_loss: 0.002896\n",
      "[003/04702] train_loss: 0.003121\n",
      "[003/04752] train_loss: 0.003072\n",
      "[004/00003] train_loss: 0.002991\n",
      "[004/00053] train_loss: 0.002771\n",
      "[004/00103] train_loss: 0.002862\n",
      "[004/00153] train_loss: 0.002691\n",
      "[004/00203] train_loss: 0.002620\n",
      "[004/00253] train_loss: 0.002755\n",
      "[004/00303] train_loss: 0.002673\n",
      "[004/00353] train_loss: 0.002789\n",
      "[004/00403] train_loss: 0.002763\n",
      "[004/00453] train_loss: 0.002771\n",
      "[004/00503] train_loss: 0.002760\n",
      "[004/00553] train_loss: 0.002628\n",
      "[004/00603] train_loss: 0.002723\n",
      "[004/00653] train_loss: 0.002786\n",
      "[004/00703] train_loss: 0.002781\n",
      "[004/00753] train_loss: 0.002964\n",
      "[004/00803] train_loss: 0.002855\n",
      "[004/00803] val_loss: 0.197200 | best_loss_val: 0.097932\n",
      "[004/00853] train_loss: 0.002787\n",
      "[004/00903] train_loss: 0.003077\n",
      "[004/00953] train_loss: 0.002839\n",
      "[004/01003] train_loss: 0.002772\n",
      "[004/01053] train_loss: 0.002817\n",
      "[004/01103] train_loss: 0.002755\n",
      "[004/01153] train_loss: 0.002661\n",
      "[004/01203] train_loss: 0.002597\n",
      "[004/01253] train_loss: 0.002674\n",
      "[004/01303] train_loss: 0.002704\n",
      "[004/01353] train_loss: 0.002751\n",
      "[004/01403] train_loss: 0.002755\n",
      "[004/01453] train_loss: 0.002784\n",
      "[004/01503] train_loss: 0.002635\n",
      "[004/01553] train_loss: 0.002797\n",
      "[004/01603] train_loss: 0.002878\n",
      "[004/01653] train_loss: 0.003078\n",
      "[004/01703] train_loss: 0.002770\n",
      "[004/01753] train_loss: 0.002857\n",
      "[004/01803] train_loss: 0.002701\n",
      "[004/01803] val_loss: 0.114974 | best_loss_val: 0.097932\n",
      "[004/01853] train_loss: 0.002841\n",
      "[004/01903] train_loss: 0.002849\n",
      "[004/01953] train_loss: 0.002717\n",
      "[004/02003] train_loss: 0.002697\n",
      "[004/02053] train_loss: 0.002823\n",
      "[004/02103] train_loss: 0.002729\n",
      "[004/02153] train_loss: 0.002639\n",
      "[004/02203] train_loss: 0.002818\n",
      "[004/02253] train_loss: 0.002833\n",
      "[004/02303] train_loss: 0.002596\n",
      "[004/02353] train_loss: 0.002751\n",
      "[004/02403] train_loss: 0.002953\n",
      "[004/02453] train_loss: 0.002709\n",
      "[004/02503] train_loss: 0.002747\n",
      "[004/02553] train_loss: 0.002915\n",
      "[004/02603] train_loss: 0.002893\n",
      "[004/02653] train_loss: 0.002845\n",
      "[004/02703] train_loss: 0.002936\n",
      "[004/02753] train_loss: 0.002750\n",
      "[004/02803] train_loss: 0.002815\n",
      "[004/02803] val_loss: 0.183824 | best_loss_val: 0.097932\n",
      "[004/02853] train_loss: 0.002871\n",
      "[004/02903] train_loss: 0.002691\n",
      "[004/02953] train_loss: 0.002733\n",
      "[004/03003] train_loss: 0.002932\n",
      "[004/03053] train_loss: 0.002741\n",
      "[004/03103] train_loss: 0.002750\n",
      "[004/03153] train_loss: 0.002758\n",
      "[004/03203] train_loss: 0.002912\n",
      "[004/03253] train_loss: 0.002621\n",
      "[004/03303] train_loss: 0.002783\n",
      "[004/03353] train_loss: 0.002914\n",
      "[004/03403] train_loss: 0.002703\n",
      "[004/03453] train_loss: 0.002680\n",
      "[004/03503] train_loss: 0.002849\n",
      "[004/03553] train_loss: 0.002782\n",
      "[004/03603] train_loss: 0.002700\n",
      "[004/03653] train_loss: 0.002865\n",
      "[004/03703] train_loss: 0.002880\n",
      "[004/03753] train_loss: 0.002802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[004/03803] train_loss: 0.002726\n",
      "[004/03803] val_loss: 0.123703 | best_loss_val: 0.097932\n",
      "[004/03853] train_loss: 0.002607\n",
      "[004/03903] train_loss: 0.002880\n",
      "[004/03953] train_loss: 0.002847\n",
      "[004/04003] train_loss: 0.002806\n",
      "[004/04053] train_loss: 0.002759\n",
      "[004/04103] train_loss: 0.002992\n",
      "[004/04153] train_loss: 0.002830\n",
      "[004/04203] train_loss: 0.002726\n",
      "[004/04253] train_loss: 0.002940\n",
      "[004/04303] train_loss: 0.002944\n",
      "[004/04353] train_loss: 0.002801\n",
      "[004/04403] train_loss: 0.002629\n",
      "[004/04453] train_loss: 0.002714\n",
      "[004/04503] train_loss: 0.002674\n",
      "[004/04553] train_loss: 0.002633\n",
      "[004/04603] train_loss: 0.002784\n",
      "[004/04653] train_loss: 0.002696\n",
      "[004/04703] train_loss: 0.002609\n",
      "[004/04753] train_loss: 0.002687\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    'experiment_name': '3_1_3depn_generalization',\n",
    "    'device': 'cuda:0',  # change this to cpu if you do not have a GPU\n",
    "    'is_overfit': False,\n",
    "    'batch_size': 32,\n",
    "    'resume_ckpt': None,\n",
    "    'learning_rate': 0.001,\n",
    "    'max_epochs': 5,\n",
    "    'print_every_n': 50,\n",
    "    'validate_every_n': 1000,\n",
    "}\n",
    "#train_3depn.main(config)  # should be able to get best_loss_val < 0.1 after a few hours and 5 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (f) Inference\n",
    "\n",
    "Implement the missing bits in `exercise_3/inference/infer_3depn.py`. You should then be able to see your reconstructions below.\n",
    "\n",
    "The outputs of our provided visualization functions are, from left to right:\n",
    "- Input, partial shape\n",
    "- Predicted completion\n",
    "- Target shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exercise_3.util.visualization import visualize_meshes\n",
    "from exercise_3.inference.infer_3depn import InferenceHandler3DEPN\n",
    "\n",
    "# create a handler for inference using a trained checkpoint\n",
    "inferer = InferenceHandler3DEPN('exercise_3/runs/3_1_3depn_generalization/model_best.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1385d5ef5e14ea88db31e8ef6131f2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_sdf = ShapeNet.get_shape_sdf('03636649/b286c9c136784db2af1744fdb1fbe7df__0__')\n",
    "target_df = ShapeNet.get_shape_df('03636649/b286c9c136784db2af1744fdb1fbe7df__0__')\n",
    "\n",
    "input_mesh, reconstructed_mesh, target_mesh = inferer.infer_single(input_sdf, target_df)\n",
    "visualize_meshes([input_mesh, reconstructed_mesh, target_mesh], flip_axes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d3125009b5e472a9cb9f1f5ac9f27ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_sdf = ShapeNet.get_shape_sdf('03636649/23eaba9bdd51a5b0dfe9cab879fd37e8__1__')\n",
    "target_df = ShapeNet.get_shape_df('03636649/23eaba9bdd51a5b0dfe9cab879fd37e8__0__')\n",
    "\n",
    "input_mesh, reconstructed_mesh, target_mesh = inferer.infer_single(input_sdf, target_df)\n",
    "visualize_meshes([input_mesh, reconstructed_mesh, target_mesh], flip_axes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c94310a01a054767977ea9d615c33a6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_sdf = ShapeNet.get_shape_sdf('02691156/5de2cc606b65b960e0b6546e08902f28__0__')\n",
    "target_df = ShapeNet.get_shape_df('02691156/5de2cc606b65b960e0b6546e08902f28__0__')\n",
    "\n",
    "input_mesh, reconstructed_mesh, target_mesh = inferer.infer_single(input_sdf, target_df)\n",
    "visualize_meshes([input_mesh, reconstructed_mesh, target_mesh], flip_axes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 DeepSDF\n",
    "\n",
    "\n",
    "Here, we will take a look at 3D-reconstruction using [DeepSDF](https://arxiv.org/abs/1901.05103). We recommend reading the paper before attempting the exercise.\n",
    "\n",
    "DeepSDF is an auto-decoder based approach that learns a continuous SDF representation for a class of shapes. Once trained, it can be used for shape representation, interpolation and shape completion. We'll look at each of these\n",
    "applications.\n",
    "\n",
    "<img src=\"exercise_3/images/deepsdf_teaser.png\" alt=\"deepsdf_teaser\" style=\"width: 800px;\"/>\n",
    "\n",
    "During training, the autodecoder optimizes both the network parameters and the latent codes representing each of the training shapes. Once trained, to reconstruct a shape given its SDF observations, a latent code is\n",
    "optimized keeping the network parameters fixed, such that the optimized latent code gives the lowest error with observed SDF values.\n",
    "\n",
    "An advantage that implicit representations have over voxel/grid based approaches is that they are not tied to a particular grid resolution, and can be evaluated at any resolution once trained.\n",
    "\n",
    "Similar to previous exercise, we'll first download the processed dataset, look at the implementation of the dataset, the model and the trainer, try out overfitting and generalization over the entire dataset, and finally inference on unseen samples.\n",
    "\n",
    "### (a) Downloading the data\n",
    "\n",
    "Whereas volumetric models output entire 3d shape representations, implicit models like DeepSDF work on per point basis. The network takes in a 3D-coordinate (and additionally the latent vector) and outputs the SDF value at the queried point. To train such a model,\n",
    "we therefore need, for each of the training shapes, a bunch of points with their corresponding SDF values for supervision. Points are sampled more aggressively near the surface of the object as we want to capture a more detailed SDF near the surface. For those curious,\n",
    "data preparation is decribed in more detail in section 5 of the paper.\n",
    "\n",
    "We'll be using the ShapeNet Sofa class for the experiments in this exercise. We've already prepared this data, so that you don't need to deal with the preprocessing. For each shape, the following files are provided:\n",
    "- `mesh.obj` representing the mesh representation of the shape\n",
    "- `sdf.npz` file containing large number of points sampled on and around the mesh and their sdf values; contains numpy arrays under keys \"pos\" and \"neg\", containing points with positive and negative sdf values respectively\n",
    "\n",
    "```\n",
    "# contents of exercise_3/data/sdf_sofas\n",
    "1faa4c299b93a3e5593ebeeedbff73b/                    # shape 0\n",
    "    ├── mesh.obj                                    # shape 0 mesh\n",
    "    ├── sdf.npz                                     # shape 0 sdf\n",
    "    ├── surface.obj                                 # shape 0 surface\n",
    "1fde48d83065ef5877a929f61fea4d0/                    # shape 1\n",
    "1fe1411b6c8097acf008d8a3590fb522/                   # shape 2\n",
    ":\n",
    "```\n",
    "Download and extract the data with the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ...\n",
      "Extracting ...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "print('Downloading ...')\n",
    "# File sizes: ~10GB\n",
    "!wget https://www.dropbox.com/s/4k5pw126nzus8ef/sdf_sofas.zip\\?dl\\=0 -O exercise_3/data/sdf_sofas.zip -P exercise_3/data\n",
    "\n",
    "print('Extracting ...')\n",
    "!unzip -q /usr/home/sut/datasets/e3/sdf_sofas.zip -d /usr/home/sut/datasets/e3\n",
    "!rm /usr/home/sut/datasets/e3/sdf_sofas.zip\n",
    "\n",
    "print('Done.')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Dataset\n",
    "\n",
    "We provide a partial implementation of the dataset in `exercise_3/data/shape_implicit.py`.\n",
    "Your task is to complete the `#TODOs` so that the dataset works as specified by the docstrings.\n",
    "\n",
    "Once done, you can try running the following code blocks as sanity checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train set: 1226\n",
      "Length of val set: 137\n",
      "Length of overfit set: 1\n"
     ]
    }
   ],
   "source": [
    "from exercise_3.data.shape_implicit import ShapeImplicit\n",
    "\n",
    "num_points_to_samples = 40000\n",
    "train_dataset = ShapeImplicit(num_points_to_samples, \"train\")\n",
    "val_dataset = ShapeImplicit(num_points_to_samples, \"val\")\n",
    "overfit_dataset = ShapeImplicit(num_points_to_samples, \"overfit\")\n",
    "\n",
    "# Get length, which is a call to __len__ function\n",
    "print(f'Length of train set: {len(train_dataset)}')  # expected output: 1226\n",
    "# Get length, which is a call to __len__ function\n",
    "print(f'Length of val set: {len(val_dataset)}')  # expected output: 137\n",
    "# Get length, which is a call to __len__ function\n",
    "print(f'Length of overfit set: {len(overfit_dataset)}')  # expected output: 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's take a look at the points sampled for a particular shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from exercise_3.util.visualization import visualize_mesh, visualize_pointcloud\n",
    "\n",
    "shape_id = train_dataset[0]['name']\n",
    "points = train_dataset[0]['points']\n",
    "sdf = train_dataset[0]['sdf']\n",
    "\n",
    "# sampled points inside the shape\n",
    "inside_points = points[sdf[:, 0] < 0, :].numpy()\n",
    "\n",
    "# sampled points outside the shape\n",
    "outside_points = points[sdf[:, 0] > 0, :].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mesh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/home/sut/.conda/envs/idp/lib/python3.7/site-packages/traittypes/traittypes.py:101: UserWarning: Given trait value dtype \"uint32\" does not match required type \"uint32\". A coerced copy has been created.\n",
      "  np.dtype(self.dtype).name))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0d43266b5074e718cfb36d4625c87ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mesh = ShapeImplicit.get_mesh(shape_id)\n",
    "print('Mesh')\n",
    "visualize_mesh(mesh.vertices, mesh.faces, flip_axes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled points with negative SDF (inside)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "733a8b6773e64a6d850a7d3d3873fcb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Sampled points with negative SDF (inside)')\n",
    "visualize_pointcloud(inside_points, 0.025, flip_axes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled points with positive SDF (outside)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12c6f69080de4745b6850eac68e00192",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Sampled points with positive SDF (outside)')\n",
    "visualize_pointcloud(outside_points, 0.025, flip_axes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice that more points are sampled close to the surface rather than away from the surface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### (c) Model\n",
    "\n",
    "The DeepSDF auto-decoder architecture is visualized below:\n",
    "\n",
    "<img src=\"exercise_3/images/deepsdf_architecture.png\" alt=\"deepsdf_arch\" style=\"width: 640px;\"/>\n",
    "\n",
    "Things to note:\n",
    "\n",
    "- The network takes in the latent code for a shape concatenated with the query 3d coordinate, making up a 259 length vector (assuming latent code length is 256).\n",
    "- The network consist of a sequence of weight-normed linear layers, each followed by a ReLU and a dropout. For weight norming a layer, check out `torch.nn.utils.weight_norm`. Each of these linear layers outputs a 512 dimensional vector, except the 4th layer which outputs a 253 dimensional vector.\n",
    "- The output of the 4th layer is concatenated with the input, making the input to the 5th layer a 512 dimensional vector.\n",
    "- The final layer is a simple linear layer without any norm, dropout or non-linearity, with a single dimensional output representing the SDF value.\n",
    "\n",
    "Implement this architecture in file `exercise_3/model/deepsdf.py`.\n",
    "\n",
    "Here are some basic sanity tests once you're done with your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   | Name    | Type           | Params \n",
      "---------------------------------------------\n",
      "0  | wn1     | Linear         | 133632 \n",
      "1  | wn2     | Linear         | 263168 \n",
      "2  | wn3     | Linear         | 263168 \n",
      "3  | wn4     | Linear         | 130042 \n",
      "4  | wn5     | Linear         | 263168 \n",
      "5  | wn6     | Linear         | 263168 \n",
      "6  | wn7     | Linear         | 263168 \n",
      "7  | wn8     | Linear         | 263168 \n",
      "8  | fc      | Linear         | 513    \n",
      "9  | relu    | ReLU           | 0      \n",
      "10 | dropout | Dropout        | 0      \n",
      "11 | TOTAL   | DeepSDFDecoder | 1843195\n",
      "\n",
      "Output tensor shape:  torch.Size([4096, 1])\n",
      "\n",
      "Number of traininable params: 1.84M\n"
     ]
    }
   ],
   "source": [
    "from exercise_3.model.deepsdf import DeepSDFDecoder\n",
    "from exercise_3.util.model import summarize_model\n",
    "\n",
    "deepsdf = DeepSDFDecoder(latent_size=256)\n",
    "print(summarize_model(deepsdf))\n",
    "\n",
    "# input to the network is a concatenation of point coordinates (3) and the latent code (256 in this example);\n",
    "# here we use a batch of 4096 points\n",
    "input_tensor = torch.randn(4096, 3 + 256)\n",
    "predictions = deepsdf(input_tensor)\n",
    "\n",
    "print('\\nOutput tensor shape: ', predictions.shape)  # expected output: 4096, 1\n",
    "\n",
    "num_trainable_params = sum(p.numel() for p in deepsdf.parameters() if p.requires_grad) / 1e6\n",
    "print(f'\\nNumber of traininable params: {num_trainable_params:.2f}M')  # expected output: ~1.8M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) Training script and overfitting to a single shape\n",
    "\n",
    "Fill in the train script in `exercise_3/training/train_deepsdf.py`, and verify that your training work by overfitting to a few samples below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "[049/00000] train_loss: 0.036574\n",
      "[099/00000] train_loss: 0.024908\n",
      "[149/00000] train_loss: 0.018325\n",
      "[199/00000] train_loss: 0.014472\n",
      "[249/00000] train_loss: 0.012499\n",
      "[299/00000] train_loss: 0.011719\n",
      "[349/00000] train_loss: 0.010442\n",
      "[399/00000] train_loss: 0.010061\n",
      "[449/00000] train_loss: 0.009350\n",
      "[499/00000] train_loss: 0.009038\n",
      "[549/00000] train_loss: 0.008423\n",
      "[599/00000] train_loss: 0.008276\n",
      "[649/00000] train_loss: 0.008126\n",
      "[699/00000] train_loss: 0.007952\n",
      "[749/00000] train_loss: 0.007851\n",
      "[799/00000] train_loss: 0.007745\n",
      "[849/00000] train_loss: 0.007636\n",
      "[899/00000] train_loss: 0.007472\n",
      "[949/00000] train_loss: 0.007446\n",
      "[999/00000] train_loss: 0.007315\n",
      "[1049/00000] train_loss: 0.007084\n",
      "[1099/00000] train_loss: 0.007070\n",
      "[1149/00000] train_loss: 0.006972\n",
      "[1199/00000] train_loss: 0.006926\n",
      "[1249/00000] train_loss: 0.006890\n",
      "[1299/00000] train_loss: 0.006856\n",
      "[1349/00000] train_loss: 0.006777\n",
      "[1399/00000] train_loss: 0.006754\n",
      "[1449/00000] train_loss: 0.006792\n",
      "[1499/00000] train_loss: 0.006678\n",
      "[1549/00000] train_loss: 0.006583\n",
      "[1599/00000] train_loss: 0.006568\n",
      "[1649/00000] train_loss: 0.006554\n",
      "[1699/00000] train_loss: 0.006499\n",
      "[1749/00000] train_loss: 0.006517\n",
      "[1799/00000] train_loss: 0.006448\n",
      "[1849/00000] train_loss: 0.006440\n",
      "[1899/00000] train_loss: 0.006464\n",
      "[1949/00000] train_loss: 0.006396\n",
      "[1999/00000] train_loss: 0.006387\n"
     ]
    }
   ],
   "source": [
    "from exercise_3.training import train_deepsdf\n",
    "\n",
    "overfit_config = {\n",
    "    'experiment_name': '3_2_deepsdf_overfit',\n",
    "    'device': 'cuda:0',  # change this to cpu if you do not have a GPU\n",
    "    'is_overfit': True,\n",
    "    'num_sample_points': 4096,\n",
    "    'latent_code_length': 256,\n",
    "    'batch_size': 1,\n",
    "    'resume_ckpt': None,\n",
    "    'learning_rate_model': 0.0005,\n",
    "    'learning_rate_code': 0.001,\n",
    "    'lambda_code_regularization': 0.0001,\n",
    "    'max_epochs': 2000,\n",
    "    'print_every_n': 50,\n",
    "    'visualize_every_n': 250,\n",
    "}\n",
    "\n",
    "train_deepsdf.main(overfit_config)  # expected loss around 0.0062"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the overfitted shape reconstruction to check if it looks reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "345dc9e9f94a45b6a3a099fb42e0be72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT\n",
      "Overfit\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55e308fee23445caad13d16d4222a444",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load and visualize GT mesh of the overfit sample\n",
    "gt_mesh = ShapeImplicit.get_mesh('7e728818848f191bee7d178666aae23d')\n",
    "print('GT')\n",
    "visualize_mesh(gt_mesh.vertices, gt_mesh.faces, flip_axes=True)\n",
    "\n",
    "# Load and visualize reconstructed overfit sample; it's okay if they don't look visually exact, since we don't run \n",
    "# the training too long and have a learning rate decay while training \n",
    "mesh_path = \"exercise_3/runs/3_2_deepsdf_overfit/meshes/01999_000.obj\"\n",
    "overfit_output = trimesh.load(mesh_path)\n",
    "print('Overfit')\n",
    "visualize_mesh(overfit_output.vertices, overfit_output.faces, flip_axes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (e) Training over entire train set\n",
    "\n",
    "Once overfitting works, we can train on the entire train set.\n",
    "\n",
    "Note: This training will take a few hours on a GPU (took ~3 hrs for 500 epochs on our 2080Ti, which already gave decent results). Please make sure to start training early enough before the submission deadline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "[000/00049] train_loss: 0.036851\n",
      "[000/00099] train_loss: 0.035113\n",
      "[000/00149] train_loss: 0.035015\n",
      "[000/00199] train_loss: 0.032840\n",
      "[000/00249] train_loss: 0.033793\n",
      "[000/00299] train_loss: 0.033049\n",
      "[000/00349] train_loss: 0.032726\n",
      "[000/00399] train_loss: 0.031962\n",
      "[000/00449] train_loss: 0.031669\n",
      "[000/00499] train_loss: 0.033765\n",
      "[000/00549] train_loss: 0.033609\n",
      "[000/00599] train_loss: 0.031352\n",
      "[000/00649] train_loss: 0.032456\n",
      "[000/00699] train_loss: 0.031511\n",
      "[000/00749] train_loss: 0.031687\n",
      "[000/00799] train_loss: 0.032332\n",
      "[000/00849] train_loss: 0.032986\n",
      "[000/00899] train_loss: 0.031316\n",
      "[000/00949] train_loss: 0.030946\n",
      "[000/00999] train_loss: 0.032103\n",
      "[000/01049] train_loss: 0.031212\n",
      "[000/01099] train_loss: 0.031363\n",
      "[000/01149] train_loss: 0.030994\n",
      "[000/01199] train_loss: 0.032314\n",
      "[001/00023] train_loss: 0.031954\n",
      "[001/00073] train_loss: 0.030850\n",
      "[001/00123] train_loss: 0.032167\n",
      "[001/00173] train_loss: 0.030934\n",
      "[001/00223] train_loss: 0.030180\n",
      "[001/00273] train_loss: 0.030689\n",
      "[001/00323] train_loss: 0.031285\n",
      "[001/00373] train_loss: 0.030703\n",
      "[001/00423] train_loss: 0.030926\n",
      "[001/00473] train_loss: 0.030811\n",
      "[001/00523] train_loss: 0.030000\n",
      "[001/00573] train_loss: 0.031184\n",
      "[001/00623] train_loss: 0.030299\n",
      "[001/00673] train_loss: 0.029821\n",
      "[001/00723] train_loss: 0.031565\n",
      "[001/00773] train_loss: 0.031921\n",
      "[001/00823] train_loss: 0.029549\n",
      "[001/00873] train_loss: 0.030931\n",
      "[001/00923] train_loss: 0.030365\n",
      "[001/00973] train_loss: 0.031280\n",
      "[001/01023] train_loss: 0.030620\n",
      "[001/01073] train_loss: 0.029638\n",
      "[001/01123] train_loss: 0.029887\n",
      "[001/01173] train_loss: 0.030706\n",
      "[001/01223] train_loss: 0.028951\n",
      "[002/00047] train_loss: 0.030211\n",
      "[002/00097] train_loss: 0.029512\n",
      "[002/00147] train_loss: 0.030216\n",
      "[002/00197] train_loss: 0.030246\n",
      "[002/00247] train_loss: 0.029590\n",
      "[002/00297] train_loss: 0.029481\n",
      "[002/00347] train_loss: 0.029069\n",
      "[002/00397] train_loss: 0.029422\n",
      "[002/00447] train_loss: 0.029331\n",
      "[002/00497] train_loss: 0.029647\n",
      "[002/00547] train_loss: 0.030598\n",
      "[002/00597] train_loss: 0.029417\n",
      "[002/00647] train_loss: 0.028605\n",
      "[002/00697] train_loss: 0.029912\n",
      "[002/00747] train_loss: 0.029369\n",
      "[002/00797] train_loss: 0.029333\n",
      "[002/00847] train_loss: 0.028604\n",
      "[002/00897] train_loss: 0.028762\n",
      "[002/00947] train_loss: 0.028511\n",
      "[002/00997] train_loss: 0.028706\n",
      "[002/01047] train_loss: 0.029363\n",
      "[002/01097] train_loss: 0.029474\n",
      "[002/01147] train_loss: 0.028954\n",
      "[002/01197] train_loss: 0.029435\n",
      "[003/00021] train_loss: 0.030083\n",
      "[003/00071] train_loss: 0.028709\n",
      "[003/00121] train_loss: 0.027990\n",
      "[003/00171] train_loss: 0.027921\n",
      "[003/00221] train_loss: 0.027621\n",
      "[003/00271] train_loss: 0.028323\n",
      "[003/00321] train_loss: 0.027670\n",
      "[003/00371] train_loss: 0.027696\n",
      "[003/00421] train_loss: 0.028168\n",
      "[003/00471] train_loss: 0.026820\n",
      "[003/00521] train_loss: 0.027274\n",
      "[003/00571] train_loss: 0.027410\n",
      "[003/00621] train_loss: 0.027926\n",
      "[003/00671] train_loss: 0.028241\n",
      "[003/00721] train_loss: 0.027472\n",
      "[003/00771] train_loss: 0.029611\n",
      "[003/00821] train_loss: 0.028252\n",
      "[003/00871] train_loss: 0.026941\n",
      "[003/00921] train_loss: 0.027808\n",
      "[003/00971] train_loss: 0.027404\n",
      "[003/01021] train_loss: 0.027256\n",
      "[003/01071] train_loss: 0.027561\n",
      "[003/01121] train_loss: 0.026842\n",
      "[003/01171] train_loss: 0.027050\n",
      "[003/01221] train_loss: 0.026410\n",
      "[004/00045] train_loss: 0.027463\n",
      "[004/00095] train_loss: 0.027140\n",
      "[004/00145] train_loss: 0.027392\n",
      "[004/00195] train_loss: 0.027120\n",
      "[004/00245] train_loss: 0.025772\n",
      "[004/00295] train_loss: 0.026699\n",
      "[004/00345] train_loss: 0.025854\n",
      "[004/00395] train_loss: 0.026442\n",
      "[004/00445] train_loss: 0.026267\n",
      "[004/00495] train_loss: 0.026461\n",
      "[004/00545] train_loss: 0.025208\n",
      "[004/00595] train_loss: 0.025724\n",
      "[004/00645] train_loss: 0.025591\n",
      "[004/00695] train_loss: 0.027562\n",
      "[004/00745] train_loss: 0.025638\n",
      "[004/00795] train_loss: 0.025477\n",
      "[004/00845] train_loss: 0.025850\n",
      "[004/00895] train_loss: 0.025983\n",
      "[004/00945] train_loss: 0.025002\n",
      "[004/00995] train_loss: 0.025823\n",
      "[004/01045] train_loss: 0.025444\n",
      "[004/01095] train_loss: 0.026403\n",
      "[004/01145] train_loss: 0.025792\n",
      "[004/01195] train_loss: 0.025436\n",
      "[005/00019] train_loss: 0.026500\n",
      "[005/00069] train_loss: 0.027140\n",
      "[005/00119] train_loss: 0.027581\n",
      "[005/00169] train_loss: 0.026564\n",
      "[005/00219] train_loss: 0.025159\n",
      "[005/00269] train_loss: 0.026245\n",
      "[005/00319] train_loss: 0.024618\n",
      "[005/00369] train_loss: 0.025193\n",
      "[005/00419] train_loss: 0.024478\n",
      "[005/00469] train_loss: 0.024516\n",
      "[005/00519] train_loss: 0.025383\n",
      "[005/00569] train_loss: 0.024765\n",
      "[005/00619] train_loss: 0.025034\n",
      "[005/00669] train_loss: 0.025175\n",
      "[005/00719] train_loss: 0.024848\n",
      "[005/00769] train_loss: 0.024092\n",
      "[005/00819] train_loss: 0.024487\n",
      "[005/00869] train_loss: 0.024051\n",
      "[005/00919] train_loss: 0.024263\n",
      "[005/00969] train_loss: 0.025265\n",
      "[005/01019] train_loss: 0.024709\n",
      "[005/01069] train_loss: 0.023990\n",
      "[005/01119] train_loss: 0.025184\n",
      "[005/01169] train_loss: 0.024251\n",
      "[005/01219] train_loss: 0.024570\n",
      "[006/00043] train_loss: 0.025887\n",
      "[006/00093] train_loss: 0.025806\n",
      "[006/00143] train_loss: 0.025410\n",
      "[006/00193] train_loss: 0.024921\n",
      "[006/00243] train_loss: 0.024101\n",
      "[006/00293] train_loss: 0.024162\n",
      "[006/00343] train_loss: 0.024466\n",
      "[006/00393] train_loss: 0.024430\n",
      "[006/00443] train_loss: 0.023885\n",
      "[006/00493] train_loss: 0.023745\n",
      "[006/00543] train_loss: 0.024200\n",
      "[006/00593] train_loss: 0.023711\n",
      "[006/00643] train_loss: 0.023683\n",
      "[006/00693] train_loss: 0.024241\n",
      "[006/00743] train_loss: 0.024450\n",
      "[006/00793] train_loss: 0.023330\n",
      "[006/00843] train_loss: 0.023176\n",
      "[006/00893] train_loss: 0.023762\n",
      "[006/00943] train_loss: 0.023667\n",
      "[006/00993] train_loss: 0.023712\n",
      "[006/01043] train_loss: 0.024383\n",
      "[006/01093] train_loss: 0.024297\n",
      "[006/01143] train_loss: 0.024325\n",
      "[006/01193] train_loss: 0.023690\n",
      "[007/00017] train_loss: 0.025342\n",
      "[007/00067] train_loss: 0.025512\n",
      "[007/00117] train_loss: 0.024382\n",
      "[007/00167] train_loss: 0.024252\n",
      "[007/00217] train_loss: 0.024207\n",
      "[007/00267] train_loss: 0.023524\n",
      "[007/00317] train_loss: 0.024149\n",
      "[007/00367] train_loss: 0.023312\n",
      "[007/00417] train_loss: 0.022797\n",
      "[007/00467] train_loss: 0.023217\n",
      "[007/00517] train_loss: 0.022782\n",
      "[007/00567] train_loss: 0.023753\n",
      "[007/00617] train_loss: 0.023837\n",
      "[007/00667] train_loss: 0.022091\n",
      "[007/00717] train_loss: 0.023269\n",
      "[007/00767] train_loss: 0.022351\n",
      "[007/00817] train_loss: 0.023458\n",
      "[007/00867] train_loss: 0.024154\n",
      "[007/00917] train_loss: 0.022269\n",
      "[007/00967] train_loss: 0.023416\n",
      "[007/01017] train_loss: 0.022368\n",
      "[007/01067] train_loss: 0.023055\n",
      "[007/01117] train_loss: 0.023281\n",
      "[007/01167] train_loss: 0.024150\n",
      "[007/01217] train_loss: 0.023460\n",
      "[008/00041] train_loss: 0.025488\n",
      "[008/00091] train_loss: 0.024151\n",
      "[008/00141] train_loss: 0.023246\n",
      "[008/00191] train_loss: 0.024328\n",
      "[008/00241] train_loss: 0.023123\n",
      "[008/00291] train_loss: 0.023654\n",
      "[008/00341] train_loss: 0.023574\n",
      "[008/00391] train_loss: 0.023049\n",
      "[008/00441] train_loss: 0.023036\n",
      "[008/00491] train_loss: 0.022168\n",
      "[008/00541] train_loss: 0.022408\n",
      "[008/00591] train_loss: 0.022207\n",
      "[008/00641] train_loss: 0.023585\n",
      "[008/00691] train_loss: 0.023082\n",
      "[008/00741] train_loss: 0.021547\n",
      "[008/00791] train_loss: 0.022539\n",
      "[008/00841] train_loss: 0.022823\n",
      "[008/00891] train_loss: 0.023109\n",
      "[008/00941] train_loss: 0.022197\n",
      "[008/00991] train_loss: 0.022531\n",
      "[008/01041] train_loss: 0.021878\n",
      "[008/01091] train_loss: 0.022761\n",
      "[008/01141] train_loss: 0.022444\n",
      "[008/01191] train_loss: 0.022452\n",
      "[009/00015] train_loss: 0.022808\n",
      "[009/00065] train_loss: 0.023261\n",
      "[009/00115] train_loss: 0.024004\n",
      "[009/00165] train_loss: 0.022758\n",
      "[009/00215] train_loss: 0.022280\n",
      "[009/00265] train_loss: 0.022998\n",
      "[009/00315] train_loss: 0.022552\n",
      "[009/00365] train_loss: 0.022350\n",
      "[009/00415] train_loss: 0.021521\n",
      "[009/00465] train_loss: 0.021616\n",
      "[009/00515] train_loss: 0.021917\n",
      "[009/00565] train_loss: 0.022009\n",
      "[009/00615] train_loss: 0.022074\n",
      "[009/00665] train_loss: 0.021946\n",
      "[009/00715] train_loss: 0.022335\n",
      "[009/00765] train_loss: 0.021496\n",
      "[009/00815] train_loss: 0.022082\n",
      "[009/00865] train_loss: 0.021819\n",
      "[009/00915] train_loss: 0.021722\n",
      "[009/00965] train_loss: 0.022206\n",
      "[009/01015] train_loss: 0.021369\n",
      "[009/01065] train_loss: 0.022436\n",
      "[009/01115] train_loss: 0.022929\n",
      "[009/01165] train_loss: 0.022368\n",
      "[009/01215] train_loss: 0.020933\n",
      "[010/00039] train_loss: 0.023615\n",
      "[010/00089] train_loss: 0.024146\n",
      "[010/00139] train_loss: 0.023380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[010/00189] train_loss: 0.022812\n",
      "[010/00239] train_loss: 0.021524\n",
      "[010/00289] train_loss: 0.021697\n",
      "[010/00339] train_loss: 0.022148\n",
      "[010/00389] train_loss: 0.021753\n",
      "[010/00439] train_loss: 0.021383\n",
      "[010/00489] train_loss: 0.020876\n",
      "[010/00539] train_loss: 0.021279\n",
      "[010/00589] train_loss: 0.021763\n",
      "[010/00639] train_loss: 0.022156\n",
      "[010/00689] train_loss: 0.022065\n",
      "[010/00739] train_loss: 0.021402\n",
      "[010/00789] train_loss: 0.021733\n",
      "[010/00839] train_loss: 0.020511\n",
      "[010/00889] train_loss: 0.021120\n",
      "[010/00939] train_loss: 0.020994\n",
      "[010/00989] train_loss: 0.022260\n",
      "[010/01039] train_loss: 0.021153\n",
      "[010/01089] train_loss: 0.021970\n",
      "[010/01139] train_loss: 0.021376\n",
      "[010/01189] train_loss: 0.021319\n",
      "[011/00013] train_loss: 0.022439\n",
      "[011/00063] train_loss: 0.023922\n",
      "[011/00113] train_loss: 0.022925\n",
      "[011/00163] train_loss: 0.020781\n",
      "[011/00213] train_loss: 0.022753\n",
      "[011/00263] train_loss: 0.021750\n",
      "[011/00313] train_loss: 0.022196\n",
      "[011/00363] train_loss: 0.021182\n",
      "[011/00413] train_loss: 0.021775\n",
      "[011/00463] train_loss: 0.020905\n",
      "[011/00513] train_loss: 0.021526\n",
      "[011/00563] train_loss: 0.020868\n",
      "[011/00613] train_loss: 0.021091\n",
      "[011/00663] train_loss: 0.022101\n",
      "[011/00713] train_loss: 0.020445\n",
      "[011/00763] train_loss: 0.021371\n",
      "[011/00813] train_loss: 0.021277\n",
      "[011/00863] train_loss: 0.021064\n",
      "[011/00913] train_loss: 0.021127\n",
      "[011/00963] train_loss: 0.020160\n",
      "[011/01013] train_loss: 0.020977\n",
      "[011/01063] train_loss: 0.021595\n",
      "[011/01113] train_loss: 0.020902\n",
      "[011/01163] train_loss: 0.019912\n",
      "[011/01213] train_loss: 0.019934\n",
      "[012/00037] train_loss: 0.023644\n",
      "[012/00087] train_loss: 0.024016\n",
      "[012/00137] train_loss: 0.023411\n",
      "[012/00187] train_loss: 0.021532\n",
      "[012/00237] train_loss: 0.021281\n",
      "[012/00287] train_loss: 0.020830\n",
      "[012/00337] train_loss: 0.022543\n",
      "[012/00387] train_loss: 0.020812\n",
      "[012/00437] train_loss: 0.020677\n",
      "[012/00487] train_loss: 0.020989\n",
      "[012/00537] train_loss: 0.021578\n",
      "[012/00587] train_loss: 0.020669\n",
      "[012/00637] train_loss: 0.020311\n",
      "[012/00687] train_loss: 0.020811\n",
      "[012/00737] train_loss: 0.020379\n",
      "[012/00787] train_loss: 0.020972\n",
      "[012/00837] train_loss: 0.020815\n",
      "[012/00887] train_loss: 0.020672\n",
      "[012/00937] train_loss: 0.020048\n",
      "[012/00987] train_loss: 0.021199\n",
      "[012/01037] train_loss: 0.019305\n",
      "[012/01087] train_loss: 0.020680\n",
      "[012/01137] train_loss: 0.020536\n",
      "[012/01187] train_loss: 0.020346\n",
      "[013/00011] train_loss: 0.022214\n",
      "[013/00061] train_loss: 0.024514\n",
      "[013/00111] train_loss: 0.022312\n",
      "[013/00161] train_loss: 0.022694\n",
      "[013/00211] train_loss: 0.021799\n",
      "[013/00261] train_loss: 0.020679\n",
      "[013/00311] train_loss: 0.020909\n",
      "[013/00361] train_loss: 0.020972\n",
      "[013/00411] train_loss: 0.020478\n",
      "[013/00461] train_loss: 0.020156\n",
      "[013/00511] train_loss: 0.020046\n",
      "[013/00561] train_loss: 0.020740\n",
      "[013/00611] train_loss: 0.020126\n",
      "[013/00661] train_loss: 0.020012\n",
      "[013/00711] train_loss: 0.020580\n",
      "[013/00761] train_loss: 0.021073\n",
      "[013/00811] train_loss: 0.019797\n",
      "[013/00861] train_loss: 0.020431\n",
      "[013/00911] train_loss: 0.019782\n",
      "[013/00961] train_loss: 0.020705\n",
      "[013/01011] train_loss: 0.020608\n",
      "[013/01061] train_loss: 0.020060\n",
      "[013/01111] train_loss: 0.020581\n",
      "[013/01161] train_loss: 0.019541\n",
      "[013/01211] train_loss: 0.020864\n",
      "[014/00035] train_loss: 0.023122\n",
      "[014/00085] train_loss: 0.022497\n",
      "[014/00135] train_loss: 0.021707\n",
      "[014/00185] train_loss: 0.021298\n",
      "[014/00235] train_loss: 0.020907\n",
      "[014/00285] train_loss: 0.022132\n",
      "[014/00335] train_loss: 0.021182\n",
      "[014/00385] train_loss: 0.020642\n",
      "[014/00435] train_loss: 0.020546\n",
      "[014/00485] train_loss: 0.020847\n",
      "[014/00535] train_loss: 0.019951\n",
      "[014/00585] train_loss: 0.019704\n",
      "[014/00635] train_loss: 0.020342\n",
      "[014/00685] train_loss: 0.019783\n",
      "[014/00735] train_loss: 0.020040\n",
      "[014/00785] train_loss: 0.020459\n",
      "[014/00835] train_loss: 0.020589\n",
      "[014/00885] train_loss: 0.019165\n",
      "[014/00935] train_loss: 0.019921\n",
      "[014/00985] train_loss: 0.020211\n",
      "[014/01035] train_loss: 0.020214\n",
      "[014/01085] train_loss: 0.019908\n",
      "[014/01135] train_loss: 0.020108\n",
      "[014/01185] train_loss: 0.020488\n",
      "[015/00009] train_loss: 0.020808\n",
      "[015/00059] train_loss: 0.022234\n",
      "[015/00109] train_loss: 0.022868\n",
      "[015/00159] train_loss: 0.022077\n",
      "[015/00209] train_loss: 0.020895\n",
      "[015/00259] train_loss: 0.020928\n",
      "[015/00309] train_loss: 0.021000\n",
      "[015/00359] train_loss: 0.019879\n",
      "[015/00409] train_loss: 0.019677\n",
      "[015/00459] train_loss: 0.019634\n",
      "[015/00509] train_loss: 0.019743\n",
      "[015/00559] train_loss: 0.019692\n",
      "[015/00609] train_loss: 0.019397\n",
      "[015/00659] train_loss: 0.020801\n",
      "[015/00709] train_loss: 0.019613\n",
      "[015/00759] train_loss: 0.019576\n",
      "[015/00809] train_loss: 0.020122\n",
      "[015/00859] train_loss: 0.019481\n",
      "[015/00909] train_loss: 0.019615\n",
      "[015/00959] train_loss: 0.020258\n",
      "[015/01009] train_loss: 0.020192\n",
      "[015/01059] train_loss: 0.019553\n",
      "[015/01109] train_loss: 0.019979\n",
      "[015/01159] train_loss: 0.020546\n",
      "[015/01209] train_loss: 0.019389\n",
      "[016/00033] train_loss: 0.021395\n",
      "[016/00083] train_loss: 0.022994\n",
      "[016/00133] train_loss: 0.021678\n",
      "[016/00183] train_loss: 0.020867\n",
      "[016/00233] train_loss: 0.020079\n",
      "[016/00283] train_loss: 0.020152\n",
      "[016/00333] train_loss: 0.020025\n",
      "[016/00383] train_loss: 0.021164\n",
      "[016/00433] train_loss: 0.020132\n",
      "[016/00483] train_loss: 0.019421\n",
      "[016/00533] train_loss: 0.020134\n",
      "[016/00583] train_loss: 0.020035\n",
      "[016/00633] train_loss: 0.019760\n",
      "[016/00683] train_loss: 0.018831\n",
      "[016/00733] train_loss: 0.019178\n",
      "[016/00783] train_loss: 0.020072\n",
      "[016/00833] train_loss: 0.019184\n",
      "[016/00883] train_loss: 0.019283\n",
      "[016/00933] train_loss: 0.018898\n",
      "[016/00983] train_loss: 0.019232\n",
      "[016/01033] train_loss: 0.019570\n",
      "[016/01083] train_loss: 0.019369\n",
      "[016/01133] train_loss: 0.018948\n",
      "[016/01183] train_loss: 0.018746\n",
      "[017/00007] train_loss: 0.020775\n",
      "[017/00057] train_loss: 0.023310\n",
      "[017/00107] train_loss: 0.021400\n",
      "[017/00157] train_loss: 0.021807\n",
      "[017/00207] train_loss: 0.021038\n",
      "[017/00257] train_loss: 0.020649\n",
      "[017/00307] train_loss: 0.021074\n",
      "[017/00357] train_loss: 0.019796\n",
      "[017/00407] train_loss: 0.020049\n",
      "[017/00457] train_loss: 0.019437\n",
      "[017/00507] train_loss: 0.020242\n",
      "[017/00557] train_loss: 0.020384\n",
      "[017/00607] train_loss: 0.019623\n",
      "[017/00657] train_loss: 0.020170\n",
      "[017/00707] train_loss: 0.019208\n",
      "[017/00757] train_loss: 0.019852\n",
      "[017/00807] train_loss: 0.019542\n",
      "[017/00857] train_loss: 0.019876\n",
      "[017/00907] train_loss: 0.019705\n",
      "[017/00957] train_loss: 0.020041\n",
      "[017/01007] train_loss: 0.019271\n",
      "[017/01057] train_loss: 0.019487\n",
      "[017/01107] train_loss: 0.018411\n",
      "[017/01157] train_loss: 0.019693\n",
      "[017/01207] train_loss: 0.019499\n",
      "[018/00031] train_loss: 0.021697\n",
      "[018/00081] train_loss: 0.022136\n",
      "[018/00131] train_loss: 0.020757\n",
      "[018/00181] train_loss: 0.021015\n",
      "[018/00231] train_loss: 0.020881\n",
      "[018/00281] train_loss: 0.019863\n",
      "[018/00331] train_loss: 0.020045\n",
      "[018/00381] train_loss: 0.020386\n",
      "[018/00431] train_loss: 0.019826\n",
      "[018/00481] train_loss: 0.019655\n",
      "[018/00531] train_loss: 0.018201\n",
      "[018/00581] train_loss: 0.019443\n",
      "[018/00631] train_loss: 0.019507\n",
      "[018/00681] train_loss: 0.019136\n",
      "[018/00731] train_loss: 0.019073\n",
      "[018/00781] train_loss: 0.019482\n",
      "[018/00831] train_loss: 0.018705\n",
      "[018/00881] train_loss: 0.019114\n",
      "[018/00931] train_loss: 0.018869\n",
      "[018/00981] train_loss: 0.020290\n",
      "[018/01031] train_loss: 0.018832\n",
      "[018/01081] train_loss: 0.019277\n",
      "[018/01131] train_loss: 0.018179\n",
      "[018/01181] train_loss: 0.019092\n",
      "[019/00005] train_loss: 0.019806\n",
      "[019/00055] train_loss: 0.021863\n",
      "[019/00105] train_loss: 0.021685\n",
      "[019/00155] train_loss: 0.021127\n",
      "[019/00205] train_loss: 0.020289\n",
      "[019/00255] train_loss: 0.020027\n",
      "[019/00305] train_loss: 0.018908\n",
      "[019/00355] train_loss: 0.019958\n",
      "[019/00405] train_loss: 0.020306\n",
      "[019/00455] train_loss: 0.019847\n",
      "[019/00505] train_loss: 0.018695\n",
      "[019/00555] train_loss: 0.018425\n",
      "[019/00605] train_loss: 0.019563\n",
      "[019/00655] train_loss: 0.018980\n",
      "[019/00705] train_loss: 0.019122\n",
      "[019/00755] train_loss: 0.020013\n",
      "[019/00805] train_loss: 0.018762\n",
      "[019/00855] train_loss: 0.019039\n",
      "[019/00905] train_loss: 0.017861\n",
      "[019/00955] train_loss: 0.018991\n",
      "[019/01005] train_loss: 0.018688\n",
      "[019/01055] train_loss: 0.019415\n",
      "[019/01105] train_loss: 0.019111\n",
      "[019/01155] train_loss: 0.018608\n",
      "[019/01205] train_loss: 0.019320\n",
      "[020/00029] train_loss: 0.021836\n",
      "[020/00079] train_loss: 0.022256\n",
      "[020/00129] train_loss: 0.020270\n",
      "[020/00179] train_loss: 0.020768\n",
      "[020/00229] train_loss: 0.019703\n",
      "[020/00279] train_loss: 0.019703\n",
      "[020/00329] train_loss: 0.019649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[020/00379] train_loss: 0.019774\n",
      "[020/00429] train_loss: 0.019528\n",
      "[020/00479] train_loss: 0.018786\n",
      "[020/00529] train_loss: 0.019236\n",
      "[020/00579] train_loss: 0.019681\n",
      "[020/00629] train_loss: 0.019782\n",
      "[020/00679] train_loss: 0.018506\n",
      "[020/00729] train_loss: 0.019079\n",
      "[020/00779] train_loss: 0.018854\n",
      "[020/00829] train_loss: 0.018454\n",
      "[020/00879] train_loss: 0.018475\n",
      "[020/00929] train_loss: 0.018866\n",
      "[020/00979] train_loss: 0.019351\n",
      "[020/01029] train_loss: 0.018185\n",
      "[020/01079] train_loss: 0.018147\n",
      "[020/01129] train_loss: 0.018895\n",
      "[020/01179] train_loss: 0.019145\n",
      "[021/00003] train_loss: 0.019358\n",
      "[021/00053] train_loss: 0.021614\n",
      "[021/00103] train_loss: 0.021599\n",
      "[021/00153] train_loss: 0.020891\n",
      "[021/00203] train_loss: 0.020321\n",
      "[021/00253] train_loss: 0.020215\n",
      "[021/00303] train_loss: 0.018401\n",
      "[021/00353] train_loss: 0.018568\n",
      "[021/00403] train_loss: 0.019549\n",
      "[021/00453] train_loss: 0.017492\n",
      "[021/00503] train_loss: 0.018883\n",
      "[021/00553] train_loss: 0.019389\n",
      "[021/00603] train_loss: 0.018209\n",
      "[021/00653] train_loss: 0.017560\n",
      "[021/00703] train_loss: 0.018817\n",
      "[021/00753] train_loss: 0.018503\n",
      "[021/00803] train_loss: 0.018560\n",
      "[021/00853] train_loss: 0.018378\n",
      "[021/00903] train_loss: 0.019496\n",
      "[021/00953] train_loss: 0.019015\n",
      "[021/01003] train_loss: 0.019952\n",
      "[021/01053] train_loss: 0.018768\n",
      "[021/01103] train_loss: 0.018850\n",
      "[021/01153] train_loss: 0.018349\n",
      "[021/01203] train_loss: 0.020027\n",
      "[022/00027] train_loss: 0.020229\n",
      "[022/00077] train_loss: 0.022356\n",
      "[022/00127] train_loss: 0.020738\n",
      "[022/00177] train_loss: 0.020339\n",
      "[022/00227] train_loss: 0.020251\n",
      "[022/00277] train_loss: 0.020307\n",
      "[022/00327] train_loss: 0.018604\n",
      "[022/00377] train_loss: 0.019059\n",
      "[022/00427] train_loss: 0.019188\n",
      "[022/00477] train_loss: 0.019976\n",
      "[022/00527] train_loss: 0.018618\n",
      "[022/00577] train_loss: 0.018545\n",
      "[022/00627] train_loss: 0.018594\n",
      "[022/00677] train_loss: 0.018316\n",
      "[022/00727] train_loss: 0.018080\n",
      "[022/00777] train_loss: 0.018912\n",
      "[022/00827] train_loss: 0.018349\n",
      "[022/00877] train_loss: 0.018500\n",
      "[022/00927] train_loss: 0.018366\n",
      "[022/00977] train_loss: 0.018310\n",
      "[022/01027] train_loss: 0.018223\n",
      "[022/01077] train_loss: 0.018182\n",
      "[022/01127] train_loss: 0.018275\n",
      "[022/01177] train_loss: 0.018793\n",
      "[023/00001] train_loss: 0.018535\n",
      "[023/00051] train_loss: 0.021994\n",
      "[023/00101] train_loss: 0.021328\n",
      "[023/00151] train_loss: 0.020471\n",
      "[023/00201] train_loss: 0.019708\n",
      "[023/00251] train_loss: 0.019914\n",
      "[023/00301] train_loss: 0.020026\n",
      "[023/00351] train_loss: 0.018154\n",
      "[023/00401] train_loss: 0.018364\n",
      "[023/00451] train_loss: 0.019188\n",
      "[023/00501] train_loss: 0.018437\n",
      "[023/00551] train_loss: 0.017970\n",
      "[023/00601] train_loss: 0.019086\n",
      "[023/00651] train_loss: 0.018563\n",
      "[023/00701] train_loss: 0.017527\n",
      "[023/00751] train_loss: 0.018310\n",
      "[023/00801] train_loss: 0.019823\n",
      "[023/00851] train_loss: 0.018764\n",
      "[023/00901] train_loss: 0.018698\n",
      "[023/00951] train_loss: 0.018783\n",
      "[023/01001] train_loss: 0.017810\n",
      "[023/01051] train_loss: 0.017502\n",
      "[023/01101] train_loss: 0.018973\n",
      "[023/01151] train_loss: 0.017714\n",
      "[023/01201] train_loss: 0.017759\n",
      "[024/00025] train_loss: 0.020251\n",
      "[024/00075] train_loss: 0.020257\n",
      "[024/00125] train_loss: 0.020012\n",
      "[024/00175] train_loss: 0.019169\n",
      "[024/00225] train_loss: 0.019094\n",
      "[024/00275] train_loss: 0.018537\n",
      "[024/00325] train_loss: 0.019260\n",
      "[024/00375] train_loss: 0.019675\n",
      "[024/00425] train_loss: 0.018707\n",
      "[024/00475] train_loss: 0.018355\n",
      "[024/00525] train_loss: 0.018218\n",
      "[024/00575] train_loss: 0.018575\n",
      "[024/00625] train_loss: 0.018005\n",
      "[024/00675] train_loss: 0.018376\n",
      "[024/00725] train_loss: 0.017536\n",
      "[024/00775] train_loss: 0.018619\n",
      "[024/00825] train_loss: 0.019190\n",
      "[024/00875] train_loss: 0.018184\n",
      "[024/00925] train_loss: 0.019403\n",
      "[024/00975] train_loss: 0.017744\n",
      "[024/01025] train_loss: 0.018766\n",
      "[024/01075] train_loss: 0.018664\n",
      "[024/01125] train_loss: 0.018355\n",
      "[024/01175] train_loss: 0.018285\n",
      "[024/01225] train_loss: 0.018151\n",
      "[025/00049] train_loss: 0.020661\n",
      "[025/00099] train_loss: 0.019793\n",
      "[025/00149] train_loss: 0.019688\n",
      "[025/00199] train_loss: 0.020175\n",
      "[025/00249] train_loss: 0.020119\n",
      "[025/00299] train_loss: 0.019359\n",
      "[025/00349] train_loss: 0.018579\n",
      "[025/00399] train_loss: 0.018518\n",
      "[025/00449] train_loss: 0.018543\n",
      "[025/00499] train_loss: 0.017838\n",
      "[025/00549] train_loss: 0.018670\n",
      "[025/00599] train_loss: 0.018487\n",
      "[025/00649] train_loss: 0.018513\n",
      "[025/00699] train_loss: 0.018628\n",
      "[025/00749] train_loss: 0.018713\n",
      "[025/00799] train_loss: 0.017765\n",
      "[025/00849] train_loss: 0.018477\n",
      "[025/00899] train_loss: 0.018049\n",
      "[025/00949] train_loss: 0.018182\n",
      "[025/00999] train_loss: 0.017567\n",
      "[025/01049] train_loss: 0.019030\n",
      "[025/01099] train_loss: 0.018185\n",
      "[025/01149] train_loss: 0.018816\n",
      "[025/01199] train_loss: 0.018132\n",
      "[026/00023] train_loss: 0.019192\n",
      "[026/00073] train_loss: 0.020101\n",
      "[026/00123] train_loss: 0.020306\n",
      "[026/00173] train_loss: 0.019350\n",
      "[026/00223] train_loss: 0.018780\n",
      "[026/00273] train_loss: 0.020331\n",
      "[026/00323] train_loss: 0.017891\n",
      "[026/00373] train_loss: 0.018313\n",
      "[026/00423] train_loss: 0.018511\n",
      "[026/00473] train_loss: 0.017392\n",
      "[026/00523] train_loss: 0.017477\n",
      "[026/00573] train_loss: 0.018960\n",
      "[026/00623] train_loss: 0.018513\n",
      "[026/00673] train_loss: 0.018595\n",
      "[026/00723] train_loss: 0.017896\n",
      "[026/00773] train_loss: 0.017867\n",
      "[026/00823] train_loss: 0.017690\n",
      "[026/00873] train_loss: 0.017934\n",
      "[026/00923] train_loss: 0.017459\n",
      "[026/00973] train_loss: 0.018034\n",
      "[026/01023] train_loss: 0.018658\n",
      "[026/01073] train_loss: 0.017383\n",
      "[026/01123] train_loss: 0.017356\n",
      "[026/01173] train_loss: 0.018280\n",
      "[026/01223] train_loss: 0.018245\n",
      "[027/00047] train_loss: 0.020145\n",
      "[027/00097] train_loss: 0.021004\n",
      "[027/00147] train_loss: 0.019411\n",
      "[027/00197] train_loss: 0.019555\n",
      "[027/00247] train_loss: 0.019914\n",
      "[027/00297] train_loss: 0.018535\n",
      "[027/00347] train_loss: 0.018129\n",
      "[027/00397] train_loss: 0.018595\n",
      "[027/00447] train_loss: 0.019259\n",
      "[027/00497] train_loss: 0.017705\n",
      "[027/00547] train_loss: 0.018636\n",
      "[027/00597] train_loss: 0.018658\n",
      "[027/00647] train_loss: 0.018201\n",
      "[027/00697] train_loss: 0.018127\n",
      "[027/00747] train_loss: 0.017771\n",
      "[027/00797] train_loss: 0.017677\n",
      "[027/00847] train_loss: 0.017750\n",
      "[027/00897] train_loss: 0.017466\n",
      "[027/00947] train_loss: 0.017820\n",
      "[027/00997] train_loss: 0.017416\n",
      "[027/01047] train_loss: 0.017521\n",
      "[027/01097] train_loss: 0.017188\n",
      "[027/01147] train_loss: 0.018149\n",
      "[027/01197] train_loss: 0.018347\n",
      "[028/00021] train_loss: 0.018835\n",
      "[028/00071] train_loss: 0.020191\n",
      "[028/00121] train_loss: 0.020082\n",
      "[028/00171] train_loss: 0.019954\n",
      "[028/00221] train_loss: 0.018678\n",
      "[028/00271] train_loss: 0.019076\n",
      "[028/00321] train_loss: 0.018664\n",
      "[028/00371] train_loss: 0.017642\n",
      "[028/00421] train_loss: 0.018765\n",
      "[028/00471] train_loss: 0.018225\n",
      "[028/00521] train_loss: 0.017408\n",
      "[028/00571] train_loss: 0.017905\n",
      "[028/00621] train_loss: 0.017933\n",
      "[028/00671] train_loss: 0.017461\n",
      "[028/00721] train_loss: 0.017724\n",
      "[028/00771] train_loss: 0.017316\n",
      "[028/00821] train_loss: 0.018400\n",
      "[028/00871] train_loss: 0.017434\n",
      "[028/00921] train_loss: 0.017632\n",
      "[028/00971] train_loss: 0.017756\n",
      "[028/01021] train_loss: 0.017882\n",
      "[028/01071] train_loss: 0.017384\n",
      "[028/01121] train_loss: 0.017632\n",
      "[028/01171] train_loss: 0.018282\n",
      "[028/01221] train_loss: 0.018596\n",
      "[029/00045] train_loss: 0.021198\n",
      "[029/00095] train_loss: 0.020270\n",
      "[029/00145] train_loss: 0.018380\n",
      "[029/00195] train_loss: 0.020132\n",
      "[029/00245] train_loss: 0.018917\n",
      "[029/00295] train_loss: 0.018764\n",
      "[029/00345] train_loss: 0.019274\n",
      "[029/00395] train_loss: 0.017922\n",
      "[029/00445] train_loss: 0.017731\n",
      "[029/00495] train_loss: 0.017552\n",
      "[029/00545] train_loss: 0.017880\n",
      "[029/00595] train_loss: 0.018343\n",
      "[029/00645] train_loss: 0.017162\n",
      "[029/00695] train_loss: 0.017496\n",
      "[029/00745] train_loss: 0.017251\n",
      "[029/00795] train_loss: 0.017505\n",
      "[029/00845] train_loss: 0.017531\n",
      "[029/00895] train_loss: 0.018264\n",
      "[029/00945] train_loss: 0.018352\n",
      "[029/00995] train_loss: 0.017210\n",
      "[029/01045] train_loss: 0.017246\n",
      "[029/01095] train_loss: 0.016981\n",
      "[029/01145] train_loss: 0.017616\n",
      "[029/01195] train_loss: 0.018823\n",
      "[030/00019] train_loss: 0.018831\n",
      "[030/00069] train_loss: 0.021265\n",
      "[030/00119] train_loss: 0.019307\n",
      "[030/00169] train_loss: 0.019304\n",
      "[030/00219] train_loss: 0.018772\n",
      "[030/00269] train_loss: 0.017818\n",
      "[030/00319] train_loss: 0.019059\n",
      "[030/00369] train_loss: 0.019173\n",
      "[030/00419] train_loss: 0.018449\n",
      "[030/00469] train_loss: 0.017770\n",
      "[030/00519] train_loss: 0.017501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[030/00569] train_loss: 0.018338\n",
      "[030/00619] train_loss: 0.017723\n",
      "[030/00669] train_loss: 0.017262\n",
      "[030/00719] train_loss: 0.017956\n",
      "[030/00769] train_loss: 0.017202\n",
      "[030/00819] train_loss: 0.016946\n",
      "[030/00869] train_loss: 0.018047\n",
      "[030/00919] train_loss: 0.017746\n",
      "[030/00969] train_loss: 0.017658\n",
      "[030/01019] train_loss: 0.017764\n",
      "[030/01069] train_loss: 0.017640\n",
      "[030/01119] train_loss: 0.017771\n",
      "[030/01169] train_loss: 0.017269\n",
      "[030/01219] train_loss: 0.017887\n",
      "[031/00043] train_loss: 0.021076\n",
      "[031/00093] train_loss: 0.019368\n",
      "[031/00143] train_loss: 0.019240\n",
      "[031/00193] train_loss: 0.018646\n",
      "[031/00243] train_loss: 0.018962\n",
      "[031/00293] train_loss: 0.017781\n",
      "[031/00343] train_loss: 0.017864\n",
      "[031/00393] train_loss: 0.018322\n",
      "[031/00443] train_loss: 0.018111\n",
      "[031/00493] train_loss: 0.018086\n",
      "[031/00543] train_loss: 0.017743\n",
      "[031/00593] train_loss: 0.018185\n",
      "[031/00643] train_loss: 0.017772\n",
      "[031/00693] train_loss: 0.017374\n",
      "[031/00743] train_loss: 0.016968\n",
      "[031/00793] train_loss: 0.017491\n",
      "[031/00843] train_loss: 0.017075\n",
      "[031/00893] train_loss: 0.017732\n",
      "[031/00943] train_loss: 0.017953\n",
      "[031/00993] train_loss: 0.016860\n",
      "[031/01043] train_loss: 0.017283\n",
      "[031/01093] train_loss: 0.017810\n",
      "[031/01143] train_loss: 0.017709\n",
      "[031/01193] train_loss: 0.017820\n",
      "[032/00017] train_loss: 0.019126\n",
      "[032/00067] train_loss: 0.019376\n",
      "[032/00117] train_loss: 0.020261\n",
      "[032/00167] train_loss: 0.019641\n",
      "[032/00217] train_loss: 0.019095\n",
      "[032/00267] train_loss: 0.018419\n",
      "[032/00317] train_loss: 0.017682\n",
      "[032/00367] train_loss: 0.018310\n",
      "[032/00417] train_loss: 0.017609\n",
      "[032/00467] train_loss: 0.017530\n",
      "[032/00517] train_loss: 0.016963\n",
      "[032/00567] train_loss: 0.017045\n",
      "[032/00617] train_loss: 0.017763\n",
      "[032/00667] train_loss: 0.017842\n",
      "[032/00717] train_loss: 0.017088\n",
      "[032/00767] train_loss: 0.017427\n",
      "[032/00817] train_loss: 0.017960\n",
      "[032/00867] train_loss: 0.017213\n",
      "[032/00917] train_loss: 0.017092\n",
      "[032/00967] train_loss: 0.018603\n",
      "[032/01017] train_loss: 0.017929\n",
      "[032/01067] train_loss: 0.017117\n",
      "[032/01117] train_loss: 0.016836\n",
      "[032/01167] train_loss: 0.016961\n",
      "[032/01217] train_loss: 0.017568\n",
      "[033/00041] train_loss: 0.019380\n",
      "[033/00091] train_loss: 0.019268\n",
      "[033/00141] train_loss: 0.018775\n",
      "[033/00191] train_loss: 0.018022\n",
      "[033/00241] train_loss: 0.019158\n",
      "[033/00291] train_loss: 0.018484\n",
      "[033/00341] train_loss: 0.018304\n",
      "[033/00391] train_loss: 0.017409\n",
      "[033/00441] train_loss: 0.017775\n",
      "[033/00491] train_loss: 0.018016\n",
      "[033/00541] train_loss: 0.017253\n",
      "[033/00591] train_loss: 0.018180\n",
      "[033/00641] train_loss: 0.018097\n",
      "[033/00691] train_loss: 0.017506\n",
      "[033/00741] train_loss: 0.017961\n",
      "[033/00791] train_loss: 0.016332\n",
      "[033/00841] train_loss: 0.017638\n",
      "[033/00891] train_loss: 0.017437\n",
      "[033/00941] train_loss: 0.018092\n",
      "[033/00991] train_loss: 0.017393\n",
      "[033/01041] train_loss: 0.017224\n",
      "[033/01091] train_loss: 0.017840\n",
      "[033/01141] train_loss: 0.017687\n",
      "[033/01191] train_loss: 0.017654\n",
      "[034/00015] train_loss: 0.018620\n",
      "[034/00065] train_loss: 0.019821\n",
      "[034/00115] train_loss: 0.018824\n",
      "[034/00165] train_loss: 0.018050\n",
      "[034/00215] train_loss: 0.019300\n",
      "[034/00265] train_loss: 0.017809\n",
      "[034/00315] train_loss: 0.017805\n",
      "[034/00365] train_loss: 0.017721\n",
      "[034/00415] train_loss: 0.017913\n",
      "[034/00465] train_loss: 0.018156\n",
      "[034/00515] train_loss: 0.017968\n",
      "[034/00565] train_loss: 0.017498\n",
      "[034/00615] train_loss: 0.018208\n",
      "[034/00665] train_loss: 0.016880\n",
      "[034/00715] train_loss: 0.018219\n",
      "[034/00765] train_loss: 0.017564\n",
      "[034/00815] train_loss: 0.018065\n",
      "[034/00865] train_loss: 0.016188\n",
      "[034/00915] train_loss: 0.017550\n",
      "[034/00965] train_loss: 0.017254\n",
      "[034/01015] train_loss: 0.016378\n",
      "[034/01065] train_loss: 0.017751\n",
      "[034/01115] train_loss: 0.017689\n",
      "[034/01165] train_loss: 0.017296\n",
      "[034/01215] train_loss: 0.016732\n",
      "[035/00039] train_loss: 0.019129\n",
      "[035/00089] train_loss: 0.019047\n",
      "[035/00139] train_loss: 0.018822\n",
      "[035/00189] train_loss: 0.018233\n",
      "[035/00239] train_loss: 0.018097\n",
      "[035/00289] train_loss: 0.018312\n",
      "[035/00339] train_loss: 0.018097\n",
      "[035/00389] train_loss: 0.017474\n",
      "[035/00439] train_loss: 0.017081\n",
      "[035/00489] train_loss: 0.017775\n",
      "[035/00539] train_loss: 0.017956\n",
      "[035/00589] train_loss: 0.017638\n",
      "[035/00639] train_loss: 0.016788\n",
      "[035/00689] train_loss: 0.016730\n",
      "[035/00739] train_loss: 0.017756\n",
      "[035/00789] train_loss: 0.017308\n",
      "[035/00839] train_loss: 0.017617\n",
      "[035/00889] train_loss: 0.017322\n",
      "[035/00939] train_loss: 0.017158\n",
      "[035/00989] train_loss: 0.017518\n",
      "[035/01039] train_loss: 0.016261\n",
      "[035/01089] train_loss: 0.016669\n",
      "[035/01139] train_loss: 0.016934\n",
      "[035/01189] train_loss: 0.016440\n",
      "[036/00013] train_loss: 0.017674\n",
      "[036/00063] train_loss: 0.020078\n",
      "[036/00113] train_loss: 0.019112\n",
      "[036/00163] train_loss: 0.019174\n",
      "[036/00213] train_loss: 0.018653\n",
      "[036/00263] train_loss: 0.018503\n",
      "[036/00313] train_loss: 0.017608\n",
      "[036/00363] train_loss: 0.016943\n",
      "[036/00413] train_loss: 0.017631\n",
      "[036/00463] train_loss: 0.016928\n",
      "[036/00513] train_loss: 0.017126\n",
      "[036/00563] train_loss: 0.017714\n",
      "[036/00613] train_loss: 0.017033\n",
      "[036/00663] train_loss: 0.017332\n",
      "[036/00713] train_loss: 0.017236\n",
      "[036/00763] train_loss: 0.016563\n",
      "[036/00813] train_loss: 0.016736\n",
      "[036/00863] train_loss: 0.016014\n",
      "[036/00913] train_loss: 0.017042\n",
      "[036/00963] train_loss: 0.017924\n",
      "[036/01013] train_loss: 0.017215\n",
      "[036/01063] train_loss: 0.016402\n",
      "[036/01113] train_loss: 0.017096\n",
      "[036/01163] train_loss: 0.017536\n",
      "[036/01213] train_loss: 0.017008\n",
      "[037/00037] train_loss: 0.019944\n",
      "[037/00087] train_loss: 0.019889\n",
      "[037/00137] train_loss: 0.019323\n",
      "[037/00187] train_loss: 0.018359\n",
      "[037/00237] train_loss: 0.017032\n",
      "[037/00287] train_loss: 0.017323\n",
      "[037/00337] train_loss: 0.017807\n",
      "[037/00387] train_loss: 0.017343\n",
      "[037/00437] train_loss: 0.017370\n",
      "[037/00487] train_loss: 0.017910\n",
      "[037/00537] train_loss: 0.017378\n",
      "[037/00587] train_loss: 0.016746\n",
      "[037/00637] train_loss: 0.017634\n",
      "[037/00687] train_loss: 0.017356\n",
      "[037/00737] train_loss: 0.017148\n",
      "[037/00787] train_loss: 0.017123\n",
      "[037/00837] train_loss: 0.016574\n",
      "[037/00887] train_loss: 0.015856\n",
      "[037/00937] train_loss: 0.017016\n",
      "[037/00987] train_loss: 0.017559\n",
      "[037/01037] train_loss: 0.017439\n",
      "[037/01087] train_loss: 0.017159\n",
      "[037/01137] train_loss: 0.016611\n",
      "[037/01187] train_loss: 0.016786\n",
      "[038/00011] train_loss: 0.016948\n",
      "[038/00061] train_loss: 0.020358\n",
      "[038/00111] train_loss: 0.019460\n",
      "[038/00161] train_loss: 0.018755\n",
      "[038/00211] train_loss: 0.017557\n",
      "[038/00261] train_loss: 0.018352\n",
      "[038/00311] train_loss: 0.018028\n",
      "[038/00361] train_loss: 0.017767\n",
      "[038/00411] train_loss: 0.017424\n",
      "[038/00461] train_loss: 0.018106\n",
      "[038/00511] train_loss: 0.017775\n",
      "[038/00561] train_loss: 0.017653\n",
      "[038/00611] train_loss: 0.017269\n",
      "[038/00661] train_loss: 0.016289\n",
      "[038/00711] train_loss: 0.016698\n",
      "[038/00761] train_loss: 0.017065\n",
      "[038/00811] train_loss: 0.017252\n",
      "[038/00861] train_loss: 0.016442\n",
      "[038/00911] train_loss: 0.016384\n",
      "[038/00961] train_loss: 0.016139\n",
      "[038/01011] train_loss: 0.016346\n",
      "[038/01061] train_loss: 0.017725\n",
      "[038/01111] train_loss: 0.017459\n",
      "[038/01161] train_loss: 0.016633\n",
      "[038/01211] train_loss: 0.016365\n",
      "[039/00035] train_loss: 0.018944\n",
      "[039/00085] train_loss: 0.018719\n",
      "[039/00135] train_loss: 0.019030\n",
      "[039/00185] train_loss: 0.018282\n",
      "[039/00235] train_loss: 0.018715\n",
      "[039/00285] train_loss: 0.017840\n",
      "[039/00335] train_loss: 0.018185\n",
      "[039/00385] train_loss: 0.017838\n",
      "[039/00435] train_loss: 0.017490\n",
      "[039/00485] train_loss: 0.016998\n",
      "[039/00535] train_loss: 0.017399\n",
      "[039/00585] train_loss: 0.016842\n",
      "[039/00635] train_loss: 0.016612\n",
      "[039/00685] train_loss: 0.016666\n",
      "[039/00735] train_loss: 0.016873\n",
      "[039/00785] train_loss: 0.017172\n",
      "[039/00835] train_loss: 0.017528\n",
      "[039/00885] train_loss: 0.017007\n",
      "[039/00935] train_loss: 0.018044\n",
      "[039/00985] train_loss: 0.017013\n",
      "[039/01035] train_loss: 0.017122\n",
      "[039/01085] train_loss: 0.015934\n",
      "[039/01135] train_loss: 0.016807\n",
      "[039/01185] train_loss: 0.016086\n",
      "[040/00009] train_loss: 0.017671\n",
      "[040/00059] train_loss: 0.019395\n",
      "[040/00109] train_loss: 0.018644\n",
      "[040/00159] train_loss: 0.018332\n",
      "[040/00209] train_loss: 0.018627\n",
      "[040/00259] train_loss: 0.018107\n",
      "[040/00309] train_loss: 0.017017\n",
      "[040/00359] train_loss: 0.016857\n",
      "[040/00409] train_loss: 0.016867\n",
      "[040/00459] train_loss: 0.016475\n",
      "[040/00509] train_loss: 0.017257\n",
      "[040/00559] train_loss: 0.016120\n",
      "[040/00609] train_loss: 0.016584\n",
      "[040/00659] train_loss: 0.017415\n",
      "[040/00709] train_loss: 0.017833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[040/00759] train_loss: 0.016825\n",
      "[040/00809] train_loss: 0.017373\n",
      "[040/00859] train_loss: 0.017423\n",
      "[040/00909] train_loss: 0.016908\n",
      "[040/00959] train_loss: 0.016570\n",
      "[040/01009] train_loss: 0.016706\n",
      "[040/01059] train_loss: 0.016811\n",
      "[040/01109] train_loss: 0.017144\n",
      "[040/01159] train_loss: 0.017343\n",
      "[040/01209] train_loss: 0.017002\n",
      "[041/00033] train_loss: 0.019355\n",
      "[041/00083] train_loss: 0.019048\n",
      "[041/00133] train_loss: 0.018927\n",
      "[041/00183] train_loss: 0.017667\n",
      "[041/00233] train_loss: 0.017321\n",
      "[041/00283] train_loss: 0.016578\n",
      "[041/00333] train_loss: 0.016856\n",
      "[041/00383] train_loss: 0.017789\n",
      "[041/00433] train_loss: 0.016809\n",
      "[041/00483] train_loss: 0.016819\n",
      "[041/00533] train_loss: 0.015956\n",
      "[041/00583] train_loss: 0.017424\n",
      "[041/00633] train_loss: 0.016752\n",
      "[041/00683] train_loss: 0.017015\n",
      "[041/00733] train_loss: 0.016378\n",
      "[041/00783] train_loss: 0.016595\n",
      "[041/00833] train_loss: 0.016675\n",
      "[041/00883] train_loss: 0.017331\n",
      "[041/00933] train_loss: 0.016102\n",
      "[041/00983] train_loss: 0.016431\n",
      "[041/01033] train_loss: 0.017211\n",
      "[041/01083] train_loss: 0.016455\n",
      "[041/01133] train_loss: 0.016496\n",
      "[041/01183] train_loss: 0.016440\n",
      "[042/00007] train_loss: 0.016902\n",
      "[042/00057] train_loss: 0.019864\n",
      "[042/00107] train_loss: 0.018912\n",
      "[042/00157] train_loss: 0.017485\n",
      "[042/00207] train_loss: 0.018414\n",
      "[042/00257] train_loss: 0.017206\n",
      "[042/00307] train_loss: 0.017093\n",
      "[042/00357] train_loss: 0.017409\n",
      "[042/00407] train_loss: 0.017342\n",
      "[042/00457] train_loss: 0.017580\n",
      "[042/00507] train_loss: 0.017347\n",
      "[042/00557] train_loss: 0.016632\n",
      "[042/00607] train_loss: 0.016024\n",
      "[042/00657] train_loss: 0.015795\n",
      "[042/00707] train_loss: 0.016554\n",
      "[042/00757] train_loss: 0.016943\n",
      "[042/00807] train_loss: 0.016229\n",
      "[042/00857] train_loss: 0.017422\n",
      "[042/00907] train_loss: 0.016720\n",
      "[042/00957] train_loss: 0.016749\n",
      "[042/01007] train_loss: 0.015927\n",
      "[042/01057] train_loss: 0.016598\n",
      "[042/01107] train_loss: 0.016375\n",
      "[042/01157] train_loss: 0.016106\n",
      "[042/01207] train_loss: 0.016438\n",
      "[043/00031] train_loss: 0.017746\n",
      "[043/00081] train_loss: 0.018498\n",
      "[043/00131] train_loss: 0.018557\n",
      "[043/00181] train_loss: 0.018573\n",
      "[043/00231] train_loss: 0.016909\n",
      "[043/00281] train_loss: 0.017735\n",
      "[043/00331] train_loss: 0.018200\n",
      "[043/00381] train_loss: 0.018090\n",
      "[043/00431] train_loss: 0.018001\n",
      "[043/00481] train_loss: 0.017135\n",
      "[043/00531] train_loss: 0.016629\n",
      "[043/00581] train_loss: 0.016266\n",
      "[043/00631] train_loss: 0.016871\n",
      "[043/00681] train_loss: 0.016338\n",
      "[043/00731] train_loss: 0.017290\n",
      "[043/00781] train_loss: 0.016148\n",
      "[043/00831] train_loss: 0.017019\n",
      "[043/00881] train_loss: 0.017004\n",
      "[043/00931] train_loss: 0.016695\n",
      "[043/00981] train_loss: 0.016494\n",
      "[043/01031] train_loss: 0.016863\n",
      "[043/01081] train_loss: 0.016845\n",
      "[043/01131] train_loss: 0.016740\n",
      "[043/01181] train_loss: 0.016452\n",
      "[044/00005] train_loss: 0.016245\n",
      "[044/00055] train_loss: 0.018816\n",
      "[044/00105] train_loss: 0.019228\n",
      "[044/00155] train_loss: 0.017841\n",
      "[044/00205] train_loss: 0.017019\n",
      "[044/00255] train_loss: 0.016406\n",
      "[044/00305] train_loss: 0.016925\n",
      "[044/00355] train_loss: 0.017144\n",
      "[044/00405] train_loss: 0.016859\n",
      "[044/00455] train_loss: 0.018044\n",
      "[044/00505] train_loss: 0.017470\n",
      "[044/00555] train_loss: 0.017542\n",
      "[044/00605] train_loss: 0.016563\n",
      "[044/00655] train_loss: 0.016526\n",
      "[044/00705] train_loss: 0.016529\n",
      "[044/00755] train_loss: 0.016496\n",
      "[044/00805] train_loss: 0.016438\n",
      "[044/00855] train_loss: 0.017020\n",
      "[044/00905] train_loss: 0.017909\n",
      "[044/00955] train_loss: 0.015946\n",
      "[044/01005] train_loss: 0.015687\n",
      "[044/01055] train_loss: 0.016414\n",
      "[044/01105] train_loss: 0.016272\n",
      "[044/01155] train_loss: 0.016413\n",
      "[044/01205] train_loss: 0.016454\n",
      "[045/00029] train_loss: 0.018499\n",
      "[045/00079] train_loss: 0.019484\n",
      "[045/00129] train_loss: 0.017757\n",
      "[045/00179] train_loss: 0.018080\n",
      "[045/00229] train_loss: 0.017791\n",
      "[045/00279] train_loss: 0.017088\n",
      "[045/00329] train_loss: 0.017713\n",
      "[045/00379] train_loss: 0.016977\n",
      "[045/00429] train_loss: 0.016829\n",
      "[045/00479] train_loss: 0.016841\n",
      "[045/00529] train_loss: 0.016675\n",
      "[045/00579] train_loss: 0.017457\n",
      "[045/00629] train_loss: 0.017128\n",
      "[045/00679] train_loss: 0.017126\n",
      "[045/00729] train_loss: 0.016355\n",
      "[045/00779] train_loss: 0.016920\n",
      "[045/00829] train_loss: 0.016903\n",
      "[045/00879] train_loss: 0.015847\n",
      "[045/00929] train_loss: 0.016409\n",
      "[045/00979] train_loss: 0.016296\n",
      "[045/01029] train_loss: 0.016487\n",
      "[045/01079] train_loss: 0.016544\n",
      "[045/01129] train_loss: 0.016856\n",
      "[045/01179] train_loss: 0.016053\n",
      "[046/00003] train_loss: 0.016162\n",
      "[046/00053] train_loss: 0.019715\n",
      "[046/00103] train_loss: 0.018140\n",
      "[046/00153] train_loss: 0.017982\n",
      "[046/00203] train_loss: 0.016694\n",
      "[046/00253] train_loss: 0.017148\n",
      "[046/00303] train_loss: 0.016513\n",
      "[046/00353] train_loss: 0.017519\n",
      "[046/00403] train_loss: 0.017337\n",
      "[046/00453] train_loss: 0.016977\n",
      "[046/00503] train_loss: 0.016071\n",
      "[046/00553] train_loss: 0.016506\n",
      "[046/00603] train_loss: 0.017045\n",
      "[046/00653] train_loss: 0.015732\n",
      "[046/00703] train_loss: 0.016206\n",
      "[046/00753] train_loss: 0.016116\n",
      "[046/00803] train_loss: 0.015403\n",
      "[046/00853] train_loss: 0.016676\n",
      "[046/00903] train_loss: 0.016463\n",
      "[046/00953] train_loss: 0.016604\n",
      "[046/01003] train_loss: 0.017223\n",
      "[046/01053] train_loss: 0.016541\n",
      "[046/01103] train_loss: 0.015857\n",
      "[046/01153] train_loss: 0.016061\n",
      "[046/01203] train_loss: 0.015764\n",
      "[047/00027] train_loss: 0.018380\n",
      "[047/00077] train_loss: 0.018556\n",
      "[047/00127] train_loss: 0.017751\n",
      "[047/00177] train_loss: 0.017785\n",
      "[047/00227] train_loss: 0.017749\n",
      "[047/00277] train_loss: 0.016789\n",
      "[047/00327] train_loss: 0.017479\n",
      "[047/00377] train_loss: 0.016734\n",
      "[047/00427] train_loss: 0.016655\n",
      "[047/00477] train_loss: 0.016320\n",
      "[047/00527] train_loss: 0.016450\n",
      "[047/00577] train_loss: 0.015673\n",
      "[047/00627] train_loss: 0.016360\n",
      "[047/00677] train_loss: 0.016496\n",
      "[047/00727] train_loss: 0.016140\n",
      "[047/00777] train_loss: 0.016119\n",
      "[047/00827] train_loss: 0.015641\n",
      "[047/00877] train_loss: 0.016291\n",
      "[047/00927] train_loss: 0.015754\n",
      "[047/00977] train_loss: 0.017377\n",
      "[047/01027] train_loss: 0.016025\n",
      "[047/01077] train_loss: 0.015789\n",
      "[047/01127] train_loss: 0.015833\n",
      "[047/01177] train_loss: 0.015884\n",
      "[048/00001] train_loss: 0.016398\n",
      "[048/00051] train_loss: 0.018552\n",
      "[048/00101] train_loss: 0.018730\n",
      "[048/00151] train_loss: 0.017506\n",
      "[048/00201] train_loss: 0.017235\n",
      "[048/00251] train_loss: 0.016763\n",
      "[048/00301] train_loss: 0.016260\n",
      "[048/00351] train_loss: 0.016414\n",
      "[048/00401] train_loss: 0.016335\n",
      "[048/00451] train_loss: 0.016193\n",
      "[048/00501] train_loss: 0.016856\n",
      "[048/00551] train_loss: 0.016646\n",
      "[048/00601] train_loss: 0.017298\n",
      "[048/00651] train_loss: 0.016881\n",
      "[048/00701] train_loss: 0.017158\n",
      "[048/00751] train_loss: 0.017237\n",
      "[048/00801] train_loss: 0.015731\n",
      "[048/00851] train_loss: 0.016130\n",
      "[048/00901] train_loss: 0.016323\n",
      "[048/00951] train_loss: 0.015939\n",
      "[048/01001] train_loss: 0.016670\n",
      "[048/01051] train_loss: 0.017078\n",
      "[048/01101] train_loss: 0.015711\n",
      "[048/01151] train_loss: 0.016171\n",
      "[048/01201] train_loss: 0.015339\n",
      "[049/00025] train_loss: 0.017987\n",
      "[049/00075] train_loss: 0.018665\n",
      "[049/00125] train_loss: 0.018287\n",
      "[049/00175] train_loss: 0.016404\n",
      "[049/00225] train_loss: 0.017936\n",
      "[049/00275] train_loss: 0.016533\n",
      "[049/00325] train_loss: 0.016354\n",
      "[049/00375] train_loss: 0.017869\n",
      "[049/00425] train_loss: 0.016697\n",
      "[049/00475] train_loss: 0.016404\n",
      "[049/00525] train_loss: 0.015956\n",
      "[049/00575] train_loss: 0.015847\n",
      "[049/00625] train_loss: 0.016184\n",
      "[049/00675] train_loss: 0.016410\n",
      "[049/00725] train_loss: 0.015468\n",
      "[049/00775] train_loss: 0.017129\n",
      "[049/00825] train_loss: 0.015887\n",
      "[049/00875] train_loss: 0.016023\n",
      "[049/00925] train_loss: 0.016554\n",
      "[049/00975] train_loss: 0.016891\n",
      "[049/01025] train_loss: 0.016187\n",
      "[049/01075] train_loss: 0.016099\n",
      "[049/01125] train_loss: 0.016289\n",
      "[049/01175] train_loss: 0.016047\n",
      "[049/01225] train_loss: 0.016937\n",
      "[050/00049] train_loss: 0.018290\n",
      "[050/00099] train_loss: 0.017634\n",
      "[050/00149] train_loss: 0.018004\n",
      "[050/00199] train_loss: 0.016863\n",
      "[050/00249] train_loss: 0.016756\n",
      "[050/00299] train_loss: 0.016734\n",
      "[050/00349] train_loss: 0.017084\n",
      "[050/00399] train_loss: 0.017040\n",
      "[050/00449] train_loss: 0.016871\n",
      "[050/00499] train_loss: 0.016560\n",
      "[050/00549] train_loss: 0.017412\n",
      "[050/00599] train_loss: 0.015919\n",
      "[050/00649] train_loss: 0.016914\n",
      "[050/00699] train_loss: 0.016162\n",
      "[050/00749] train_loss: 0.015772\n",
      "[050/00799] train_loss: 0.016436\n",
      "[050/00849] train_loss: 0.015594\n",
      "[050/00899] train_loss: 0.015949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[050/00949] train_loss: 0.016015\n",
      "[050/00999] train_loss: 0.016611\n",
      "[050/01049] train_loss: 0.015681\n",
      "[050/01099] train_loss: 0.015304\n",
      "[050/01149] train_loss: 0.016393\n",
      "[050/01199] train_loss: 0.015423\n",
      "[051/00023] train_loss: 0.017693\n",
      "[051/00073] train_loss: 0.017378\n",
      "[051/00123] train_loss: 0.018207\n",
      "[051/00173] train_loss: 0.017310\n",
      "[051/00223] train_loss: 0.017286\n",
      "[051/00273] train_loss: 0.017727\n",
      "[051/00323] train_loss: 0.017013\n",
      "[051/00373] train_loss: 0.017062\n",
      "[051/00423] train_loss: 0.016504\n",
      "[051/00473] train_loss: 0.016108\n",
      "[051/00523] train_loss: 0.016565\n",
      "[051/00573] train_loss: 0.016662\n",
      "[051/00623] train_loss: 0.016281\n",
      "[051/00673] train_loss: 0.017132\n",
      "[051/00723] train_loss: 0.016568\n",
      "[051/00773] train_loss: 0.016900\n",
      "[051/00823] train_loss: 0.016068\n",
      "[051/00873] train_loss: 0.015744\n",
      "[051/00923] train_loss: 0.015336\n",
      "[051/00973] train_loss: 0.016171\n",
      "[051/01023] train_loss: 0.015507\n",
      "[051/01073] train_loss: 0.016082\n",
      "[051/01123] train_loss: 0.015393\n",
      "[051/01173] train_loss: 0.015940\n",
      "[051/01223] train_loss: 0.016222\n",
      "[052/00047] train_loss: 0.019057\n",
      "[052/00097] train_loss: 0.018051\n",
      "[052/00147] train_loss: 0.018418\n",
      "[052/00197] train_loss: 0.017689\n",
      "[052/00247] train_loss: 0.016780\n",
      "[052/00297] train_loss: 0.016536\n",
      "[052/00347] train_loss: 0.016112\n",
      "[052/00397] train_loss: 0.015785\n",
      "[052/00447] train_loss: 0.016250\n",
      "[052/00497] train_loss: 0.015912\n",
      "[052/00547] train_loss: 0.015356\n",
      "[052/00597] train_loss: 0.016580\n",
      "[052/00647] train_loss: 0.015622\n",
      "[052/00697] train_loss: 0.016564\n",
      "[052/00747] train_loss: 0.016555\n",
      "[052/00797] train_loss: 0.016753\n",
      "[052/00847] train_loss: 0.016096\n",
      "[052/00897] train_loss: 0.016358\n",
      "[052/00947] train_loss: 0.015745\n",
      "[052/00997] train_loss: 0.015633\n",
      "[052/01047] train_loss: 0.016666\n",
      "[052/01097] train_loss: 0.016985\n",
      "[052/01147] train_loss: 0.015884\n",
      "[052/01197] train_loss: 0.015672\n",
      "[053/00021] train_loss: 0.016350\n",
      "[053/00071] train_loss: 0.018020\n",
      "[053/00121] train_loss: 0.016868\n",
      "[053/00171] train_loss: 0.018230\n",
      "[053/00221] train_loss: 0.016955\n",
      "[053/00271] train_loss: 0.017148\n",
      "[053/00321] train_loss: 0.016810\n",
      "[053/00371] train_loss: 0.015543\n",
      "[053/00421] train_loss: 0.015797\n",
      "[053/00471] train_loss: 0.016268\n",
      "[053/00521] train_loss: 0.016013\n",
      "[053/00571] train_loss: 0.016035\n",
      "[053/00621] train_loss: 0.015646\n",
      "[053/00671] train_loss: 0.016109\n",
      "[053/00721] train_loss: 0.016016\n",
      "[053/00771] train_loss: 0.015834\n",
      "[053/00821] train_loss: 0.016203\n",
      "[053/00871] train_loss: 0.016172\n",
      "[053/00921] train_loss: 0.015913\n",
      "[053/00971] train_loss: 0.016503\n",
      "[053/01021] train_loss: 0.015705\n",
      "[053/01071] train_loss: 0.016107\n",
      "[053/01121] train_loss: 0.016137\n",
      "[053/01171] train_loss: 0.015930\n",
      "[053/01221] train_loss: 0.015594\n",
      "[054/00045] train_loss: 0.018725\n",
      "[054/00095] train_loss: 0.017975\n",
      "[054/00145] train_loss: 0.017565\n",
      "[054/00195] train_loss: 0.016896\n",
      "[054/00245] train_loss: 0.015644\n",
      "[054/00295] train_loss: 0.016448\n",
      "[054/00345] train_loss: 0.016040\n",
      "[054/00395] train_loss: 0.016362\n",
      "[054/00445] train_loss: 0.016231\n",
      "[054/00495] train_loss: 0.015762\n",
      "[054/00545] train_loss: 0.015732\n",
      "[054/00595] train_loss: 0.016257\n",
      "[054/00645] train_loss: 0.017053\n",
      "[054/00695] train_loss: 0.016803\n",
      "[054/00745] train_loss: 0.016541\n",
      "[054/00795] train_loss: 0.015591\n",
      "[054/00845] train_loss: 0.015263\n",
      "[054/00895] train_loss: 0.016076\n",
      "[054/00945] train_loss: 0.015757\n",
      "[054/00995] train_loss: 0.016266\n",
      "[054/01045] train_loss: 0.015794\n",
      "[054/01095] train_loss: 0.016363\n",
      "[054/01145] train_loss: 0.015740\n",
      "[054/01195] train_loss: 0.015909\n",
      "[055/00019] train_loss: 0.016468\n",
      "[055/00069] train_loss: 0.017680\n",
      "[055/00119] train_loss: 0.017779\n",
      "[055/00169] train_loss: 0.017142\n",
      "[055/00219] train_loss: 0.016573\n",
      "[055/00269] train_loss: 0.016031\n",
      "[055/00319] train_loss: 0.015838\n",
      "[055/00369] train_loss: 0.016725\n",
      "[055/00419] train_loss: 0.016685\n",
      "[055/00469] train_loss: 0.016453\n",
      "[055/00519] train_loss: 0.016636\n",
      "[055/00569] train_loss: 0.016516\n",
      "[055/00619] train_loss: 0.016793\n",
      "[055/00669] train_loss: 0.015052\n",
      "[055/00719] train_loss: 0.016374\n",
      "[055/00769] train_loss: 0.016538\n",
      "[055/00819] train_loss: 0.016198\n",
      "[055/00869] train_loss: 0.015758\n",
      "[055/00919] train_loss: 0.014943\n",
      "[055/00969] train_loss: 0.016089\n",
      "[055/01019] train_loss: 0.015259\n",
      "[055/01069] train_loss: 0.015162\n",
      "[055/01119] train_loss: 0.015799\n",
      "[055/01169] train_loss: 0.015231\n",
      "[055/01219] train_loss: 0.016900\n",
      "[056/00043] train_loss: 0.018591\n",
      "[056/00093] train_loss: 0.017882\n",
      "[056/00143] train_loss: 0.017130\n",
      "[056/00193] train_loss: 0.017320\n",
      "[056/00243] train_loss: 0.015847\n",
      "[056/00293] train_loss: 0.016442\n",
      "[056/00343] train_loss: 0.016681\n",
      "[056/00393] train_loss: 0.017089\n",
      "[056/00443] train_loss: 0.015885\n",
      "[056/00493] train_loss: 0.016367\n",
      "[056/00543] train_loss: 0.016238\n",
      "[056/00593] train_loss: 0.016022\n",
      "[056/00643] train_loss: 0.016489\n",
      "[056/00693] train_loss: 0.015346\n",
      "[056/00743] train_loss: 0.015994\n",
      "[056/00793] train_loss: 0.015571\n",
      "[056/00843] train_loss: 0.015938\n",
      "[056/00893] train_loss: 0.015622\n",
      "[056/00943] train_loss: 0.015652\n",
      "[056/00993] train_loss: 0.015626\n",
      "[056/01043] train_loss: 0.015991\n",
      "[056/01093] train_loss: 0.016404\n",
      "[056/01143] train_loss: 0.016128\n",
      "[056/01193] train_loss: 0.016318\n",
      "[057/00017] train_loss: 0.016488\n",
      "[057/00067] train_loss: 0.017743\n",
      "[057/00117] train_loss: 0.017303\n",
      "[057/00167] train_loss: 0.016618\n",
      "[057/00217] train_loss: 0.016803\n",
      "[057/00267] train_loss: 0.016884\n",
      "[057/00317] train_loss: 0.016398\n",
      "[057/00367] train_loss: 0.017042\n",
      "[057/00417] train_loss: 0.016121\n",
      "[057/00467] train_loss: 0.015717\n",
      "[057/00517] train_loss: 0.015557\n",
      "[057/00567] train_loss: 0.015567\n",
      "[057/00617] train_loss: 0.016071\n",
      "[057/00667] train_loss: 0.015824\n",
      "[057/00717] train_loss: 0.015443\n",
      "[057/00767] train_loss: 0.016047\n",
      "[057/00817] train_loss: 0.015412\n",
      "[057/00867] train_loss: 0.016202\n",
      "[057/00917] train_loss: 0.016121\n",
      "[057/00967] train_loss: 0.015831\n",
      "[057/01017] train_loss: 0.015509\n",
      "[057/01067] train_loss: 0.015433\n",
      "[057/01117] train_loss: 0.015678\n",
      "[057/01167] train_loss: 0.016589\n",
      "[057/01217] train_loss: 0.015807\n",
      "[058/00041] train_loss: 0.017529\n",
      "[058/00091] train_loss: 0.017316\n",
      "[058/00141] train_loss: 0.017050\n",
      "[058/00191] train_loss: 0.016819\n",
      "[058/00241] train_loss: 0.017182\n",
      "[058/00291] train_loss: 0.016690\n",
      "[058/00341] train_loss: 0.015721\n",
      "[058/00391] train_loss: 0.016080\n",
      "[058/00441] train_loss: 0.016484\n",
      "[058/00491] train_loss: 0.016166\n",
      "[058/00541] train_loss: 0.015423\n",
      "[058/00591] train_loss: 0.015394\n",
      "[058/00641] train_loss: 0.016594\n",
      "[058/00691] train_loss: 0.015093\n",
      "[058/00741] train_loss: 0.015610\n",
      "[058/00791] train_loss: 0.016578\n",
      "[058/00841] train_loss: 0.016162\n",
      "[058/00891] train_loss: 0.015998\n",
      "[058/00941] train_loss: 0.015889\n",
      "[058/00991] train_loss: 0.015458\n",
      "[058/01041] train_loss: 0.016939\n",
      "[058/01091] train_loss: 0.015101\n",
      "[058/01141] train_loss: 0.015702\n",
      "[058/01191] train_loss: 0.015723\n",
      "[059/00015] train_loss: 0.016612\n",
      "[059/00065] train_loss: 0.018678\n",
      "[059/00115] train_loss: 0.017139\n",
      "[059/00165] train_loss: 0.016906\n",
      "[059/00215] train_loss: 0.017228\n",
      "[059/00265] train_loss: 0.016017\n",
      "[059/00315] train_loss: 0.016700\n",
      "[059/00365] train_loss: 0.016066\n",
      "[059/00415] train_loss: 0.016148\n",
      "[059/00465] train_loss: 0.015759\n",
      "[059/00515] train_loss: 0.015480\n",
      "[059/00565] train_loss: 0.016054\n",
      "[059/00615] train_loss: 0.016057\n",
      "[059/00665] train_loss: 0.016128\n",
      "[059/00715] train_loss: 0.015912\n",
      "[059/00765] train_loss: 0.015794\n",
      "[059/00815] train_loss: 0.016359\n",
      "[059/00865] train_loss: 0.015478\n",
      "[059/00915] train_loss: 0.016024\n",
      "[059/00965] train_loss: 0.015697\n",
      "[059/01015] train_loss: 0.016720\n",
      "[059/01065] train_loss: 0.015534\n",
      "[059/01115] train_loss: 0.015996\n",
      "[059/01165] train_loss: 0.015608\n",
      "[059/01215] train_loss: 0.015389\n",
      "[060/00039] train_loss: 0.017708\n",
      "[060/00089] train_loss: 0.017118\n",
      "[060/00139] train_loss: 0.017947\n",
      "[060/00189] train_loss: 0.016725\n",
      "[060/00239] train_loss: 0.017193\n",
      "[060/00289] train_loss: 0.016170\n",
      "[060/00339] train_loss: 0.015972\n",
      "[060/00389] train_loss: 0.015438\n",
      "[060/00439] train_loss: 0.015245\n",
      "[060/00489] train_loss: 0.016077\n",
      "[060/00539] train_loss: 0.016529\n",
      "[060/00589] train_loss: 0.015481\n",
      "[060/00639] train_loss: 0.015742\n",
      "[060/00689] train_loss: 0.015579\n",
      "[060/00739] train_loss: 0.015355\n",
      "[060/00789] train_loss: 0.015440\n",
      "[060/00839] train_loss: 0.016035\n",
      "[060/00889] train_loss: 0.014993\n",
      "[060/00939] train_loss: 0.016499\n",
      "[060/00989] train_loss: 0.015537\n",
      "[060/01039] train_loss: 0.014711\n",
      "[060/01089] train_loss: 0.016122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[060/01139] train_loss: 0.015105\n",
      "[060/01189] train_loss: 0.015605\n",
      "[061/00013] train_loss: 0.015672\n",
      "[061/00063] train_loss: 0.018073\n",
      "[061/00113] train_loss: 0.016587\n",
      "[061/00163] train_loss: 0.017459\n",
      "[061/00213] train_loss: 0.016914\n",
      "[061/00263] train_loss: 0.016583\n",
      "[061/00313] train_loss: 0.016272\n",
      "[061/00363] train_loss: 0.015841\n",
      "[061/00413] train_loss: 0.015656\n",
      "[061/00463] train_loss: 0.015889\n",
      "[061/00513] train_loss: 0.015732\n",
      "[061/00563] train_loss: 0.016299\n",
      "[061/00613] train_loss: 0.015288\n",
      "[061/00663] train_loss: 0.016972\n",
      "[061/00713] train_loss: 0.015431\n",
      "[061/00763] train_loss: 0.015375\n",
      "[061/00813] train_loss: 0.015967\n",
      "[061/00863] train_loss: 0.015356\n",
      "[061/00913] train_loss: 0.016152\n",
      "[061/00963] train_loss: 0.016529\n",
      "[061/01013] train_loss: 0.015726\n",
      "[061/01063] train_loss: 0.015548\n",
      "[061/01113] train_loss: 0.014635\n",
      "[061/01163] train_loss: 0.014927\n",
      "[061/01213] train_loss: 0.014701\n",
      "[062/00037] train_loss: 0.018065\n",
      "[062/00087] train_loss: 0.018582\n",
      "[062/00137] train_loss: 0.017062\n",
      "[062/00187] train_loss: 0.016835\n",
      "[062/00237] train_loss: 0.015868\n",
      "[062/00287] train_loss: 0.016074\n",
      "[062/00337] train_loss: 0.016812\n",
      "[062/00387] train_loss: 0.015884\n",
      "[062/00437] train_loss: 0.016303\n",
      "[062/00487] train_loss: 0.015570\n",
      "[062/00537] train_loss: 0.015781\n",
      "[062/00587] train_loss: 0.015476\n",
      "[062/00637] train_loss: 0.015635\n",
      "[062/00687] train_loss: 0.015517\n",
      "[062/00737] train_loss: 0.015904\n",
      "[062/00787] train_loss: 0.015352\n",
      "[062/00837] train_loss: 0.015682\n",
      "[062/00887] train_loss: 0.015190\n",
      "[062/00937] train_loss: 0.015533\n",
      "[062/00987] train_loss: 0.015339\n",
      "[062/01037] train_loss: 0.015334\n",
      "[062/01087] train_loss: 0.015600\n",
      "[062/01137] train_loss: 0.015013\n",
      "[062/01187] train_loss: 0.015930\n",
      "[063/00011] train_loss: 0.015846\n",
      "[063/00061] train_loss: 0.018308\n",
      "[063/00111] train_loss: 0.017349\n",
      "[063/00161] train_loss: 0.016945\n",
      "[063/00211] train_loss: 0.016317\n",
      "[063/00261] train_loss: 0.016733\n",
      "[063/00311] train_loss: 0.016197\n",
      "[063/00361] train_loss: 0.015545\n",
      "[063/00411] train_loss: 0.015688\n",
      "[063/00461] train_loss: 0.015970\n",
      "[063/00511] train_loss: 0.015792\n",
      "[063/00561] train_loss: 0.016357\n",
      "[063/00611] train_loss: 0.015434\n",
      "[063/00661] train_loss: 0.015833\n",
      "[063/00711] train_loss: 0.015990\n",
      "[063/00761] train_loss: 0.015502\n",
      "[063/00811] train_loss: 0.015326\n",
      "[063/00861] train_loss: 0.015351\n",
      "[063/00911] train_loss: 0.016313\n",
      "[063/00961] train_loss: 0.015184\n",
      "[063/01011] train_loss: 0.015522\n",
      "[063/01061] train_loss: 0.015238\n",
      "[063/01111] train_loss: 0.015526\n",
      "[063/01161] train_loss: 0.015069\n",
      "[063/01211] train_loss: 0.015162\n",
      "[064/00035] train_loss: 0.017224\n",
      "[064/00085] train_loss: 0.017159\n",
      "[064/00135] train_loss: 0.016456\n",
      "[064/00185] train_loss: 0.016328\n",
      "[064/00235] train_loss: 0.016252\n",
      "[064/00285] train_loss: 0.016250\n",
      "[064/00335] train_loss: 0.015759\n",
      "[064/00385] train_loss: 0.016050\n",
      "[064/00435] train_loss: 0.016149\n",
      "[064/00485] train_loss: 0.015668\n",
      "[064/00535] train_loss: 0.015246\n",
      "[064/00585] train_loss: 0.014754\n",
      "[064/00635] train_loss: 0.015624\n",
      "[064/00685] train_loss: 0.015547\n",
      "[064/00735] train_loss: 0.015078\n",
      "[064/00785] train_loss: 0.015588\n",
      "[064/00835] train_loss: 0.016060\n",
      "[064/00885] train_loss: 0.016083\n",
      "[064/00935] train_loss: 0.015350\n",
      "[064/00985] train_loss: 0.015297\n",
      "[064/01035] train_loss: 0.016876\n",
      "[064/01085] train_loss: 0.015399\n",
      "[064/01135] train_loss: 0.015152\n",
      "[064/01185] train_loss: 0.015591\n",
      "[065/00009] train_loss: 0.015761\n",
      "[065/00059] train_loss: 0.017218\n",
      "[065/00109] train_loss: 0.017124\n",
      "[065/00159] train_loss: 0.016512\n",
      "[065/00209] train_loss: 0.016281\n",
      "[065/00259] train_loss: 0.016221\n",
      "[065/00309] train_loss: 0.015729\n",
      "[065/00359] train_loss: 0.015157\n",
      "[065/00409] train_loss: 0.016350\n",
      "[065/00459] train_loss: 0.015839\n",
      "[065/00509] train_loss: 0.015817\n",
      "[065/00559] train_loss: 0.015151\n",
      "[065/00609] train_loss: 0.016492\n",
      "[065/00659] train_loss: 0.015434\n",
      "[065/00709] train_loss: 0.016097\n",
      "[065/00759] train_loss: 0.015047\n",
      "[065/00809] train_loss: 0.015818\n",
      "[065/00859] train_loss: 0.015876\n",
      "[065/00909] train_loss: 0.015634\n",
      "[065/00959] train_loss: 0.015624\n",
      "[065/01009] train_loss: 0.015620\n",
      "[065/01059] train_loss: 0.015360\n",
      "[065/01109] train_loss: 0.014843\n",
      "[065/01159] train_loss: 0.015210\n",
      "[065/01209] train_loss: 0.014682\n",
      "[066/00033] train_loss: 0.016808\n",
      "[066/00083] train_loss: 0.017599\n",
      "[066/00133] train_loss: 0.016879\n",
      "[066/00183] train_loss: 0.016166\n",
      "[066/00233] train_loss: 0.015443\n",
      "[066/00283] train_loss: 0.016112\n",
      "[066/00333] train_loss: 0.015257\n",
      "[066/00383] train_loss: 0.016050\n",
      "[066/00433] train_loss: 0.015266\n",
      "[066/00483] train_loss: 0.015736\n",
      "[066/00533] train_loss: 0.015626\n",
      "[066/00583] train_loss: 0.015401\n",
      "[066/00633] train_loss: 0.015575\n",
      "[066/00683] train_loss: 0.016090\n",
      "[066/00733] train_loss: 0.014784\n",
      "[066/00783] train_loss: 0.015232\n",
      "[066/00833] train_loss: 0.015794\n",
      "[066/00883] train_loss: 0.016058\n",
      "[066/00933] train_loss: 0.014302\n",
      "[066/00983] train_loss: 0.015268\n",
      "[066/01033] train_loss: 0.015753\n",
      "[066/01083] train_loss: 0.015033\n",
      "[066/01133] train_loss: 0.015400\n",
      "[066/01183] train_loss: 0.015982\n",
      "[067/00007] train_loss: 0.016167\n",
      "[067/00057] train_loss: 0.017627\n",
      "[067/00107] train_loss: 0.016769\n",
      "[067/00157] train_loss: 0.015842\n",
      "[067/00207] train_loss: 0.016123\n",
      "[067/00257] train_loss: 0.015776\n",
      "[067/00307] train_loss: 0.015069\n",
      "[067/00357] train_loss: 0.015785\n",
      "[067/00407] train_loss: 0.015064\n",
      "[067/00457] train_loss: 0.015670\n",
      "[067/00507] train_loss: 0.014871\n",
      "[067/00557] train_loss: 0.015858\n",
      "[067/00607] train_loss: 0.015342\n",
      "[067/00657] train_loss: 0.015509\n",
      "[067/00707] train_loss: 0.015607\n",
      "[067/00757] train_loss: 0.016520\n",
      "[067/00807] train_loss: 0.015111\n",
      "[067/00857] train_loss: 0.015876\n",
      "[067/00907] train_loss: 0.014932\n",
      "[067/00957] train_loss: 0.015040\n",
      "[067/01007] train_loss: 0.016521\n",
      "[067/01057] train_loss: 0.015671\n",
      "[067/01107] train_loss: 0.015877\n",
      "[067/01157] train_loss: 0.015780\n",
      "[067/01207] train_loss: 0.015460\n",
      "[068/00031] train_loss: 0.016800\n",
      "[068/00081] train_loss: 0.017133\n",
      "[068/00131] train_loss: 0.016874\n",
      "[068/00181] train_loss: 0.015323\n",
      "[068/00231] train_loss: 0.016500\n",
      "[068/00281] train_loss: 0.015557\n",
      "[068/00331] train_loss: 0.015640\n",
      "[068/00381] train_loss: 0.016232\n",
      "[068/00431] train_loss: 0.016196\n",
      "[068/00481] train_loss: 0.015891\n",
      "[068/00531] train_loss: 0.016003\n",
      "[068/00581] train_loss: 0.015551\n",
      "[068/00631] train_loss: 0.015451\n",
      "[068/00681] train_loss: 0.015503\n",
      "[068/00731] train_loss: 0.015988\n",
      "[068/00781] train_loss: 0.015290\n",
      "[068/00831] train_loss: 0.015738\n",
      "[068/00881] train_loss: 0.015034\n",
      "[068/00931] train_loss: 0.015414\n",
      "[068/00981] train_loss: 0.016512\n",
      "[068/01031] train_loss: 0.016353\n",
      "[068/01081] train_loss: 0.015794\n",
      "[068/01131] train_loss: 0.015570\n",
      "[068/01181] train_loss: 0.015129\n",
      "[069/00005] train_loss: 0.015964\n",
      "[069/00055] train_loss: 0.017846\n",
      "[069/00105] train_loss: 0.016694\n",
      "[069/00155] train_loss: 0.016072\n",
      "[069/00205] train_loss: 0.016616\n",
      "[069/00255] train_loss: 0.015621\n",
      "[069/00305] train_loss: 0.015256\n",
      "[069/00355] train_loss: 0.016382\n",
      "[069/00405] train_loss: 0.015383\n",
      "[069/00455] train_loss: 0.016105\n",
      "[069/00505] train_loss: 0.015968\n",
      "[069/00555] train_loss: 0.014654\n",
      "[069/00605] train_loss: 0.014607\n",
      "[069/00655] train_loss: 0.015730\n",
      "[069/00705] train_loss: 0.015886\n",
      "[069/00755] train_loss: 0.015470\n",
      "[069/00805] train_loss: 0.015632\n",
      "[069/00855] train_loss: 0.015574\n",
      "[069/00905] train_loss: 0.015078\n",
      "[069/00955] train_loss: 0.015112\n",
      "[069/01005] train_loss: 0.015321\n",
      "[069/01055] train_loss: 0.014639\n",
      "[069/01105] train_loss: 0.015652\n",
      "[069/01155] train_loss: 0.014903\n",
      "[069/01205] train_loss: 0.015369\n",
      "[070/00029] train_loss: 0.016012\n",
      "[070/00079] train_loss: 0.016710\n",
      "[070/00129] train_loss: 0.016614\n",
      "[070/00179] train_loss: 0.016173\n",
      "[070/00229] train_loss: 0.016216\n",
      "[070/00279] train_loss: 0.015613\n",
      "[070/00329] train_loss: 0.015659\n",
      "[070/00379] train_loss: 0.014783\n",
      "[070/00429] train_loss: 0.015819\n",
      "[070/00479] train_loss: 0.015688\n",
      "[070/00529] train_loss: 0.015458\n",
      "[070/00579] train_loss: 0.016091\n",
      "[070/00629] train_loss: 0.015606\n",
      "[070/00679] train_loss: 0.015095\n",
      "[070/00729] train_loss: 0.014728\n",
      "[070/00779] train_loss: 0.015971\n",
      "[070/00829] train_loss: 0.015982\n",
      "[070/00879] train_loss: 0.015340\n",
      "[070/00929] train_loss: 0.015478\n",
      "[070/00979] train_loss: 0.015829\n",
      "[070/01029] train_loss: 0.015709\n",
      "[070/01079] train_loss: 0.015717\n",
      "[070/01129] train_loss: 0.016168\n",
      "[070/01179] train_loss: 0.015232\n",
      "[071/00003] train_loss: 0.014816\n",
      "[071/00053] train_loss: 0.016771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[071/00103] train_loss: 0.016585\n",
      "[071/00153] train_loss: 0.015959\n",
      "[071/00203] train_loss: 0.015997\n",
      "[071/00253] train_loss: 0.016022\n",
      "[071/00303] train_loss: 0.016400\n",
      "[071/00353] train_loss: 0.015019\n",
      "[071/00403] train_loss: 0.014959\n",
      "[071/00453] train_loss: 0.016080\n",
      "[071/00503] train_loss: 0.014389\n",
      "[071/00553] train_loss: 0.015438\n",
      "[071/00603] train_loss: 0.015434\n",
      "[071/00653] train_loss: 0.014991\n",
      "[071/00703] train_loss: 0.015280\n",
      "[071/00753] train_loss: 0.015629\n",
      "[071/00803] train_loss: 0.015211\n",
      "[071/00853] train_loss: 0.015182\n",
      "[071/00903] train_loss: 0.014629\n",
      "[071/00953] train_loss: 0.015069\n",
      "[071/01003] train_loss: 0.014755\n",
      "[071/01053] train_loss: 0.015283\n",
      "[071/01103] train_loss: 0.014502\n",
      "[071/01153] train_loss: 0.015100\n",
      "[071/01203] train_loss: 0.015540\n",
      "[072/00027] train_loss: 0.015913\n",
      "[072/00077] train_loss: 0.017252\n",
      "[072/00127] train_loss: 0.016485\n",
      "[072/00177] train_loss: 0.016611\n",
      "[072/00227] train_loss: 0.015882\n",
      "[072/00277] train_loss: 0.015873\n",
      "[072/00327] train_loss: 0.016473\n",
      "[072/00377] train_loss: 0.015391\n",
      "[072/00427] train_loss: 0.015875\n",
      "[072/00477] train_loss: 0.015468\n",
      "[072/00527] train_loss: 0.014836\n",
      "[072/00577] train_loss: 0.015444\n",
      "[072/00627] train_loss: 0.014796\n",
      "[072/00677] train_loss: 0.015577\n",
      "[072/00727] train_loss: 0.015393\n",
      "[072/00777] train_loss: 0.015389\n",
      "[072/00827] train_loss: 0.015355\n",
      "[072/00877] train_loss: 0.014262\n",
      "[072/00927] train_loss: 0.014887\n",
      "[072/00977] train_loss: 0.015559\n",
      "[072/01027] train_loss: 0.015070\n",
      "[072/01077] train_loss: 0.014899\n",
      "[072/01127] train_loss: 0.015287\n",
      "[072/01177] train_loss: 0.014515\n",
      "[073/00001] train_loss: 0.015453\n",
      "[073/00051] train_loss: 0.018462\n",
      "[073/00101] train_loss: 0.016345\n",
      "[073/00151] train_loss: 0.015930\n",
      "[073/00201] train_loss: 0.016204\n",
      "[073/00251] train_loss: 0.016246\n",
      "[073/00301] train_loss: 0.016887\n",
      "[073/00351] train_loss: 0.015448\n",
      "[073/00401] train_loss: 0.015643\n",
      "[073/00451] train_loss: 0.014886\n",
      "[073/00501] train_loss: 0.016072\n",
      "[073/00551] train_loss: 0.016017\n",
      "[073/00601] train_loss: 0.014685\n",
      "[073/00651] train_loss: 0.016125\n",
      "[073/00701] train_loss: 0.014642\n",
      "[073/00751] train_loss: 0.014851\n",
      "[073/00801] train_loss: 0.015145\n",
      "[073/00851] train_loss: 0.014822\n",
      "[073/00901] train_loss: 0.015279\n",
      "[073/00951] train_loss: 0.014831\n",
      "[073/01001] train_loss: 0.014638\n",
      "[073/01051] train_loss: 0.015347\n",
      "[073/01101] train_loss: 0.015048\n",
      "[073/01151] train_loss: 0.014780\n",
      "[073/01201] train_loss: 0.015272\n",
      "[074/00025] train_loss: 0.015975\n",
      "[074/00075] train_loss: 0.017157\n",
      "[074/00125] train_loss: 0.017232\n",
      "[074/00175] train_loss: 0.016810\n",
      "[074/00225] train_loss: 0.015544\n",
      "[074/00275] train_loss: 0.016093\n",
      "[074/00325] train_loss: 0.015582\n",
      "[074/00375] train_loss: 0.015259\n",
      "[074/00425] train_loss: 0.015320\n",
      "[074/00475] train_loss: 0.016005\n",
      "[074/00525] train_loss: 0.014513\n",
      "[074/00575] train_loss: 0.015353\n",
      "[074/00625] train_loss: 0.014367\n",
      "[074/00675] train_loss: 0.015910\n",
      "[074/00725] train_loss: 0.015369\n",
      "[074/00775] train_loss: 0.015120\n",
      "[074/00825] train_loss: 0.014825\n",
      "[074/00875] train_loss: 0.015295\n",
      "[074/00925] train_loss: 0.013873\n",
      "[074/00975] train_loss: 0.014564\n",
      "[074/01025] train_loss: 0.014734\n",
      "[074/01075] train_loss: 0.014226\n",
      "[074/01125] train_loss: 0.015288\n",
      "[074/01175] train_loss: 0.014907\n",
      "[074/01225] train_loss: 0.015273\n",
      "[075/00049] train_loss: 0.017180\n",
      "[075/00099] train_loss: 0.016856\n",
      "[075/00149] train_loss: 0.016684\n",
      "[075/00199] train_loss: 0.015267\n",
      "[075/00249] train_loss: 0.016008\n",
      "[075/00299] train_loss: 0.015900\n",
      "[075/00349] train_loss: 0.015590\n",
      "[075/00399] train_loss: 0.015782\n",
      "[075/00449] train_loss: 0.015139\n",
      "[075/00499] train_loss: 0.014621\n",
      "[075/00549] train_loss: 0.015027\n",
      "[075/00599] train_loss: 0.015318\n",
      "[075/00649] train_loss: 0.014878\n",
      "[075/00699] train_loss: 0.016109\n",
      "[075/00749] train_loss: 0.015384\n",
      "[075/00799] train_loss: 0.014736\n",
      "[075/00849] train_loss: 0.014743\n",
      "[075/00899] train_loss: 0.015335\n",
      "[075/00949] train_loss: 0.014876\n",
      "[075/00999] train_loss: 0.015299\n",
      "[075/01049] train_loss: 0.014279\n",
      "[075/01099] train_loss: 0.014963\n",
      "[075/01149] train_loss: 0.015674\n",
      "[075/01199] train_loss: 0.014912\n",
      "[076/00023] train_loss: 0.016563\n",
      "[076/00073] train_loss: 0.016958\n",
      "[076/00123] train_loss: 0.017122\n",
      "[076/00173] train_loss: 0.016412\n",
      "[076/00223] train_loss: 0.015660\n",
      "[076/00273] train_loss: 0.015778\n",
      "[076/00323] train_loss: 0.015281\n",
      "[076/00373] train_loss: 0.015367\n",
      "[076/00423] train_loss: 0.015683\n",
      "[076/00473] train_loss: 0.015302\n",
      "[076/00523] train_loss: 0.014709\n",
      "[076/00573] train_loss: 0.015951\n",
      "[076/00623] train_loss: 0.014903\n",
      "[076/00673] train_loss: 0.014335\n",
      "[076/00723] train_loss: 0.015062\n",
      "[076/00773] train_loss: 0.015183\n",
      "[076/00823] train_loss: 0.015339\n",
      "[076/00873] train_loss: 0.015532\n",
      "[076/00923] train_loss: 0.015889\n",
      "[076/00973] train_loss: 0.015104\n",
      "[076/01023] train_loss: 0.014682\n",
      "[076/01073] train_loss: 0.015134\n",
      "[076/01123] train_loss: 0.015250\n",
      "[076/01173] train_loss: 0.015263\n",
      "[076/01223] train_loss: 0.013951\n",
      "[077/00047] train_loss: 0.016927\n",
      "[077/00097] train_loss: 0.016300\n",
      "[077/00147] train_loss: 0.014984\n",
      "[077/00197] train_loss: 0.015597\n",
      "[077/00247] train_loss: 0.016424\n",
      "[077/00297] train_loss: 0.014444\n",
      "[077/00347] train_loss: 0.015035\n",
      "[077/00397] train_loss: 0.015563\n",
      "[077/00447] train_loss: 0.015889\n",
      "[077/00497] train_loss: 0.016029\n",
      "[077/00547] train_loss: 0.014565\n",
      "[077/00597] train_loss: 0.014361\n",
      "[077/00647] train_loss: 0.016127\n",
      "[077/00697] train_loss: 0.014907\n",
      "[077/00747] train_loss: 0.014766\n",
      "[077/00797] train_loss: 0.015299\n",
      "[077/00847] train_loss: 0.015727\n",
      "[077/00897] train_loss: 0.014958\n",
      "[077/00947] train_loss: 0.015727\n",
      "[077/00997] train_loss: 0.014370\n",
      "[077/01047] train_loss: 0.014178\n",
      "[077/01097] train_loss: 0.014943\n",
      "[077/01147] train_loss: 0.014869\n",
      "[077/01197] train_loss: 0.014526\n",
      "[078/00021] train_loss: 0.016351\n",
      "[078/00071] train_loss: 0.016663\n",
      "[078/00121] train_loss: 0.016932\n",
      "[078/00171] train_loss: 0.016124\n",
      "[078/00221] train_loss: 0.016401\n",
      "[078/00271] train_loss: 0.015951\n",
      "[078/00321] train_loss: 0.015555\n",
      "[078/00371] train_loss: 0.015117\n",
      "[078/00421] train_loss: 0.015837\n",
      "[078/00471] train_loss: 0.015077\n",
      "[078/00521] train_loss: 0.014425\n",
      "[078/00571] train_loss: 0.014866\n",
      "[078/00621] train_loss: 0.014766\n",
      "[078/00671] train_loss: 0.015458\n",
      "[078/00721] train_loss: 0.015321\n",
      "[078/00771] train_loss: 0.014770\n",
      "[078/00821] train_loss: 0.015041\n",
      "[078/00871] train_loss: 0.014173\n",
      "[078/00921] train_loss: 0.015220\n",
      "[078/00971] train_loss: 0.015098\n",
      "[078/01021] train_loss: 0.015189\n",
      "[078/01071] train_loss: 0.014983\n",
      "[078/01121] train_loss: 0.014657\n",
      "[078/01171] train_loss: 0.014748\n",
      "[078/01221] train_loss: 0.014878\n",
      "[079/00045] train_loss: 0.017251\n",
      "[079/00095] train_loss: 0.015975\n",
      "[079/00145] train_loss: 0.017085\n",
      "[079/00195] train_loss: 0.015179\n",
      "[079/00245] train_loss: 0.014721\n",
      "[079/00295] train_loss: 0.015689\n",
      "[079/00345] train_loss: 0.015189\n",
      "[079/00395] train_loss: 0.014573\n",
      "[079/00445] train_loss: 0.015346\n",
      "[079/00495] train_loss: 0.015441\n",
      "[079/00545] train_loss: 0.014371\n",
      "[079/00595] train_loss: 0.015467\n",
      "[079/00645] train_loss: 0.014561\n",
      "[079/00695] train_loss: 0.015862\n",
      "[079/00745] train_loss: 0.014903\n",
      "[079/00795] train_loss: 0.014724\n",
      "[079/00845] train_loss: 0.014873\n",
      "[079/00895] train_loss: 0.014894\n",
      "[079/00945] train_loss: 0.015575\n",
      "[079/00995] train_loss: 0.014741\n",
      "[079/01045] train_loss: 0.015079\n",
      "[079/01095] train_loss: 0.014813\n",
      "[079/01145] train_loss: 0.014014\n",
      "[079/01195] train_loss: 0.014598\n",
      "[080/00019] train_loss: 0.015774\n",
      "[080/00069] train_loss: 0.016739\n",
      "[080/00119] train_loss: 0.016111\n",
      "[080/00169] train_loss: 0.014906\n",
      "[080/00219] train_loss: 0.016577\n",
      "[080/00269] train_loss: 0.015643\n",
      "[080/00319] train_loss: 0.016248\n",
      "[080/00369] train_loss: 0.014596\n",
      "[080/00419] train_loss: 0.015016\n",
      "[080/00469] train_loss: 0.015444\n",
      "[080/00519] train_loss: 0.014055\n",
      "[080/00569] train_loss: 0.015413\n",
      "[080/00619] train_loss: 0.015612\n",
      "[080/00669] train_loss: 0.014679\n",
      "[080/00719] train_loss: 0.015299\n",
      "[080/00769] train_loss: 0.014344\n",
      "[080/00819] train_loss: 0.015128\n",
      "[080/00869] train_loss: 0.015557\n",
      "[080/00919] train_loss: 0.014726\n",
      "[080/00969] train_loss: 0.015229\n",
      "[080/01019] train_loss: 0.015169\n",
      "[080/01069] train_loss: 0.014683\n",
      "[080/01119] train_loss: 0.016371\n",
      "[080/01169] train_loss: 0.015188\n",
      "[080/01219] train_loss: 0.014770\n",
      "[081/00043] train_loss: 0.016313\n",
      "[081/00093] train_loss: 0.016613\n",
      "[081/00143] train_loss: 0.015635\n",
      "[081/00193] train_loss: 0.016218\n",
      "[081/00243] train_loss: 0.015534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[081/00293] train_loss: 0.015477\n",
      "[081/00343] train_loss: 0.015979\n",
      "[081/00393] train_loss: 0.015508\n",
      "[081/00443] train_loss: 0.014696\n",
      "[081/00493] train_loss: 0.014510\n",
      "[081/00543] train_loss: 0.015474\n",
      "[081/00593] train_loss: 0.015166\n",
      "[081/00643] train_loss: 0.014609\n",
      "[081/00693] train_loss: 0.015064\n",
      "[081/00743] train_loss: 0.015333\n",
      "[081/00793] train_loss: 0.014574\n",
      "[081/00843] train_loss: 0.015510\n",
      "[081/00893] train_loss: 0.014162\n",
      "[081/00943] train_loss: 0.015669\n",
      "[081/00993] train_loss: 0.015200\n",
      "[081/01043] train_loss: 0.014454\n",
      "[081/01093] train_loss: 0.015271\n",
      "[081/01143] train_loss: 0.014098\n",
      "[081/01193] train_loss: 0.015259\n",
      "[082/00017] train_loss: 0.016194\n",
      "[082/00067] train_loss: 0.016566\n",
      "[082/00117] train_loss: 0.015617\n",
      "[082/00167] train_loss: 0.015929\n",
      "[082/00217] train_loss: 0.015560\n",
      "[082/00267] train_loss: 0.016017\n",
      "[082/00317] train_loss: 0.015026\n",
      "[082/00367] train_loss: 0.015558\n",
      "[082/00417] train_loss: 0.015722\n",
      "[082/00467] train_loss: 0.015256\n",
      "[082/00517] train_loss: 0.014947\n",
      "[082/00567] train_loss: 0.014586\n",
      "[082/00617] train_loss: 0.014994\n",
      "[082/00667] train_loss: 0.015306\n",
      "[082/00717] train_loss: 0.014844\n",
      "[082/00767] train_loss: 0.015092\n",
      "[082/00817] train_loss: 0.014951\n",
      "[082/00867] train_loss: 0.014923\n",
      "[082/00917] train_loss: 0.014763\n",
      "[082/00967] train_loss: 0.014956\n",
      "[082/01017] train_loss: 0.015261\n",
      "[082/01067] train_loss: 0.014460\n",
      "[082/01117] train_loss: 0.014927\n",
      "[082/01167] train_loss: 0.014824\n",
      "[082/01217] train_loss: 0.014976\n",
      "[083/00041] train_loss: 0.016367\n",
      "[083/00091] train_loss: 0.016057\n",
      "[083/00141] train_loss: 0.015790\n",
      "[083/00191] train_loss: 0.016115\n",
      "[083/00241] train_loss: 0.015186\n",
      "[083/00291] train_loss: 0.015506\n",
      "[083/00341] train_loss: 0.014579\n",
      "[083/00391] train_loss: 0.015675\n",
      "[083/00441] train_loss: 0.015322\n",
      "[083/00491] train_loss: 0.014871\n",
      "[083/00541] train_loss: 0.014888\n",
      "[083/00591] train_loss: 0.015596\n",
      "[083/00641] train_loss: 0.014932\n",
      "[083/00691] train_loss: 0.015686\n",
      "[083/00741] train_loss: 0.014083\n",
      "[083/00791] train_loss: 0.015787\n",
      "[083/00841] train_loss: 0.014597\n",
      "[083/00891] train_loss: 0.015149\n",
      "[083/00941] train_loss: 0.014635\n",
      "[083/00991] train_loss: 0.014051\n",
      "[083/01041] train_loss: 0.015251\n",
      "[083/01091] train_loss: 0.014630\n",
      "[083/01141] train_loss: 0.014543\n",
      "[083/01191] train_loss: 0.014723\n",
      "[084/00015] train_loss: 0.014505\n",
      "[084/00065] train_loss: 0.016146\n",
      "[084/00115] train_loss: 0.017330\n",
      "[084/00165] train_loss: 0.015490\n",
      "[084/00215] train_loss: 0.014841\n",
      "[084/00265] train_loss: 0.015320\n",
      "[084/00315] train_loss: 0.015185\n",
      "[084/00365] train_loss: 0.015038\n",
      "[084/00415] train_loss: 0.014405\n",
      "[084/00465] train_loss: 0.015203\n",
      "[084/00515] train_loss: 0.014589\n",
      "[084/00565] train_loss: 0.014729\n",
      "[084/00615] train_loss: 0.014592\n",
      "[084/00665] train_loss: 0.014825\n",
      "[084/00715] train_loss: 0.014519\n",
      "[084/00765] train_loss: 0.014466\n",
      "[084/00815] train_loss: 0.014623\n",
      "[084/00865] train_loss: 0.014634\n",
      "[084/00915] train_loss: 0.015107\n",
      "[084/00965] train_loss: 0.015318\n",
      "[084/01015] train_loss: 0.014016\n",
      "[084/01065] train_loss: 0.014960\n",
      "[084/01115] train_loss: 0.015118\n",
      "[084/01165] train_loss: 0.014668\n",
      "[084/01215] train_loss: 0.014558\n",
      "[085/00039] train_loss: 0.016032\n",
      "[085/00089] train_loss: 0.017201\n",
      "[085/00139] train_loss: 0.016129\n",
      "[085/00189] train_loss: 0.015987\n",
      "[085/00239] train_loss: 0.016605\n",
      "[085/00289] train_loss: 0.015633\n",
      "[085/00339] train_loss: 0.015070\n",
      "[085/00389] train_loss: 0.014467\n",
      "[085/00439] train_loss: 0.014995\n",
      "[085/00489] train_loss: 0.014938\n",
      "[085/00539] train_loss: 0.016239\n",
      "[085/00589] train_loss: 0.014160\n",
      "[085/00639] train_loss: 0.014493\n",
      "[085/00689] train_loss: 0.015421\n",
      "[085/00739] train_loss: 0.014279\n",
      "[085/00789] train_loss: 0.015143\n",
      "[085/00839] train_loss: 0.015232\n",
      "[085/00889] train_loss: 0.015157\n",
      "[085/00939] train_loss: 0.015506\n",
      "[085/00989] train_loss: 0.014342\n",
      "[085/01039] train_loss: 0.014420\n",
      "[085/01089] train_loss: 0.014135\n",
      "[085/01139] train_loss: 0.014619\n",
      "[085/01189] train_loss: 0.015029\n",
      "[086/00013] train_loss: 0.015153\n",
      "[086/00063] train_loss: 0.017203\n",
      "[086/00113] train_loss: 0.016640\n",
      "[086/00163] train_loss: 0.015645\n",
      "[086/00213] train_loss: 0.016070\n",
      "[086/00263] train_loss: 0.015027\n",
      "[086/00313] train_loss: 0.015257\n",
      "[086/00363] train_loss: 0.015098\n",
      "[086/00413] train_loss: 0.015038\n",
      "[086/00463] train_loss: 0.014643\n",
      "[086/00513] train_loss: 0.015578\n",
      "[086/00563] train_loss: 0.014608\n",
      "[086/00613] train_loss: 0.014736\n",
      "[086/00663] train_loss: 0.014646\n",
      "[086/00713] train_loss: 0.014568\n",
      "[086/00763] train_loss: 0.014215\n",
      "[086/00813] train_loss: 0.014774\n",
      "[086/00863] train_loss: 0.014614\n",
      "[086/00913] train_loss: 0.014856\n",
      "[086/00963] train_loss: 0.014018\n",
      "[086/01013] train_loss: 0.013931\n",
      "[086/01063] train_loss: 0.015373\n",
      "[086/01113] train_loss: 0.013888\n",
      "[086/01163] train_loss: 0.014829\n",
      "[086/01213] train_loss: 0.014263\n",
      "[087/00037] train_loss: 0.016015\n",
      "[087/00087] train_loss: 0.016208\n",
      "[087/00137] train_loss: 0.015706\n",
      "[087/00187] train_loss: 0.016383\n",
      "[087/00237] train_loss: 0.015077\n",
      "[087/00287] train_loss: 0.015401\n",
      "[087/00337] train_loss: 0.014660\n",
      "[087/00387] train_loss: 0.015678\n",
      "[087/00437] train_loss: 0.014794\n",
      "[087/00487] train_loss: 0.014949\n",
      "[087/00537] train_loss: 0.014257\n",
      "[087/00587] train_loss: 0.014850\n",
      "[087/00637] train_loss: 0.015771\n",
      "[087/00687] train_loss: 0.014797\n",
      "[087/00737] train_loss: 0.014987\n",
      "[087/00787] train_loss: 0.014665\n",
      "[087/00837] train_loss: 0.014096\n",
      "[087/00887] train_loss: 0.014477\n",
      "[087/00937] train_loss: 0.013929\n",
      "[087/00987] train_loss: 0.014451\n",
      "[087/01037] train_loss: 0.014764\n",
      "[087/01087] train_loss: 0.014252\n",
      "[087/01137] train_loss: 0.014106\n",
      "[087/01187] train_loss: 0.015244\n",
      "[088/00011] train_loss: 0.015641\n",
      "[088/00061] train_loss: 0.016782\n",
      "[088/00111] train_loss: 0.015618\n",
      "[088/00161] train_loss: 0.016200\n",
      "[088/00211] train_loss: 0.015538\n",
      "[088/00261] train_loss: 0.016019\n",
      "[088/00311] train_loss: 0.014662\n",
      "[088/00361] train_loss: 0.015762\n",
      "[088/00411] train_loss: 0.014750\n",
      "[088/00461] train_loss: 0.014726\n",
      "[088/00511] train_loss: 0.014662\n",
      "[088/00561] train_loss: 0.014272\n",
      "[088/00611] train_loss: 0.014178\n",
      "[088/00661] train_loss: 0.014254\n",
      "[088/00711] train_loss: 0.014315\n",
      "[088/00761] train_loss: 0.013912\n",
      "[088/00811] train_loss: 0.015458\n",
      "[088/00861] train_loss: 0.015042\n",
      "[088/00911] train_loss: 0.015336\n",
      "[088/00961] train_loss: 0.014662\n",
      "[088/01011] train_loss: 0.014460\n",
      "[088/01061] train_loss: 0.014435\n",
      "[088/01111] train_loss: 0.013832\n",
      "[088/01161] train_loss: 0.014359\n",
      "[088/01211] train_loss: 0.014336\n",
      "[089/00035] train_loss: 0.017112\n",
      "[089/00085] train_loss: 0.016382\n",
      "[089/00135] train_loss: 0.016037\n",
      "[089/00185] train_loss: 0.015246\n",
      "[089/00235] train_loss: 0.014696\n",
      "[089/00285] train_loss: 0.014935\n",
      "[089/00335] train_loss: 0.014700\n",
      "[089/00385] train_loss: 0.014876\n",
      "[089/00435] train_loss: 0.014939\n",
      "[089/00485] train_loss: 0.015064\n",
      "[089/00535] train_loss: 0.014750\n",
      "[089/00585] train_loss: 0.014954\n",
      "[089/00635] train_loss: 0.015190\n",
      "[089/00685] train_loss: 0.014092\n",
      "[089/00735] train_loss: 0.014514\n",
      "[089/00785] train_loss: 0.015179\n",
      "[089/00835] train_loss: 0.014092\n",
      "[089/00885] train_loss: 0.014358\n",
      "[089/00935] train_loss: 0.014214\n",
      "[089/00985] train_loss: 0.013894\n",
      "[089/01035] train_loss: 0.014251\n",
      "[089/01085] train_loss: 0.014873\n",
      "[089/01135] train_loss: 0.013868\n",
      "[089/01185] train_loss: 0.014273\n",
      "[090/00009] train_loss: 0.014777\n",
      "[090/00059] train_loss: 0.016392\n",
      "[090/00109] train_loss: 0.015865\n",
      "[090/00159] train_loss: 0.015430\n",
      "[090/00209] train_loss: 0.015057\n",
      "[090/00259] train_loss: 0.014892\n",
      "[090/00309] train_loss: 0.015715\n",
      "[090/00359] train_loss: 0.015601\n",
      "[090/00409] train_loss: 0.014389\n",
      "[090/00459] train_loss: 0.015495\n",
      "[090/00509] train_loss: 0.014066\n",
      "[090/00559] train_loss: 0.015043\n",
      "[090/00609] train_loss: 0.014654\n",
      "[090/00659] train_loss: 0.014752\n",
      "[090/00709] train_loss: 0.015022\n",
      "[090/00759] train_loss: 0.014204\n",
      "[090/00809] train_loss: 0.013942\n",
      "[090/00859] train_loss: 0.014977\n",
      "[090/00909] train_loss: 0.014524\n",
      "[090/00959] train_loss: 0.015107\n",
      "[090/01009] train_loss: 0.014459\n",
      "[090/01059] train_loss: 0.014298\n",
      "[090/01109] train_loss: 0.014970\n",
      "[090/01159] train_loss: 0.014524\n",
      "[090/01209] train_loss: 0.014604\n",
      "[091/00033] train_loss: 0.016282\n",
      "[091/00083] train_loss: 0.016210\n",
      "[091/00133] train_loss: 0.015855\n",
      "[091/00183] train_loss: 0.014970\n",
      "[091/00233] train_loss: 0.015930\n",
      "[091/00283] train_loss: 0.015875\n",
      "[091/00333] train_loss: 0.015152\n",
      "[091/00383] train_loss: 0.015200\n",
      "[091/00433] train_loss: 0.014990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[091/00483] train_loss: 0.015202\n",
      "[091/00533] train_loss: 0.014569\n",
      "[091/00583] train_loss: 0.015527\n",
      "[091/00633] train_loss: 0.014815\n",
      "[091/00683] train_loss: 0.015010\n",
      "[091/00733] train_loss: 0.014305\n",
      "[091/00783] train_loss: 0.014759\n",
      "[091/00833] train_loss: 0.014702\n",
      "[091/00883] train_loss: 0.014856\n",
      "[091/00933] train_loss: 0.013767\n",
      "[091/00983] train_loss: 0.014484\n",
      "[091/01033] train_loss: 0.014611\n",
      "[091/01083] train_loss: 0.014904\n",
      "[091/01133] train_loss: 0.014757\n",
      "[091/01183] train_loss: 0.014355\n",
      "[092/00007] train_loss: 0.014750\n",
      "[092/00057] train_loss: 0.016959\n",
      "[092/00107] train_loss: 0.015873\n",
      "[092/00157] train_loss: 0.015386\n",
      "[092/00207] train_loss: 0.014751\n",
      "[092/00257] train_loss: 0.014582\n",
      "[092/00307] train_loss: 0.013967\n",
      "[092/00357] train_loss: 0.014637\n",
      "[092/00407] train_loss: 0.014438\n",
      "[092/00457] train_loss: 0.014438\n",
      "[092/00507] train_loss: 0.014255\n",
      "[092/00557] train_loss: 0.014842\n",
      "[092/00607] train_loss: 0.014711\n",
      "[092/00657] train_loss: 0.014936\n",
      "[092/00707] train_loss: 0.014876\n",
      "[092/00757] train_loss: 0.014787\n",
      "[092/00807] train_loss: 0.014655\n",
      "[092/00857] train_loss: 0.014121\n",
      "[092/00907] train_loss: 0.014256\n",
      "[092/00957] train_loss: 0.015474\n",
      "[092/01007] train_loss: 0.013842\n",
      "[092/01057] train_loss: 0.014486\n",
      "[092/01107] train_loss: 0.015470\n",
      "[092/01157] train_loss: 0.015149\n",
      "[092/01207] train_loss: 0.014259\n",
      "[093/00031] train_loss: 0.015650\n",
      "[093/00081] train_loss: 0.014938\n",
      "[093/00131] train_loss: 0.015407\n",
      "[093/00181] train_loss: 0.015319\n",
      "[093/00231] train_loss: 0.015754\n",
      "[093/00281] train_loss: 0.015134\n",
      "[093/00331] train_loss: 0.014718\n",
      "[093/00381] train_loss: 0.014541\n",
      "[093/00431] train_loss: 0.015008\n",
      "[093/00481] train_loss: 0.014513\n",
      "[093/00531] train_loss: 0.014638\n",
      "[093/00581] train_loss: 0.014709\n",
      "[093/00631] train_loss: 0.014366\n",
      "[093/00681] train_loss: 0.015488\n",
      "[093/00731] train_loss: 0.014353\n",
      "[093/00781] train_loss: 0.015469\n",
      "[093/00831] train_loss: 0.015461\n",
      "[093/00881] train_loss: 0.015167\n",
      "[093/00931] train_loss: 0.015693\n",
      "[093/00981] train_loss: 0.014204\n",
      "[093/01031] train_loss: 0.014608\n",
      "[093/01081] train_loss: 0.013929\n",
      "[093/01131] train_loss: 0.014592\n",
      "[093/01181] train_loss: 0.014096\n",
      "[094/00005] train_loss: 0.014234\n",
      "[094/00055] train_loss: 0.016214\n",
      "[094/00105] train_loss: 0.015588\n",
      "[094/00155] train_loss: 0.015327\n",
      "[094/00205] train_loss: 0.015097\n",
      "[094/00255] train_loss: 0.014947\n",
      "[094/00305] train_loss: 0.013859\n",
      "[094/00355] train_loss: 0.015665\n",
      "[094/00405] train_loss: 0.014604\n",
      "[094/00455] train_loss: 0.015094\n",
      "[094/00505] train_loss: 0.014713\n",
      "[094/00555] train_loss: 0.014799\n",
      "[094/00605] train_loss: 0.014971\n",
      "[094/00655] train_loss: 0.014244\n",
      "[094/00705] train_loss: 0.014297\n",
      "[094/00755] train_loss: 0.014708\n",
      "[094/00805] train_loss: 0.014252\n",
      "[094/00855] train_loss: 0.014217\n",
      "[094/00905] train_loss: 0.014454\n",
      "[094/00955] train_loss: 0.014400\n",
      "[094/01005] train_loss: 0.013820\n",
      "[094/01055] train_loss: 0.015132\n",
      "[094/01105] train_loss: 0.013987\n",
      "[094/01155] train_loss: 0.014129\n",
      "[094/01205] train_loss: 0.014521\n",
      "[095/00029] train_loss: 0.014918\n",
      "[095/00079] train_loss: 0.015309\n",
      "[095/00129] train_loss: 0.016118\n",
      "[095/00179] train_loss: 0.015622\n",
      "[095/00229] train_loss: 0.015784\n",
      "[095/00279] train_loss: 0.014914\n",
      "[095/00329] train_loss: 0.015376\n",
      "[095/00379] train_loss: 0.014223\n",
      "[095/00429] train_loss: 0.014140\n",
      "[095/00479] train_loss: 0.014271\n",
      "[095/00529] train_loss: 0.014482\n",
      "[095/00579] train_loss: 0.014355\n",
      "[095/00629] train_loss: 0.013636\n",
      "[095/00679] train_loss: 0.014282\n",
      "[095/00729] train_loss: 0.014740\n",
      "[095/00779] train_loss: 0.014842\n",
      "[095/00829] train_loss: 0.014524\n",
      "[095/00879] train_loss: 0.014888\n",
      "[095/00929] train_loss: 0.013984\n",
      "[095/00979] train_loss: 0.015428\n",
      "[095/01029] train_loss: 0.014435\n",
      "[095/01079] train_loss: 0.014625\n",
      "[095/01129] train_loss: 0.014605\n",
      "[095/01179] train_loss: 0.013825\n",
      "[096/00003] train_loss: 0.014497\n",
      "[096/00053] train_loss: 0.015436\n",
      "[096/00103] train_loss: 0.016210\n",
      "[096/00153] train_loss: 0.015217\n",
      "[096/00203] train_loss: 0.015665\n",
      "[096/00253] train_loss: 0.015076\n",
      "[096/00303] train_loss: 0.015351\n",
      "[096/00353] train_loss: 0.014436\n",
      "[096/00403] train_loss: 0.014257\n",
      "[096/00453] train_loss: 0.015454\n",
      "[096/00503] train_loss: 0.014338\n",
      "[096/00553] train_loss: 0.014696\n",
      "[096/00603] train_loss: 0.014873\n",
      "[096/00653] train_loss: 0.014079\n",
      "[096/00703] train_loss: 0.014103\n",
      "[096/00753] train_loss: 0.013559\n",
      "[096/00803] train_loss: 0.014499\n",
      "[096/00853] train_loss: 0.014754\n",
      "[096/00903] train_loss: 0.014039\n",
      "[096/00953] train_loss: 0.013823\n",
      "[096/01003] train_loss: 0.014772\n",
      "[096/01053] train_loss: 0.014497\n",
      "[096/01103] train_loss: 0.014767\n",
      "[096/01153] train_loss: 0.014470\n",
      "[096/01203] train_loss: 0.014796\n",
      "[097/00027] train_loss: 0.015520\n",
      "[097/00077] train_loss: 0.015338\n",
      "[097/00127] train_loss: 0.015295\n",
      "[097/00177] train_loss: 0.015102\n",
      "[097/00227] train_loss: 0.014726\n",
      "[097/00277] train_loss: 0.015680\n",
      "[097/00327] train_loss: 0.014996\n",
      "[097/00377] train_loss: 0.014477\n",
      "[097/00427] train_loss: 0.014791\n",
      "[097/00477] train_loss: 0.014530\n",
      "[097/00527] train_loss: 0.015070\n",
      "[097/00577] train_loss: 0.014515\n",
      "[097/00627] train_loss: 0.014437\n",
      "[097/00677] train_loss: 0.014981\n",
      "[097/00727] train_loss: 0.014795\n",
      "[097/00777] train_loss: 0.014599\n",
      "[097/00827] train_loss: 0.013990\n",
      "[097/00877] train_loss: 0.014141\n",
      "[097/00927] train_loss: 0.014140\n",
      "[097/00977] train_loss: 0.014406\n",
      "[097/01027] train_loss: 0.014766\n",
      "[097/01077] train_loss: 0.014398\n",
      "[097/01127] train_loss: 0.014446\n",
      "[097/01177] train_loss: 0.013354\n",
      "[098/00001] train_loss: 0.014270\n",
      "[098/00051] train_loss: 0.015988\n",
      "[098/00101] train_loss: 0.015690\n",
      "[098/00151] train_loss: 0.014605\n",
      "[098/00201] train_loss: 0.014371\n",
      "[098/00251] train_loss: 0.015168\n",
      "[098/00301] train_loss: 0.014518\n",
      "[098/00351] train_loss: 0.014247\n",
      "[098/00401] train_loss: 0.014117\n",
      "[098/00451] train_loss: 0.014329\n",
      "[098/00501] train_loss: 0.015164\n",
      "[098/00551] train_loss: 0.015762\n",
      "[098/00601] train_loss: 0.014042\n",
      "[098/00651] train_loss: 0.014801\n",
      "[098/00701] train_loss: 0.014668\n",
      "[098/00751] train_loss: 0.015180\n",
      "[098/00801] train_loss: 0.013875\n",
      "[098/00851] train_loss: 0.014935\n",
      "[098/00901] train_loss: 0.014936\n",
      "[098/00951] train_loss: 0.014267\n",
      "[098/01001] train_loss: 0.014415\n",
      "[098/01051] train_loss: 0.014926\n",
      "[098/01101] train_loss: 0.014627\n",
      "[098/01151] train_loss: 0.014055\n",
      "[098/01201] train_loss: 0.014234\n",
      "[099/00025] train_loss: 0.015780\n",
      "[099/00075] train_loss: 0.016546\n",
      "[099/00125] train_loss: 0.014950\n",
      "[099/00175] train_loss: 0.015358\n",
      "[099/00225] train_loss: 0.015377\n",
      "[099/00275] train_loss: 0.014365\n",
      "[099/00325] train_loss: 0.014670\n",
      "[099/00375] train_loss: 0.014733\n",
      "[099/00425] train_loss: 0.014189\n",
      "[099/00475] train_loss: 0.014033\n",
      "[099/00525] train_loss: 0.014603\n",
      "[099/00575] train_loss: 0.015413\n",
      "[099/00625] train_loss: 0.013948\n",
      "[099/00675] train_loss: 0.014969\n",
      "[099/00725] train_loss: 0.014229\n",
      "[099/00775] train_loss: 0.014467\n",
      "[099/00825] train_loss: 0.014665\n",
      "[099/00875] train_loss: 0.014400\n",
      "[099/00925] train_loss: 0.014619\n",
      "[099/00975] train_loss: 0.014790\n",
      "[099/01025] train_loss: 0.014471\n",
      "[099/01075] train_loss: 0.015103\n",
      "[099/01125] train_loss: 0.013705\n",
      "[099/01175] train_loss: 0.014911\n",
      "[099/01225] train_loss: 0.014002\n",
      "[100/00049] train_loss: 0.015710\n",
      "[100/00099] train_loss: 0.015893\n",
      "[100/00149] train_loss: 0.015635\n",
      "[100/00199] train_loss: 0.014578\n",
      "[100/00249] train_loss: 0.015344\n",
      "[100/00299] train_loss: 0.015223\n",
      "[100/00349] train_loss: 0.014841\n",
      "[100/00399] train_loss: 0.015019\n",
      "[100/00449] train_loss: 0.014926\n",
      "[100/00499] train_loss: 0.013599\n",
      "[100/00549] train_loss: 0.014528\n",
      "[100/00599] train_loss: 0.014605\n",
      "[100/00649] train_loss: 0.014362\n",
      "[100/00699] train_loss: 0.015020\n",
      "[100/00749] train_loss: 0.014073\n",
      "[100/00799] train_loss: 0.013952\n",
      "[100/00849] train_loss: 0.014911\n",
      "[100/00899] train_loss: 0.013650\n",
      "[100/00949] train_loss: 0.013949\n",
      "[100/00999] train_loss: 0.014242\n",
      "[100/01049] train_loss: 0.014203\n",
      "[100/01099] train_loss: 0.014469\n",
      "[100/01149] train_loss: 0.015364\n",
      "[100/01199] train_loss: 0.013995\n",
      "[101/00023] train_loss: 0.016204\n",
      "[101/00073] train_loss: 0.015885\n",
      "[101/00123] train_loss: 0.015752\n",
      "[101/00173] train_loss: 0.015417\n",
      "[101/00223] train_loss: 0.015809\n",
      "[101/00273] train_loss: 0.015653\n",
      "[101/00323] train_loss: 0.015146\n",
      "[101/00373] train_loss: 0.013866\n",
      "[101/00423] train_loss: 0.014532\n",
      "[101/00473] train_loss: 0.014640\n",
      "[101/00523] train_loss: 0.015032\n",
      "[101/00573] train_loss: 0.015167\n",
      "[101/00623] train_loss: 0.015043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101/00673] train_loss: 0.014504\n",
      "[101/00723] train_loss: 0.014570\n",
      "[101/00773] train_loss: 0.014501\n",
      "[101/00823] train_loss: 0.014180\n",
      "[101/00873] train_loss: 0.013856\n",
      "[101/00923] train_loss: 0.014199\n",
      "[101/00973] train_loss: 0.013263\n",
      "[101/01023] train_loss: 0.014201\n",
      "[101/01073] train_loss: 0.013398\n",
      "[101/01123] train_loss: 0.015199\n",
      "[101/01173] train_loss: 0.013355\n",
      "[101/01223] train_loss: 0.015069\n",
      "[102/00047] train_loss: 0.016046\n",
      "[102/00097] train_loss: 0.016067\n",
      "[102/00147] train_loss: 0.015409\n",
      "[102/00197] train_loss: 0.015038\n",
      "[102/00247] train_loss: 0.015351\n",
      "[102/00297] train_loss: 0.014381\n",
      "[102/00347] train_loss: 0.014636\n",
      "[102/00397] train_loss: 0.015081\n",
      "[102/00447] train_loss: 0.014792\n",
      "[102/00497] train_loss: 0.014651\n",
      "[102/00547] train_loss: 0.014494\n",
      "[102/00597] train_loss: 0.014897\n",
      "[102/00647] train_loss: 0.015154\n",
      "[102/00697] train_loss: 0.013915\n",
      "[102/00747] train_loss: 0.014566\n",
      "[102/00797] train_loss: 0.014647\n",
      "[102/00847] train_loss: 0.014181\n",
      "[102/00897] train_loss: 0.014323\n",
      "[102/00947] train_loss: 0.014080\n",
      "[102/00997] train_loss: 0.014771\n",
      "[102/01047] train_loss: 0.014167\n",
      "[102/01097] train_loss: 0.014008\n",
      "[102/01147] train_loss: 0.014741\n",
      "[102/01197] train_loss: 0.014629\n",
      "[103/00021] train_loss: 0.015713\n",
      "[103/00071] train_loss: 0.015410\n",
      "[103/00121] train_loss: 0.015723\n",
      "[103/00171] train_loss: 0.015561\n",
      "[103/00221] train_loss: 0.014717\n",
      "[103/00271] train_loss: 0.014563\n",
      "[103/00321] train_loss: 0.014861\n",
      "[103/00371] train_loss: 0.015182\n",
      "[103/00421] train_loss: 0.013469\n",
      "[103/00471] train_loss: 0.014606\n",
      "[103/00521] train_loss: 0.014637\n",
      "[103/00571] train_loss: 0.014194\n",
      "[103/00621] train_loss: 0.013698\n",
      "[103/00671] train_loss: 0.014459\n",
      "[103/00721] train_loss: 0.014375\n",
      "[103/00771] train_loss: 0.014894\n",
      "[103/00821] train_loss: 0.014300\n",
      "[103/00871] train_loss: 0.014781\n",
      "[103/00921] train_loss: 0.014329\n",
      "[103/00971] train_loss: 0.014503\n",
      "[103/01021] train_loss: 0.013848\n",
      "[103/01071] train_loss: 0.013612\n",
      "[103/01121] train_loss: 0.014462\n",
      "[103/01171] train_loss: 0.013677\n",
      "[103/01221] train_loss: 0.014293\n",
      "[104/00045] train_loss: 0.015303\n",
      "[104/00095] train_loss: 0.016296\n",
      "[104/00145] train_loss: 0.015422\n",
      "[104/00195] train_loss: 0.015739\n",
      "[104/00245] train_loss: 0.015031\n",
      "[104/00295] train_loss: 0.015310\n",
      "[104/00345] train_loss: 0.015426\n",
      "[104/00395] train_loss: 0.013696\n",
      "[104/00445] train_loss: 0.013993\n",
      "[104/00495] train_loss: 0.014417\n",
      "[104/00545] train_loss: 0.013708\n",
      "[104/00595] train_loss: 0.014678\n",
      "[104/00645] train_loss: 0.013903\n",
      "[104/00695] train_loss: 0.013384\n",
      "[104/00745] train_loss: 0.014139\n",
      "[104/00795] train_loss: 0.013889\n",
      "[104/00845] train_loss: 0.014180\n",
      "[104/00895] train_loss: 0.015429\n",
      "[104/00945] train_loss: 0.014827\n",
      "[104/00995] train_loss: 0.014640\n",
      "[104/01045] train_loss: 0.014280\n",
      "[104/01095] train_loss: 0.013830\n",
      "[104/01145] train_loss: 0.013251\n",
      "[104/01195] train_loss: 0.014083\n",
      "[105/00019] train_loss: 0.015101\n",
      "[105/00069] train_loss: 0.015976\n",
      "[105/00119] train_loss: 0.016139\n",
      "[105/00169] train_loss: 0.016409\n",
      "[105/00219] train_loss: 0.014981\n",
      "[105/00269] train_loss: 0.015084\n",
      "[105/00319] train_loss: 0.014962\n",
      "[105/00369] train_loss: 0.015953\n",
      "[105/00419] train_loss: 0.014198\n",
      "[105/00469] train_loss: 0.014317\n",
      "[105/00519] train_loss: 0.014295\n",
      "[105/00569] train_loss: 0.014522\n",
      "[105/00619] train_loss: 0.013939\n",
      "[105/00669] train_loss: 0.013651\n",
      "[105/00719] train_loss: 0.014305\n",
      "[105/00769] train_loss: 0.015130\n",
      "[105/00819] train_loss: 0.014051\n",
      "[105/00869] train_loss: 0.014028\n",
      "[105/00919] train_loss: 0.013441\n",
      "[105/00969] train_loss: 0.013782\n",
      "[105/01019] train_loss: 0.013019\n",
      "[105/01069] train_loss: 0.013922\n",
      "[105/01119] train_loss: 0.013727\n",
      "[105/01169] train_loss: 0.013686\n",
      "[105/01219] train_loss: 0.013567\n",
      "[106/00043] train_loss: 0.015655\n",
      "[106/00093] train_loss: 0.016045\n",
      "[106/00143] train_loss: 0.015695\n",
      "[106/00193] train_loss: 0.015005\n",
      "[106/00243] train_loss: 0.015268\n",
      "[106/00293] train_loss: 0.014989\n",
      "[106/00343] train_loss: 0.014712\n",
      "[106/00393] train_loss: 0.014622\n",
      "[106/00443] train_loss: 0.014075\n",
      "[106/00493] train_loss: 0.014323\n",
      "[106/00543] train_loss: 0.014499\n",
      "[106/00593] train_loss: 0.014001\n",
      "[106/00643] train_loss: 0.014426\n",
      "[106/00693] train_loss: 0.014467\n",
      "[106/00743] train_loss: 0.013863\n",
      "[106/00793] train_loss: 0.014099\n",
      "[106/00843] train_loss: 0.014758\n",
      "[106/00893] train_loss: 0.015430\n",
      "[106/00943] train_loss: 0.013694\n",
      "[106/00993] train_loss: 0.014545\n",
      "[106/01043] train_loss: 0.014241\n",
      "[106/01093] train_loss: 0.014477\n",
      "[106/01143] train_loss: 0.014282\n",
      "[106/01193] train_loss: 0.014951\n",
      "[107/00017] train_loss: 0.014839\n",
      "[107/00067] train_loss: 0.016003\n",
      "[107/00117] train_loss: 0.015478\n",
      "[107/00167] train_loss: 0.015558\n",
      "[107/00217] train_loss: 0.014900\n",
      "[107/00267] train_loss: 0.015044\n",
      "[107/00317] train_loss: 0.014958\n",
      "[107/00367] train_loss: 0.015393\n",
      "[107/00417] train_loss: 0.014387\n",
      "[107/00467] train_loss: 0.014966\n",
      "[107/00517] train_loss: 0.014635\n",
      "[107/00567] train_loss: 0.013902\n",
      "[107/00617] train_loss: 0.013941\n",
      "[107/00667] train_loss: 0.014631\n",
      "[107/00717] train_loss: 0.013679\n",
      "[107/00767] train_loss: 0.013727\n",
      "[107/00817] train_loss: 0.014068\n",
      "[107/00867] train_loss: 0.014496\n",
      "[107/00917] train_loss: 0.014091\n",
      "[107/00967] train_loss: 0.015098\n",
      "[107/01017] train_loss: 0.015407\n",
      "[107/01067] train_loss: 0.014275\n",
      "[107/01117] train_loss: 0.014844\n",
      "[107/01167] train_loss: 0.014345\n",
      "[107/01217] train_loss: 0.014298\n",
      "[108/00041] train_loss: 0.015178\n",
      "[108/00091] train_loss: 0.016088\n",
      "[108/00141] train_loss: 0.014539\n",
      "[108/00191] train_loss: 0.014757\n",
      "[108/00241] train_loss: 0.015266\n",
      "[108/00291] train_loss: 0.014583\n",
      "[108/00341] train_loss: 0.016064\n",
      "[108/00391] train_loss: 0.015387\n",
      "[108/00441] train_loss: 0.014557\n",
      "[108/00491] train_loss: 0.014134\n",
      "[108/00541] train_loss: 0.014963\n",
      "[108/00591] train_loss: 0.015460\n",
      "[108/00641] train_loss: 0.014700\n",
      "[108/00691] train_loss: 0.014399\n",
      "[108/00741] train_loss: 0.014250\n",
      "[108/00791] train_loss: 0.014358\n",
      "[108/00841] train_loss: 0.014282\n",
      "[108/00891] train_loss: 0.013912\n",
      "[108/00941] train_loss: 0.014722\n",
      "[108/00991] train_loss: 0.014041\n",
      "[108/01041] train_loss: 0.013949\n",
      "[108/01091] train_loss: 0.015076\n",
      "[108/01141] train_loss: 0.013828\n",
      "[108/01191] train_loss: 0.014244\n",
      "[109/00015] train_loss: 0.014317\n",
      "[109/00065] train_loss: 0.015580\n",
      "[109/00115] train_loss: 0.015682\n",
      "[109/00165] train_loss: 0.014458\n",
      "[109/00215] train_loss: 0.014138\n",
      "[109/00265] train_loss: 0.015126\n",
      "[109/00315] train_loss: 0.013149\n",
      "[109/00365] train_loss: 0.014554\n",
      "[109/00415] train_loss: 0.015054\n",
      "[109/00465] train_loss: 0.014411\n",
      "[109/00515] train_loss: 0.014643\n",
      "[109/00565] train_loss: 0.014458\n",
      "[109/00615] train_loss: 0.014550\n",
      "[109/00665] train_loss: 0.015407\n",
      "[109/00715] train_loss: 0.014553\n",
      "[109/00765] train_loss: 0.014259\n",
      "[109/00815] train_loss: 0.013944\n",
      "[109/00865] train_loss: 0.014033\n",
      "[109/00915] train_loss: 0.014412\n",
      "[109/00965] train_loss: 0.014547\n",
      "[109/01015] train_loss: 0.014411\n",
      "[109/01065] train_loss: 0.014039\n",
      "[109/01115] train_loss: 0.013015\n",
      "[109/01165] train_loss: 0.014212\n",
      "[109/01215] train_loss: 0.014204\n",
      "[110/00039] train_loss: 0.015118\n",
      "[110/00089] train_loss: 0.015325\n",
      "[110/00139] train_loss: 0.014425\n",
      "[110/00189] train_loss: 0.015561\n",
      "[110/00239] train_loss: 0.014822\n",
      "[110/00289] train_loss: 0.014665\n",
      "[110/00339] train_loss: 0.014776\n",
      "[110/00389] train_loss: 0.015174\n",
      "[110/00439] train_loss: 0.014597\n",
      "[110/00489] train_loss: 0.014828\n",
      "[110/00539] train_loss: 0.015069\n",
      "[110/00589] train_loss: 0.013511\n",
      "[110/00639] train_loss: 0.014724\n",
      "[110/00689] train_loss: 0.014200\n",
      "[110/00739] train_loss: 0.014100\n",
      "[110/00789] train_loss: 0.014276\n",
      "[110/00839] train_loss: 0.013796\n",
      "[110/00889] train_loss: 0.014806\n",
      "[110/00939] train_loss: 0.014001\n",
      "[110/00989] train_loss: 0.014069\n",
      "[110/01039] train_loss: 0.014580\n",
      "[110/01089] train_loss: 0.014621\n",
      "[110/01139] train_loss: 0.013799\n",
      "[110/01189] train_loss: 0.013659\n",
      "[111/00013] train_loss: 0.013819\n",
      "[111/00063] train_loss: 0.015937\n",
      "[111/00113] train_loss: 0.015204\n",
      "[111/00163] train_loss: 0.014477\n",
      "[111/00213] train_loss: 0.014440\n",
      "[111/00263] train_loss: 0.014349\n",
      "[111/00313] train_loss: 0.014439\n",
      "[111/00363] train_loss: 0.014039\n",
      "[111/00413] train_loss: 0.014741\n",
      "[111/00463] train_loss: 0.014839\n",
      "[111/00513] train_loss: 0.014496\n",
      "[111/00563] train_loss: 0.013598\n",
      "[111/00613] train_loss: 0.014811\n",
      "[111/00663] train_loss: 0.014067\n",
      "[111/00713] train_loss: 0.014033\n",
      "[111/00763] train_loss: 0.014580\n",
      "[111/00813] train_loss: 0.013527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[111/00863] train_loss: 0.014499\n",
      "[111/00913] train_loss: 0.014307\n",
      "[111/00963] train_loss: 0.014009\n",
      "[111/01013] train_loss: 0.014040\n",
      "[111/01063] train_loss: 0.013611\n",
      "[111/01113] train_loss: 0.015054\n",
      "[111/01163] train_loss: 0.013857\n",
      "[111/01213] train_loss: 0.014506\n",
      "[112/00037] train_loss: 0.015803\n",
      "[112/00087] train_loss: 0.014835\n",
      "[112/00137] train_loss: 0.014840\n",
      "[112/00187] train_loss: 0.014801\n",
      "[112/00237] train_loss: 0.015570\n",
      "[112/00287] train_loss: 0.015003\n",
      "[112/00337] train_loss: 0.014422\n",
      "[112/00387] train_loss: 0.014491\n",
      "[112/00437] train_loss: 0.014172\n",
      "[112/00487] train_loss: 0.013815\n",
      "[112/00537] train_loss: 0.014099\n",
      "[112/00587] train_loss: 0.013215\n",
      "[112/00637] train_loss: 0.014515\n",
      "[112/00687] train_loss: 0.014576\n",
      "[112/00737] train_loss: 0.013645\n",
      "[112/00787] train_loss: 0.014205\n",
      "[112/00837] train_loss: 0.014357\n",
      "[112/00887] train_loss: 0.014810\n",
      "[112/00937] train_loss: 0.012949\n",
      "[112/00987] train_loss: 0.014213\n",
      "[112/01037] train_loss: 0.014576\n",
      "[112/01087] train_loss: 0.013276\n",
      "[112/01137] train_loss: 0.013141\n",
      "[112/01187] train_loss: 0.013887\n",
      "[113/00011] train_loss: 0.014345\n",
      "[113/00061] train_loss: 0.014960\n",
      "[113/00111] train_loss: 0.014747\n",
      "[113/00161] train_loss: 0.016308\n",
      "[113/00211] train_loss: 0.015032\n",
      "[113/00261] train_loss: 0.014635\n",
      "[113/00311] train_loss: 0.015011\n",
      "[113/00361] train_loss: 0.014430\n",
      "[113/00411] train_loss: 0.015791\n",
      "[113/00461] train_loss: 0.014418\n",
      "[113/00511] train_loss: 0.013977\n",
      "[113/00561] train_loss: 0.013957\n",
      "[113/00611] train_loss: 0.014363\n",
      "[113/00661] train_loss: 0.013725\n",
      "[113/00711] train_loss: 0.014605\n",
      "[113/00761] train_loss: 0.014144\n",
      "[113/00811] train_loss: 0.013598\n",
      "[113/00861] train_loss: 0.015035\n",
      "[113/00911] train_loss: 0.013996\n",
      "[113/00961] train_loss: 0.013799\n",
      "[113/01011] train_loss: 0.013537\n",
      "[113/01061] train_loss: 0.013914\n",
      "[113/01111] train_loss: 0.013701\n",
      "[113/01161] train_loss: 0.014265\n",
      "[113/01211] train_loss: 0.013585\n",
      "[114/00035] train_loss: 0.015824\n",
      "[114/00085] train_loss: 0.015959\n",
      "[114/00135] train_loss: 0.015237\n",
      "[114/00185] train_loss: 0.015909\n",
      "[114/00235] train_loss: 0.014179\n",
      "[114/00285] train_loss: 0.014583\n",
      "[114/00335] train_loss: 0.015085\n",
      "[114/00385] train_loss: 0.013753\n",
      "[114/00435] train_loss: 0.014023\n",
      "[114/00485] train_loss: 0.015050\n",
      "[114/00535] train_loss: 0.014396\n",
      "[114/00585] train_loss: 0.014817\n",
      "[114/00635] train_loss: 0.013967\n",
      "[114/00685] train_loss: 0.013749\n",
      "[114/00735] train_loss: 0.014552\n",
      "[114/00785] train_loss: 0.013443\n",
      "[114/00835] train_loss: 0.014289\n",
      "[114/00885] train_loss: 0.014753\n",
      "[114/00935] train_loss: 0.013972\n",
      "[114/00985] train_loss: 0.014458\n",
      "[114/01035] train_loss: 0.014310\n",
      "[114/01085] train_loss: 0.013868\n",
      "[114/01135] train_loss: 0.014383\n",
      "[114/01185] train_loss: 0.013731\n",
      "[115/00009] train_loss: 0.013787\n",
      "[115/00059] train_loss: 0.015262\n",
      "[115/00109] train_loss: 0.014532\n",
      "[115/00159] train_loss: 0.014729\n",
      "[115/00209] train_loss: 0.014923\n",
      "[115/00259] train_loss: 0.014463\n",
      "[115/00309] train_loss: 0.014191\n",
      "[115/00359] train_loss: 0.014774\n",
      "[115/00409] train_loss: 0.014093\n",
      "[115/00459] train_loss: 0.013790\n",
      "[115/00509] train_loss: 0.014531\n",
      "[115/00559] train_loss: 0.013918\n",
      "[115/00609] train_loss: 0.014498\n",
      "[115/00659] train_loss: 0.014244\n",
      "[115/00709] train_loss: 0.014911\n",
      "[115/00759] train_loss: 0.015206\n",
      "[115/00809] train_loss: 0.014406\n",
      "[115/00859] train_loss: 0.014435\n",
      "[115/00909] train_loss: 0.014122\n",
      "[115/00959] train_loss: 0.013595\n",
      "[115/01009] train_loss: 0.014419\n",
      "[115/01059] train_loss: 0.013514\n",
      "[115/01109] train_loss: 0.013899\n",
      "[115/01159] train_loss: 0.013917\n",
      "[115/01209] train_loss: 0.014080\n",
      "[116/00033] train_loss: 0.015307\n",
      "[116/00083] train_loss: 0.015224\n",
      "[116/00133] train_loss: 0.015030\n",
      "[116/00183] train_loss: 0.014881\n",
      "[116/00233] train_loss: 0.014460\n",
      "[116/00283] train_loss: 0.014122\n",
      "[116/00333] train_loss: 0.014364\n",
      "[116/00383] train_loss: 0.014013\n",
      "[116/00433] train_loss: 0.014860\n",
      "[116/00483] train_loss: 0.013941\n",
      "[116/00533] train_loss: 0.014327\n",
      "[116/00583] train_loss: 0.014289\n",
      "[116/00633] train_loss: 0.014270\n",
      "[116/00683] train_loss: 0.014184\n",
      "[116/00733] train_loss: 0.013863\n",
      "[116/00783] train_loss: 0.015174\n",
      "[116/00833] train_loss: 0.013942\n",
      "[116/00883] train_loss: 0.013872\n",
      "[116/00933] train_loss: 0.014253\n",
      "[116/00983] train_loss: 0.014965\n",
      "[116/01033] train_loss: 0.014456\n",
      "[116/01083] train_loss: 0.013934\n",
      "[116/01133] train_loss: 0.012691\n",
      "[116/01183] train_loss: 0.013574\n",
      "[117/00007] train_loss: 0.014530\n",
      "[117/00057] train_loss: 0.015969\n",
      "[117/00107] train_loss: 0.014760\n",
      "[117/00157] train_loss: 0.014868\n",
      "[117/00207] train_loss: 0.014205\n",
      "[117/00257] train_loss: 0.014511\n",
      "[117/00307] train_loss: 0.015525\n",
      "[117/00357] train_loss: 0.014990\n",
      "[117/00407] train_loss: 0.015404\n",
      "[117/00457] train_loss: 0.014328\n",
      "[117/00507] train_loss: 0.015288\n",
      "[117/00557] train_loss: 0.013996\n",
      "[117/00607] train_loss: 0.013734\n",
      "[117/00657] train_loss: 0.014360\n",
      "[117/00707] train_loss: 0.013528\n",
      "[117/00757] train_loss: 0.014401\n",
      "[117/00807] train_loss: 0.013994\n",
      "[117/00857] train_loss: 0.014781\n",
      "[117/00907] train_loss: 0.014233\n",
      "[117/00957] train_loss: 0.013335\n",
      "[117/01007] train_loss: 0.013250\n",
      "[117/01057] train_loss: 0.014140\n",
      "[117/01107] train_loss: 0.015232\n",
      "[117/01157] train_loss: 0.013301\n",
      "[117/01207] train_loss: 0.013485\n",
      "[118/00031] train_loss: 0.015017\n",
      "[118/00081] train_loss: 0.015486\n",
      "[118/00131] train_loss: 0.014312\n",
      "[118/00181] train_loss: 0.014884\n",
      "[118/00231] train_loss: 0.014952\n",
      "[118/00281] train_loss: 0.014275\n",
      "[118/00331] train_loss: 0.014440\n",
      "[118/00381] train_loss: 0.014137\n",
      "[118/00431] train_loss: 0.014550\n",
      "[118/00481] train_loss: 0.013960\n",
      "[118/00531] train_loss: 0.014576\n",
      "[118/00581] train_loss: 0.014369\n",
      "[118/00631] train_loss: 0.014186\n",
      "[118/00681] train_loss: 0.014074\n",
      "[118/00731] train_loss: 0.013878\n",
      "[118/00781] train_loss: 0.013516\n",
      "[118/00831] train_loss: 0.013853\n",
      "[118/00881] train_loss: 0.014909\n",
      "[118/00931] train_loss: 0.014126\n",
      "[118/00981] train_loss: 0.013751\n",
      "[118/01031] train_loss: 0.013670\n",
      "[118/01081] train_loss: 0.013448\n",
      "[118/01131] train_loss: 0.014322\n",
      "[118/01181] train_loss: 0.014738\n",
      "[119/00005] train_loss: 0.014830\n",
      "[119/00055] train_loss: 0.014437\n",
      "[119/00105] train_loss: 0.014483\n",
      "[119/00155] train_loss: 0.014991\n",
      "[119/00205] train_loss: 0.014785\n",
      "[119/00255] train_loss: 0.014384\n",
      "[119/00305] train_loss: 0.014605\n",
      "[119/00355] train_loss: 0.014743\n",
      "[119/00405] train_loss: 0.014863\n",
      "[119/00455] train_loss: 0.014105\n",
      "[119/00505] train_loss: 0.013855\n",
      "[119/00555] train_loss: 0.014432\n",
      "[119/00605] train_loss: 0.013933\n",
      "[119/00655] train_loss: 0.013901\n",
      "[119/00705] train_loss: 0.015689\n",
      "[119/00755] train_loss: 0.014203\n",
      "[119/00805] train_loss: 0.013883\n",
      "[119/00855] train_loss: 0.013428\n",
      "[119/00905] train_loss: 0.014351\n",
      "[119/00955] train_loss: 0.014208\n",
      "[119/01005] train_loss: 0.013540\n",
      "[119/01055] train_loss: 0.013707\n",
      "[119/01105] train_loss: 0.014031\n",
      "[119/01155] train_loss: 0.013858\n",
      "[119/01205] train_loss: 0.013916\n",
      "[120/00029] train_loss: 0.014311\n",
      "[120/00079] train_loss: 0.015250\n",
      "[120/00129] train_loss: 0.015106\n",
      "[120/00179] train_loss: 0.014548\n",
      "[120/00229] train_loss: 0.014691\n",
      "[120/00279] train_loss: 0.014708\n",
      "[120/00329] train_loss: 0.013957\n",
      "[120/00379] train_loss: 0.014034\n",
      "[120/00429] train_loss: 0.014090\n",
      "[120/00479] train_loss: 0.014276\n",
      "[120/00529] train_loss: 0.014012\n",
      "[120/00579] train_loss: 0.014589\n",
      "[120/00629] train_loss: 0.013944\n",
      "[120/00679] train_loss: 0.014250\n",
      "[120/00729] train_loss: 0.013745\n",
      "[120/00779] train_loss: 0.014145\n",
      "[120/00829] train_loss: 0.013918\n",
      "[120/00879] train_loss: 0.013902\n",
      "[120/00929] train_loss: 0.014382\n",
      "[120/00979] train_loss: 0.014120\n",
      "[120/01029] train_loss: 0.014132\n",
      "[120/01079] train_loss: 0.013008\n",
      "[120/01129] train_loss: 0.013791\n",
      "[120/01179] train_loss: 0.014802\n",
      "[121/00003] train_loss: 0.014108\n",
      "[121/00053] train_loss: 0.015517\n",
      "[121/00103] train_loss: 0.014902\n",
      "[121/00153] train_loss: 0.014610\n",
      "[121/00203] train_loss: 0.014468\n",
      "[121/00253] train_loss: 0.014242\n",
      "[121/00303] train_loss: 0.014785\n",
      "[121/00353] train_loss: 0.014346\n",
      "[121/00403] train_loss: 0.014246\n",
      "[121/00453] train_loss: 0.013411\n",
      "[121/00503] train_loss: 0.013517\n",
      "[121/00553] train_loss: 0.013519\n",
      "[121/00603] train_loss: 0.014667\n",
      "[121/00653] train_loss: 0.014577\n",
      "[121/00703] train_loss: 0.013236\n",
      "[121/00753] train_loss: 0.014448\n",
      "[121/00803] train_loss: 0.014307\n",
      "[121/00853] train_loss: 0.014460\n",
      "[121/00903] train_loss: 0.014359\n",
      "[121/00953] train_loss: 0.013414\n",
      "[121/01003] train_loss: 0.013045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[121/01053] train_loss: 0.014125\n",
      "[121/01103] train_loss: 0.014083\n",
      "[121/01153] train_loss: 0.013418\n",
      "[121/01203] train_loss: 0.013484\n",
      "[122/00027] train_loss: 0.014773\n",
      "[122/00077] train_loss: 0.015012\n",
      "[122/00127] train_loss: 0.015001\n",
      "[122/00177] train_loss: 0.014658\n",
      "[122/00227] train_loss: 0.014469\n",
      "[122/00277] train_loss: 0.014156\n",
      "[122/00327] train_loss: 0.014429\n",
      "[122/00377] train_loss: 0.013987\n",
      "[122/00427] train_loss: 0.014152\n",
      "[122/00477] train_loss: 0.014870\n",
      "[122/00527] train_loss: 0.014023\n",
      "[122/00577] train_loss: 0.013464\n",
      "[122/00627] train_loss: 0.014454\n",
      "[122/00677] train_loss: 0.014235\n",
      "[122/00727] train_loss: 0.014957\n",
      "[122/00777] train_loss: 0.013653\n",
      "[122/00827] train_loss: 0.014512\n",
      "[122/00877] train_loss: 0.013419\n",
      "[122/00927] train_loss: 0.013798\n",
      "[122/00977] train_loss: 0.014223\n",
      "[122/01027] train_loss: 0.013487\n",
      "[122/01077] train_loss: 0.015011\n",
      "[122/01127] train_loss: 0.014777\n",
      "[122/01177] train_loss: 0.014149\n",
      "[123/00001] train_loss: 0.014884\n",
      "[123/00051] train_loss: 0.015088\n",
      "[123/00101] train_loss: 0.014662\n",
      "[123/00151] train_loss: 0.015036\n",
      "[123/00201] train_loss: 0.014683\n",
      "[123/00251] train_loss: 0.013837\n",
      "[123/00301] train_loss: 0.013412\n",
      "[123/00351] train_loss: 0.014732\n",
      "[123/00401] train_loss: 0.014260\n",
      "[123/00451] train_loss: 0.013877\n",
      "[123/00501] train_loss: 0.014663\n",
      "[123/00551] train_loss: 0.014361\n",
      "[123/00601] train_loss: 0.014395\n",
      "[123/00651] train_loss: 0.013926\n",
      "[123/00701] train_loss: 0.014173\n",
      "[123/00751] train_loss: 0.014085\n",
      "[123/00801] train_loss: 0.013630\n",
      "[123/00851] train_loss: 0.013541\n",
      "[123/00901] train_loss: 0.013457\n",
      "[123/00951] train_loss: 0.013790\n",
      "[123/01001] train_loss: 0.013779\n",
      "[123/01051] train_loss: 0.014476\n",
      "[123/01101] train_loss: 0.013781\n",
      "[123/01151] train_loss: 0.013966\n",
      "[123/01201] train_loss: 0.014305\n",
      "[124/00025] train_loss: 0.015145\n",
      "[124/00075] train_loss: 0.015270\n",
      "[124/00125] train_loss: 0.015534\n",
      "[124/00175] train_loss: 0.014466\n",
      "[124/00225] train_loss: 0.014385\n",
      "[124/00275] train_loss: 0.014276\n",
      "[124/00325] train_loss: 0.014784\n",
      "[124/00375] train_loss: 0.014526\n",
      "[124/00425] train_loss: 0.014279\n",
      "[124/00475] train_loss: 0.014242\n",
      "[124/00525] train_loss: 0.014203\n",
      "[124/00575] train_loss: 0.014185\n",
      "[124/00625] train_loss: 0.013498\n",
      "[124/00675] train_loss: 0.013598\n",
      "[124/00725] train_loss: 0.014684\n",
      "[124/00775] train_loss: 0.014523\n",
      "[124/00825] train_loss: 0.013256\n",
      "[124/00875] train_loss: 0.014209\n",
      "[124/00925] train_loss: 0.013749\n",
      "[124/00975] train_loss: 0.014095\n",
      "[124/01025] train_loss: 0.013974\n",
      "[124/01075] train_loss: 0.015272\n",
      "[124/01125] train_loss: 0.013901\n",
      "[124/01175] train_loss: 0.012870\n",
      "[124/01225] train_loss: 0.013457\n",
      "[125/00049] train_loss: 0.015625\n",
      "[125/00099] train_loss: 0.014668\n",
      "[125/00149] train_loss: 0.015204\n",
      "[125/00199] train_loss: 0.014040\n",
      "[125/00249] train_loss: 0.014253\n",
      "[125/00299] train_loss: 0.014192\n",
      "[125/00349] train_loss: 0.014331\n",
      "[125/00399] train_loss: 0.013925\n",
      "[125/00449] train_loss: 0.013011\n",
      "[125/00499] train_loss: 0.012873\n",
      "[125/00549] train_loss: 0.014293\n",
      "[125/00599] train_loss: 0.014339\n",
      "[125/00649] train_loss: 0.013516\n",
      "[125/00699] train_loss: 0.014241\n",
      "[125/00749] train_loss: 0.015356\n",
      "[125/00799] train_loss: 0.013909\n",
      "[125/00849] train_loss: 0.013952\n",
      "[125/00899] train_loss: 0.013928\n",
      "[125/00949] train_loss: 0.013322\n",
      "[125/00999] train_loss: 0.013844\n",
      "[125/01049] train_loss: 0.013499\n",
      "[125/01099] train_loss: 0.013773\n",
      "[125/01149] train_loss: 0.014180\n",
      "[125/01199] train_loss: 0.014593\n",
      "[126/00023] train_loss: 0.014795\n",
      "[126/00073] train_loss: 0.014929\n",
      "[126/00123] train_loss: 0.014997\n",
      "[126/00173] train_loss: 0.014154\n",
      "[126/00223] train_loss: 0.014410\n",
      "[126/00273] train_loss: 0.014418\n",
      "[126/00323] train_loss: 0.013500\n",
      "[126/00373] train_loss: 0.014174\n",
      "[126/00423] train_loss: 0.014760\n",
      "[126/00473] train_loss: 0.014394\n",
      "[126/00523] train_loss: 0.013816\n",
      "[126/00573] train_loss: 0.014019\n",
      "[126/00623] train_loss: 0.013795\n",
      "[126/00673] train_loss: 0.013509\n",
      "[126/00723] train_loss: 0.013104\n",
      "[126/00773] train_loss: 0.014229\n",
      "[126/00823] train_loss: 0.013662\n",
      "[126/00873] train_loss: 0.013903\n",
      "[126/00923] train_loss: 0.014592\n",
      "[126/00973] train_loss: 0.014092\n",
      "[126/01023] train_loss: 0.013463\n",
      "[126/01073] train_loss: 0.014179\n",
      "[126/01123] train_loss: 0.013968\n",
      "[126/01173] train_loss: 0.013833\n",
      "[126/01223] train_loss: 0.013741\n",
      "[127/00047] train_loss: 0.015780\n",
      "[127/00097] train_loss: 0.015255\n",
      "[127/00147] train_loss: 0.014654\n",
      "[127/00197] train_loss: 0.015189\n",
      "[127/00247] train_loss: 0.014410\n",
      "[127/00297] train_loss: 0.014333\n",
      "[127/00347] train_loss: 0.014334\n",
      "[127/00397] train_loss: 0.014192\n",
      "[127/00447] train_loss: 0.014303\n",
      "[127/00497] train_loss: 0.013600\n",
      "[127/00547] train_loss: 0.013954\n",
      "[127/00597] train_loss: 0.013547\n",
      "[127/00647] train_loss: 0.014160\n",
      "[127/00697] train_loss: 0.013705\n",
      "[127/00747] train_loss: 0.014145\n",
      "[127/00797] train_loss: 0.013764\n",
      "[127/00847] train_loss: 0.013753\n",
      "[127/00897] train_loss: 0.013477\n",
      "[127/00947] train_loss: 0.014147\n",
      "[127/00997] train_loss: 0.013687\n",
      "[127/01047] train_loss: 0.014018\n",
      "[127/01097] train_loss: 0.013613\n",
      "[127/01147] train_loss: 0.013457\n",
      "[127/01197] train_loss: 0.014367\n",
      "[128/00021] train_loss: 0.013796\n",
      "[128/00071] train_loss: 0.015241\n",
      "[128/00121] train_loss: 0.015456\n",
      "[128/00171] train_loss: 0.014230\n",
      "[128/00221] train_loss: 0.013767\n",
      "[128/00271] train_loss: 0.013944\n",
      "[128/00321] train_loss: 0.014579\n",
      "[128/00371] train_loss: 0.013564\n",
      "[128/00421] train_loss: 0.014745\n",
      "[128/00471] train_loss: 0.014488\n",
      "[128/00521] train_loss: 0.014292\n",
      "[128/00571] train_loss: 0.013630\n",
      "[128/00621] train_loss: 0.014091\n",
      "[128/00671] train_loss: 0.013677\n",
      "[128/00721] train_loss: 0.013757\n",
      "[128/00771] train_loss: 0.014021\n",
      "[128/00821] train_loss: 0.013532\n",
      "[128/00871] train_loss: 0.014164\n",
      "[128/00921] train_loss: 0.013923\n",
      "[128/00971] train_loss: 0.013292\n",
      "[128/01021] train_loss: 0.013683\n",
      "[128/01071] train_loss: 0.014392\n",
      "[128/01121] train_loss: 0.013515\n",
      "[128/01171] train_loss: 0.014119\n",
      "[128/01221] train_loss: 0.013239\n",
      "[129/00045] train_loss: 0.014397\n",
      "[129/00095] train_loss: 0.014641\n",
      "[129/00145] train_loss: 0.014106\n",
      "[129/00195] train_loss: 0.014232\n",
      "[129/00245] train_loss: 0.014762\n",
      "[129/00295] train_loss: 0.014189\n",
      "[129/00345] train_loss: 0.013862\n",
      "[129/00395] train_loss: 0.014278\n",
      "[129/00445] train_loss: 0.014027\n",
      "[129/00495] train_loss: 0.013784\n",
      "[129/00545] train_loss: 0.014272\n",
      "[129/00595] train_loss: 0.014017\n",
      "[129/00645] train_loss: 0.013927\n",
      "[129/00695] train_loss: 0.013728\n",
      "[129/00745] train_loss: 0.013273\n",
      "[129/00795] train_loss: 0.013601\n",
      "[129/00845] train_loss: 0.013170\n",
      "[129/00895] train_loss: 0.013790\n",
      "[129/00945] train_loss: 0.014789\n",
      "[129/00995] train_loss: 0.013559\n",
      "[129/01045] train_loss: 0.013237\n",
      "[129/01095] train_loss: 0.013896\n",
      "[129/01145] train_loss: 0.014221\n",
      "[129/01195] train_loss: 0.013610\n",
      "[130/00019] train_loss: 0.014130\n",
      "[130/00069] train_loss: 0.015496\n",
      "[130/00119] train_loss: 0.015491\n",
      "[130/00169] train_loss: 0.014845\n",
      "[130/00219] train_loss: 0.014459\n",
      "[130/00269] train_loss: 0.014372\n",
      "[130/00319] train_loss: 0.013764\n",
      "[130/00369] train_loss: 0.013576\n",
      "[130/00419] train_loss: 0.013435\n",
      "[130/00469] train_loss: 0.013850\n",
      "[130/00519] train_loss: 0.014145\n",
      "[130/00569] train_loss: 0.013536\n",
      "[130/00619] train_loss: 0.014196\n",
      "[130/00669] train_loss: 0.013946\n",
      "[130/00719] train_loss: 0.014121\n",
      "[130/00769] train_loss: 0.014285\n",
      "[130/00819] train_loss: 0.013098\n",
      "[130/00869] train_loss: 0.013470\n",
      "[130/00919] train_loss: 0.013388\n",
      "[130/00969] train_loss: 0.014327\n",
      "[130/01019] train_loss: 0.013858\n",
      "[130/01069] train_loss: 0.012921\n",
      "[130/01119] train_loss: 0.013735\n",
      "[130/01169] train_loss: 0.013875\n",
      "[130/01219] train_loss: 0.013007\n",
      "[131/00043] train_loss: 0.014832\n",
      "[131/00093] train_loss: 0.014671\n",
      "[131/00143] train_loss: 0.014706\n",
      "[131/00193] train_loss: 0.014742\n",
      "[131/00243] train_loss: 0.013228\n",
      "[131/00293] train_loss: 0.014328\n",
      "[131/00343] train_loss: 0.014693\n",
      "[131/00393] train_loss: 0.013895\n",
      "[131/00443] train_loss: 0.013991\n",
      "[131/00493] train_loss: 0.013560\n",
      "[131/00543] train_loss: 0.014225\n",
      "[131/00593] train_loss: 0.014085\n",
      "[131/00643] train_loss: 0.014243\n",
      "[131/00693] train_loss: 0.013230\n",
      "[131/00743] train_loss: 0.013198\n",
      "[131/00793] train_loss: 0.014011\n",
      "[131/00843] train_loss: 0.014323\n",
      "[131/00893] train_loss: 0.013131\n",
      "[131/00943] train_loss: 0.013720\n",
      "[131/00993] train_loss: 0.014540\n",
      "[131/01043] train_loss: 0.013376\n",
      "[131/01093] train_loss: 0.014249\n",
      "[131/01143] train_loss: 0.013333\n",
      "[131/01193] train_loss: 0.013794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[132/00017] train_loss: 0.014660\n",
      "[132/00067] train_loss: 0.015064\n",
      "[132/00117] train_loss: 0.014945\n",
      "[132/00167] train_loss: 0.015057\n",
      "[132/00217] train_loss: 0.013470\n",
      "[132/00267] train_loss: 0.014145\n",
      "[132/00317] train_loss: 0.014001\n",
      "[132/00367] train_loss: 0.014970\n",
      "[132/00417] train_loss: 0.014643\n",
      "[132/00467] train_loss: 0.014042\n",
      "[132/00517] train_loss: 0.014206\n",
      "[132/00567] train_loss: 0.014104\n",
      "[132/00617] train_loss: 0.013062\n",
      "[132/00667] train_loss: 0.014091\n",
      "[132/00717] train_loss: 0.013138\n",
      "[132/00767] train_loss: 0.014110\n",
      "[132/00817] train_loss: 0.013315\n",
      "[132/00867] train_loss: 0.014282\n",
      "[132/00917] train_loss: 0.013683\n",
      "[132/00967] train_loss: 0.013453\n",
      "[132/01017] train_loss: 0.014167\n",
      "[132/01067] train_loss: 0.013633\n",
      "[132/01117] train_loss: 0.013794\n",
      "[132/01167] train_loss: 0.013628\n",
      "[132/01217] train_loss: 0.013971\n",
      "[133/00041] train_loss: 0.014629\n",
      "[133/00091] train_loss: 0.014359\n",
      "[133/00141] train_loss: 0.013990\n",
      "[133/00191] train_loss: 0.014882\n",
      "[133/00241] train_loss: 0.013800\n",
      "[133/00291] train_loss: 0.014433\n",
      "[133/00341] train_loss: 0.014801\n",
      "[133/00391] train_loss: 0.013248\n",
      "[133/00441] train_loss: 0.014215\n",
      "[133/00491] train_loss: 0.013694\n",
      "[133/00541] train_loss: 0.013854\n",
      "[133/00591] train_loss: 0.013610\n",
      "[133/00641] train_loss: 0.014393\n",
      "[133/00691] train_loss: 0.014255\n",
      "[133/00741] train_loss: 0.014194\n",
      "[133/00791] train_loss: 0.014195\n",
      "[133/00841] train_loss: 0.013742\n",
      "[133/00891] train_loss: 0.013809\n",
      "[133/00941] train_loss: 0.014890\n",
      "[133/00991] train_loss: 0.014364\n",
      "[133/01041] train_loss: 0.013842\n",
      "[133/01091] train_loss: 0.013320\n",
      "[133/01141] train_loss: 0.013407\n",
      "[133/01191] train_loss: 0.013683\n",
      "[134/00015] train_loss: 0.013947\n",
      "[134/00065] train_loss: 0.015037\n",
      "[134/00115] train_loss: 0.014547\n",
      "[134/00165] train_loss: 0.014726\n",
      "[134/00215] train_loss: 0.014708\n",
      "[134/00265] train_loss: 0.014650\n",
      "[134/00315] train_loss: 0.014800\n",
      "[134/00365] train_loss: 0.013159\n",
      "[134/00415] train_loss: 0.013938\n",
      "[134/00465] train_loss: 0.014264\n",
      "[134/00515] train_loss: 0.014197\n",
      "[134/00565] train_loss: 0.014478\n",
      "[134/00615] train_loss: 0.013206\n",
      "[134/00665] train_loss: 0.014352\n",
      "[134/00715] train_loss: 0.013754\n",
      "[134/00765] train_loss: 0.013174\n",
      "[134/00815] train_loss: 0.013499\n",
      "[134/00865] train_loss: 0.013475\n",
      "[134/00915] train_loss: 0.013896\n",
      "[134/00965] train_loss: 0.014189\n",
      "[134/01015] train_loss: 0.014059\n",
      "[134/01065] train_loss: 0.013730\n",
      "[134/01115] train_loss: 0.014319\n",
      "[134/01165] train_loss: 0.013817\n",
      "[134/01215] train_loss: 0.013027\n",
      "[135/00039] train_loss: 0.014704\n",
      "[135/00089] train_loss: 0.014713\n",
      "[135/00139] train_loss: 0.015128\n",
      "[135/00189] train_loss: 0.015035\n",
      "[135/00239] train_loss: 0.014355\n",
      "[135/00289] train_loss: 0.014270\n",
      "[135/00339] train_loss: 0.014375\n",
      "[135/00389] train_loss: 0.014012\n",
      "[135/00439] train_loss: 0.013588\n",
      "[135/00489] train_loss: 0.014635\n",
      "[135/00539] train_loss: 0.013904\n",
      "[135/00589] train_loss: 0.013992\n",
      "[135/00639] train_loss: 0.014242\n",
      "[135/00689] train_loss: 0.013390\n",
      "[135/00739] train_loss: 0.013607\n",
      "[135/00789] train_loss: 0.013686\n",
      "[135/00839] train_loss: 0.014169\n",
      "[135/00889] train_loss: 0.013603\n",
      "[135/00939] train_loss: 0.013691\n",
      "[135/00989] train_loss: 0.013791\n",
      "[135/01039] train_loss: 0.013040\n",
      "[135/01089] train_loss: 0.013142\n",
      "[135/01139] train_loss: 0.013467\n",
      "[135/01189] train_loss: 0.013685\n",
      "[136/00013] train_loss: 0.013182\n",
      "[136/00063] train_loss: 0.014898\n",
      "[136/00113] train_loss: 0.014428\n",
      "[136/00163] train_loss: 0.014010\n",
      "[136/00213] train_loss: 0.014370\n",
      "[136/00263] train_loss: 0.013982\n",
      "[136/00313] train_loss: 0.014222\n",
      "[136/00363] train_loss: 0.013636\n",
      "[136/00413] train_loss: 0.013835\n",
      "[136/00463] train_loss: 0.013900\n",
      "[136/00513] train_loss: 0.013399\n",
      "[136/00563] train_loss: 0.013236\n",
      "[136/00613] train_loss: 0.014188\n",
      "[136/00663] train_loss: 0.014011\n",
      "[136/00713] train_loss: 0.013858\n",
      "[136/00763] train_loss: 0.013749\n",
      "[136/00813] train_loss: 0.013970\n",
      "[136/00863] train_loss: 0.013577\n",
      "[136/00913] train_loss: 0.012725\n",
      "[136/00963] train_loss: 0.013531\n",
      "[136/01013] train_loss: 0.014345\n",
      "[136/01063] train_loss: 0.013802\n",
      "[136/01113] train_loss: 0.014185\n",
      "[136/01163] train_loss: 0.013467\n",
      "[136/01213] train_loss: 0.013755\n",
      "[137/00037] train_loss: 0.014645\n",
      "[137/00087] train_loss: 0.014416\n",
      "[137/00137] train_loss: 0.013780\n",
      "[137/00187] train_loss: 0.014489\n",
      "[137/00237] train_loss: 0.014600\n",
      "[137/00287] train_loss: 0.014063\n",
      "[137/00337] train_loss: 0.013906\n",
      "[137/00387] train_loss: 0.013302\n",
      "[137/00437] train_loss: 0.014508\n",
      "[137/00487] train_loss: 0.013783\n",
      "[137/00537] train_loss: 0.013660\n",
      "[137/00587] train_loss: 0.013453\n",
      "[137/00637] train_loss: 0.013128\n",
      "[137/00687] train_loss: 0.013895\n",
      "[137/00737] train_loss: 0.013652\n",
      "[137/00787] train_loss: 0.013934\n",
      "[137/00837] train_loss: 0.013529\n",
      "[137/00887] train_loss: 0.013902\n",
      "[137/00937] train_loss: 0.014197\n",
      "[137/00987] train_loss: 0.014048\n",
      "[137/01037] train_loss: 0.013709\n",
      "[137/01087] train_loss: 0.013411\n",
      "[137/01137] train_loss: 0.013382\n",
      "[137/01187] train_loss: 0.013357\n",
      "[138/00011] train_loss: 0.013974\n",
      "[138/00061] train_loss: 0.014461\n",
      "[138/00111] train_loss: 0.014507\n",
      "[138/00161] train_loss: 0.013851\n",
      "[138/00211] train_loss: 0.014138\n",
      "[138/00261] train_loss: 0.013954\n",
      "[138/00311] train_loss: 0.014634\n",
      "[138/00361] train_loss: 0.014180\n",
      "[138/00411] train_loss: 0.014241\n",
      "[138/00461] train_loss: 0.013404\n",
      "[138/00511] train_loss: 0.014546\n",
      "[138/00561] train_loss: 0.013354\n",
      "[138/00611] train_loss: 0.013921\n",
      "[138/00661] train_loss: 0.013994\n",
      "[138/00711] train_loss: 0.013332\n",
      "[138/00761] train_loss: 0.013631\n",
      "[138/00811] train_loss: 0.014087\n",
      "[138/00861] train_loss: 0.014776\n",
      "[138/00911] train_loss: 0.013834\n",
      "[138/00961] train_loss: 0.013523\n",
      "[138/01011] train_loss: 0.013825\n",
      "[138/01061] train_loss: 0.014029\n",
      "[138/01111] train_loss: 0.013480\n",
      "[138/01161] train_loss: 0.012842\n",
      "[138/01211] train_loss: 0.013314\n",
      "[139/00035] train_loss: 0.013965\n",
      "[139/00085] train_loss: 0.014775\n",
      "[139/00135] train_loss: 0.014039\n",
      "[139/00185] train_loss: 0.014682\n",
      "[139/00235] train_loss: 0.014362\n",
      "[139/00285] train_loss: 0.014053\n",
      "[139/00335] train_loss: 0.013523\n",
      "[139/00385] train_loss: 0.013630\n",
      "[139/00435] train_loss: 0.014748\n",
      "[139/00485] train_loss: 0.014479\n",
      "[139/00535] train_loss: 0.014087\n",
      "[139/00585] train_loss: 0.013114\n",
      "[139/00635] train_loss: 0.013236\n",
      "[139/00685] train_loss: 0.013090\n",
      "[139/00735] train_loss: 0.013299\n",
      "[139/00785] train_loss: 0.014479\n",
      "[139/00835] train_loss: 0.013896\n",
      "[139/00885] train_loss: 0.013294\n",
      "[139/00935] train_loss: 0.013926\n",
      "[139/00985] train_loss: 0.014063\n",
      "[139/01035] train_loss: 0.013893\n",
      "[139/01085] train_loss: 0.014187\n",
      "[139/01135] train_loss: 0.013472\n",
      "[139/01185] train_loss: 0.013492\n",
      "[140/00009] train_loss: 0.013353\n",
      "[140/00059] train_loss: 0.015340\n",
      "[140/00109] train_loss: 0.013983\n",
      "[140/00159] train_loss: 0.014389\n",
      "[140/00209] train_loss: 0.014194\n",
      "[140/00259] train_loss: 0.014021\n",
      "[140/00309] train_loss: 0.014100\n",
      "[140/00359] train_loss: 0.013522\n",
      "[140/00409] train_loss: 0.014136\n",
      "[140/00459] train_loss: 0.014400\n",
      "[140/00509] train_loss: 0.014498\n",
      "[140/00559] train_loss: 0.013135\n",
      "[140/00609] train_loss: 0.014095\n",
      "[140/00659] train_loss: 0.013942\n",
      "[140/00709] train_loss: 0.013796\n",
      "[140/00759] train_loss: 0.014322\n",
      "[140/00809] train_loss: 0.014438\n",
      "[140/00859] train_loss: 0.013381\n",
      "[140/00909] train_loss: 0.013063\n",
      "[140/00959] train_loss: 0.013759\n",
      "[140/01009] train_loss: 0.013899\n",
      "[140/01059] train_loss: 0.013884\n",
      "[140/01109] train_loss: 0.013703\n",
      "[140/01159] train_loss: 0.013199\n",
      "[140/01209] train_loss: 0.012947\n",
      "[141/00033] train_loss: 0.014253\n",
      "[141/00083] train_loss: 0.014592\n",
      "[141/00133] train_loss: 0.013907\n",
      "[141/00183] train_loss: 0.013680\n",
      "[141/00233] train_loss: 0.014159\n",
      "[141/00283] train_loss: 0.014317\n",
      "[141/00333] train_loss: 0.014677\n",
      "[141/00383] train_loss: 0.013660\n",
      "[141/00433] train_loss: 0.013730\n",
      "[141/00483] train_loss: 0.012934\n",
      "[141/00533] train_loss: 0.014670\n",
      "[141/00583] train_loss: 0.013296\n",
      "[141/00633] train_loss: 0.013588\n",
      "[141/00683] train_loss: 0.013246\n",
      "[141/00733] train_loss: 0.013214\n",
      "[141/00783] train_loss: 0.014014\n",
      "[141/00833] train_loss: 0.013669\n",
      "[141/00883] train_loss: 0.012315\n",
      "[141/00933] train_loss: 0.013845\n",
      "[141/00983] train_loss: 0.013180\n",
      "[141/01033] train_loss: 0.013433\n",
      "[141/01083] train_loss: 0.013640\n",
      "[141/01133] train_loss: 0.013795\n",
      "[141/01183] train_loss: 0.014116\n",
      "[142/00007] train_loss: 0.013238\n",
      "[142/00057] train_loss: 0.014891\n",
      "[142/00107] train_loss: 0.014564\n",
      "[142/00157] train_loss: 0.014759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[142/00207] train_loss: 0.013720\n",
      "[142/00257] train_loss: 0.013961\n",
      "[142/00307] train_loss: 0.013454\n",
      "[142/00357] train_loss: 0.014626\n",
      "[142/00407] train_loss: 0.014611\n",
      "[142/00457] train_loss: 0.014178\n",
      "[142/00507] train_loss: 0.013391\n",
      "[142/00557] train_loss: 0.014681\n",
      "[142/00607] train_loss: 0.013568\n",
      "[142/00657] train_loss: 0.013289\n",
      "[142/00707] train_loss: 0.014092\n",
      "[142/00757] train_loss: 0.013803\n",
      "[142/00807] train_loss: 0.013276\n",
      "[142/00857] train_loss: 0.013785\n",
      "[142/00907] train_loss: 0.012843\n",
      "[142/00957] train_loss: 0.013973\n",
      "[142/01007] train_loss: 0.013522\n",
      "[142/01057] train_loss: 0.013307\n",
      "[142/01107] train_loss: 0.012380\n",
      "[142/01157] train_loss: 0.013297\n",
      "[142/01207] train_loss: 0.013543\n",
      "[143/00031] train_loss: 0.013903\n",
      "[143/00081] train_loss: 0.014052\n",
      "[143/00131] train_loss: 0.014516\n",
      "[143/00181] train_loss: 0.014259\n",
      "[143/00231] train_loss: 0.013962\n",
      "[143/00281] train_loss: 0.013104\n",
      "[143/00331] train_loss: 0.013867\n",
      "[143/00381] train_loss: 0.013055\n",
      "[143/00431] train_loss: 0.013514\n",
      "[143/00481] train_loss: 0.014981\n",
      "[143/00531] train_loss: 0.013580\n",
      "[143/00581] train_loss: 0.014601\n",
      "[143/00631] train_loss: 0.013884\n",
      "[143/00681] train_loss: 0.013399\n",
      "[143/00731] train_loss: 0.013959\n",
      "[143/00781] train_loss: 0.013851\n",
      "[143/00831] train_loss: 0.012605\n",
      "[143/00881] train_loss: 0.013771\n",
      "[143/00931] train_loss: 0.014180\n",
      "[143/00981] train_loss: 0.013496\n",
      "[143/01031] train_loss: 0.012980\n",
      "[143/01081] train_loss: 0.013099\n",
      "[143/01131] train_loss: 0.014194\n",
      "[143/01181] train_loss: 0.013278\n",
      "[144/00005] train_loss: 0.012768\n",
      "[144/00055] train_loss: 0.015042\n",
      "[144/00105] train_loss: 0.014851\n",
      "[144/00155] train_loss: 0.014784\n",
      "[144/00205] train_loss: 0.013856\n",
      "[144/00255] train_loss: 0.013831\n",
      "[144/00305] train_loss: 0.014128\n",
      "[144/00355] train_loss: 0.014127\n",
      "[144/00405] train_loss: 0.013844\n",
      "[144/00455] train_loss: 0.013626\n",
      "[144/00505] train_loss: 0.014709\n",
      "[144/00555] train_loss: 0.014239\n",
      "[144/00605] train_loss: 0.013375\n",
      "[144/00655] train_loss: 0.012983\n",
      "[144/00705] train_loss: 0.013283\n",
      "[144/00755] train_loss: 0.013527\n",
      "[144/00805] train_loss: 0.014015\n",
      "[144/00855] train_loss: 0.013459\n",
      "[144/00905] train_loss: 0.013631\n",
      "[144/00955] train_loss: 0.012809\n",
      "[144/01005] train_loss: 0.013574\n",
      "[144/01055] train_loss: 0.012404\n",
      "[144/01105] train_loss: 0.013961\n",
      "[144/01155] train_loss: 0.012726\n",
      "[144/01205] train_loss: 0.013587\n",
      "[145/00029] train_loss: 0.013957\n",
      "[145/00079] train_loss: 0.014571\n",
      "[145/00129] train_loss: 0.014941\n",
      "[145/00179] train_loss: 0.014391\n",
      "[145/00229] train_loss: 0.014210\n",
      "[145/00279] train_loss: 0.013711\n",
      "[145/00329] train_loss: 0.014022\n",
      "[145/00379] train_loss: 0.013845\n",
      "[145/00429] train_loss: 0.013802\n",
      "[145/00479] train_loss: 0.013772\n",
      "[145/00529] train_loss: 0.013552\n",
      "[145/00579] train_loss: 0.013994\n",
      "[145/00629] train_loss: 0.014243\n",
      "[145/00679] train_loss: 0.013825\n",
      "[145/00729] train_loss: 0.013785\n",
      "[145/00779] train_loss: 0.014648\n",
      "[145/00829] train_loss: 0.013495\n",
      "[145/00879] train_loss: 0.012929\n",
      "[145/00929] train_loss: 0.012994\n",
      "[145/00979] train_loss: 0.013071\n",
      "[145/01029] train_loss: 0.012307\n",
      "[145/01079] train_loss: 0.013351\n",
      "[145/01129] train_loss: 0.013034\n",
      "[145/01179] train_loss: 0.013518\n",
      "[146/00003] train_loss: 0.013782\n",
      "[146/00053] train_loss: 0.015187\n",
      "[146/00103] train_loss: 0.013943\n",
      "[146/00153] train_loss: 0.013943\n",
      "[146/00203] train_loss: 0.014799\n",
      "[146/00253] train_loss: 0.013751\n",
      "[146/00303] train_loss: 0.014358\n",
      "[146/00353] train_loss: 0.013585\n",
      "[146/00403] train_loss: 0.013896\n",
      "[146/00453] train_loss: 0.013231\n",
      "[146/00503] train_loss: 0.013818\n",
      "[146/00553] train_loss: 0.013353\n",
      "[146/00603] train_loss: 0.012844\n",
      "[146/00653] train_loss: 0.014090\n",
      "[146/00703] train_loss: 0.013347\n",
      "[146/00753] train_loss: 0.014247\n",
      "[146/00803] train_loss: 0.014299\n",
      "[146/00853] train_loss: 0.013813\n",
      "[146/00903] train_loss: 0.013616\n",
      "[146/00953] train_loss: 0.013123\n",
      "[146/01003] train_loss: 0.013878\n",
      "[146/01053] train_loss: 0.013196\n",
      "[146/01103] train_loss: 0.013271\n",
      "[146/01153] train_loss: 0.013348\n",
      "[146/01203] train_loss: 0.013727\n",
      "[147/00027] train_loss: 0.014210\n",
      "[147/00077] train_loss: 0.013821\n",
      "[147/00127] train_loss: 0.014576\n",
      "[147/00177] train_loss: 0.013706\n",
      "[147/00227] train_loss: 0.014168\n",
      "[147/00277] train_loss: 0.014212\n",
      "[147/00327] train_loss: 0.014102\n",
      "[147/00377] train_loss: 0.013900\n",
      "[147/00427] train_loss: 0.013286\n",
      "[147/00477] train_loss: 0.013714\n",
      "[147/00527] train_loss: 0.013924\n",
      "[147/00577] train_loss: 0.014104\n",
      "[147/00627] train_loss: 0.013465\n",
      "[147/00677] train_loss: 0.013698\n",
      "[147/00727] train_loss: 0.014156\n",
      "[147/00777] train_loss: 0.013324\n",
      "[147/00827] train_loss: 0.013714\n",
      "[147/00877] train_loss: 0.013215\n",
      "[147/00927] train_loss: 0.013220\n",
      "[147/00977] train_loss: 0.013314\n",
      "[147/01027] train_loss: 0.013091\n",
      "[147/01077] train_loss: 0.014003\n",
      "[147/01127] train_loss: 0.013644\n",
      "[147/01177] train_loss: 0.012916\n",
      "[148/00001] train_loss: 0.013421\n",
      "[148/00051] train_loss: 0.014788\n",
      "[148/00101] train_loss: 0.014390\n",
      "[148/00151] train_loss: 0.014807\n",
      "[148/00201] train_loss: 0.014040\n",
      "[148/00251] train_loss: 0.013830\n",
      "[148/00301] train_loss: 0.014009\n",
      "[148/00351] train_loss: 0.013663\n",
      "[148/00401] train_loss: 0.013623\n",
      "[148/00451] train_loss: 0.013867\n",
      "[148/00501] train_loss: 0.013883\n",
      "[148/00551] train_loss: 0.012936\n",
      "[148/00601] train_loss: 0.013552\n",
      "[148/00651] train_loss: 0.013498\n",
      "[148/00701] train_loss: 0.013425\n",
      "[148/00751] train_loss: 0.013710\n",
      "[148/00801] train_loss: 0.012853\n",
      "[148/00851] train_loss: 0.013489\n",
      "[148/00901] train_loss: 0.014953\n",
      "[148/00951] train_loss: 0.014016\n",
      "[148/01001] train_loss: 0.013672\n",
      "[148/01051] train_loss: 0.013278\n",
      "[148/01101] train_loss: 0.013172\n",
      "[148/01151] train_loss: 0.013324\n",
      "[148/01201] train_loss: 0.013253\n",
      "[149/00025] train_loss: 0.014336\n",
      "[149/00075] train_loss: 0.014367\n",
      "[149/00125] train_loss: 0.013744\n",
      "[149/00175] train_loss: 0.014168\n",
      "[149/00225] train_loss: 0.013841\n",
      "[149/00275] train_loss: 0.013951\n",
      "[149/00325] train_loss: 0.013594\n",
      "[149/00375] train_loss: 0.013577\n",
      "[149/00425] train_loss: 0.013001\n",
      "[149/00475] train_loss: 0.013507\n",
      "[149/00525] train_loss: 0.013787\n",
      "[149/00575] train_loss: 0.013156\n",
      "[149/00625] train_loss: 0.013411\n",
      "[149/00675] train_loss: 0.014365\n",
      "[149/00725] train_loss: 0.012809\n",
      "[149/00775] train_loss: 0.013675\n",
      "[149/00825] train_loss: 0.013433\n",
      "[149/00875] train_loss: 0.013138\n",
      "[149/00925] train_loss: 0.014082\n",
      "[149/00975] train_loss: 0.013061\n",
      "[149/01025] train_loss: 0.013047\n",
      "[149/01075] train_loss: 0.012770\n",
      "[149/01125] train_loss: 0.014050\n",
      "[149/01175] train_loss: 0.013945\n",
      "[149/01225] train_loss: 0.013374\n",
      "[150/00049] train_loss: 0.014700\n",
      "[150/00099] train_loss: 0.014688\n",
      "[150/00149] train_loss: 0.014783\n",
      "[150/00199] train_loss: 0.014661\n",
      "[150/00249] train_loss: 0.014109\n",
      "[150/00299] train_loss: 0.013559\n",
      "[150/00349] train_loss: 0.013691\n",
      "[150/00399] train_loss: 0.013706\n",
      "[150/00449] train_loss: 0.013692\n",
      "[150/00499] train_loss: 0.013231\n",
      "[150/00549] train_loss: 0.012558\n",
      "[150/00599] train_loss: 0.012823\n",
      "[150/00649] train_loss: 0.013723\n",
      "[150/00699] train_loss: 0.013605\n",
      "[150/00749] train_loss: 0.014646\n",
      "[150/00799] train_loss: 0.013107\n",
      "[150/00849] train_loss: 0.013443\n",
      "[150/00899] train_loss: 0.013394\n",
      "[150/00949] train_loss: 0.013972\n",
      "[150/00999] train_loss: 0.013093\n",
      "[150/01049] train_loss: 0.014078\n",
      "[150/01099] train_loss: 0.013078\n",
      "[150/01149] train_loss: 0.013299\n",
      "[150/01199] train_loss: 0.013700\n",
      "[151/00023] train_loss: 0.014451\n",
      "[151/00073] train_loss: 0.014659\n",
      "[151/00123] train_loss: 0.014170\n",
      "[151/00173] train_loss: 0.013914\n",
      "[151/00223] train_loss: 0.014625\n",
      "[151/00273] train_loss: 0.013118\n",
      "[151/00323] train_loss: 0.013460\n",
      "[151/00373] train_loss: 0.014576\n",
      "[151/00423] train_loss: 0.013472\n",
      "[151/00473] train_loss: 0.013066\n",
      "[151/00523] train_loss: 0.012811\n",
      "[151/00573] train_loss: 0.013967\n",
      "[151/00623] train_loss: 0.013873\n",
      "[151/00673] train_loss: 0.013482\n",
      "[151/00723] train_loss: 0.013091\n",
      "[151/00773] train_loss: 0.012655\n",
      "[151/00823] train_loss: 0.013017\n",
      "[151/00873] train_loss: 0.013816\n",
      "[151/00923] train_loss: 0.013686\n",
      "[151/00973] train_loss: 0.013166\n",
      "[151/01023] train_loss: 0.013272\n",
      "[151/01073] train_loss: 0.013111\n",
      "[151/01123] train_loss: 0.012835\n",
      "[151/01173] train_loss: 0.012970\n",
      "[151/01223] train_loss: 0.013250\n",
      "[152/00047] train_loss: 0.013788\n",
      "[152/00097] train_loss: 0.014404\n",
      "[152/00147] train_loss: 0.013822\n",
      "[152/00197] train_loss: 0.013890\n",
      "[152/00247] train_loss: 0.013791\n",
      "[152/00297] train_loss: 0.013230\n",
      "[152/00347] train_loss: 0.013717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[152/00397] train_loss: 0.013047\n",
      "[152/00447] train_loss: 0.014263\n",
      "[152/00497] train_loss: 0.013462\n",
      "[152/00547] train_loss: 0.013052\n",
      "[152/00597] train_loss: 0.013877\n",
      "[152/00647] train_loss: 0.013921\n",
      "[152/00697] train_loss: 0.014365\n",
      "[152/00747] train_loss: 0.013792\n",
      "[152/00797] train_loss: 0.013798\n",
      "[152/00847] train_loss: 0.013475\n",
      "[152/00897] train_loss: 0.013849\n",
      "[152/00947] train_loss: 0.013632\n",
      "[152/00997] train_loss: 0.013328\n",
      "[152/01047] train_loss: 0.012816\n",
      "[152/01097] train_loss: 0.013616\n",
      "[152/01147] train_loss: 0.013567\n",
      "[152/01197] train_loss: 0.012944\n",
      "[153/00021] train_loss: 0.014368\n",
      "[153/00071] train_loss: 0.014222\n",
      "[153/00121] train_loss: 0.013810\n",
      "[153/00171] train_loss: 0.013659\n",
      "[153/00221] train_loss: 0.013640\n",
      "[153/00271] train_loss: 0.013255\n",
      "[153/00321] train_loss: 0.013973\n",
      "[153/00371] train_loss: 0.014775\n",
      "[153/00421] train_loss: 0.013063\n",
      "[153/00471] train_loss: 0.012955\n",
      "[153/00521] train_loss: 0.013687\n",
      "[153/00571] train_loss: 0.013493\n",
      "[153/00621] train_loss: 0.014288\n",
      "[153/00671] train_loss: 0.013220\n",
      "[153/00721] train_loss: 0.013271\n",
      "[153/00771] train_loss: 0.014086\n",
      "[153/00821] train_loss: 0.013796\n",
      "[153/00871] train_loss: 0.012761\n",
      "[153/00921] train_loss: 0.013238\n",
      "[153/00971] train_loss: 0.014330\n",
      "[153/01021] train_loss: 0.013773\n",
      "[153/01071] train_loss: 0.013046\n",
      "[153/01121] train_loss: 0.013395\n",
      "[153/01171] train_loss: 0.013426\n",
      "[153/01221] train_loss: 0.013297\n",
      "[154/00045] train_loss: 0.014044\n",
      "[154/00095] train_loss: 0.014666\n",
      "[154/00145] train_loss: 0.013596\n",
      "[154/00195] train_loss: 0.014091\n",
      "[154/00245] train_loss: 0.013833\n",
      "[154/00295] train_loss: 0.013692\n",
      "[154/00345] train_loss: 0.013238\n",
      "[154/00395] train_loss: 0.014144\n",
      "[154/00445] train_loss: 0.013473\n",
      "[154/00495] train_loss: 0.014457\n",
      "[154/00545] train_loss: 0.013824\n",
      "[154/00595] train_loss: 0.013420\n",
      "[154/00645] train_loss: 0.013384\n",
      "[154/00695] train_loss: 0.014050\n",
      "[154/00745] train_loss: 0.014324\n",
      "[154/00795] train_loss: 0.014058\n",
      "[154/00845] train_loss: 0.013682\n",
      "[154/00895] train_loss: 0.012692\n",
      "[154/00945] train_loss: 0.012953\n",
      "[154/00995] train_loss: 0.013136\n",
      "[154/01045] train_loss: 0.012274\n",
      "[154/01095] train_loss: 0.013757\n",
      "[154/01145] train_loss: 0.013787\n",
      "[154/01195] train_loss: 0.014096\n",
      "[155/00019] train_loss: 0.013527\n",
      "[155/00069] train_loss: 0.013762\n",
      "[155/00119] train_loss: 0.014353\n",
      "[155/00169] train_loss: 0.013036\n",
      "[155/00219] train_loss: 0.013810\n",
      "[155/00269] train_loss: 0.013818\n",
      "[155/00319] train_loss: 0.013701\n",
      "[155/00369] train_loss: 0.013844\n",
      "[155/00419] train_loss: 0.013816\n",
      "[155/00469] train_loss: 0.014074\n",
      "[155/00519] train_loss: 0.013948\n",
      "[155/00569] train_loss: 0.013372\n",
      "[155/00619] train_loss: 0.014075\n",
      "[155/00669] train_loss: 0.012982\n",
      "[155/00719] train_loss: 0.013873\n",
      "[155/00769] train_loss: 0.013192\n",
      "[155/00819] train_loss: 0.013200\n",
      "[155/00869] train_loss: 0.014225\n",
      "[155/00919] train_loss: 0.013484\n",
      "[155/00969] train_loss: 0.014129\n",
      "[155/01019] train_loss: 0.013213\n",
      "[155/01069] train_loss: 0.013258\n",
      "[155/01119] train_loss: 0.012909\n",
      "[155/01169] train_loss: 0.013021\n",
      "[155/01219] train_loss: 0.012565\n",
      "[156/00043] train_loss: 0.015226\n",
      "[156/00093] train_loss: 0.013723\n",
      "[156/00143] train_loss: 0.015036\n",
      "[156/00193] train_loss: 0.013698\n",
      "[156/00243] train_loss: 0.013545\n",
      "[156/00293] train_loss: 0.013003\n",
      "[156/00343] train_loss: 0.014171\n",
      "[156/00393] train_loss: 0.014045\n",
      "[156/00443] train_loss: 0.014195\n",
      "[156/00493] train_loss: 0.014055\n",
      "[156/00543] train_loss: 0.012829\n",
      "[156/00593] train_loss: 0.013683\n",
      "[156/00643] train_loss: 0.013868\n",
      "[156/00693] train_loss: 0.013467\n",
      "[156/00743] train_loss: 0.014143\n",
      "[156/00793] train_loss: 0.012919\n",
      "[156/00843] train_loss: 0.013574\n",
      "[156/00893] train_loss: 0.013539\n",
      "[156/00943] train_loss: 0.013427\n",
      "[156/00993] train_loss: 0.013953\n",
      "[156/01043] train_loss: 0.012713\n",
      "[156/01093] train_loss: 0.012883\n",
      "[156/01143] train_loss: 0.012915\n",
      "[156/01193] train_loss: 0.013344\n",
      "[157/00017] train_loss: 0.013843\n",
      "[157/00067] train_loss: 0.013647\n",
      "[157/00117] train_loss: 0.014065\n",
      "[157/00167] train_loss: 0.015012\n",
      "[157/00217] train_loss: 0.014273\n",
      "[157/00267] train_loss: 0.014320\n",
      "[157/00317] train_loss: 0.014216\n",
      "[157/00367] train_loss: 0.013826\n",
      "[157/00417] train_loss: 0.013455\n",
      "[157/00467] train_loss: 0.013447\n",
      "[157/00517] train_loss: 0.013599\n",
      "[157/00567] train_loss: 0.013503\n",
      "[157/00617] train_loss: 0.013192\n",
      "[157/00667] train_loss: 0.013111\n",
      "[157/00717] train_loss: 0.012369\n",
      "[157/00767] train_loss: 0.013926\n",
      "[157/00817] train_loss: 0.013304\n",
      "[157/00867] train_loss: 0.012789\n",
      "[157/00917] train_loss: 0.013765\n",
      "[157/00967] train_loss: 0.013458\n",
      "[157/01017] train_loss: 0.013497\n",
      "[157/01067] train_loss: 0.012994\n",
      "[157/01117] train_loss: 0.013312\n",
      "[157/01167] train_loss: 0.012469\n",
      "[157/01217] train_loss: 0.013208\n",
      "[158/00041] train_loss: 0.014498\n",
      "[158/00091] train_loss: 0.014095\n",
      "[158/00141] train_loss: 0.014092\n",
      "[158/00191] train_loss: 0.014321\n",
      "[158/00241] train_loss: 0.013477\n",
      "[158/00291] train_loss: 0.013654\n",
      "[158/00341] train_loss: 0.013598\n",
      "[158/00391] train_loss: 0.013233\n",
      "[158/00441] train_loss: 0.013664\n",
      "[158/00491] train_loss: 0.013644\n",
      "[158/00541] train_loss: 0.013753\n",
      "[158/00591] train_loss: 0.013442\n",
      "[158/00641] train_loss: 0.014593\n",
      "[158/00691] train_loss: 0.013470\n",
      "[158/00741] train_loss: 0.013461\n",
      "[158/00791] train_loss: 0.012915\n",
      "[158/00841] train_loss: 0.013118\n",
      "[158/00891] train_loss: 0.013299\n",
      "[158/00941] train_loss: 0.013975\n",
      "[158/00991] train_loss: 0.013324\n",
      "[158/01041] train_loss: 0.013124\n",
      "[158/01091] train_loss: 0.013371\n",
      "[158/01141] train_loss: 0.013385\n",
      "[158/01191] train_loss: 0.013310\n",
      "[159/00015] train_loss: 0.013864\n",
      "[159/00065] train_loss: 0.014639\n",
      "[159/00115] train_loss: 0.014220\n",
      "[159/00165] train_loss: 0.013512\n",
      "[159/00215] train_loss: 0.014427\n",
      "[159/00265] train_loss: 0.013924\n",
      "[159/00315] train_loss: 0.013029\n",
      "[159/00365] train_loss: 0.014043\n",
      "[159/00415] train_loss: 0.013657\n",
      "[159/00465] train_loss: 0.013515\n",
      "[159/00515] train_loss: 0.013453\n",
      "[159/00565] train_loss: 0.013764\n",
      "[159/00615] train_loss: 0.013439\n",
      "[159/00665] train_loss: 0.012733\n",
      "[159/00715] train_loss: 0.012235\n",
      "[159/00765] train_loss: 0.013693\n",
      "[159/00815] train_loss: 0.013178\n",
      "[159/00865] train_loss: 0.013479\n",
      "[159/00915] train_loss: 0.012819\n",
      "[159/00965] train_loss: 0.011832\n",
      "[159/01015] train_loss: 0.013832\n",
      "[159/01065] train_loss: 0.013149\n",
      "[159/01115] train_loss: 0.013096\n",
      "[159/01165] train_loss: 0.013028\n",
      "[159/01215] train_loss: 0.013989\n",
      "[160/00039] train_loss: 0.014988\n",
      "[160/00089] train_loss: 0.014276\n",
      "[160/00139] train_loss: 0.013356\n",
      "[160/00189] train_loss: 0.013866\n",
      "[160/00239] train_loss: 0.014400\n",
      "[160/00289] train_loss: 0.013346\n",
      "[160/00339] train_loss: 0.014229\n",
      "[160/00389] train_loss: 0.013348\n",
      "[160/00439] train_loss: 0.013678\n",
      "[160/00489] train_loss: 0.013673\n",
      "[160/00539] train_loss: 0.013880\n",
      "[160/00589] train_loss: 0.013631\n",
      "[160/00639] train_loss: 0.013067\n",
      "[160/00689] train_loss: 0.012632\n",
      "[160/00739] train_loss: 0.012691\n",
      "[160/00789] train_loss: 0.013444\n",
      "[160/00839] train_loss: 0.013558\n",
      "[160/00889] train_loss: 0.013184\n",
      "[160/00939] train_loss: 0.013150\n",
      "[160/00989] train_loss: 0.013276\n",
      "[160/01039] train_loss: 0.012427\n",
      "[160/01089] train_loss: 0.013433\n",
      "[160/01139] train_loss: 0.013434\n",
      "[160/01189] train_loss: 0.013651\n",
      "[161/00013] train_loss: 0.012975\n",
      "[161/00063] train_loss: 0.014129\n",
      "[161/00113] train_loss: 0.013548\n",
      "[161/00163] train_loss: 0.013477\n",
      "[161/00213] train_loss: 0.014546\n",
      "[161/00263] train_loss: 0.013714\n",
      "[161/00313] train_loss: 0.013893\n",
      "[161/00363] train_loss: 0.012902\n",
      "[161/00413] train_loss: 0.013109\n",
      "[161/00463] train_loss: 0.012784\n",
      "[161/00513] train_loss: 0.014305\n",
      "[161/00563] train_loss: 0.013962\n",
      "[161/00613] train_loss: 0.012780\n",
      "[161/00663] train_loss: 0.013832\n",
      "[161/00713] train_loss: 0.013429\n",
      "[161/00763] train_loss: 0.013450\n",
      "[161/00813] train_loss: 0.013297\n",
      "[161/00863] train_loss: 0.012552\n",
      "[161/00913] train_loss: 0.013308\n",
      "[161/00963] train_loss: 0.013430\n",
      "[161/01013] train_loss: 0.013053\n",
      "[161/01063] train_loss: 0.013839\n",
      "[161/01113] train_loss: 0.013056\n",
      "[161/01163] train_loss: 0.013007\n",
      "[161/01213] train_loss: 0.012991\n",
      "[162/00037] train_loss: 0.014139\n",
      "[162/00087] train_loss: 0.013957\n",
      "[162/00137] train_loss: 0.013753\n",
      "[162/00187] train_loss: 0.014573\n",
      "[162/00237] train_loss: 0.014238\n",
      "[162/00287] train_loss: 0.013544\n",
      "[162/00337] train_loss: 0.013687\n",
      "[162/00387] train_loss: 0.014058\n",
      "[162/00437] train_loss: 0.013047\n",
      "[162/00487] train_loss: 0.013076\n",
      "[162/00537] train_loss: 0.012640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[162/00587] train_loss: 0.013687\n",
      "[162/00637] train_loss: 0.012808\n",
      "[162/00687] train_loss: 0.013774\n",
      "[162/00737] train_loss: 0.013401\n",
      "[162/00787] train_loss: 0.013576\n",
      "[162/00837] train_loss: 0.012748\n",
      "[162/00887] train_loss: 0.013276\n",
      "[162/00937] train_loss: 0.013422\n",
      "[162/00987] train_loss: 0.013537\n",
      "[162/01037] train_loss: 0.013598\n",
      "[162/01087] train_loss: 0.013266\n",
      "[162/01137] train_loss: 0.013455\n",
      "[162/01187] train_loss: 0.013160\n",
      "[163/00011] train_loss: 0.014418\n",
      "[163/00061] train_loss: 0.013427\n",
      "[163/00111] train_loss: 0.014601\n",
      "[163/00161] train_loss: 0.014400\n",
      "[163/00211] train_loss: 0.013951\n",
      "[163/00261] train_loss: 0.014195\n",
      "[163/00311] train_loss: 0.013253\n",
      "[163/00361] train_loss: 0.013385\n",
      "[163/00411] train_loss: 0.012770\n",
      "[163/00461] train_loss: 0.013681\n",
      "[163/00511] train_loss: 0.013343\n",
      "[163/00561] train_loss: 0.013676\n",
      "[163/00611] train_loss: 0.013690\n",
      "[163/00661] train_loss: 0.012962\n",
      "[163/00711] train_loss: 0.013093\n",
      "[163/00761] train_loss: 0.013165\n",
      "[163/00811] train_loss: 0.014057\n",
      "[163/00861] train_loss: 0.013449\n",
      "[163/00911] train_loss: 0.013108\n",
      "[163/00961] train_loss: 0.012771\n",
      "[163/01011] train_loss: 0.013081\n",
      "[163/01061] train_loss: 0.012708\n",
      "[163/01111] train_loss: 0.013487\n",
      "[163/01161] train_loss: 0.013067\n",
      "[163/01211] train_loss: 0.013257\n",
      "[164/00035] train_loss: 0.015013\n",
      "[164/00085] train_loss: 0.013858\n",
      "[164/00135] train_loss: 0.013458\n",
      "[164/00185] train_loss: 0.013445\n",
      "[164/00235] train_loss: 0.013522\n",
      "[164/00285] train_loss: 0.013308\n",
      "[164/00335] train_loss: 0.014072\n",
      "[164/00385] train_loss: 0.013877\n",
      "[164/00435] train_loss: 0.013135\n",
      "[164/00485] train_loss: 0.013490\n",
      "[164/00535] train_loss: 0.013413\n",
      "[164/00585] train_loss: 0.012942\n",
      "[164/00635] train_loss: 0.013053\n",
      "[164/00685] train_loss: 0.013001\n",
      "[164/00735] train_loss: 0.013403\n",
      "[164/00785] train_loss: 0.013672\n",
      "[164/00835] train_loss: 0.014369\n",
      "[164/00885] train_loss: 0.013951\n",
      "[164/00935] train_loss: 0.012970\n",
      "[164/00985] train_loss: 0.013395\n",
      "[164/01035] train_loss: 0.013741\n",
      "[164/01085] train_loss: 0.013166\n",
      "[164/01135] train_loss: 0.013648\n",
      "[164/01185] train_loss: 0.012394\n",
      "[165/00009] train_loss: 0.013655\n",
      "[165/00059] train_loss: 0.014284\n",
      "[165/00109] train_loss: 0.014116\n",
      "[165/00159] train_loss: 0.013923\n",
      "[165/00209] train_loss: 0.014034\n",
      "[165/00259] train_loss: 0.013313\n",
      "[165/00309] train_loss: 0.013477\n",
      "[165/00359] train_loss: 0.013608\n",
      "[165/00409] train_loss: 0.013841\n",
      "[165/00459] train_loss: 0.012461\n",
      "[165/00509] train_loss: 0.013739\n",
      "[165/00559] train_loss: 0.013188\n",
      "[165/00609] train_loss: 0.013742\n",
      "[165/00659] train_loss: 0.012836\n",
      "[165/00709] train_loss: 0.013075\n",
      "[165/00759] train_loss: 0.013693\n",
      "[165/00809] train_loss: 0.012907\n",
      "[165/00859] train_loss: 0.013288\n",
      "[165/00909] train_loss: 0.013012\n",
      "[165/00959] train_loss: 0.013401\n",
      "[165/01009] train_loss: 0.012816\n",
      "[165/01059] train_loss: 0.012540\n",
      "[165/01109] train_loss: 0.012723\n",
      "[165/01159] train_loss: 0.012956\n",
      "[165/01209] train_loss: 0.012725\n",
      "[166/00033] train_loss: 0.013684\n",
      "[166/00083] train_loss: 0.014635\n",
      "[166/00133] train_loss: 0.013291\n",
      "[166/00183] train_loss: 0.012973\n",
      "[166/00233] train_loss: 0.013646\n",
      "[166/00283] train_loss: 0.013800\n",
      "[166/00333] train_loss: 0.014172\n",
      "[166/00383] train_loss: 0.014193\n",
      "[166/00433] train_loss: 0.012433\n",
      "[166/00483] train_loss: 0.013830\n",
      "[166/00533] train_loss: 0.013140\n",
      "[166/00583] train_loss: 0.013872\n",
      "[166/00633] train_loss: 0.013650\n",
      "[166/00683] train_loss: 0.013060\n",
      "[166/00733] train_loss: 0.013335\n",
      "[166/00783] train_loss: 0.013668\n",
      "[166/00833] train_loss: 0.013138\n",
      "[166/00883] train_loss: 0.013159\n",
      "[166/00933] train_loss: 0.014349\n",
      "[166/00983] train_loss: 0.012662\n",
      "[166/01033] train_loss: 0.012336\n",
      "[166/01083] train_loss: 0.013321\n",
      "[166/01133] train_loss: 0.012844\n",
      "[166/01183] train_loss: 0.013366\n",
      "[167/00007] train_loss: 0.013440\n",
      "[167/00057] train_loss: 0.014145\n",
      "[167/00107] train_loss: 0.014103\n",
      "[167/00157] train_loss: 0.013535\n",
      "[167/00207] train_loss: 0.013098\n",
      "[167/00257] train_loss: 0.013523\n",
      "[167/00307] train_loss: 0.013545\n",
      "[167/00357] train_loss: 0.013647\n",
      "[167/00407] train_loss: 0.014088\n",
      "[167/00457] train_loss: 0.012882\n",
      "[167/00507] train_loss: 0.012703\n",
      "[167/00557] train_loss: 0.013248\n",
      "[167/00607] train_loss: 0.014494\n",
      "[167/00657] train_loss: 0.013172\n",
      "[167/00707] train_loss: 0.013274\n",
      "[167/00757] train_loss: 0.013438\n",
      "[167/00807] train_loss: 0.013576\n",
      "[167/00857] train_loss: 0.013068\n",
      "[167/00907] train_loss: 0.012476\n",
      "[167/00957] train_loss: 0.013441\n",
      "[167/01007] train_loss: 0.013808\n",
      "[167/01057] train_loss: 0.013280\n",
      "[167/01107] train_loss: 0.013601\n",
      "[167/01157] train_loss: 0.012160\n",
      "[167/01207] train_loss: 0.012418\n",
      "[168/00031] train_loss: 0.013893\n",
      "[168/00081] train_loss: 0.014451\n",
      "[168/00131] train_loss: 0.014386\n",
      "[168/00181] train_loss: 0.013590\n",
      "[168/00231] train_loss: 0.014230\n",
      "[168/00281] train_loss: 0.012591\n",
      "[168/00331] train_loss: 0.012788\n",
      "[168/00381] train_loss: 0.013694\n",
      "[168/00431] train_loss: 0.014798\n",
      "[168/00481] train_loss: 0.012832\n",
      "[168/00531] train_loss: 0.013442\n",
      "[168/00581] train_loss: 0.012360\n",
      "[168/00631] train_loss: 0.013581\n",
      "[168/00681] train_loss: 0.013584\n",
      "[168/00731] train_loss: 0.013137\n",
      "[168/00781] train_loss: 0.012800\n",
      "[168/00831] train_loss: 0.013015\n",
      "[168/00881] train_loss: 0.013445\n",
      "[168/00931] train_loss: 0.013069\n",
      "[168/00981] train_loss: 0.013686\n",
      "[168/01031] train_loss: 0.012929\n",
      "[168/01081] train_loss: 0.013253\n",
      "[168/01131] train_loss: 0.012872\n",
      "[168/01181] train_loss: 0.012582\n",
      "[169/00005] train_loss: 0.013715\n",
      "[169/00055] train_loss: 0.013326\n",
      "[169/00105] train_loss: 0.013437\n",
      "[169/00155] train_loss: 0.014339\n",
      "[169/00205] train_loss: 0.013743\n",
      "[169/00255] train_loss: 0.014010\n",
      "[169/00305] train_loss: 0.013392\n",
      "[169/00355] train_loss: 0.014053\n",
      "[169/00405] train_loss: 0.013001\n",
      "[169/00455] train_loss: 0.013229\n",
      "[169/00505] train_loss: 0.012613\n",
      "[169/00555] train_loss: 0.012799\n",
      "[169/00605] train_loss: 0.013001\n",
      "[169/00655] train_loss: 0.013196\n",
      "[169/00705] train_loss: 0.012861\n",
      "[169/00755] train_loss: 0.012958\n",
      "[169/00805] train_loss: 0.012922\n",
      "[169/00855] train_loss: 0.013164\n",
      "[169/00905] train_loss: 0.013159\n",
      "[169/00955] train_loss: 0.013107\n",
      "[169/01005] train_loss: 0.012749\n",
      "[169/01055] train_loss: 0.012340\n",
      "[169/01105] train_loss: 0.013880\n",
      "[169/01155] train_loss: 0.012954\n",
      "[169/01205] train_loss: 0.012580\n",
      "[170/00029] train_loss: 0.013318\n",
      "[170/00079] train_loss: 0.014160\n",
      "[170/00129] train_loss: 0.014500\n",
      "[170/00179] train_loss: 0.013559\n",
      "[170/00229] train_loss: 0.013122\n",
      "[170/00279] train_loss: 0.014455\n",
      "[170/00329] train_loss: 0.013743\n",
      "[170/00379] train_loss: 0.013739\n",
      "[170/00429] train_loss: 0.013823\n",
      "[170/00479] train_loss: 0.012477\n",
      "[170/00529] train_loss: 0.013275\n",
      "[170/00579] train_loss: 0.013334\n",
      "[170/00629] train_loss: 0.013129\n",
      "[170/00679] train_loss: 0.012877\n",
      "[170/00729] train_loss: 0.013921\n",
      "[170/00779] train_loss: 0.013469\n",
      "[170/00829] train_loss: 0.012704\n",
      "[170/00879] train_loss: 0.013385\n",
      "[170/00929] train_loss: 0.012883\n",
      "[170/00979] train_loss: 0.013083\n",
      "[170/01029] train_loss: 0.012543\n",
      "[170/01079] train_loss: 0.013005\n",
      "[170/01129] train_loss: 0.014061\n",
      "[170/01179] train_loss: 0.013290\n",
      "[171/00003] train_loss: 0.013071\n",
      "[171/00053] train_loss: 0.013689\n",
      "[171/00103] train_loss: 0.013317\n",
      "[171/00153] train_loss: 0.014322\n",
      "[171/00203] train_loss: 0.013829\n",
      "[171/00253] train_loss: 0.012920\n",
      "[171/00303] train_loss: 0.013093\n",
      "[171/00353] train_loss: 0.013585\n",
      "[171/00403] train_loss: 0.013126\n",
      "[171/00453] train_loss: 0.013217\n",
      "[171/00503] train_loss: 0.012745\n",
      "[171/00553] train_loss: 0.013248\n",
      "[171/00603] train_loss: 0.013557\n",
      "[171/00653] train_loss: 0.013813\n",
      "[171/00703] train_loss: 0.012657\n",
      "[171/00753] train_loss: 0.013590\n",
      "[171/00803] train_loss: 0.013713\n",
      "[171/00853] train_loss: 0.014055\n",
      "[171/00903] train_loss: 0.012736\n",
      "[171/00953] train_loss: 0.012486\n",
      "[171/01003] train_loss: 0.013304\n",
      "[171/01053] train_loss: 0.013537\n",
      "[171/01103] train_loss: 0.013261\n",
      "[171/01153] train_loss: 0.013067\n",
      "[171/01203] train_loss: 0.013149\n",
      "[172/00027] train_loss: 0.013715\n",
      "[172/00077] train_loss: 0.014331\n",
      "[172/00127] train_loss: 0.013382\n",
      "[172/00177] train_loss: 0.013796\n",
      "[172/00227] train_loss: 0.013480\n",
      "[172/00277] train_loss: 0.013617\n",
      "[172/00327] train_loss: 0.014044\n",
      "[172/00377] train_loss: 0.013794\n",
      "[172/00427] train_loss: 0.012559\n",
      "[172/00477] train_loss: 0.013676\n",
      "[172/00527] train_loss: 0.012600\n",
      "[172/00577] train_loss: 0.013096\n",
      "[172/00627] train_loss: 0.013263\n",
      "[172/00677] train_loss: 0.013483\n",
      "[172/00727] train_loss: 0.013246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[172/00777] train_loss: 0.013084\n",
      "[172/00827] train_loss: 0.013098\n",
      "[172/00877] train_loss: 0.013493\n",
      "[172/00927] train_loss: 0.013437\n",
      "[172/00977] train_loss: 0.013079\n",
      "[172/01027] train_loss: 0.013279\n",
      "[172/01077] train_loss: 0.012365\n",
      "[172/01127] train_loss: 0.013412\n",
      "[172/01177] train_loss: 0.012545\n",
      "[173/00001] train_loss: 0.013077\n",
      "[173/00051] train_loss: 0.014300\n",
      "[173/00101] train_loss: 0.014275\n",
      "[173/00151] train_loss: 0.012742\n",
      "[173/00201] train_loss: 0.013671\n",
      "[173/00251] train_loss: 0.013428\n",
      "[173/00301] train_loss: 0.012996\n",
      "[173/00351] train_loss: 0.012769\n",
      "[173/00401] train_loss: 0.013274\n",
      "[173/00451] train_loss: 0.013213\n",
      "[173/00501] train_loss: 0.013504\n",
      "[173/00551] train_loss: 0.013435\n",
      "[173/00601] train_loss: 0.012714\n",
      "[173/00651] train_loss: 0.013260\n",
      "[173/00701] train_loss: 0.013254\n",
      "[173/00751] train_loss: 0.012918\n",
      "[173/00801] train_loss: 0.012622\n",
      "[173/00851] train_loss: 0.012660\n",
      "[173/00901] train_loss: 0.013322\n",
      "[173/00951] train_loss: 0.012664\n",
      "[173/01001] train_loss: 0.012799\n",
      "[173/01051] train_loss: 0.013113\n",
      "[173/01101] train_loss: 0.012903\n",
      "[173/01151] train_loss: 0.012587\n",
      "[173/01201] train_loss: 0.012805\n",
      "[174/00025] train_loss: 0.013727\n",
      "[174/00075] train_loss: 0.013934\n",
      "[174/00125] train_loss: 0.013168\n",
      "[174/00175] train_loss: 0.013833\n",
      "[174/00225] train_loss: 0.013519\n",
      "[174/00275] train_loss: 0.013021\n",
      "[174/00325] train_loss: 0.013382\n",
      "[174/00375] train_loss: 0.013355\n",
      "[174/00425] train_loss: 0.013589\n",
      "[174/00475] train_loss: 0.012599\n",
      "[174/00525] train_loss: 0.014636\n",
      "[174/00575] train_loss: 0.014209\n",
      "[174/00625] train_loss: 0.013490\n",
      "[174/00675] train_loss: 0.012785\n",
      "[174/00725] train_loss: 0.013184\n",
      "[174/00775] train_loss: 0.013467\n",
      "[174/00825] train_loss: 0.013109\n",
      "[174/00875] train_loss: 0.012642\n",
      "[174/00925] train_loss: 0.012821\n",
      "[174/00975] train_loss: 0.013194\n",
      "[174/01025] train_loss: 0.013230\n",
      "[174/01075] train_loss: 0.013434\n",
      "[174/01125] train_loss: 0.013102\n",
      "[174/01175] train_loss: 0.013415\n",
      "[174/01225] train_loss: 0.013279\n",
      "[175/00049] train_loss: 0.015043\n",
      "[175/00099] train_loss: 0.013775\n",
      "[175/00149] train_loss: 0.013984\n",
      "[175/00199] train_loss: 0.013525\n",
      "[175/00249] train_loss: 0.013295\n",
      "[175/00299] train_loss: 0.012990\n",
      "[175/00349] train_loss: 0.012583\n",
      "[175/00399] train_loss: 0.012821\n",
      "[175/00449] train_loss: 0.012939\n",
      "[175/00499] train_loss: 0.012572\n",
      "[175/00549] train_loss: 0.013149\n",
      "[175/00599] train_loss: 0.013049\n",
      "[175/00649] train_loss: 0.012933\n",
      "[175/00699] train_loss: 0.012335\n",
      "[175/00749] train_loss: 0.013535\n",
      "[175/00799] train_loss: 0.013106\n",
      "[175/00849] train_loss: 0.013565\n",
      "[175/00899] train_loss: 0.013033\n",
      "[175/00949] train_loss: 0.013324\n",
      "[175/00999] train_loss: 0.012907\n",
      "[175/01049] train_loss: 0.012944\n",
      "[175/01099] train_loss: 0.014074\n",
      "[175/01149] train_loss: 0.013338\n",
      "[175/01199] train_loss: 0.013357\n",
      "[176/00023] train_loss: 0.012717\n",
      "[176/00073] train_loss: 0.013993\n",
      "[176/00123] train_loss: 0.013910\n",
      "[176/00173] train_loss: 0.014190\n",
      "[176/00223] train_loss: 0.014112\n",
      "[176/00273] train_loss: 0.013873\n",
      "[176/00323] train_loss: 0.013110\n",
      "[176/00373] train_loss: 0.013533\n",
      "[176/00423] train_loss: 0.014025\n",
      "[176/00473] train_loss: 0.013488\n",
      "[176/00523] train_loss: 0.013093\n",
      "[176/00573] train_loss: 0.013243\n",
      "[176/00623] train_loss: 0.013681\n",
      "[176/00673] train_loss: 0.013007\n",
      "[176/00723] train_loss: 0.012580\n",
      "[176/00773] train_loss: 0.012934\n",
      "[176/00823] train_loss: 0.012756\n",
      "[176/00873] train_loss: 0.014024\n",
      "[176/00923] train_loss: 0.013711\n",
      "[176/00973] train_loss: 0.013222\n",
      "[176/01023] train_loss: 0.013005\n",
      "[176/01073] train_loss: 0.012710\n",
      "[176/01123] train_loss: 0.012746\n",
      "[176/01173] train_loss: 0.012657\n",
      "[176/01223] train_loss: 0.012274\n",
      "[177/00047] train_loss: 0.014480\n",
      "[177/00097] train_loss: 0.013596\n",
      "[177/00147] train_loss: 0.013453\n",
      "[177/00197] train_loss: 0.014007\n",
      "[177/00247] train_loss: 0.012998\n",
      "[177/00297] train_loss: 0.012700\n",
      "[177/00347] train_loss: 0.013742\n",
      "[177/00397] train_loss: 0.012731\n",
      "[177/00447] train_loss: 0.012775\n",
      "[177/00497] train_loss: 0.013285\n",
      "[177/00547] train_loss: 0.012607\n",
      "[177/00597] train_loss: 0.013996\n",
      "[177/00647] train_loss: 0.013740\n",
      "[177/00697] train_loss: 0.013434\n",
      "[177/00747] train_loss: 0.012670\n",
      "[177/00797] train_loss: 0.012929\n",
      "[177/00847] train_loss: 0.012579\n",
      "[177/00897] train_loss: 0.013196\n",
      "[177/00947] train_loss: 0.012889\n",
      "[177/00997] train_loss: 0.014136\n",
      "[177/01047] train_loss: 0.012908\n",
      "[177/01097] train_loss: 0.013042\n",
      "[177/01147] train_loss: 0.013292\n",
      "[177/01197] train_loss: 0.012906\n",
      "[178/00021] train_loss: 0.014293\n",
      "[178/00071] train_loss: 0.013784\n",
      "[178/00121] train_loss: 0.013870\n",
      "[178/00171] train_loss: 0.013928\n",
      "[178/00221] train_loss: 0.013762\n",
      "[178/00271] train_loss: 0.013389\n",
      "[178/00321] train_loss: 0.013427\n",
      "[178/00371] train_loss: 0.013080\n",
      "[178/00421] train_loss: 0.013641\n",
      "[178/00471] train_loss: 0.012366\n",
      "[178/00521] train_loss: 0.013238\n",
      "[178/00571] train_loss: 0.014108\n",
      "[178/00621] train_loss: 0.014112\n",
      "[178/00671] train_loss: 0.012859\n",
      "[178/00721] train_loss: 0.012907\n",
      "[178/00771] train_loss: 0.012546\n",
      "[178/00821] train_loss: 0.013092\n",
      "[178/00871] train_loss: 0.013207\n",
      "[178/00921] train_loss: 0.013224\n",
      "[178/00971] train_loss: 0.012238\n",
      "[178/01021] train_loss: 0.013445\n",
      "[178/01071] train_loss: 0.012428\n",
      "[178/01121] train_loss: 0.013103\n",
      "[178/01171] train_loss: 0.013449\n",
      "[178/01221] train_loss: 0.013653\n",
      "[179/00045] train_loss: 0.014157\n",
      "[179/00095] train_loss: 0.014402\n",
      "[179/00145] train_loss: 0.013710\n",
      "[179/00195] train_loss: 0.013844\n",
      "[179/00245] train_loss: 0.013044\n",
      "[179/00295] train_loss: 0.013251\n",
      "[179/00345] train_loss: 0.012708\n",
      "[179/00395] train_loss: 0.012804\n",
      "[179/00445] train_loss: 0.012781\n",
      "[179/00495] train_loss: 0.012813\n",
      "[179/00545] train_loss: 0.013846\n",
      "[179/00595] train_loss: 0.013121\n",
      "[179/00645] train_loss: 0.013301\n",
      "[179/00695] train_loss: 0.012388\n",
      "[179/00745] train_loss: 0.013120\n",
      "[179/00795] train_loss: 0.012406\n",
      "[179/00845] train_loss: 0.012490\n",
      "[179/00895] train_loss: 0.012714\n",
      "[179/00945] train_loss: 0.012662\n",
      "[179/00995] train_loss: 0.012964\n",
      "[179/01045] train_loss: 0.012669\n",
      "[179/01095] train_loss: 0.013032\n",
      "[179/01145] train_loss: 0.013569\n",
      "[179/01195] train_loss: 0.013223\n",
      "[180/00019] train_loss: 0.013591\n",
      "[180/00069] train_loss: 0.014557\n",
      "[180/00119] train_loss: 0.014390\n",
      "[180/00169] train_loss: 0.013046\n",
      "[180/00219] train_loss: 0.013510\n",
      "[180/00269] train_loss: 0.013790\n",
      "[180/00319] train_loss: 0.013286\n",
      "[180/00369] train_loss: 0.012711\n",
      "[180/00419] train_loss: 0.013753\n",
      "[180/00469] train_loss: 0.013305\n",
      "[180/00519] train_loss: 0.013217\n",
      "[180/00569] train_loss: 0.012773\n",
      "[180/00619] train_loss: 0.013214\n",
      "[180/00669] train_loss: 0.013009\n",
      "[180/00719] train_loss: 0.012623\n",
      "[180/00769] train_loss: 0.013166\n",
      "[180/00819] train_loss: 0.012496\n",
      "[180/00869] train_loss: 0.013504\n",
      "[180/00919] train_loss: 0.013454\n",
      "[180/00969] train_loss: 0.013302\n",
      "[180/01019] train_loss: 0.011860\n",
      "[180/01069] train_loss: 0.012709\n",
      "[180/01119] train_loss: 0.012899\n",
      "[180/01169] train_loss: 0.012131\n",
      "[180/01219] train_loss: 0.013811\n",
      "[181/00043] train_loss: 0.013742\n",
      "[181/00093] train_loss: 0.013301\n",
      "[181/00143] train_loss: 0.013719\n",
      "[181/00193] train_loss: 0.014044\n",
      "[181/00243] train_loss: 0.013499\n",
      "[181/00293] train_loss: 0.012921\n",
      "[181/00343] train_loss: 0.013674\n",
      "[181/00393] train_loss: 0.013291\n",
      "[181/00443] train_loss: 0.012219\n",
      "[181/00493] train_loss: 0.013022\n",
      "[181/00543] train_loss: 0.012740\n",
      "[181/00593] train_loss: 0.012611\n",
      "[181/00643] train_loss: 0.012655\n",
      "[181/00693] train_loss: 0.013581\n",
      "[181/00743] train_loss: 0.013101\n",
      "[181/00793] train_loss: 0.013370\n",
      "[181/00843] train_loss: 0.012115\n",
      "[181/00893] train_loss: 0.012832\n",
      "[181/00943] train_loss: 0.013130\n",
      "[181/00993] train_loss: 0.013294\n",
      "[181/01043] train_loss: 0.013251\n",
      "[181/01093] train_loss: 0.012537\n",
      "[181/01143] train_loss: 0.014109\n",
      "[181/01193] train_loss: 0.013213\n",
      "[182/00017] train_loss: 0.013478\n",
      "[182/00067] train_loss: 0.014156\n",
      "[182/00117] train_loss: 0.014108\n",
      "[182/00167] train_loss: 0.013250\n",
      "[182/00217] train_loss: 0.013461\n",
      "[182/00267] train_loss: 0.012507\n",
      "[182/00317] train_loss: 0.013171\n",
      "[182/00367] train_loss: 0.013666\n",
      "[182/00417] train_loss: 0.013590\n",
      "[182/00467] train_loss: 0.014155\n",
      "[182/00517] train_loss: 0.013080\n",
      "[182/00567] train_loss: 0.013364\n",
      "[182/00617] train_loss: 0.012538\n",
      "[182/00667] train_loss: 0.013249\n",
      "[182/00717] train_loss: 0.013970\n",
      "[182/00767] train_loss: 0.012172\n",
      "[182/00817] train_loss: 0.012870\n",
      "[182/00867] train_loss: 0.013432\n",
      "[182/00917] train_loss: 0.012216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[182/00967] train_loss: 0.013590\n",
      "[182/01017] train_loss: 0.013060\n",
      "[182/01067] train_loss: 0.013152\n",
      "[182/01117] train_loss: 0.014350\n",
      "[182/01167] train_loss: 0.012589\n",
      "[182/01217] train_loss: 0.012554\n",
      "[183/00041] train_loss: 0.014057\n",
      "[183/00091] train_loss: 0.013778\n",
      "[183/00141] train_loss: 0.013218\n",
      "[183/00191] train_loss: 0.013173\n",
      "[183/00241] train_loss: 0.013661\n",
      "[183/00291] train_loss: 0.013277\n",
      "[183/00341] train_loss: 0.013994\n",
      "[183/00391] train_loss: 0.012987\n",
      "[183/00441] train_loss: 0.012857\n",
      "[183/00491] train_loss: 0.012889\n",
      "[183/00541] train_loss: 0.013550\n",
      "[183/00591] train_loss: 0.012589\n",
      "[183/00641] train_loss: 0.012770\n",
      "[183/00691] train_loss: 0.013249\n",
      "[183/00741] train_loss: 0.012726\n",
      "[183/00791] train_loss: 0.012595\n",
      "[183/00841] train_loss: 0.012514\n",
      "[183/00891] train_loss: 0.012562\n",
      "[183/00941] train_loss: 0.012670\n",
      "[183/00991] train_loss: 0.012814\n",
      "[183/01041] train_loss: 0.013758\n",
      "[183/01091] train_loss: 0.013055\n",
      "[183/01141] train_loss: 0.012597\n",
      "[183/01191] train_loss: 0.012341\n",
      "[184/00015] train_loss: 0.012826\n",
      "[184/00065] train_loss: 0.013398\n",
      "[184/00115] train_loss: 0.013785\n",
      "[184/00165] train_loss: 0.013962\n",
      "[184/00215] train_loss: 0.013644\n",
      "[184/00265] train_loss: 0.013277\n",
      "[184/00315] train_loss: 0.013639\n",
      "[184/00365] train_loss: 0.013097\n",
      "[184/00415] train_loss: 0.012843\n",
      "[184/00465] train_loss: 0.013240\n",
      "[184/00515] train_loss: 0.012448\n",
      "[184/00565] train_loss: 0.013843\n",
      "[184/00615] train_loss: 0.012756\n",
      "[184/00665] train_loss: 0.013776\n",
      "[184/00715] train_loss: 0.013708\n",
      "[184/00765] train_loss: 0.012315\n",
      "[184/00815] train_loss: 0.013918\n",
      "[184/00865] train_loss: 0.013016\n",
      "[184/00915] train_loss: 0.013219\n",
      "[184/00965] train_loss: 0.012662\n",
      "[184/01015] train_loss: 0.013819\n",
      "[184/01065] train_loss: 0.012081\n",
      "[184/01115] train_loss: 0.013111\n",
      "[184/01165] train_loss: 0.013390\n",
      "[184/01215] train_loss: 0.012764\n",
      "[185/00039] train_loss: 0.012996\n",
      "[185/00089] train_loss: 0.013480\n",
      "[185/00139] train_loss: 0.012808\n",
      "[185/00189] train_loss: 0.013165\n",
      "[185/00239] train_loss: 0.013622\n",
      "[185/00289] train_loss: 0.014152\n",
      "[185/00339] train_loss: 0.012839\n",
      "[185/00389] train_loss: 0.013023\n",
      "[185/00439] train_loss: 0.013054\n",
      "[185/00489] train_loss: 0.012579\n",
      "[185/00539] train_loss: 0.013136\n",
      "[185/00589] train_loss: 0.013130\n",
      "[185/00639] train_loss: 0.013211\n",
      "[185/00689] train_loss: 0.013213\n",
      "[185/00739] train_loss: 0.013612\n",
      "[185/00789] train_loss: 0.012757\n",
      "[185/00839] train_loss: 0.013703\n",
      "[185/00889] train_loss: 0.012769\n",
      "[185/00939] train_loss: 0.013463\n",
      "[185/00989] train_loss: 0.013077\n",
      "[185/01039] train_loss: 0.013304\n",
      "[185/01089] train_loss: 0.012404\n",
      "[185/01139] train_loss: 0.013118\n",
      "[185/01189] train_loss: 0.012608\n",
      "[186/00013] train_loss: 0.013199\n",
      "[186/00063] train_loss: 0.013890\n",
      "[186/00113] train_loss: 0.013390\n",
      "[186/00163] train_loss: 0.013512\n",
      "[186/00213] train_loss: 0.013349\n",
      "[186/00263] train_loss: 0.013541\n",
      "[186/00313] train_loss: 0.013194\n",
      "[186/00363] train_loss: 0.012753\n",
      "[186/00413] train_loss: 0.012743\n",
      "[186/00463] train_loss: 0.013108\n",
      "[186/00513] train_loss: 0.013358\n",
      "[186/00563] train_loss: 0.013574\n",
      "[186/00613] train_loss: 0.013628\n",
      "[186/00663] train_loss: 0.013112\n",
      "[186/00713] train_loss: 0.012813\n",
      "[186/00763] train_loss: 0.012875\n",
      "[186/00813] train_loss: 0.012758\n",
      "[186/00863] train_loss: 0.013116\n",
      "[186/00913] train_loss: 0.012746\n",
      "[186/00963] train_loss: 0.012581\n",
      "[186/01013] train_loss: 0.012800\n",
      "[186/01063] train_loss: 0.013606\n",
      "[186/01113] train_loss: 0.012615\n",
      "[186/01163] train_loss: 0.012755\n",
      "[186/01213] train_loss: 0.013506\n",
      "[187/00037] train_loss: 0.014129\n",
      "[187/00087] train_loss: 0.013215\n",
      "[187/00137] train_loss: 0.013753\n",
      "[187/00187] train_loss: 0.013201\n",
      "[187/00237] train_loss: 0.013364\n",
      "[187/00287] train_loss: 0.013045\n",
      "[187/00337] train_loss: 0.013146\n",
      "[187/00387] train_loss: 0.013731\n",
      "[187/00437] train_loss: 0.013159\n",
      "[187/00487] train_loss: 0.013100\n",
      "[187/00537] train_loss: 0.013190\n",
      "[187/00587] train_loss: 0.013114\n",
      "[187/00637] train_loss: 0.013819\n",
      "[187/00687] train_loss: 0.012230\n",
      "[187/00737] train_loss: 0.012188\n",
      "[187/00787] train_loss: 0.012584\n",
      "[187/00837] train_loss: 0.013667\n",
      "[187/00887] train_loss: 0.012365\n",
      "[187/00937] train_loss: 0.012438\n",
      "[187/00987] train_loss: 0.014076\n",
      "[187/01037] train_loss: 0.012779\n",
      "[187/01087] train_loss: 0.012728\n",
      "[187/01137] train_loss: 0.012309\n",
      "[187/01187] train_loss: 0.012785\n",
      "[188/00011] train_loss: 0.014209\n",
      "[188/00061] train_loss: 0.013785\n",
      "[188/00111] train_loss: 0.013180\n",
      "[188/00161] train_loss: 0.013819\n",
      "[188/00211] train_loss: 0.014037\n",
      "[188/00261] train_loss: 0.013530\n",
      "[188/00311] train_loss: 0.012758\n",
      "[188/00361] train_loss: 0.013288\n",
      "[188/00411] train_loss: 0.013142\n",
      "[188/00461] train_loss: 0.013252\n",
      "[188/00511] train_loss: 0.013024\n",
      "[188/00561] train_loss: 0.012692\n",
      "[188/00611] train_loss: 0.013130\n",
      "[188/00661] train_loss: 0.013227\n",
      "[188/00711] train_loss: 0.013303\n",
      "[188/00761] train_loss: 0.012464\n",
      "[188/00811] train_loss: 0.012932\n",
      "[188/00861] train_loss: 0.012264\n",
      "[188/00911] train_loss: 0.012127\n",
      "[188/00961] train_loss: 0.013020\n",
      "[188/01011] train_loss: 0.012565\n",
      "[188/01061] train_loss: 0.012674\n",
      "[188/01111] train_loss: 0.013306\n",
      "[188/01161] train_loss: 0.012675\n",
      "[188/01211] train_loss: 0.013153\n",
      "[189/00035] train_loss: 0.013227\n",
      "[189/00085] train_loss: 0.013253\n",
      "[189/00135] train_loss: 0.013733\n",
      "[189/00185] train_loss: 0.013358\n",
      "[189/00235] train_loss: 0.013726\n",
      "[189/00285] train_loss: 0.013034\n",
      "[189/00335] train_loss: 0.013530\n",
      "[189/00385] train_loss: 0.013016\n",
      "[189/00435] train_loss: 0.013283\n",
      "[189/00485] train_loss: 0.013636\n",
      "[189/00535] train_loss: 0.013517\n",
      "[189/00585] train_loss: 0.012860\n",
      "[189/00635] train_loss: 0.012922\n",
      "[189/00685] train_loss: 0.012973\n",
      "[189/00735] train_loss: 0.013023\n",
      "[189/00785] train_loss: 0.012460\n",
      "[189/00835] train_loss: 0.012779\n",
      "[189/00885] train_loss: 0.012550\n",
      "[189/00935] train_loss: 0.012440\n",
      "[189/00985] train_loss: 0.012513\n",
      "[189/01035] train_loss: 0.012135\n",
      "[189/01085] train_loss: 0.012938\n",
      "[189/01135] train_loss: 0.012593\n",
      "[189/01185] train_loss: 0.012156\n",
      "[190/00009] train_loss: 0.013280\n",
      "[190/00059] train_loss: 0.013756\n",
      "[190/00109] train_loss: 0.013081\n",
      "[190/00159] train_loss: 0.013546\n",
      "[190/00209] train_loss: 0.013331\n",
      "[190/00259] train_loss: 0.012713\n",
      "[190/00309] train_loss: 0.012897\n",
      "[190/00359] train_loss: 0.013614\n",
      "[190/00409] train_loss: 0.012773\n",
      "[190/00459] train_loss: 0.013045\n",
      "[190/00509] train_loss: 0.013383\n",
      "[190/00559] train_loss: 0.012893\n",
      "[190/00609] train_loss: 0.013296\n",
      "[190/00659] train_loss: 0.012440\n",
      "[190/00709] train_loss: 0.012965\n",
      "[190/00759] train_loss: 0.013251\n",
      "[190/00809] train_loss: 0.012675\n",
      "[190/00859] train_loss: 0.012973\n",
      "[190/00909] train_loss: 0.013783\n",
      "[190/00959] train_loss: 0.013051\n",
      "[190/01009] train_loss: 0.013430\n",
      "[190/01059] train_loss: 0.012859\n",
      "[190/01109] train_loss: 0.012825\n",
      "[190/01159] train_loss: 0.012873\n",
      "[190/01209] train_loss: 0.012383\n",
      "[191/00033] train_loss: 0.014783\n",
      "[191/00083] train_loss: 0.013658\n",
      "[191/00133] train_loss: 0.013071\n",
      "[191/00183] train_loss: 0.013917\n",
      "[191/00233] train_loss: 0.013174\n",
      "[191/00283] train_loss: 0.013476\n",
      "[191/00333] train_loss: 0.013061\n",
      "[191/00383] train_loss: 0.013014\n",
      "[191/00433] train_loss: 0.012435\n",
      "[191/00483] train_loss: 0.013013\n",
      "[191/00533] train_loss: 0.013086\n",
      "[191/00583] train_loss: 0.012227\n",
      "[191/00633] train_loss: 0.012806\n",
      "[191/00683] train_loss: 0.012633\n",
      "[191/00733] train_loss: 0.012101\n",
      "[191/00783] train_loss: 0.013482\n",
      "[191/00833] train_loss: 0.012483\n",
      "[191/00883] train_loss: 0.012872\n",
      "[191/00933] train_loss: 0.012697\n",
      "[191/00983] train_loss: 0.013328\n",
      "[191/01033] train_loss: 0.012737\n",
      "[191/01083] train_loss: 0.013569\n",
      "[191/01133] train_loss: 0.013277\n",
      "[191/01183] train_loss: 0.012973\n",
      "[192/00007] train_loss: 0.012739\n",
      "[192/00057] train_loss: 0.013560\n",
      "[192/00107] train_loss: 0.012985\n",
      "[192/00157] train_loss: 0.014595\n",
      "[192/00207] train_loss: 0.012909\n",
      "[192/00257] train_loss: 0.013698\n",
      "[192/00307] train_loss: 0.013438\n",
      "[192/00357] train_loss: 0.013642\n",
      "[192/00407] train_loss: 0.012786\n",
      "[192/00457] train_loss: 0.012923\n",
      "[192/00507] train_loss: 0.013237\n",
      "[192/00557] train_loss: 0.013264\n",
      "[192/00607] train_loss: 0.013072\n",
      "[192/00657] train_loss: 0.012784\n",
      "[192/00707] train_loss: 0.013028\n",
      "[192/00757] train_loss: 0.012706\n",
      "[192/00807] train_loss: 0.013184\n",
      "[192/00857] train_loss: 0.013603\n",
      "[192/00907] train_loss: 0.013159\n",
      "[192/00957] train_loss: 0.013304\n",
      "[192/01007] train_loss: 0.013955\n",
      "[192/01057] train_loss: 0.013723\n",
      "[192/01107] train_loss: 0.013081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[192/01157] train_loss: 0.012234\n",
      "[192/01207] train_loss: 0.012905\n",
      "[193/00031] train_loss: 0.013885\n",
      "[193/00081] train_loss: 0.014001\n",
      "[193/00131] train_loss: 0.013770\n",
      "[193/00181] train_loss: 0.012645\n",
      "[193/00231] train_loss: 0.012915\n",
      "[193/00281] train_loss: 0.012446\n",
      "[193/00331] train_loss: 0.012790\n",
      "[193/00381] train_loss: 0.012634\n",
      "[193/00431] train_loss: 0.012199\n",
      "[193/00481] train_loss: 0.012865\n",
      "[193/00531] train_loss: 0.013210\n",
      "[193/00581] train_loss: 0.013280\n",
      "[193/00631] train_loss: 0.013697\n",
      "[193/00681] train_loss: 0.012966\n",
      "[193/00731] train_loss: 0.012669\n",
      "[193/00781] train_loss: 0.014192\n",
      "[193/00831] train_loss: 0.013440\n",
      "[193/00881] train_loss: 0.013053\n",
      "[193/00931] train_loss: 0.012977\n",
      "[193/00981] train_loss: 0.012572\n",
      "[193/01031] train_loss: 0.012809\n",
      "[193/01081] train_loss: 0.013021\n",
      "[193/01131] train_loss: 0.012459\n",
      "[193/01181] train_loss: 0.012474\n",
      "[194/00005] train_loss: 0.012542\n",
      "[194/00055] train_loss: 0.014309\n",
      "[194/00105] train_loss: 0.013363\n",
      "[194/00155] train_loss: 0.013107\n",
      "[194/00205] train_loss: 0.013500\n",
      "[194/00255] train_loss: 0.013581\n",
      "[194/00305] train_loss: 0.013061\n",
      "[194/00355] train_loss: 0.012659\n",
      "[194/00405] train_loss: 0.012955\n",
      "[194/00455] train_loss: 0.014152\n",
      "[194/00505] train_loss: 0.012979\n",
      "[194/00555] train_loss: 0.011980\n",
      "[194/00605] train_loss: 0.012566\n",
      "[194/00655] train_loss: 0.012658\n",
      "[194/00705] train_loss: 0.012943\n",
      "[194/00755] train_loss: 0.012511\n",
      "[194/00805] train_loss: 0.013341\n",
      "[194/00855] train_loss: 0.013024\n",
      "[194/00905] train_loss: 0.012620\n",
      "[194/00955] train_loss: 0.013323\n",
      "[194/01005] train_loss: 0.012292\n",
      "[194/01055] train_loss: 0.013856\n",
      "[194/01105] train_loss: 0.012940\n",
      "[194/01155] train_loss: 0.012463\n",
      "[194/01205] train_loss: 0.013113\n",
      "[195/00029] train_loss: 0.012228\n",
      "[195/00079] train_loss: 0.013991\n",
      "[195/00129] train_loss: 0.013559\n",
      "[195/00179] train_loss: 0.013351\n",
      "[195/00229] train_loss: 0.013411\n",
      "[195/00279] train_loss: 0.013782\n",
      "[195/00329] train_loss: 0.013683\n",
      "[195/00379] train_loss: 0.013044\n",
      "[195/00429] train_loss: 0.012851\n",
      "[195/00479] train_loss: 0.012398\n",
      "[195/00529] train_loss: 0.013071\n",
      "[195/00579] train_loss: 0.012418\n",
      "[195/00629] train_loss: 0.013323\n",
      "[195/00679] train_loss: 0.012643\n",
      "[195/00729] train_loss: 0.012497\n",
      "[195/00779] train_loss: 0.012632\n",
      "[195/00829] train_loss: 0.012734\n",
      "[195/00879] train_loss: 0.013338\n",
      "[195/00929] train_loss: 0.012490\n",
      "[195/00979] train_loss: 0.012413\n",
      "[195/01029] train_loss: 0.012500\n",
      "[195/01079] train_loss: 0.013151\n",
      "[195/01129] train_loss: 0.012684\n",
      "[195/01179] train_loss: 0.012437\n",
      "[196/00003] train_loss: 0.013181\n",
      "[196/00053] train_loss: 0.014082\n",
      "[196/00103] train_loss: 0.013546\n",
      "[196/00153] train_loss: 0.012662\n",
      "[196/00203] train_loss: 0.013245\n",
      "[196/00253] train_loss: 0.013154\n",
      "[196/00303] train_loss: 0.012769\n",
      "[196/00353] train_loss: 0.014357\n",
      "[196/00403] train_loss: 0.013500\n",
      "[196/00453] train_loss: 0.012865\n",
      "[196/00503] train_loss: 0.012839\n",
      "[196/00553] train_loss: 0.012821\n",
      "[196/00603] train_loss: 0.014035\n",
      "[196/00653] train_loss: 0.013407\n",
      "[196/00703] train_loss: 0.012691\n",
      "[196/00753] train_loss: 0.013960\n",
      "[196/00803] train_loss: 0.013618\n",
      "[196/00853] train_loss: 0.012471\n",
      "[196/00903] train_loss: 0.013025\n",
      "[196/00953] train_loss: 0.012455\n",
      "[196/01003] train_loss: 0.013557\n",
      "[196/01053] train_loss: 0.012546\n",
      "[196/01103] train_loss: 0.013057\n",
      "[196/01153] train_loss: 0.011968\n",
      "[196/01203] train_loss: 0.012528\n",
      "[197/00027] train_loss: 0.013259\n",
      "[197/00077] train_loss: 0.014345\n",
      "[197/00127] train_loss: 0.013266\n",
      "[197/00177] train_loss: 0.013265\n",
      "[197/00227] train_loss: 0.013030\n",
      "[197/00277] train_loss: 0.012933\n",
      "[197/00327] train_loss: 0.012347\n",
      "[197/00377] train_loss: 0.012488\n",
      "[197/00427] train_loss: 0.012902\n",
      "[197/00477] train_loss: 0.012928\n",
      "[197/00527] train_loss: 0.014637\n",
      "[197/00577] train_loss: 0.012558\n",
      "[197/00627] train_loss: 0.012909\n",
      "[197/00677] train_loss: 0.013229\n",
      "[197/00727] train_loss: 0.013537\n",
      "[197/00777] train_loss: 0.013483\n",
      "[197/00827] train_loss: 0.012403\n",
      "[197/00877] train_loss: 0.012585\n",
      "[197/00927] train_loss: 0.012447\n",
      "[197/00977] train_loss: 0.012772\n",
      "[197/01027] train_loss: 0.013068\n",
      "[197/01077] train_loss: 0.012576\n",
      "[197/01127] train_loss: 0.012328\n",
      "[197/01177] train_loss: 0.012632\n",
      "[198/00001] train_loss: 0.012564\n",
      "[198/00051] train_loss: 0.013704\n",
      "[198/00101] train_loss: 0.013837\n",
      "[198/00151] train_loss: 0.013499\n",
      "[198/00201] train_loss: 0.012396\n",
      "[198/00251] train_loss: 0.013605\n",
      "[198/00301] train_loss: 0.013310\n",
      "[198/00351] train_loss: 0.012442\n",
      "[198/00401] train_loss: 0.013222\n",
      "[198/00451] train_loss: 0.013290\n",
      "[198/00501] train_loss: 0.012883\n",
      "[198/00551] train_loss: 0.012825\n",
      "[198/00601] train_loss: 0.013307\n",
      "[198/00651] train_loss: 0.013162\n",
      "[198/00701] train_loss: 0.012955\n",
      "[198/00751] train_loss: 0.012563\n",
      "[198/00801] train_loss: 0.013725\n",
      "[198/00851] train_loss: 0.012190\n",
      "[198/00901] train_loss: 0.012816\n",
      "[198/00951] train_loss: 0.012609\n",
      "[198/01001] train_loss: 0.012834\n",
      "[198/01051] train_loss: 0.012590\n",
      "[198/01101] train_loss: 0.012276\n",
      "[198/01151] train_loss: 0.013748\n",
      "[198/01201] train_loss: 0.012976\n",
      "[199/00025] train_loss: 0.012981\n",
      "[199/00075] train_loss: 0.014156\n",
      "[199/00125] train_loss: 0.013537\n",
      "[199/00175] train_loss: 0.013073\n",
      "[199/00225] train_loss: 0.013510\n",
      "[199/00275] train_loss: 0.013075\n",
      "[199/00325] train_loss: 0.013327\n",
      "[199/00375] train_loss: 0.013250\n",
      "[199/00425] train_loss: 0.012440\n",
      "[199/00475] train_loss: 0.012763\n",
      "[199/00525] train_loss: 0.012883\n",
      "[199/00575] train_loss: 0.012300\n",
      "[199/00625] train_loss: 0.012305\n",
      "[199/00675] train_loss: 0.013091\n",
      "[199/00725] train_loss: 0.012245\n",
      "[199/00775] train_loss: 0.012113\n",
      "[199/00825] train_loss: 0.013144\n",
      "[199/00875] train_loss: 0.012187\n",
      "[199/00925] train_loss: 0.011989\n",
      "[199/00975] train_loss: 0.012250\n",
      "[199/01025] train_loss: 0.012405\n",
      "[199/01075] train_loss: 0.012820\n",
      "[199/01125] train_loss: 0.012501\n",
      "[199/01175] train_loss: 0.012535\n",
      "[199/01225] train_loss: 0.013833\n",
      "[200/00049] train_loss: 0.013799\n",
      "[200/00099] train_loss: 0.013664\n",
      "[200/00149] train_loss: 0.014090\n",
      "[200/00199] train_loss: 0.014385\n",
      "[200/00249] train_loss: 0.013701\n",
      "[200/00299] train_loss: 0.012580\n",
      "[200/00349] train_loss: 0.012878\n",
      "[200/00399] train_loss: 0.012749\n",
      "[200/00449] train_loss: 0.012887\n",
      "[200/00499] train_loss: 0.012673\n",
      "[200/00549] train_loss: 0.012796\n",
      "[200/00599] train_loss: 0.012431\n",
      "[200/00649] train_loss: 0.013039\n",
      "[200/00699] train_loss: 0.013054\n",
      "[200/00749] train_loss: 0.012651\n",
      "[200/00799] train_loss: 0.012573\n",
      "[200/00849] train_loss: 0.012713\n",
      "[200/00899] train_loss: 0.012867\n",
      "[200/00949] train_loss: 0.013018\n",
      "[200/00999] train_loss: 0.012835\n",
      "[200/01049] train_loss: 0.012328\n",
      "[200/01099] train_loss: 0.013304\n",
      "[200/01149] train_loss: 0.012527\n",
      "[200/01199] train_loss: 0.012938\n",
      "[201/00023] train_loss: 0.012630\n",
      "[201/00073] train_loss: 0.013981\n",
      "[201/00123] train_loss: 0.012406\n",
      "[201/00173] train_loss: 0.013586\n",
      "[201/00223] train_loss: 0.012990\n",
      "[201/00273] train_loss: 0.013827\n",
      "[201/00323] train_loss: 0.012852\n",
      "[201/00373] train_loss: 0.012667\n",
      "[201/00423] train_loss: 0.013471\n",
      "[201/00473] train_loss: 0.013780\n",
      "[201/00523] train_loss: 0.012761\n",
      "[201/00573] train_loss: 0.012763\n",
      "[201/00623] train_loss: 0.011915\n",
      "[201/00673] train_loss: 0.012972\n",
      "[201/00723] train_loss: 0.012599\n",
      "[201/00773] train_loss: 0.012923\n",
      "[201/00823] train_loss: 0.012638\n",
      "[201/00873] train_loss: 0.012865\n",
      "[201/00923] train_loss: 0.013001\n",
      "[201/00973] train_loss: 0.012857\n",
      "[201/01023] train_loss: 0.013150\n",
      "[201/01073] train_loss: 0.012913\n",
      "[201/01123] train_loss: 0.012482\n",
      "[201/01173] train_loss: 0.012359\n",
      "[201/01223] train_loss: 0.012604\n",
      "[202/00047] train_loss: 0.013395\n",
      "[202/00097] train_loss: 0.013616\n",
      "[202/00147] train_loss: 0.014066\n",
      "[202/00197] train_loss: 0.012887\n",
      "[202/00247] train_loss: 0.012949\n",
      "[202/00297] train_loss: 0.012682\n",
      "[202/00347] train_loss: 0.012996\n",
      "[202/00397] train_loss: 0.012828\n",
      "[202/00447] train_loss: 0.013307\n",
      "[202/00497] train_loss: 0.012598\n",
      "[202/00547] train_loss: 0.013109\n",
      "[202/00597] train_loss: 0.013190\n",
      "[202/00647] train_loss: 0.013049\n",
      "[202/00697] train_loss: 0.012438\n",
      "[202/00747] train_loss: 0.013025\n",
      "[202/00797] train_loss: 0.012708\n",
      "[202/00847] train_loss: 0.013750\n",
      "[202/00897] train_loss: 0.012777\n",
      "[202/00947] train_loss: 0.012754\n",
      "[202/00997] train_loss: 0.012451\n",
      "[202/01047] train_loss: 0.012513\n",
      "[202/01097] train_loss: 0.013040\n",
      "[202/01147] train_loss: 0.012809\n",
      "[202/01197] train_loss: 0.012658\n",
      "[203/00021] train_loss: 0.013271\n",
      "[203/00071] train_loss: 0.013912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[203/00121] train_loss: 0.013449\n",
      "[203/00171] train_loss: 0.012781\n",
      "[203/00221] train_loss: 0.012539\n",
      "[203/00271] train_loss: 0.013012\n",
      "[203/00321] train_loss: 0.012287\n",
      "[203/00371] train_loss: 0.013129\n",
      "[203/00421] train_loss: 0.013421\n",
      "[203/00471] train_loss: 0.012994\n",
      "[203/00521] train_loss: 0.013748\n",
      "[203/00571] train_loss: 0.013129\n",
      "[203/00621] train_loss: 0.012066\n",
      "[203/00671] train_loss: 0.012327\n",
      "[203/00721] train_loss: 0.013052\n",
      "[203/00771] train_loss: 0.012214\n",
      "[203/00821] train_loss: 0.012329\n",
      "[203/00871] train_loss: 0.013121\n",
      "[203/00921] train_loss: 0.012616\n",
      "[203/00971] train_loss: 0.012387\n",
      "[203/01021] train_loss: 0.012912\n",
      "[203/01071] train_loss: 0.012972\n",
      "[203/01121] train_loss: 0.013050\n",
      "[203/01171] train_loss: 0.012474\n",
      "[203/01221] train_loss: 0.011993\n",
      "[204/00045] train_loss: 0.013255\n",
      "[204/00095] train_loss: 0.013049\n",
      "[204/00145] train_loss: 0.013164\n",
      "[204/00195] train_loss: 0.013855\n",
      "[204/00245] train_loss: 0.013980\n",
      "[204/00295] train_loss: 0.013114\n",
      "[204/00345] train_loss: 0.013031\n",
      "[204/00395] train_loss: 0.013150\n",
      "[204/00445] train_loss: 0.013627\n",
      "[204/00495] train_loss: 0.013203\n",
      "[204/00545] train_loss: 0.012941\n",
      "[204/00595] train_loss: 0.012741\n",
      "[204/00645] train_loss: 0.012217\n",
      "[204/00695] train_loss: 0.012883\n",
      "[204/00745] train_loss: 0.014177\n",
      "[204/00795] train_loss: 0.012351\n",
      "[204/00845] train_loss: 0.012672\n",
      "[204/00895] train_loss: 0.012951\n",
      "[204/00945] train_loss: 0.012820\n",
      "[204/00995] train_loss: 0.012259\n",
      "[204/01045] train_loss: 0.012389\n",
      "[204/01095] train_loss: 0.012276\n",
      "[204/01145] train_loss: 0.012482\n",
      "[204/01195] train_loss: 0.012422\n",
      "[205/00019] train_loss: 0.013060\n",
      "[205/00069] train_loss: 0.013387\n",
      "[205/00119] train_loss: 0.013447\n",
      "[205/00169] train_loss: 0.013356\n",
      "[205/00219] train_loss: 0.013684\n",
      "[205/00269] train_loss: 0.012796\n",
      "[205/00319] train_loss: 0.013098\n",
      "[205/00369] train_loss: 0.012188\n",
      "[205/00419] train_loss: 0.011865\n",
      "[205/00469] train_loss: 0.013172\n",
      "[205/00519] train_loss: 0.012134\n",
      "[205/00569] train_loss: 0.012602\n",
      "[205/00619] train_loss: 0.013195\n",
      "[205/00669] train_loss: 0.012489\n",
      "[205/00719] train_loss: 0.013059\n",
      "[205/00769] train_loss: 0.013580\n",
      "[205/00819] train_loss: 0.012171\n",
      "[205/00869] train_loss: 0.012733\n",
      "[205/00919] train_loss: 0.012268\n",
      "[205/00969] train_loss: 0.012382\n",
      "[205/01019] train_loss: 0.012661\n",
      "[205/01069] train_loss: 0.013093\n",
      "[205/01119] train_loss: 0.012344\n",
      "[205/01169] train_loss: 0.011915\n",
      "[205/01219] train_loss: 0.012964\n",
      "[206/00043] train_loss: 0.013458\n",
      "[206/00093] train_loss: 0.013404\n",
      "[206/00143] train_loss: 0.013418\n",
      "[206/00193] train_loss: 0.013527\n",
      "[206/00243] train_loss: 0.013021\n",
      "[206/00293] train_loss: 0.012932\n",
      "[206/00343] train_loss: 0.013353\n",
      "[206/00393] train_loss: 0.013482\n",
      "[206/00443] train_loss: 0.013018\n",
      "[206/00493] train_loss: 0.012919\n",
      "[206/00543] train_loss: 0.012841\n",
      "[206/00593] train_loss: 0.013089\n",
      "[206/00643] train_loss: 0.012581\n",
      "[206/00693] train_loss: 0.013295\n",
      "[206/00743] train_loss: 0.012472\n",
      "[206/00793] train_loss: 0.013030\n",
      "[206/00843] train_loss: 0.013270\n",
      "[206/00893] train_loss: 0.012237\n",
      "[206/00943] train_loss: 0.012511\n",
      "[206/00993] train_loss: 0.012126\n",
      "[206/01043] train_loss: 0.012619\n",
      "[206/01093] train_loss: 0.012632\n",
      "[206/01143] train_loss: 0.012804\n",
      "[206/01193] train_loss: 0.011878\n",
      "[207/00017] train_loss: 0.012790\n",
      "[207/00067] train_loss: 0.013534\n",
      "[207/00117] train_loss: 0.013973\n",
      "[207/00167] train_loss: 0.013626\n",
      "[207/00217] train_loss: 0.013154\n",
      "[207/00267] train_loss: 0.012786\n",
      "[207/00317] train_loss: 0.012847\n",
      "[207/00367] train_loss: 0.012863\n",
      "[207/00417] train_loss: 0.013139\n",
      "[207/00467] train_loss: 0.012550\n",
      "[207/00517] train_loss: 0.012390\n",
      "[207/00567] train_loss: 0.012543\n",
      "[207/00617] train_loss: 0.013556\n",
      "[207/00667] train_loss: 0.012550\n",
      "[207/00717] train_loss: 0.012752\n",
      "[207/00767] train_loss: 0.012428\n",
      "[207/00817] train_loss: 0.012777\n",
      "[207/00867] train_loss: 0.012902\n",
      "[207/00917] train_loss: 0.013113\n",
      "[207/00967] train_loss: 0.012830\n",
      "[207/01017] train_loss: 0.012478\n",
      "[207/01067] train_loss: 0.012673\n",
      "[207/01117] train_loss: 0.012809\n",
      "[207/01167] train_loss: 0.012274\n",
      "[207/01217] train_loss: 0.012203\n",
      "[208/00041] train_loss: 0.013789\n",
      "[208/00091] train_loss: 0.014184\n",
      "[208/00141] train_loss: 0.013428\n",
      "[208/00191] train_loss: 0.013335\n",
      "[208/00241] train_loss: 0.012616\n",
      "[208/00291] train_loss: 0.012787\n",
      "[208/00341] train_loss: 0.013319\n",
      "[208/00391] train_loss: 0.012146\n",
      "[208/00441] train_loss: 0.013147\n",
      "[208/00491] train_loss: 0.012377\n",
      "[208/00541] train_loss: 0.012410\n",
      "[208/00591] train_loss: 0.013085\n",
      "[208/00641] train_loss: 0.012805\n",
      "[208/00691] train_loss: 0.012822\n",
      "[208/00741] train_loss: 0.012447\n",
      "[208/00791] train_loss: 0.012387\n",
      "[208/00841] train_loss: 0.012499\n",
      "[208/00891] train_loss: 0.012603\n",
      "[208/00941] train_loss: 0.012636\n",
      "[208/00991] train_loss: 0.012372\n",
      "[208/01041] train_loss: 0.012093\n",
      "[208/01091] train_loss: 0.013289\n",
      "[208/01141] train_loss: 0.012182\n",
      "[208/01191] train_loss: 0.012682\n",
      "[209/00015] train_loss: 0.013118\n",
      "[209/00065] train_loss: 0.013106\n",
      "[209/00115] train_loss: 0.012922\n",
      "[209/00165] train_loss: 0.013151\n",
      "[209/00215] train_loss: 0.012405\n",
      "[209/00265] train_loss: 0.013795\n",
      "[209/00315] train_loss: 0.012860\n",
      "[209/00365] train_loss: 0.013022\n",
      "[209/00415] train_loss: 0.012081\n",
      "[209/00465] train_loss: 0.012876\n",
      "[209/00515] train_loss: 0.012502\n",
      "[209/00565] train_loss: 0.012491\n",
      "[209/00615] train_loss: 0.012174\n",
      "[209/00665] train_loss: 0.013073\n",
      "[209/00715] train_loss: 0.012979\n",
      "[209/00765] train_loss: 0.012696\n",
      "[209/00815] train_loss: 0.012429\n",
      "[209/00865] train_loss: 0.012918\n",
      "[209/00915] train_loss: 0.012581\n",
      "[209/00965] train_loss: 0.012478\n",
      "[209/01015] train_loss: 0.012615\n",
      "[209/01065] train_loss: 0.012823\n",
      "[209/01115] train_loss: 0.013722\n",
      "[209/01165] train_loss: 0.012709\n",
      "[209/01215] train_loss: 0.012428\n",
      "[210/00039] train_loss: 0.013806\n",
      "[210/00089] train_loss: 0.013669\n",
      "[210/00139] train_loss: 0.012966\n",
      "[210/00189] train_loss: 0.013002\n",
      "[210/00239] train_loss: 0.012794\n",
      "[210/00289] train_loss: 0.012507\n",
      "[210/00339] train_loss: 0.012928\n",
      "[210/00389] train_loss: 0.013204\n",
      "[210/00439] train_loss: 0.012545\n",
      "[210/00489] train_loss: 0.011921\n",
      "[210/00539] train_loss: 0.012735\n",
      "[210/00589] train_loss: 0.012360\n",
      "[210/00639] train_loss: 0.012949\n",
      "[210/00689] train_loss: 0.013391\n",
      "[210/00739] train_loss: 0.012805\n",
      "[210/00789] train_loss: 0.013066\n",
      "[210/00839] train_loss: 0.012627\n",
      "[210/00889] train_loss: 0.011999\n",
      "[210/00939] train_loss: 0.012214\n",
      "[210/00989] train_loss: 0.012502\n",
      "[210/01039] train_loss: 0.012342\n",
      "[210/01089] train_loss: 0.012827\n",
      "[210/01139] train_loss: 0.012678\n",
      "[210/01189] train_loss: 0.012335\n",
      "[211/00013] train_loss: 0.013756\n",
      "[211/00063] train_loss: 0.013200\n",
      "[211/00113] train_loss: 0.013272\n",
      "[211/00163] train_loss: 0.012916\n",
      "[211/00213] train_loss: 0.012721\n",
      "[211/00263] train_loss: 0.012493\n",
      "[211/00313] train_loss: 0.013265\n",
      "[211/00363] train_loss: 0.013136\n",
      "[211/00413] train_loss: 0.012009\n",
      "[211/00463] train_loss: 0.012485\n",
      "[211/00513] train_loss: 0.012995\n",
      "[211/00563] train_loss: 0.012327\n",
      "[211/00613] train_loss: 0.012869\n",
      "[211/00663] train_loss: 0.012528\n",
      "[211/00713] train_loss: 0.012851\n",
      "[211/00763] train_loss: 0.012769\n",
      "[211/00813] train_loss: 0.012249\n",
      "[211/00863] train_loss: 0.012521\n",
      "[211/00913] train_loss: 0.013094\n",
      "[211/00963] train_loss: 0.012674\n",
      "[211/01013] train_loss: 0.012829\n",
      "[211/01063] train_loss: 0.013030\n",
      "[211/01113] train_loss: 0.012941\n",
      "[211/01163] train_loss: 0.012551\n",
      "[211/01213] train_loss: 0.012791\n",
      "[212/00037] train_loss: 0.013716\n",
      "[212/00087] train_loss: 0.012953\n",
      "[212/00137] train_loss: 0.012998\n",
      "[212/00187] train_loss: 0.013299\n",
      "[212/00237] train_loss: 0.012565\n",
      "[212/00287] train_loss: 0.013325\n",
      "[212/00337] train_loss: 0.011717\n",
      "[212/00387] train_loss: 0.011964\n",
      "[212/00437] train_loss: 0.012887\n",
      "[212/00487] train_loss: 0.012490\n",
      "[212/00537] train_loss: 0.013474\n",
      "[212/00587] train_loss: 0.012780\n",
      "[212/00637] train_loss: 0.013550\n",
      "[212/00687] train_loss: 0.013339\n",
      "[212/00737] train_loss: 0.012216\n",
      "[212/00787] train_loss: 0.012041\n",
      "[212/00837] train_loss: 0.012724\n",
      "[212/00887] train_loss: 0.012532\n",
      "[212/00937] train_loss: 0.013148\n",
      "[212/00987] train_loss: 0.012362\n",
      "[212/01037] train_loss: 0.013910\n",
      "[212/01087] train_loss: 0.012610\n",
      "[212/01137] train_loss: 0.012264\n",
      "[212/01187] train_loss: 0.011912\n",
      "[213/00011] train_loss: 0.012785\n",
      "[213/00061] train_loss: 0.013252\n",
      "[213/00111] train_loss: 0.013276\n",
      "[213/00161] train_loss: 0.013269\n",
      "[213/00211] train_loss: 0.012284\n",
      "[213/00261] train_loss: 0.013311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[213/00311] train_loss: 0.013111\n",
      "[213/00361] train_loss: 0.012949\n",
      "[213/00411] train_loss: 0.012322\n",
      "[213/00461] train_loss: 0.012209\n",
      "[213/00511] train_loss: 0.013195\n",
      "[213/00561] train_loss: 0.012213\n",
      "[213/00611] train_loss: 0.012602\n",
      "[213/00661] train_loss: 0.012997\n",
      "[213/00711] train_loss: 0.012498\n",
      "[213/00761] train_loss: 0.013057\n",
      "[213/00811] train_loss: 0.013020\n",
      "[213/00861] train_loss: 0.012598\n",
      "[213/00911] train_loss: 0.012326\n",
      "[213/00961] train_loss: 0.012637\n",
      "[213/01011] train_loss: 0.012528\n",
      "[213/01061] train_loss: 0.012858\n",
      "[213/01111] train_loss: 0.013367\n",
      "[213/01161] train_loss: 0.012814\n",
      "[213/01211] train_loss: 0.011771\n",
      "[214/00035] train_loss: 0.013167\n",
      "[214/00085] train_loss: 0.012594\n",
      "[214/00135] train_loss: 0.012746\n",
      "[214/00185] train_loss: 0.013352\n",
      "[214/00235] train_loss: 0.013398\n",
      "[214/00285] train_loss: 0.013329\n",
      "[214/00335] train_loss: 0.012967\n",
      "[214/00385] train_loss: 0.012440\n",
      "[214/00435] train_loss: 0.012515\n",
      "[214/00485] train_loss: 0.012500\n",
      "[214/00535] train_loss: 0.012740\n",
      "[214/00585] train_loss: 0.012580\n",
      "[214/00635] train_loss: 0.012932\n",
      "[214/00685] train_loss: 0.013396\n",
      "[214/00735] train_loss: 0.012663\n",
      "[214/00785] train_loss: 0.013465\n",
      "[214/00835] train_loss: 0.013071\n",
      "[214/00885] train_loss: 0.012135\n",
      "[214/00935] train_loss: 0.012979\n",
      "[214/00985] train_loss: 0.012031\n",
      "[214/01035] train_loss: 0.012650\n",
      "[214/01085] train_loss: 0.013108\n",
      "[214/01135] train_loss: 0.012366\n",
      "[214/01185] train_loss: 0.012742\n",
      "[215/00009] train_loss: 0.013527\n",
      "[215/00059] train_loss: 0.014069\n",
      "[215/00109] train_loss: 0.012728\n",
      "[215/00159] train_loss: 0.013131\n",
      "[215/00209] train_loss: 0.012464\n",
      "[215/00259] train_loss: 0.012931\n",
      "[215/00309] train_loss: 0.013049\n",
      "[215/00359] train_loss: 0.012611\n",
      "[215/00409] train_loss: 0.011772\n",
      "[215/00459] train_loss: 0.012543\n",
      "[215/00509] train_loss: 0.012860\n",
      "[215/00559] train_loss: 0.012940\n",
      "[215/00609] train_loss: 0.012023\n",
      "[215/00659] train_loss: 0.012838\n",
      "[215/00709] train_loss: 0.013451\n",
      "[215/00759] train_loss: 0.012805\n",
      "[215/00809] train_loss: 0.012867\n",
      "[215/00859] train_loss: 0.012390\n",
      "[215/00909] train_loss: 0.011959\n",
      "[215/00959] train_loss: 0.011948\n",
      "[215/01009] train_loss: 0.012367\n",
      "[215/01059] train_loss: 0.012837\n",
      "[215/01109] train_loss: 0.012331\n",
      "[215/01159] train_loss: 0.013051\n",
      "[215/01209] train_loss: 0.012476\n",
      "[216/00033] train_loss: 0.013297\n",
      "[216/00083] train_loss: 0.012626\n",
      "[216/00133] train_loss: 0.013309\n",
      "[216/00183] train_loss: 0.013065\n",
      "[216/00233] train_loss: 0.013429\n",
      "[216/00283] train_loss: 0.011989\n",
      "[216/00333] train_loss: 0.012391\n",
      "[216/00383] train_loss: 0.012471\n",
      "[216/00433] train_loss: 0.012153\n",
      "[216/00483] train_loss: 0.012913\n",
      "[216/00533] train_loss: 0.012868\n",
      "[216/00583] train_loss: 0.012642\n",
      "[216/00633] train_loss: 0.012654\n",
      "[216/00683] train_loss: 0.013081\n",
      "[216/00733] train_loss: 0.013405\n",
      "[216/00783] train_loss: 0.011985\n",
      "[216/00833] train_loss: 0.012339\n",
      "[216/00883] train_loss: 0.013042\n",
      "[216/00933] train_loss: 0.012668\n",
      "[216/00983] train_loss: 0.012486\n",
      "[216/01033] train_loss: 0.013040\n",
      "[216/01083] train_loss: 0.012293\n",
      "[216/01133] train_loss: 0.012362\n",
      "[216/01183] train_loss: 0.012467\n",
      "[217/00007] train_loss: 0.013010\n",
      "[217/00057] train_loss: 0.012891\n",
      "[217/00107] train_loss: 0.013865\n",
      "[217/00157] train_loss: 0.013196\n",
      "[217/00207] train_loss: 0.012567\n",
      "[217/00257] train_loss: 0.013413\n",
      "[217/00307] train_loss: 0.012924\n",
      "[217/00357] train_loss: 0.012768\n",
      "[217/00407] train_loss: 0.012949\n",
      "[217/00457] train_loss: 0.012848\n",
      "[217/00507] train_loss: 0.012732\n",
      "[217/00557] train_loss: 0.012999\n",
      "[217/00607] train_loss: 0.012310\n",
      "[217/00657] train_loss: 0.012799\n",
      "[217/00707] train_loss: 0.013278\n",
      "[217/00757] train_loss: 0.013030\n",
      "[217/00807] train_loss: 0.012541\n",
      "[217/00857] train_loss: 0.012578\n",
      "[217/00907] train_loss: 0.012625\n",
      "[217/00957] train_loss: 0.012255\n",
      "[217/01007] train_loss: 0.012458\n",
      "[217/01057] train_loss: 0.012154\n",
      "[217/01107] train_loss: 0.012323\n",
      "[217/01157] train_loss: 0.012752\n",
      "[217/01207] train_loss: 0.012143\n",
      "[218/00031] train_loss: 0.013293\n",
      "[218/00081] train_loss: 0.012651\n",
      "[218/00131] train_loss: 0.013268\n",
      "[218/00181] train_loss: 0.013192\n",
      "[218/00231] train_loss: 0.012844\n",
      "[218/00281] train_loss: 0.013029\n",
      "[218/00331] train_loss: 0.014070\n",
      "[218/00381] train_loss: 0.013205\n",
      "[218/00431] train_loss: 0.012490\n",
      "[218/00481] train_loss: 0.012606\n",
      "[218/00531] train_loss: 0.012825\n",
      "[218/00581] train_loss: 0.012354\n",
      "[218/00631] train_loss: 0.012225\n",
      "[218/00681] train_loss: 0.013043\n",
      "[218/00731] train_loss: 0.012135\n",
      "[218/00781] train_loss: 0.012212\n",
      "[218/00831] train_loss: 0.012896\n",
      "[218/00881] train_loss: 0.012911\n",
      "[218/00931] train_loss: 0.012201\n",
      "[218/00981] train_loss: 0.012640\n",
      "[218/01031] train_loss: 0.012686\n",
      "[218/01081] train_loss: 0.012620\n",
      "[218/01131] train_loss: 0.012313\n",
      "[218/01181] train_loss: 0.012422\n",
      "[219/00005] train_loss: 0.012349\n",
      "[219/00055] train_loss: 0.013170\n",
      "[219/00105] train_loss: 0.013484\n",
      "[219/00155] train_loss: 0.012823\n",
      "[219/00205] train_loss: 0.013697\n",
      "[219/00255] train_loss: 0.012252\n",
      "[219/00305] train_loss: 0.012686\n",
      "[219/00355] train_loss: 0.013343\n",
      "[219/00405] train_loss: 0.011827\n",
      "[219/00455] train_loss: 0.013080\n",
      "[219/00505] train_loss: 0.012470\n",
      "[219/00555] train_loss: 0.013345\n",
      "[219/00605] train_loss: 0.012486\n",
      "[219/00655] train_loss: 0.012457\n",
      "[219/00705] train_loss: 0.012788\n",
      "[219/00755] train_loss: 0.013182\n",
      "[219/00805] train_loss: 0.012624\n",
      "[219/00855] train_loss: 0.012337\n",
      "[219/00905] train_loss: 0.012534\n",
      "[219/00955] train_loss: 0.012141\n",
      "[219/01005] train_loss: 0.012414\n",
      "[219/01055] train_loss: 0.012309\n",
      "[219/01105] train_loss: 0.012397\n",
      "[219/01155] train_loss: 0.011705\n",
      "[219/01205] train_loss: 0.011341\n",
      "[220/00029] train_loss: 0.013006\n",
      "[220/00079] train_loss: 0.013195\n",
      "[220/00129] train_loss: 0.013254\n",
      "[220/00179] train_loss: 0.012949\n",
      "[220/00229] train_loss: 0.013169\n",
      "[220/00279] train_loss: 0.012263\n",
      "[220/00329] train_loss: 0.012914\n",
      "[220/00379] train_loss: 0.012616\n",
      "[220/00429] train_loss: 0.013238\n",
      "[220/00479] train_loss: 0.013450\n",
      "[220/00529] train_loss: 0.013131\n",
      "[220/00579] train_loss: 0.012618\n",
      "[220/00629] train_loss: 0.012132\n",
      "[220/00679] train_loss: 0.012683\n",
      "[220/00729] train_loss: 0.012463\n",
      "[220/00779] train_loss: 0.012690\n",
      "[220/00829] train_loss: 0.012505\n",
      "[220/00879] train_loss: 0.012561\n",
      "[220/00929] train_loss: 0.012676\n",
      "[220/00979] train_loss: 0.013298\n",
      "[220/01029] train_loss: 0.012515\n",
      "[220/01079] train_loss: 0.012322\n",
      "[220/01129] train_loss: 0.012855\n",
      "[220/01179] train_loss: 0.012911\n",
      "[221/00003] train_loss: 0.011634\n",
      "[221/00053] train_loss: 0.013185\n",
      "[221/00103] train_loss: 0.013714\n",
      "[221/00153] train_loss: 0.012876\n",
      "[221/00203] train_loss: 0.013111\n",
      "[221/00253] train_loss: 0.012871\n",
      "[221/00303] train_loss: 0.013142\n",
      "[221/00353] train_loss: 0.012067\n",
      "[221/00403] train_loss: 0.012819\n",
      "[221/00453] train_loss: 0.012925\n",
      "[221/00503] train_loss: 0.013393\n",
      "[221/00553] train_loss: 0.013212\n",
      "[221/00603] train_loss: 0.012146\n",
      "[221/00653] train_loss: 0.013063\n",
      "[221/00703] train_loss: 0.012026\n",
      "[221/00753] train_loss: 0.012887\n",
      "[221/00803] train_loss: 0.012421\n",
      "[221/00853] train_loss: 0.011711\n",
      "[221/00903] train_loss: 0.012326\n",
      "[221/00953] train_loss: 0.012937\n",
      "[221/01003] train_loss: 0.012335\n",
      "[221/01053] train_loss: 0.012226\n",
      "[221/01103] train_loss: 0.011895\n",
      "[221/01153] train_loss: 0.012955\n",
      "[221/01203] train_loss: 0.011978\n",
      "[222/00027] train_loss: 0.013018\n",
      "[222/00077] train_loss: 0.012459\n",
      "[222/00127] train_loss: 0.013147\n",
      "[222/00177] train_loss: 0.012784\n",
      "[222/00227] train_loss: 0.013116\n",
      "[222/00277] train_loss: 0.013272\n",
      "[222/00327] train_loss: 0.012430\n",
      "[222/00377] train_loss: 0.012734\n",
      "[222/00427] train_loss: 0.012927\n",
      "[222/00477] train_loss: 0.012785\n",
      "[222/00527] train_loss: 0.012616\n",
      "[222/00577] train_loss: 0.012769\n",
      "[222/00627] train_loss: 0.012989\n",
      "[222/00677] train_loss: 0.013042\n",
      "[222/00727] train_loss: 0.013187\n",
      "[222/00777] train_loss: 0.013318\n",
      "[222/00827] train_loss: 0.012384\n",
      "[222/00877] train_loss: 0.011908\n",
      "[222/00927] train_loss: 0.012912\n",
      "[222/00977] train_loss: 0.012175\n",
      "[222/01027] train_loss: 0.012445\n",
      "[222/01077] train_loss: 0.012027\n",
      "[222/01127] train_loss: 0.013032\n",
      "[222/01177] train_loss: 0.012453\n",
      "[223/00001] train_loss: 0.011664\n",
      "[223/00051] train_loss: 0.013283\n",
      "[223/00101] train_loss: 0.013115\n",
      "[223/00151] train_loss: 0.012766\n",
      "[223/00201] train_loss: 0.012952\n",
      "[223/00251] train_loss: 0.012562\n",
      "[223/00301] train_loss: 0.012868\n",
      "[223/00351] train_loss: 0.013396\n",
      "[223/00401] train_loss: 0.012512\n",
      "[223/00451] train_loss: 0.012716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[223/00501] train_loss: 0.012962\n",
      "[223/00551] train_loss: 0.011616\n",
      "[223/00601] train_loss: 0.012640\n",
      "[223/00651] train_loss: 0.012439\n",
      "[223/00701] train_loss: 0.012090\n",
      "[223/00751] train_loss: 0.012867\n",
      "[223/00801] train_loss: 0.013060\n",
      "[223/00851] train_loss: 0.011992\n",
      "[223/00901] train_loss: 0.011780\n",
      "[223/00951] train_loss: 0.011648\n",
      "[223/01001] train_loss: 0.012474\n",
      "[223/01051] train_loss: 0.012417\n",
      "[223/01101] train_loss: 0.012161\n",
      "[223/01151] train_loss: 0.012949\n",
      "[223/01201] train_loss: 0.013098\n",
      "[224/00025] train_loss: 0.012753\n",
      "[224/00075] train_loss: 0.012899\n",
      "[224/00125] train_loss: 0.012772\n",
      "[224/00175] train_loss: 0.013480\n",
      "[224/00225] train_loss: 0.013088\n",
      "[224/00275] train_loss: 0.012951\n",
      "[224/00325] train_loss: 0.013077\n",
      "[224/00375] train_loss: 0.013027\n",
      "[224/00425] train_loss: 0.013010\n",
      "[224/00475] train_loss: 0.012057\n",
      "[224/00525] train_loss: 0.013061\n",
      "[224/00575] train_loss: 0.012386\n",
      "[224/00625] train_loss: 0.012566\n",
      "[224/00675] train_loss: 0.012275\n",
      "[224/00725] train_loss: 0.011909\n",
      "[224/00775] train_loss: 0.012816\n",
      "[224/00825] train_loss: 0.012201\n",
      "[224/00875] train_loss: 0.012564\n",
      "[224/00925] train_loss: 0.012462\n",
      "[224/00975] train_loss: 0.013211\n",
      "[224/01025] train_loss: 0.013035\n",
      "[224/01075] train_loss: 0.012037\n",
      "[224/01125] train_loss: 0.011983\n",
      "[224/01175] train_loss: 0.012986\n",
      "[224/01225] train_loss: 0.012342\n",
      "[225/00049] train_loss: 0.012570\n",
      "[225/00099] train_loss: 0.013340\n",
      "[225/00149] train_loss: 0.012929\n",
      "[225/00199] train_loss: 0.013048\n",
      "[225/00249] train_loss: 0.012663\n",
      "[225/00299] train_loss: 0.012631\n",
      "[225/00349] train_loss: 0.013610\n",
      "[225/00399] train_loss: 0.013008\n",
      "[225/00449] train_loss: 0.012672\n",
      "[225/00499] train_loss: 0.012359\n",
      "[225/00549] train_loss: 0.012429\n",
      "[225/00599] train_loss: 0.012535\n",
      "[225/00649] train_loss: 0.012458\n",
      "[225/00699] train_loss: 0.013118\n",
      "[225/00749] train_loss: 0.012802\n",
      "[225/00799] train_loss: 0.013073\n",
      "[225/00849] train_loss: 0.012546\n",
      "[225/00899] train_loss: 0.013439\n",
      "[225/00949] train_loss: 0.012042\n",
      "[225/00999] train_loss: 0.012334\n",
      "[225/01049] train_loss: 0.012241\n",
      "[225/01099] train_loss: 0.011387\n",
      "[225/01149] train_loss: 0.012771\n",
      "[225/01199] train_loss: 0.012120\n",
      "[226/00023] train_loss: 0.012878\n",
      "[226/00073] train_loss: 0.012985\n",
      "[226/00123] train_loss: 0.012803\n",
      "[226/00173] train_loss: 0.013699\n",
      "[226/00223] train_loss: 0.012813\n",
      "[226/00273] train_loss: 0.013317\n",
      "[226/00323] train_loss: 0.012832\n",
      "[226/00373] train_loss: 0.013026\n",
      "[226/00423] train_loss: 0.012247\n",
      "[226/00473] train_loss: 0.012824\n",
      "[226/00523] train_loss: 0.013183\n",
      "[226/00573] train_loss: 0.012779\n",
      "[226/00623] train_loss: 0.012740\n",
      "[226/00673] train_loss: 0.012318\n",
      "[226/00723] train_loss: 0.012085\n",
      "[226/00773] train_loss: 0.012559\n",
      "[226/00823] train_loss: 0.012781\n",
      "[226/00873] train_loss: 0.012689\n",
      "[226/00923] train_loss: 0.013185\n",
      "[226/00973] train_loss: 0.012241\n",
      "[226/01023] train_loss: 0.012231\n",
      "[226/01073] train_loss: 0.012351\n",
      "[226/01123] train_loss: 0.012122\n",
      "[226/01173] train_loss: 0.011706\n",
      "[226/01223] train_loss: 0.013415\n",
      "[227/00047] train_loss: 0.012941\n",
      "[227/00097] train_loss: 0.013312\n",
      "[227/00147] train_loss: 0.013039\n",
      "[227/00197] train_loss: 0.012287\n",
      "[227/00247] train_loss: 0.012361\n",
      "[227/00297] train_loss: 0.012813\n",
      "[227/00347] train_loss: 0.012662\n",
      "[227/00397] train_loss: 0.012658\n",
      "[227/00447] train_loss: 0.012727\n",
      "[227/00497] train_loss: 0.013109\n",
      "[227/00547] train_loss: 0.011793\n",
      "[227/00597] train_loss: 0.012631\n",
      "[227/00647] train_loss: 0.012725\n",
      "[227/00697] train_loss: 0.011782\n",
      "[227/00747] train_loss: 0.013116\n",
      "[227/00797] train_loss: 0.013293\n",
      "[227/00847] train_loss: 0.012392\n",
      "[227/00897] train_loss: 0.012430\n",
      "[227/00947] train_loss: 0.013532\n",
      "[227/00997] train_loss: 0.012422\n",
      "[227/01047] train_loss: 0.012237\n",
      "[227/01097] train_loss: 0.012395\n",
      "[227/01147] train_loss: 0.012459\n",
      "[227/01197] train_loss: 0.012754\n",
      "[228/00021] train_loss: 0.012729\n",
      "[228/00071] train_loss: 0.012623\n",
      "[228/00121] train_loss: 0.012815\n",
      "[228/00171] train_loss: 0.012761\n",
      "[228/00221] train_loss: 0.013652\n",
      "[228/00271] train_loss: 0.012406\n",
      "[228/00321] train_loss: 0.012431\n",
      "[228/00371] train_loss: 0.011950\n",
      "[228/00421] train_loss: 0.012649\n",
      "[228/00471] train_loss: 0.012550\n",
      "[228/00521] train_loss: 0.012566\n",
      "[228/00571] train_loss: 0.012452\n",
      "[228/00621] train_loss: 0.013200\n",
      "[228/00671] train_loss: 0.013121\n",
      "[228/00721] train_loss: 0.011850\n",
      "[228/00771] train_loss: 0.012154\n",
      "[228/00821] train_loss: 0.012515\n",
      "[228/00871] train_loss: 0.011814\n",
      "[228/00921] train_loss: 0.013130\n",
      "[228/00971] train_loss: 0.013566\n",
      "[228/01021] train_loss: 0.012835\n",
      "[228/01071] train_loss: 0.012582\n",
      "[228/01121] train_loss: 0.012755\n",
      "[228/01171] train_loss: 0.012956\n",
      "[228/01221] train_loss: 0.012633\n",
      "[229/00045] train_loss: 0.013167\n",
      "[229/00095] train_loss: 0.012622\n",
      "[229/00145] train_loss: 0.013299\n",
      "[229/00195] train_loss: 0.012536\n",
      "[229/00245] train_loss: 0.012334\n",
      "[229/00295] train_loss: 0.012849\n",
      "[229/00345] train_loss: 0.012827\n",
      "[229/00395] train_loss: 0.012514\n",
      "[229/00445] train_loss: 0.012663\n",
      "[229/00495] train_loss: 0.013042\n",
      "[229/00545] train_loss: 0.012303\n",
      "[229/00595] train_loss: 0.012821\n",
      "[229/00645] train_loss: 0.012549\n",
      "[229/00695] train_loss: 0.012288\n",
      "[229/00745] train_loss: 0.012942\n",
      "[229/00795] train_loss: 0.011874\n",
      "[229/00845] train_loss: 0.012532\n",
      "[229/00895] train_loss: 0.012350\n",
      "[229/00945] train_loss: 0.011748\n",
      "[229/00995] train_loss: 0.012601\n",
      "[229/01045] train_loss: 0.012225\n",
      "[229/01095] train_loss: 0.011956\n",
      "[229/01145] train_loss: 0.013234\n",
      "[229/01195] train_loss: 0.013173\n",
      "[230/00019] train_loss: 0.012915\n",
      "[230/00069] train_loss: 0.013067\n",
      "[230/00119] train_loss: 0.013146\n",
      "[230/00169] train_loss: 0.013167\n",
      "[230/00219] train_loss: 0.012962\n",
      "[230/00269] train_loss: 0.012237\n",
      "[230/00319] train_loss: 0.012691\n",
      "[230/00369] train_loss: 0.011999\n",
      "[230/00419] train_loss: 0.013143\n",
      "[230/00469] train_loss: 0.012270\n",
      "[230/00519] train_loss: 0.012801\n",
      "[230/00569] train_loss: 0.012169\n",
      "[230/00619] train_loss: 0.012193\n",
      "[230/00669] train_loss: 0.012554\n",
      "[230/00719] train_loss: 0.012640\n",
      "[230/00769] train_loss: 0.012293\n",
      "[230/00819] train_loss: 0.012182\n",
      "[230/00869] train_loss: 0.011991\n",
      "[230/00919] train_loss: 0.012003\n",
      "[230/00969] train_loss: 0.012358\n",
      "[230/01019] train_loss: 0.012260\n",
      "[230/01069] train_loss: 0.012748\n",
      "[230/01119] train_loss: 0.012723\n",
      "[230/01169] train_loss: 0.012486\n",
      "[230/01219] train_loss: 0.013094\n",
      "[231/00043] train_loss: 0.012407\n",
      "[231/00093] train_loss: 0.013463\n",
      "[231/00143] train_loss: 0.012205\n",
      "[231/00193] train_loss: 0.012820\n",
      "[231/00243] train_loss: 0.012937\n",
      "[231/00293] train_loss: 0.011987\n",
      "[231/00343] train_loss: 0.012322\n",
      "[231/00393] train_loss: 0.011914\n",
      "[231/00443] train_loss: 0.012435\n",
      "[231/00493] train_loss: 0.012122\n",
      "[231/00543] train_loss: 0.012859\n",
      "[231/00593] train_loss: 0.012553\n",
      "[231/00643] train_loss: 0.012056\n",
      "[231/00693] train_loss: 0.012438\n",
      "[231/00743] train_loss: 0.012855\n",
      "[231/00793] train_loss: 0.012626\n",
      "[231/00843] train_loss: 0.012547\n",
      "[231/00893] train_loss: 0.012362\n",
      "[231/00943] train_loss: 0.012539\n",
      "[231/00993] train_loss: 0.012358\n",
      "[231/01043] train_loss: 0.013318\n",
      "[231/01093] train_loss: 0.012906\n",
      "[231/01143] train_loss: 0.012124\n",
      "[231/01193] train_loss: 0.012437\n",
      "[232/00017] train_loss: 0.012277\n",
      "[232/00067] train_loss: 0.013289\n",
      "[232/00117] train_loss: 0.012637\n",
      "[232/00167] train_loss: 0.012805\n",
      "[232/00217] train_loss: 0.012838\n",
      "[232/00267] train_loss: 0.011738\n",
      "[232/00317] train_loss: 0.012795\n",
      "[232/00367] train_loss: 0.012499\n",
      "[232/00417] train_loss: 0.012861\n",
      "[232/00467] train_loss: 0.012091\n",
      "[232/00517] train_loss: 0.012676\n",
      "[232/00567] train_loss: 0.011991\n",
      "[232/00617] train_loss: 0.012732\n",
      "[232/00667] train_loss: 0.013165\n",
      "[232/00717] train_loss: 0.012774\n",
      "[232/00767] train_loss: 0.012634\n",
      "[232/00817] train_loss: 0.012492\n",
      "[232/00867] train_loss: 0.011907\n",
      "[232/00917] train_loss: 0.012912\n",
      "[232/00967] train_loss: 0.012248\n",
      "[232/01017] train_loss: 0.011646\n",
      "[232/01067] train_loss: 0.012933\n",
      "[232/01117] train_loss: 0.012807\n",
      "[232/01167] train_loss: 0.012870\n",
      "[232/01217] train_loss: 0.012183\n",
      "[233/00041] train_loss: 0.013008\n",
      "[233/00091] train_loss: 0.012942\n",
      "[233/00141] train_loss: 0.012742\n",
      "[233/00191] train_loss: 0.012790\n",
      "[233/00241] train_loss: 0.013498\n",
      "[233/00291] train_loss: 0.012447\n",
      "[233/00341] train_loss: 0.012833\n",
      "[233/00391] train_loss: 0.013078\n",
      "[233/00441] train_loss: 0.012582\n",
      "[233/00491] train_loss: 0.012520\n",
      "[233/00541] train_loss: 0.012638\n",
      "[233/00591] train_loss: 0.012407\n",
      "[233/00641] train_loss: 0.012334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[233/00691] train_loss: 0.012387\n",
      "[233/00741] train_loss: 0.012794\n",
      "[233/00791] train_loss: 0.011972\n",
      "[233/00841] train_loss: 0.011946\n",
      "[233/00891] train_loss: 0.012115\n",
      "[233/00941] train_loss: 0.012919\n",
      "[233/00991] train_loss: 0.011899\n",
      "[233/01041] train_loss: 0.012447\n",
      "[233/01091] train_loss: 0.011159\n",
      "[233/01141] train_loss: 0.012857\n",
      "[233/01191] train_loss: 0.012043\n",
      "[234/00015] train_loss: 0.012746\n",
      "[234/00065] train_loss: 0.012867\n",
      "[234/00115] train_loss: 0.012769\n",
      "[234/00165] train_loss: 0.011904\n",
      "[234/00215] train_loss: 0.012580\n",
      "[234/00265] train_loss: 0.012907\n",
      "[234/00315] train_loss: 0.012623\n",
      "[234/00365] train_loss: 0.012620\n",
      "[234/00415] train_loss: 0.012856\n",
      "[234/00465] train_loss: 0.012445\n",
      "[234/00515] train_loss: 0.012912\n",
      "[234/00565] train_loss: 0.012569\n",
      "[234/00615] train_loss: 0.012631\n",
      "[234/00665] train_loss: 0.012785\n",
      "[234/00715] train_loss: 0.011748\n",
      "[234/00765] train_loss: 0.012770\n",
      "[234/00815] train_loss: 0.012850\n",
      "[234/00865] train_loss: 0.012537\n",
      "[234/00915] train_loss: 0.011672\n",
      "[234/00965] train_loss: 0.012531\n",
      "[234/01015] train_loss: 0.012449\n",
      "[234/01065] train_loss: 0.012525\n",
      "[234/01115] train_loss: 0.012244\n",
      "[234/01165] train_loss: 0.012760\n",
      "[234/01215] train_loss: 0.013150\n",
      "[235/00039] train_loss: 0.012657\n",
      "[235/00089] train_loss: 0.012686\n",
      "[235/00139] train_loss: 0.012403\n",
      "[235/00189] train_loss: 0.012462\n",
      "[235/00239] train_loss: 0.012703\n",
      "[235/00289] train_loss: 0.012841\n",
      "[235/00339] train_loss: 0.013115\n",
      "[235/00389] train_loss: 0.012850\n",
      "[235/00439] train_loss: 0.012987\n",
      "[235/00489] train_loss: 0.012710\n",
      "[235/00539] train_loss: 0.012648\n",
      "[235/00589] train_loss: 0.011473\n",
      "[235/00639] train_loss: 0.011553\n",
      "[235/00689] train_loss: 0.011897\n",
      "[235/00739] train_loss: 0.012996\n",
      "[235/00789] train_loss: 0.012833\n",
      "[235/00839] train_loss: 0.012353\n",
      "[235/00889] train_loss: 0.011954\n",
      "[235/00939] train_loss: 0.011715\n",
      "[235/00989] train_loss: 0.012585\n",
      "[235/01039] train_loss: 0.012805\n",
      "[235/01089] train_loss: 0.011824\n",
      "[235/01139] train_loss: 0.012615\n",
      "[235/01189] train_loss: 0.012384\n",
      "[236/00013] train_loss: 0.012500\n",
      "[236/00063] train_loss: 0.012878\n",
      "[236/00113] train_loss: 0.013567\n",
      "[236/00163] train_loss: 0.012798\n",
      "[236/00213] train_loss: 0.012750\n",
      "[236/00263] train_loss: 0.013352\n",
      "[236/00313] train_loss: 0.012481\n",
      "[236/00363] train_loss: 0.012483\n",
      "[236/00413] train_loss: 0.013318\n",
      "[236/00463] train_loss: 0.012339\n",
      "[236/00513] train_loss: 0.012076\n",
      "[236/00563] train_loss: 0.012576\n",
      "[236/00613] train_loss: 0.011241\n",
      "[236/00663] train_loss: 0.011700\n",
      "[236/00713] train_loss: 0.012869\n",
      "[236/00763] train_loss: 0.013336\n",
      "[236/00813] train_loss: 0.012023\n",
      "[236/00863] train_loss: 0.013288\n",
      "[236/00913] train_loss: 0.012630\n",
      "[236/00963] train_loss: 0.012654\n",
      "[236/01013] train_loss: 0.011988\n",
      "[236/01063] train_loss: 0.013204\n",
      "[236/01113] train_loss: 0.012418\n",
      "[236/01163] train_loss: 0.012350\n",
      "[236/01213] train_loss: 0.012336\n",
      "[237/00037] train_loss: 0.013187\n",
      "[237/00087] train_loss: 0.013372\n",
      "[237/00137] train_loss: 0.012590\n",
      "[237/00187] train_loss: 0.012999\n",
      "[237/00237] train_loss: 0.012056\n",
      "[237/00287] train_loss: 0.012659\n",
      "[237/00337] train_loss: 0.012793\n",
      "[237/00387] train_loss: 0.012432\n",
      "[237/00437] train_loss: 0.012321\n",
      "[237/00487] train_loss: 0.012184\n",
      "[237/00537] train_loss: 0.012615\n",
      "[237/00587] train_loss: 0.012685\n",
      "[237/00637] train_loss: 0.012206\n",
      "[237/00687] train_loss: 0.012446\n",
      "[237/00737] train_loss: 0.011981\n",
      "[237/00787] train_loss: 0.012271\n",
      "[237/00837] train_loss: 0.011955\n",
      "[237/00887] train_loss: 0.012182\n",
      "[237/00937] train_loss: 0.013291\n",
      "[237/00987] train_loss: 0.012252\n",
      "[237/01037] train_loss: 0.012888\n",
      "[237/01087] train_loss: 0.011769\n",
      "[237/01137] train_loss: 0.012665\n",
      "[237/01187] train_loss: 0.011238\n",
      "[238/00011] train_loss: 0.012922\n",
      "[238/00061] train_loss: 0.013137\n",
      "[238/00111] train_loss: 0.012606\n",
      "[238/00161] train_loss: 0.012629\n",
      "[238/00211] train_loss: 0.012629\n",
      "[238/00261] train_loss: 0.012953\n",
      "[238/00311] train_loss: 0.012838\n",
      "[238/00361] train_loss: 0.012628\n",
      "[238/00411] train_loss: 0.013647\n",
      "[238/00461] train_loss: 0.012045\n",
      "[238/00511] train_loss: 0.012579\n",
      "[238/00561] train_loss: 0.012230\n",
      "[238/00611] train_loss: 0.012361\n",
      "[238/00661] train_loss: 0.012290\n",
      "[238/00711] train_loss: 0.012143\n",
      "[238/00761] train_loss: 0.012353\n",
      "[238/00811] train_loss: 0.012386\n",
      "[238/00861] train_loss: 0.011834\n",
      "[238/00911] train_loss: 0.012274\n",
      "[238/00961] train_loss: 0.012435\n",
      "[238/01011] train_loss: 0.012123\n",
      "[238/01061] train_loss: 0.012104\n",
      "[238/01111] train_loss: 0.012930\n",
      "[238/01161] train_loss: 0.012445\n",
      "[238/01211] train_loss: 0.012950\n",
      "[239/00035] train_loss: 0.013017\n",
      "[239/00085] train_loss: 0.013562\n",
      "[239/00135] train_loss: 0.013231\n",
      "[239/00185] train_loss: 0.012395\n",
      "[239/00235] train_loss: 0.012389\n",
      "[239/00285] train_loss: 0.013385\n",
      "[239/00335] train_loss: 0.012313\n",
      "[239/00385] train_loss: 0.012584\n",
      "[239/00435] train_loss: 0.012259\n",
      "[239/00485] train_loss: 0.011997\n",
      "[239/00535] train_loss: 0.012110\n",
      "[239/00585] train_loss: 0.012629\n",
      "[239/00635] train_loss: 0.011981\n",
      "[239/00685] train_loss: 0.012423\n",
      "[239/00735] train_loss: 0.012078\n",
      "[239/00785] train_loss: 0.012040\n",
      "[239/00835] train_loss: 0.012136\n",
      "[239/00885] train_loss: 0.013092\n",
      "[239/00935] train_loss: 0.012361\n",
      "[239/00985] train_loss: 0.011862\n",
      "[239/01035] train_loss: 0.012714\n",
      "[239/01085] train_loss: 0.012085\n",
      "[239/01135] train_loss: 0.012351\n",
      "[239/01185] train_loss: 0.012456\n",
      "[240/00009] train_loss: 0.013260\n",
      "[240/00059] train_loss: 0.013162\n",
      "[240/00109] train_loss: 0.013910\n",
      "[240/00159] train_loss: 0.013224\n",
      "[240/00209] train_loss: 0.012339\n",
      "[240/00259] train_loss: 0.012085\n",
      "[240/00309] train_loss: 0.012004\n",
      "[240/00359] train_loss: 0.012110\n",
      "[240/00409] train_loss: 0.012790\n",
      "[240/00459] train_loss: 0.012589\n",
      "[240/00509] train_loss: 0.012579\n",
      "[240/00559] train_loss: 0.012538\n",
      "[240/00609] train_loss: 0.012703\n",
      "[240/00659] train_loss: 0.012463\n",
      "[240/00709] train_loss: 0.012411\n",
      "[240/00759] train_loss: 0.013506\n",
      "[240/00809] train_loss: 0.012885\n",
      "[240/00859] train_loss: 0.012132\n",
      "[240/00909] train_loss: 0.012402\n",
      "[240/00959] train_loss: 0.011925\n",
      "[240/01009] train_loss: 0.012756\n",
      "[240/01059] train_loss: 0.012457\n",
      "[240/01109] train_loss: 0.011896\n",
      "[240/01159] train_loss: 0.011557\n",
      "[240/01209] train_loss: 0.012946\n",
      "[241/00033] train_loss: 0.012877\n",
      "[241/00083] train_loss: 0.012702\n",
      "[241/00133] train_loss: 0.012862\n",
      "[241/00183] train_loss: 0.011781\n",
      "[241/00233] train_loss: 0.012677\n",
      "[241/00283] train_loss: 0.012812\n",
      "[241/00333] train_loss: 0.012042\n",
      "[241/00383] train_loss: 0.012321\n",
      "[241/00433] train_loss: 0.012549\n",
      "[241/00483] train_loss: 0.013042\n",
      "[241/00533] train_loss: 0.012673\n",
      "[241/00583] train_loss: 0.011594\n",
      "[241/00633] train_loss: 0.011902\n",
      "[241/00683] train_loss: 0.012199\n",
      "[241/00733] train_loss: 0.012000\n",
      "[241/00783] train_loss: 0.013181\n",
      "[241/00833] train_loss: 0.012294\n",
      "[241/00883] train_loss: 0.012553\n",
      "[241/00933] train_loss: 0.012385\n",
      "[241/00983] train_loss: 0.012163\n",
      "[241/01033] train_loss: 0.012251\n",
      "[241/01083] train_loss: 0.012386\n",
      "[241/01133] train_loss: 0.012290\n",
      "[241/01183] train_loss: 0.012767\n",
      "[242/00007] train_loss: 0.012812\n",
      "[242/00057] train_loss: 0.012557\n",
      "[242/00107] train_loss: 0.012496\n",
      "[242/00157] train_loss: 0.012412\n",
      "[242/00207] train_loss: 0.012834\n",
      "[242/00257] train_loss: 0.012517\n",
      "[242/00307] train_loss: 0.012586\n",
      "[242/00357] train_loss: 0.012639\n",
      "[242/00407] train_loss: 0.012309\n",
      "[242/00457] train_loss: 0.013178\n",
      "[242/00507] train_loss: 0.012062\n",
      "[242/00557] train_loss: 0.012808\n",
      "[242/00607] train_loss: 0.012242\n",
      "[242/00657] train_loss: 0.011964\n",
      "[242/00707] train_loss: 0.012199\n",
      "[242/00757] train_loss: 0.013237\n",
      "[242/00807] train_loss: 0.012261\n",
      "[242/00857] train_loss: 0.012278\n",
      "[242/00907] train_loss: 0.012408\n",
      "[242/00957] train_loss: 0.011878\n",
      "[242/01007] train_loss: 0.012923\n",
      "[242/01057] train_loss: 0.011752\n",
      "[242/01107] train_loss: 0.011823\n",
      "[242/01157] train_loss: 0.012643\n",
      "[242/01207] train_loss: 0.013110\n",
      "[243/00031] train_loss: 0.012765\n",
      "[243/00081] train_loss: 0.012551\n",
      "[243/00131] train_loss: 0.012475\n",
      "[243/00181] train_loss: 0.013776\n",
      "[243/00231] train_loss: 0.012477\n",
      "[243/00281] train_loss: 0.011507\n",
      "[243/00331] train_loss: 0.012979\n",
      "[243/00381] train_loss: 0.012846\n",
      "[243/00431] train_loss: 0.011965\n",
      "[243/00481] train_loss: 0.012480\n",
      "[243/00531] train_loss: 0.012654\n",
      "[243/00581] train_loss: 0.011968\n",
      "[243/00631] train_loss: 0.012806\n",
      "[243/00681] train_loss: 0.012465\n",
      "[243/00731] train_loss: 0.012012\n",
      "[243/00781] train_loss: 0.012731\n",
      "[243/00831] train_loss: 0.012212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[243/00881] train_loss: 0.012296\n",
      "[243/00931] train_loss: 0.012816\n",
      "[243/00981] train_loss: 0.011852\n",
      "[243/01031] train_loss: 0.012500\n",
      "[243/01081] train_loss: 0.011646\n",
      "[243/01131] train_loss: 0.012163\n",
      "[243/01181] train_loss: 0.011751\n",
      "[244/00005] train_loss: 0.012296\n",
      "[244/00055] train_loss: 0.012825\n",
      "[244/00105] train_loss: 0.012872\n",
      "[244/00155] train_loss: 0.012339\n",
      "[244/00205] train_loss: 0.012472\n",
      "[244/00255] train_loss: 0.013075\n",
      "[244/00305] train_loss: 0.013475\n",
      "[244/00355] train_loss: 0.013201\n",
      "[244/00405] train_loss: 0.012427\n",
      "[244/00455] train_loss: 0.013078\n",
      "[244/00505] train_loss: 0.012534\n",
      "[244/00555] train_loss: 0.011977\n",
      "[244/00605] train_loss: 0.012283\n",
      "[244/00655] train_loss: 0.012661\n",
      "[244/00705] train_loss: 0.012159\n",
      "[244/00755] train_loss: 0.012604\n",
      "[244/00805] train_loss: 0.012198\n",
      "[244/00855] train_loss: 0.012806\n",
      "[244/00905] train_loss: 0.012210\n",
      "[244/00955] train_loss: 0.011641\n",
      "[244/01005] train_loss: 0.012453\n",
      "[244/01055] train_loss: 0.012204\n",
      "[244/01105] train_loss: 0.011878\n",
      "[244/01155] train_loss: 0.012298\n",
      "[244/01205] train_loss: 0.011972\n",
      "[245/00029] train_loss: 0.012837\n",
      "[245/00079] train_loss: 0.013048\n",
      "[245/00129] train_loss: 0.013098\n",
      "[245/00179] train_loss: 0.012737\n",
      "[245/00229] train_loss: 0.012911\n",
      "[245/00279] train_loss: 0.012572\n",
      "[245/00329] train_loss: 0.012924\n",
      "[245/00379] train_loss: 0.012693\n",
      "[245/00429] train_loss: 0.011916\n",
      "[245/00479] train_loss: 0.011759\n",
      "[245/00529] train_loss: 0.012809\n",
      "[245/00579] train_loss: 0.011853\n",
      "[245/00629] train_loss: 0.012486\n",
      "[245/00679] train_loss: 0.012876\n",
      "[245/00729] train_loss: 0.012212\n",
      "[245/00779] train_loss: 0.012289\n",
      "[245/00829] train_loss: 0.012010\n",
      "[245/00879] train_loss: 0.012203\n",
      "[245/00929] train_loss: 0.011783\n",
      "[245/00979] train_loss: 0.012552\n",
      "[245/01029] train_loss: 0.012959\n",
      "[245/01079] train_loss: 0.011556\n",
      "[245/01129] train_loss: 0.012207\n",
      "[245/01179] train_loss: 0.012228\n",
      "[246/00003] train_loss: 0.012341\n",
      "[246/00053] train_loss: 0.011755\n",
      "[246/00103] train_loss: 0.013742\n",
      "[246/00153] train_loss: 0.012601\n",
      "[246/00203] train_loss: 0.012640\n",
      "[246/00253] train_loss: 0.012631\n",
      "[246/00303] train_loss: 0.012306\n",
      "[246/00353] train_loss: 0.012219\n",
      "[246/00403] train_loss: 0.012687\n",
      "[246/00453] train_loss: 0.013006\n",
      "[246/00503] train_loss: 0.013208\n",
      "[246/00553] train_loss: 0.012821\n",
      "[246/00603] train_loss: 0.012450\n",
      "[246/00653] train_loss: 0.011966\n",
      "[246/00703] train_loss: 0.012388\n",
      "[246/00753] train_loss: 0.011616\n",
      "[246/00803] train_loss: 0.012762\n",
      "[246/00853] train_loss: 0.011796\n",
      "[246/00903] train_loss: 0.012212\n",
      "[246/00953] train_loss: 0.012690\n",
      "[246/01003] train_loss: 0.012635\n",
      "[246/01053] train_loss: 0.011753\n",
      "[246/01103] train_loss: 0.011392\n",
      "[246/01153] train_loss: 0.011954\n",
      "[246/01203] train_loss: 0.012314\n",
      "[247/00027] train_loss: 0.012052\n",
      "[247/00077] train_loss: 0.012448\n",
      "[247/00127] train_loss: 0.013487\n",
      "[247/00177] train_loss: 0.013042\n",
      "[247/00227] train_loss: 0.011761\n",
      "[247/00277] train_loss: 0.012589\n",
      "[247/00327] train_loss: 0.011994\n",
      "[247/00377] train_loss: 0.012294\n",
      "[247/00427] train_loss: 0.012283\n",
      "[247/00477] train_loss: 0.012431\n",
      "[247/00527] train_loss: 0.012100\n",
      "[247/00577] train_loss: 0.012831\n",
      "[247/00627] train_loss: 0.012629\n",
      "[247/00677] train_loss: 0.012916\n",
      "[247/00727] train_loss: 0.011725\n",
      "[247/00777] train_loss: 0.012428\n",
      "[247/00827] train_loss: 0.012109\n",
      "[247/00877] train_loss: 0.012856\n",
      "[247/00927] train_loss: 0.012496\n",
      "[247/00977] train_loss: 0.012717\n",
      "[247/01027] train_loss: 0.012529\n",
      "[247/01077] train_loss: 0.011996\n",
      "[247/01127] train_loss: 0.012470\n",
      "[247/01177] train_loss: 0.011451\n",
      "[248/00001] train_loss: 0.012748\n",
      "[248/00051] train_loss: 0.013605\n",
      "[248/00101] train_loss: 0.012746\n",
      "[248/00151] train_loss: 0.012235\n",
      "[248/00201] train_loss: 0.012973\n",
      "[248/00251] train_loss: 0.012197\n",
      "[248/00301] train_loss: 0.012415\n",
      "[248/00351] train_loss: 0.012488\n",
      "[248/00401] train_loss: 0.012154\n",
      "[248/00451] train_loss: 0.011731\n",
      "[248/00501] train_loss: 0.012292\n",
      "[248/00551] train_loss: 0.012669\n",
      "[248/00601] train_loss: 0.012797\n",
      "[248/00651] train_loss: 0.012262\n",
      "[248/00701] train_loss: 0.011971\n",
      "[248/00751] train_loss: 0.011892\n",
      "[248/00801] train_loss: 0.012974\n",
      "[248/00851] train_loss: 0.012788\n",
      "[248/00901] train_loss: 0.012965\n",
      "[248/00951] train_loss: 0.011593\n",
      "[248/01001] train_loss: 0.012255\n",
      "[248/01051] train_loss: 0.012046\n",
      "[248/01101] train_loss: 0.012085\n",
      "[248/01151] train_loss: 0.013237\n",
      "[248/01201] train_loss: 0.012390\n",
      "[249/00025] train_loss: 0.013672\n",
      "[249/00075] train_loss: 0.013163\n",
      "[249/00125] train_loss: 0.012966\n",
      "[249/00175] train_loss: 0.012090\n",
      "[249/00225] train_loss: 0.012653\n",
      "[249/00275] train_loss: 0.012511\n",
      "[249/00325] train_loss: 0.012055\n",
      "[249/00375] train_loss: 0.012651\n",
      "[249/00425] train_loss: 0.012482\n",
      "[249/00475] train_loss: 0.012759\n",
      "[249/00525] train_loss: 0.012548\n",
      "[249/00575] train_loss: 0.012222\n",
      "[249/00625] train_loss: 0.011889\n",
      "[249/00675] train_loss: 0.012149\n",
      "[249/00725] train_loss: 0.011831\n",
      "[249/00775] train_loss: 0.012604\n",
      "[249/00825] train_loss: 0.012523\n",
      "[249/00875] train_loss: 0.012482\n",
      "[249/00925] train_loss: 0.011487\n",
      "[249/00975] train_loss: 0.011542\n",
      "[249/01025] train_loss: 0.012120\n",
      "[249/01075] train_loss: 0.012220\n",
      "[249/01125] train_loss: 0.011766\n",
      "[249/01175] train_loss: 0.011304\n",
      "[249/01225] train_loss: 0.012750\n",
      "[250/00049] train_loss: 0.012331\n",
      "[250/00099] train_loss: 0.013265\n",
      "[250/00149] train_loss: 0.013108\n",
      "[250/00199] train_loss: 0.013172\n",
      "[250/00249] train_loss: 0.013036\n",
      "[250/00299] train_loss: 0.011947\n",
      "[250/00349] train_loss: 0.012524\n",
      "[250/00399] train_loss: 0.011954\n",
      "[250/00449] train_loss: 0.012318\n",
      "[250/00499] train_loss: 0.012324\n",
      "[250/00549] train_loss: 0.012627\n",
      "[250/00599] train_loss: 0.011991\n",
      "[250/00649] train_loss: 0.012398\n",
      "[250/00699] train_loss: 0.012004\n",
      "[250/00749] train_loss: 0.013115\n",
      "[250/00799] train_loss: 0.012045\n",
      "[250/00849] train_loss: 0.012802\n",
      "[250/00899] train_loss: 0.012420\n",
      "[250/00949] train_loss: 0.012493\n",
      "[250/00999] train_loss: 0.012681\n",
      "[250/01049] train_loss: 0.011951\n",
      "[250/01099] train_loss: 0.012443\n",
      "[250/01149] train_loss: 0.011421\n",
      "[250/01199] train_loss: 0.012272\n",
      "[251/00023] train_loss: 0.012469\n",
      "[251/00073] train_loss: 0.012425\n",
      "[251/00123] train_loss: 0.012815\n",
      "[251/00173] train_loss: 0.013057\n",
      "[251/00223] train_loss: 0.012195\n",
      "[251/00273] train_loss: 0.012806\n",
      "[251/00323] train_loss: 0.012217\n",
      "[251/00373] train_loss: 0.012015\n",
      "[251/00423] train_loss: 0.012125\n",
      "[251/00473] train_loss: 0.012157\n",
      "[251/00523] train_loss: 0.012482\n",
      "[251/00573] train_loss: 0.012720\n",
      "[251/00623] train_loss: 0.012553\n",
      "[251/00673] train_loss: 0.012287\n",
      "[251/00723] train_loss: 0.012358\n",
      "[251/00773] train_loss: 0.011823\n",
      "[251/00823] train_loss: 0.012011\n",
      "[251/00873] train_loss: 0.012074\n",
      "[251/00923] train_loss: 0.012599\n",
      "[251/00973] train_loss: 0.011721\n",
      "[251/01023] train_loss: 0.011569\n",
      "[251/01073] train_loss: 0.011892\n",
      "[251/01123] train_loss: 0.011396\n",
      "[251/01173] train_loss: 0.012322\n",
      "[251/01223] train_loss: 0.012481\n",
      "[252/00047] train_loss: 0.012906\n",
      "[252/00097] train_loss: 0.012643\n",
      "[252/00147] train_loss: 0.013073\n",
      "[252/00197] train_loss: 0.012422\n",
      "[252/00247] train_loss: 0.012793\n",
      "[252/00297] train_loss: 0.012063\n",
      "[252/00347] train_loss: 0.012359\n",
      "[252/00397] train_loss: 0.012153\n",
      "[252/00447] train_loss: 0.012559\n",
      "[252/00497] train_loss: 0.011964\n",
      "[252/00547] train_loss: 0.012992\n",
      "[252/00597] train_loss: 0.013440\n",
      "[252/00647] train_loss: 0.011631\n",
      "[252/00697] train_loss: 0.012305\n",
      "[252/00747] train_loss: 0.011629\n",
      "[252/00797] train_loss: 0.012190\n",
      "[252/00847] train_loss: 0.012521\n",
      "[252/00897] train_loss: 0.011529\n",
      "[252/00947] train_loss: 0.012518\n",
      "[252/00997] train_loss: 0.012130\n",
      "[252/01047] train_loss: 0.012780\n",
      "[252/01097] train_loss: 0.012441\n",
      "[252/01147] train_loss: 0.012537\n",
      "[252/01197] train_loss: 0.012408\n",
      "[253/00021] train_loss: 0.012587\n",
      "[253/00071] train_loss: 0.013050\n",
      "[253/00121] train_loss: 0.013239\n",
      "[253/00171] train_loss: 0.012671\n",
      "[253/00221] train_loss: 0.012846\n",
      "[253/00271] train_loss: 0.012550\n",
      "[253/00321] train_loss: 0.012295\n",
      "[253/00371] train_loss: 0.012654\n",
      "[253/00421] train_loss: 0.011986\n",
      "[253/00471] train_loss: 0.012200\n",
      "[253/00521] train_loss: 0.012024\n",
      "[253/00571] train_loss: 0.012944\n",
      "[253/00621] train_loss: 0.012282\n",
      "[253/00671] train_loss: 0.011384\n",
      "[253/00721] train_loss: 0.011736\n",
      "[253/00771] train_loss: 0.011926\n",
      "[253/00821] train_loss: 0.012024\n",
      "[253/00871] train_loss: 0.012086\n",
      "[253/00921] train_loss: 0.011751\n",
      "[253/00971] train_loss: 0.011519\n",
      "[253/01021] train_loss: 0.011909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[253/01071] train_loss: 0.012398\n",
      "[253/01121] train_loss: 0.012211\n",
      "[253/01171] train_loss: 0.012268\n",
      "[253/01221] train_loss: 0.012175\n",
      "[254/00045] train_loss: 0.013080\n",
      "[254/00095] train_loss: 0.013322\n",
      "[254/00145] train_loss: 0.012533\n",
      "[254/00195] train_loss: 0.012952\n",
      "[254/00245] train_loss: 0.012679\n",
      "[254/00295] train_loss: 0.012518\n",
      "[254/00345] train_loss: 0.012986\n",
      "[254/00395] train_loss: 0.012533\n",
      "[254/00445] train_loss: 0.012917\n",
      "[254/00495] train_loss: 0.012324\n",
      "[254/00545] train_loss: 0.012224\n",
      "[254/00595] train_loss: 0.012051\n",
      "[254/00645] train_loss: 0.012270\n",
      "[254/00695] train_loss: 0.012100\n",
      "[254/00745] train_loss: 0.012416\n",
      "[254/00795] train_loss: 0.012260\n",
      "[254/00845] train_loss: 0.011810\n",
      "[254/00895] train_loss: 0.012934\n",
      "[254/00945] train_loss: 0.012218\n",
      "[254/00995] train_loss: 0.012590\n",
      "[254/01045] train_loss: 0.012704\n",
      "[254/01095] train_loss: 0.012158\n",
      "[254/01145] train_loss: 0.011865\n",
      "[254/01195] train_loss: 0.012632\n",
      "[255/00019] train_loss: 0.012510\n",
      "[255/00069] train_loss: 0.012917\n",
      "[255/00119] train_loss: 0.013062\n",
      "[255/00169] train_loss: 0.012779\n",
      "[255/00219] train_loss: 0.012167\n",
      "[255/00269] train_loss: 0.012091\n",
      "[255/00319] train_loss: 0.012172\n",
      "[255/00369] train_loss: 0.012761\n",
      "[255/00419] train_loss: 0.012255\n",
      "[255/00469] train_loss: 0.011838\n",
      "[255/00519] train_loss: 0.012663\n",
      "[255/00569] train_loss: 0.012136\n",
      "[255/00619] train_loss: 0.012486\n",
      "[255/00669] train_loss: 0.012920\n",
      "[255/00719] train_loss: 0.011531\n",
      "[255/00769] train_loss: 0.012705\n",
      "[255/00819] train_loss: 0.012231\n",
      "[255/00869] train_loss: 0.011532\n",
      "[255/00919] train_loss: 0.011660\n",
      "[255/00969] train_loss: 0.012527\n",
      "[255/01019] train_loss: 0.012327\n",
      "[255/01069] train_loss: 0.012448\n",
      "[255/01119] train_loss: 0.012113\n",
      "[255/01169] train_loss: 0.011821\n",
      "[255/01219] train_loss: 0.011610\n",
      "[256/00043] train_loss: 0.012900\n",
      "[256/00093] train_loss: 0.012650\n",
      "[256/00143] train_loss: 0.012937\n",
      "[256/00193] train_loss: 0.013222\n",
      "[256/00243] train_loss: 0.012463\n",
      "[256/00293] train_loss: 0.012393\n",
      "[256/00343] train_loss: 0.012228\n",
      "[256/00393] train_loss: 0.012469\n",
      "[256/00443] train_loss: 0.012689\n",
      "[256/00493] train_loss: 0.012583\n",
      "[256/00543] train_loss: 0.012410\n",
      "[256/00593] train_loss: 0.011836\n",
      "[256/00643] train_loss: 0.012029\n",
      "[256/00693] train_loss: 0.012265\n",
      "[256/00743] train_loss: 0.012287\n",
      "[256/00793] train_loss: 0.012263\n",
      "[256/00843] train_loss: 0.012196\n",
      "[256/00893] train_loss: 0.012219\n",
      "[256/00943] train_loss: 0.012211\n",
      "[256/00993] train_loss: 0.011571\n",
      "[256/01043] train_loss: 0.012175\n",
      "[256/01093] train_loss: 0.012525\n",
      "[256/01143] train_loss: 0.012868\n",
      "[256/01193] train_loss: 0.012307\n",
      "[257/00017] train_loss: 0.012418\n",
      "[257/00067] train_loss: 0.013093\n",
      "[257/00117] train_loss: 0.013015\n",
      "[257/00167] train_loss: 0.012572\n",
      "[257/00217] train_loss: 0.012476\n",
      "[257/00267] train_loss: 0.012184\n",
      "[257/00317] train_loss: 0.011739\n",
      "[257/00367] train_loss: 0.012976\n",
      "[257/00417] train_loss: 0.012522\n",
      "[257/00467] train_loss: 0.012551\n",
      "[257/00517] train_loss: 0.011571\n",
      "[257/00567] train_loss: 0.012225\n",
      "[257/00617] train_loss: 0.012764\n",
      "[257/00667] train_loss: 0.011864\n",
      "[257/00717] train_loss: 0.011823\n",
      "[257/00767] train_loss: 0.011779\n",
      "[257/00817] train_loss: 0.012101\n",
      "[257/00867] train_loss: 0.012419\n",
      "[257/00917] train_loss: 0.012410\n",
      "[257/00967] train_loss: 0.012310\n",
      "[257/01017] train_loss: 0.012355\n",
      "[257/01067] train_loss: 0.012466\n",
      "[257/01117] train_loss: 0.012834\n",
      "[257/01167] train_loss: 0.012049\n",
      "[257/01217] train_loss: 0.011653\n",
      "[258/00041] train_loss: 0.012725\n",
      "[258/00091] train_loss: 0.012832\n",
      "[258/00141] train_loss: 0.012543\n",
      "[258/00191] train_loss: 0.012410\n",
      "[258/00241] train_loss: 0.012244\n",
      "[258/00291] train_loss: 0.012236\n",
      "[258/00341] train_loss: 0.011951\n",
      "[258/00391] train_loss: 0.012893\n",
      "[258/00441] train_loss: 0.012295\n",
      "[258/00491] train_loss: 0.013031\n",
      "[258/00541] train_loss: 0.012562\n",
      "[258/00591] train_loss: 0.012246\n",
      "[258/00641] train_loss: 0.012245\n",
      "[258/00691] train_loss: 0.012280\n",
      "[258/00741] train_loss: 0.011656\n",
      "[258/00791] train_loss: 0.012021\n",
      "[258/00841] train_loss: 0.012294\n",
      "[258/00891] train_loss: 0.012176\n",
      "[258/00941] train_loss: 0.012677\n",
      "[258/00991] train_loss: 0.012082\n",
      "[258/01041] train_loss: 0.012883\n",
      "[258/01091] train_loss: 0.011627\n",
      "[258/01141] train_loss: 0.012494\n",
      "[258/01191] train_loss: 0.012046\n",
      "[259/00015] train_loss: 0.012844\n",
      "[259/00065] train_loss: 0.013696\n",
      "[259/00115] train_loss: 0.012502\n",
      "[259/00165] train_loss: 0.012021\n",
      "[259/00215] train_loss: 0.011932\n",
      "[259/00265] train_loss: 0.012805\n",
      "[259/00315] train_loss: 0.011753\n",
      "[259/00365] train_loss: 0.012084\n",
      "[259/00415] train_loss: 0.011800\n",
      "[259/00465] train_loss: 0.012045\n",
      "[259/00515] train_loss: 0.012622\n",
      "[259/00565] train_loss: 0.012253\n",
      "[259/00615] train_loss: 0.012481\n",
      "[259/00665] train_loss: 0.012534\n",
      "[259/00715] train_loss: 0.012009\n",
      "[259/00765] train_loss: 0.011743\n",
      "[259/00815] train_loss: 0.012455\n",
      "[259/00865] train_loss: 0.012555\n",
      "[259/00915] train_loss: 0.012862\n",
      "[259/00965] train_loss: 0.011523\n",
      "[259/01015] train_loss: 0.011512\n",
      "[259/01065] train_loss: 0.011591\n",
      "[259/01115] train_loss: 0.011467\n",
      "[259/01165] train_loss: 0.011763\n",
      "[259/01215] train_loss: 0.012300\n",
      "[260/00039] train_loss: 0.012459\n",
      "[260/00089] train_loss: 0.013070\n",
      "[260/00139] train_loss: 0.012597\n",
      "[260/00189] train_loss: 0.012711\n",
      "[260/00239] train_loss: 0.012603\n",
      "[260/00289] train_loss: 0.011792\n",
      "[260/00339] train_loss: 0.012333\n",
      "[260/00389] train_loss: 0.012878\n",
      "[260/00439] train_loss: 0.012013\n",
      "[260/00489] train_loss: 0.013233\n",
      "[260/00539] train_loss: 0.012804\n",
      "[260/00589] train_loss: 0.012073\n",
      "[260/00639] train_loss: 0.012516\n",
      "[260/00689] train_loss: 0.012502\n",
      "[260/00739] train_loss: 0.012648\n",
      "[260/00789] train_loss: 0.012380\n",
      "[260/00839] train_loss: 0.012187\n",
      "[260/00889] train_loss: 0.012903\n",
      "[260/00939] train_loss: 0.011820\n",
      "[260/00989] train_loss: 0.012898\n",
      "[260/01039] train_loss: 0.011901\n",
      "[260/01089] train_loss: 0.011854\n",
      "[260/01139] train_loss: 0.012219\n",
      "[260/01189] train_loss: 0.012117\n",
      "[261/00013] train_loss: 0.012606\n",
      "[261/00063] train_loss: 0.012432\n",
      "[261/00113] train_loss: 0.012549\n",
      "[261/00163] train_loss: 0.012521\n",
      "[261/00213] train_loss: 0.012677\n",
      "[261/00263] train_loss: 0.011595\n",
      "[261/00313] train_loss: 0.012697\n",
      "[261/00363] train_loss: 0.012580\n",
      "[261/00413] train_loss: 0.012323\n",
      "[261/00463] train_loss: 0.012021\n",
      "[261/00513] train_loss: 0.012337\n",
      "[261/00563] train_loss: 0.012232\n",
      "[261/00613] train_loss: 0.012165\n",
      "[261/00663] train_loss: 0.011871\n",
      "[261/00713] train_loss: 0.012298\n",
      "[261/00763] train_loss: 0.011627\n",
      "[261/00813] train_loss: 0.012336\n",
      "[261/00863] train_loss: 0.011849\n",
      "[261/00913] train_loss: 0.012138\n",
      "[261/00963] train_loss: 0.012338\n",
      "[261/01013] train_loss: 0.012257\n",
      "[261/01063] train_loss: 0.011713\n",
      "[261/01113] train_loss: 0.011968\n",
      "[261/01163] train_loss: 0.011606\n",
      "[261/01213] train_loss: 0.011910\n",
      "[262/00037] train_loss: 0.012769\n",
      "[262/00087] train_loss: 0.013554\n",
      "[262/00137] train_loss: 0.013653\n",
      "[262/00187] train_loss: 0.012637\n",
      "[262/00237] train_loss: 0.012461\n",
      "[262/00287] train_loss: 0.012092\n",
      "[262/00337] train_loss: 0.012088\n",
      "[262/00387] train_loss: 0.012054\n",
      "[262/00437] train_loss: 0.012569\n",
      "[262/00487] train_loss: 0.012055\n",
      "[262/00537] train_loss: 0.012348\n",
      "[262/00587] train_loss: 0.012153\n",
      "[262/00637] train_loss: 0.012488\n",
      "[262/00687] train_loss: 0.012154\n",
      "[262/00737] train_loss: 0.011553\n",
      "[262/00787] train_loss: 0.012391\n",
      "[262/00837] train_loss: 0.012087\n",
      "[262/00887] train_loss: 0.013210\n",
      "[262/00937] train_loss: 0.011836\n",
      "[262/00987] train_loss: 0.011377\n",
      "[262/01037] train_loss: 0.012274\n",
      "[262/01087] train_loss: 0.012171\n",
      "[262/01137] train_loss: 0.011680\n",
      "[262/01187] train_loss: 0.012271\n",
      "[263/00011] train_loss: 0.011973\n",
      "[263/00061] train_loss: 0.012803\n",
      "[263/00111] train_loss: 0.012213\n",
      "[263/00161] train_loss: 0.012342\n",
      "[263/00211] train_loss: 0.012429\n",
      "[263/00261] train_loss: 0.012351\n",
      "[263/00311] train_loss: 0.012517\n",
      "[263/00361] train_loss: 0.012329\n",
      "[263/00411] train_loss: 0.012337\n",
      "[263/00461] train_loss: 0.012327\n",
      "[263/00511] train_loss: 0.012821\n",
      "[263/00561] train_loss: 0.012658\n",
      "[263/00611] train_loss: 0.012531\n",
      "[263/00661] train_loss: 0.011877\n",
      "[263/00711] train_loss: 0.012307\n",
      "[263/00761] train_loss: 0.011437\n",
      "[263/00811] train_loss: 0.012045\n",
      "[263/00861] train_loss: 0.012136\n",
      "[263/00911] train_loss: 0.012195\n",
      "[263/00961] train_loss: 0.011979\n",
      "[263/01011] train_loss: 0.011897\n",
      "[263/01061] train_loss: 0.011945\n",
      "[263/01111] train_loss: 0.012879\n",
      "[263/01161] train_loss: 0.011239\n",
      "[263/01211] train_loss: 0.011947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[264/00035] train_loss: 0.013238\n",
      "[264/00085] train_loss: 0.012654\n",
      "[264/00135] train_loss: 0.012794\n",
      "[264/00185] train_loss: 0.012827\n",
      "[264/00235] train_loss: 0.012625\n",
      "[264/00285] train_loss: 0.012278\n",
      "[264/00335] train_loss: 0.012269\n",
      "[264/00385] train_loss: 0.012510\n",
      "[264/00435] train_loss: 0.012179\n",
      "[264/00485] train_loss: 0.012358\n",
      "[264/00535] train_loss: 0.012246\n",
      "[264/00585] train_loss: 0.012544\n",
      "[264/00635] train_loss: 0.012315\n",
      "[264/00685] train_loss: 0.012349\n",
      "[264/00735] train_loss: 0.012830\n",
      "[264/00785] train_loss: 0.011863\n",
      "[264/00835] train_loss: 0.012702\n",
      "[264/00885] train_loss: 0.012584\n",
      "[264/00935] train_loss: 0.011726\n",
      "[264/00985] train_loss: 0.012683\n",
      "[264/01035] train_loss: 0.011939\n",
      "[264/01085] train_loss: 0.012018\n",
      "[264/01135] train_loss: 0.012260\n",
      "[264/01185] train_loss: 0.012150\n",
      "[265/00009] train_loss: 0.012249\n",
      "[265/00059] train_loss: 0.013109\n",
      "[265/00109] train_loss: 0.012698\n",
      "[265/00159] train_loss: 0.012413\n",
      "[265/00209] train_loss: 0.012655\n",
      "[265/00259] train_loss: 0.012250\n",
      "[265/00309] train_loss: 0.012364\n",
      "[265/00359] train_loss: 0.012542\n",
      "[265/00409] train_loss: 0.012400\n",
      "[265/00459] train_loss: 0.012536\n",
      "[265/00509] train_loss: 0.011688\n",
      "[265/00559] train_loss: 0.012355\n",
      "[265/00609] train_loss: 0.012023\n",
      "[265/00659] train_loss: 0.012046\n",
      "[265/00709] train_loss: 0.012087\n",
      "[265/00759] train_loss: 0.012625\n",
      "[265/00809] train_loss: 0.011952\n",
      "[265/00859] train_loss: 0.011954\n",
      "[265/00909] train_loss: 0.011779\n",
      "[265/00959] train_loss: 0.011950\n",
      "[265/01009] train_loss: 0.012944\n",
      "[265/01059] train_loss: 0.011787\n",
      "[265/01109] train_loss: 0.011869\n",
      "[265/01159] train_loss: 0.012330\n",
      "[265/01209] train_loss: 0.011764\n",
      "[266/00033] train_loss: 0.013410\n",
      "[266/00083] train_loss: 0.012521\n",
      "[266/00133] train_loss: 0.012599\n",
      "[266/00183] train_loss: 0.012785\n",
      "[266/00233] train_loss: 0.012419\n",
      "[266/00283] train_loss: 0.012898\n",
      "[266/00333] train_loss: 0.012574\n",
      "[266/00383] train_loss: 0.012456\n",
      "[266/00433] train_loss: 0.012459\n",
      "[266/00483] train_loss: 0.011908\n",
      "[266/00533] train_loss: 0.012329\n",
      "[266/00583] train_loss: 0.011632\n",
      "[266/00633] train_loss: 0.012276\n",
      "[266/00683] train_loss: 0.012073\n",
      "[266/00733] train_loss: 0.012362\n",
      "[266/00783] train_loss: 0.012207\n",
      "[266/00833] train_loss: 0.011031\n",
      "[266/00883] train_loss: 0.012481\n",
      "[266/00933] train_loss: 0.012887\n",
      "[266/00983] train_loss: 0.012126\n",
      "[266/01033] train_loss: 0.011951\n",
      "[266/01083] train_loss: 0.012173\n",
      "[266/01133] train_loss: 0.011945\n",
      "[266/01183] train_loss: 0.012661\n",
      "[267/00007] train_loss: 0.011726\n",
      "[267/00057] train_loss: 0.013282\n",
      "[267/00107] train_loss: 0.012401\n",
      "[267/00157] train_loss: 0.012727\n",
      "[267/00207] train_loss: 0.012734\n",
      "[267/00257] train_loss: 0.012569\n",
      "[267/00307] train_loss: 0.012491\n",
      "[267/00357] train_loss: 0.012896\n",
      "[267/00407] train_loss: 0.011946\n",
      "[267/00457] train_loss: 0.012573\n",
      "[267/00507] train_loss: 0.011469\n",
      "[267/00557] train_loss: 0.012772\n",
      "[267/00607] train_loss: 0.011576\n",
      "[267/00657] train_loss: 0.011591\n",
      "[267/00707] train_loss: 0.012079\n",
      "[267/00757] train_loss: 0.013049\n",
      "[267/00807] train_loss: 0.012632\n",
      "[267/00857] train_loss: 0.012030\n",
      "[267/00907] train_loss: 0.011884\n",
      "[267/00957] train_loss: 0.011621\n",
      "[267/01007] train_loss: 0.011622\n",
      "[267/01057] train_loss: 0.012346\n",
      "[267/01107] train_loss: 0.012218\n",
      "[267/01157] train_loss: 0.012155\n",
      "[267/01207] train_loss: 0.012078\n",
      "[268/00031] train_loss: 0.012033\n",
      "[268/00081] train_loss: 0.012639\n",
      "[268/00131] train_loss: 0.013093\n",
      "[268/00181] train_loss: 0.012546\n",
      "[268/00231] train_loss: 0.012480\n",
      "[268/00281] train_loss: 0.012465\n",
      "[268/00331] train_loss: 0.011991\n",
      "[268/00381] train_loss: 0.012450\n",
      "[268/00431] train_loss: 0.012487\n",
      "[268/00481] train_loss: 0.013270\n",
      "[268/00531] train_loss: 0.012431\n",
      "[268/00581] train_loss: 0.012226\n",
      "[268/00631] train_loss: 0.011635\n",
      "[268/00681] train_loss: 0.012208\n",
      "[268/00731] train_loss: 0.011875\n",
      "[268/00781] train_loss: 0.011808\n",
      "[268/00831] train_loss: 0.013072\n",
      "[268/00881] train_loss: 0.011904\n",
      "[268/00931] train_loss: 0.012016\n",
      "[268/00981] train_loss: 0.011682\n",
      "[268/01031] train_loss: 0.011569\n",
      "[268/01081] train_loss: 0.012328\n",
      "[268/01131] train_loss: 0.012698\n",
      "[268/01181] train_loss: 0.012187\n",
      "[269/00005] train_loss: 0.011502\n",
      "[269/00055] train_loss: 0.013060\n",
      "[269/00105] train_loss: 0.012525\n",
      "[269/00155] train_loss: 0.012743\n",
      "[269/00205] train_loss: 0.012795\n",
      "[269/00255] train_loss: 0.013136\n",
      "[269/00305] train_loss: 0.012312\n",
      "[269/00355] train_loss: 0.012400\n",
      "[269/00405] train_loss: 0.012467\n",
      "[269/00455] train_loss: 0.012500\n",
      "[269/00505] train_loss: 0.011481\n",
      "[269/00555] train_loss: 0.012038\n",
      "[269/00605] train_loss: 0.011889\n",
      "[269/00655] train_loss: 0.012164\n",
      "[269/00705] train_loss: 0.011798\n",
      "[269/00755] train_loss: 0.011314\n",
      "[269/00805] train_loss: 0.011363\n",
      "[269/00855] train_loss: 0.012259\n",
      "[269/00905] train_loss: 0.012086\n",
      "[269/00955] train_loss: 0.011883\n",
      "[269/01005] train_loss: 0.011688\n",
      "[269/01055] train_loss: 0.012361\n",
      "[269/01105] train_loss: 0.012832\n",
      "[269/01155] train_loss: 0.012201\n",
      "[269/01205] train_loss: 0.012312\n",
      "[270/00029] train_loss: 0.012786\n",
      "[270/00079] train_loss: 0.012091\n",
      "[270/00129] train_loss: 0.012716\n",
      "[270/00179] train_loss: 0.012547\n",
      "[270/00229] train_loss: 0.012134\n",
      "[270/00279] train_loss: 0.012247\n",
      "[270/00329] train_loss: 0.012864\n",
      "[270/00379] train_loss: 0.012816\n",
      "[270/00429] train_loss: 0.012562\n",
      "[270/00479] train_loss: 0.012778\n",
      "[270/00529] train_loss: 0.011887\n",
      "[270/00579] train_loss: 0.012767\n",
      "[270/00629] train_loss: 0.011958\n",
      "[270/00679] train_loss: 0.012744\n",
      "[270/00729] train_loss: 0.012000\n",
      "[270/00779] train_loss: 0.011844\n",
      "[270/00829] train_loss: 0.012393\n",
      "[270/00879] train_loss: 0.011655\n",
      "[270/00929] train_loss: 0.012262\n",
      "[270/00979] train_loss: 0.011656\n",
      "[270/01029] train_loss: 0.011705\n",
      "[270/01079] train_loss: 0.012661\n",
      "[270/01129] train_loss: 0.012066\n",
      "[270/01179] train_loss: 0.012202\n",
      "[271/00003] train_loss: 0.012115\n",
      "[271/00053] train_loss: 0.013377\n",
      "[271/00103] train_loss: 0.012595\n",
      "[271/00153] train_loss: 0.012429\n",
      "[271/00203] train_loss: 0.012724\n",
      "[271/00253] train_loss: 0.011883\n",
      "[271/00303] train_loss: 0.012879\n",
      "[271/00353] train_loss: 0.012241\n",
      "[271/00403] train_loss: 0.012051\n",
      "[271/00453] train_loss: 0.012020\n",
      "[271/00503] train_loss: 0.012764\n",
      "[271/00553] train_loss: 0.012446\n",
      "[271/00603] train_loss: 0.012846\n",
      "[271/00653] train_loss: 0.012273\n",
      "[271/00703] train_loss: 0.012252\n",
      "[271/00753] train_loss: 0.011624\n",
      "[271/00803] train_loss: 0.012229\n",
      "[271/00853] train_loss: 0.011391\n",
      "[271/00903] train_loss: 0.012077\n",
      "[271/00953] train_loss: 0.011985\n",
      "[271/01003] train_loss: 0.012428\n",
      "[271/01053] train_loss: 0.011600\n",
      "[271/01103] train_loss: 0.011957\n",
      "[271/01153] train_loss: 0.011596\n",
      "[271/01203] train_loss: 0.012119\n",
      "[272/00027] train_loss: 0.012432\n",
      "[272/00077] train_loss: 0.012670\n",
      "[272/00127] train_loss: 0.013042\n",
      "[272/00177] train_loss: 0.012462\n",
      "[272/00227] train_loss: 0.011973\n",
      "[272/00277] train_loss: 0.012444\n",
      "[272/00327] train_loss: 0.013027\n",
      "[272/00377] train_loss: 0.012358\n",
      "[272/00427] train_loss: 0.011924\n",
      "[272/00477] train_loss: 0.012076\n",
      "[272/00527] train_loss: 0.012414\n",
      "[272/00577] train_loss: 0.012060\n",
      "[272/00627] train_loss: 0.011966\n",
      "[272/00677] train_loss: 0.012256\n",
      "[272/00727] train_loss: 0.012052\n",
      "[272/00777] train_loss: 0.011957\n",
      "[272/00827] train_loss: 0.011967\n",
      "[272/00877] train_loss: 0.012220\n",
      "[272/00927] train_loss: 0.012351\n",
      "[272/00977] train_loss: 0.013194\n",
      "[272/01027] train_loss: 0.012512\n",
      "[272/01077] train_loss: 0.011951\n",
      "[272/01127] train_loss: 0.012790\n",
      "[272/01177] train_loss: 0.012387\n",
      "[273/00001] train_loss: 0.012090\n",
      "[273/00051] train_loss: 0.012736\n",
      "[273/00101] train_loss: 0.012955\n",
      "[273/00151] train_loss: 0.012738\n",
      "[273/00201] train_loss: 0.012967\n",
      "[273/00251] train_loss: 0.012394\n",
      "[273/00301] train_loss: 0.012669\n",
      "[273/00351] train_loss: 0.012050\n",
      "[273/00401] train_loss: 0.011960\n",
      "[273/00451] train_loss: 0.011638\n",
      "[273/00501] train_loss: 0.011732\n",
      "[273/00551] train_loss: 0.012652\n",
      "[273/00601] train_loss: 0.011745\n",
      "[273/00651] train_loss: 0.012554\n",
      "[273/00701] train_loss: 0.012302\n",
      "[273/00751] train_loss: 0.012051\n",
      "[273/00801] train_loss: 0.011679\n",
      "[273/00851] train_loss: 0.012073\n",
      "[273/00901] train_loss: 0.012078\n",
      "[273/00951] train_loss: 0.012038\n",
      "[273/01001] train_loss: 0.011942\n",
      "[273/01051] train_loss: 0.012026\n",
      "[273/01101] train_loss: 0.011672\n",
      "[273/01151] train_loss: 0.012136\n",
      "[273/01201] train_loss: 0.012258\n",
      "[274/00025] train_loss: 0.012924\n",
      "[274/00075] train_loss: 0.012790\n",
      "[274/00125] train_loss: 0.012646\n",
      "[274/00175] train_loss: 0.012274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[274/00225] train_loss: 0.012315\n",
      "[274/00275] train_loss: 0.012173\n",
      "[274/00325] train_loss: 0.012569\n",
      "[274/00375] train_loss: 0.012889\n",
      "[274/00425] train_loss: 0.012475\n",
      "[274/00475] train_loss: 0.012050\n",
      "[274/00525] train_loss: 0.012141\n",
      "[274/00575] train_loss: 0.012219\n",
      "[274/00625] train_loss: 0.012039\n",
      "[274/00675] train_loss: 0.012549\n",
      "[274/00725] train_loss: 0.011711\n",
      "[274/00775] train_loss: 0.011581\n",
      "[274/00825] train_loss: 0.012135\n",
      "[274/00875] train_loss: 0.011658\n",
      "[274/00925] train_loss: 0.012065\n",
      "[274/00975] train_loss: 0.012545\n",
      "[274/01025] train_loss: 0.011379\n",
      "[274/01075] train_loss: 0.012107\n",
      "[274/01125] train_loss: 0.011837\n",
      "[274/01175] train_loss: 0.012245\n",
      "[274/01225] train_loss: 0.012333\n",
      "[275/00049] train_loss: 0.012029\n",
      "[275/00099] train_loss: 0.012684\n",
      "[275/00149] train_loss: 0.013087\n",
      "[275/00199] train_loss: 0.011819\n",
      "[275/00249] train_loss: 0.012894\n",
      "[275/00299] train_loss: 0.011860\n",
      "[275/00349] train_loss: 0.011972\n",
      "[275/00399] train_loss: 0.012494\n",
      "[275/00449] train_loss: 0.011728\n",
      "[275/00499] train_loss: 0.012279\n",
      "[275/00549] train_loss: 0.012942\n",
      "[275/00599] train_loss: 0.011969\n",
      "[275/00649] train_loss: 0.011833\n",
      "[275/00699] train_loss: 0.011721\n",
      "[275/00749] train_loss: 0.012294\n",
      "[275/00799] train_loss: 0.012079\n",
      "[275/00849] train_loss: 0.012522\n",
      "[275/00899] train_loss: 0.011905\n",
      "[275/00949] train_loss: 0.012076\n",
      "[275/00999] train_loss: 0.011591\n",
      "[275/01049] train_loss: 0.012384\n",
      "[275/01099] train_loss: 0.013047\n",
      "[275/01149] train_loss: 0.011845\n",
      "[275/01199] train_loss: 0.011683\n",
      "[276/00023] train_loss: 0.012113\n",
      "[276/00073] train_loss: 0.012722\n",
      "[276/00123] train_loss: 0.012294\n",
      "[276/00173] train_loss: 0.012689\n",
      "[276/00223] train_loss: 0.012182\n",
      "[276/00273] train_loss: 0.012495\n",
      "[276/00323] train_loss: 0.012426\n",
      "[276/00373] train_loss: 0.012141\n",
      "[276/00423] train_loss: 0.012004\n",
      "[276/00473] train_loss: 0.012793\n",
      "[276/00523] train_loss: 0.011572\n",
      "[276/00573] train_loss: 0.012248\n",
      "[276/00623] train_loss: 0.011755\n",
      "[276/00673] train_loss: 0.012010\n",
      "[276/00723] train_loss: 0.011882\n",
      "[276/00773] train_loss: 0.012229\n",
      "[276/00823] train_loss: 0.012180\n",
      "[276/00873] train_loss: 0.012381\n",
      "[276/00923] train_loss: 0.012075\n",
      "[276/00973] train_loss: 0.011582\n",
      "[276/01023] train_loss: 0.012394\n",
      "[276/01073] train_loss: 0.011838\n",
      "[276/01123] train_loss: 0.011672\n",
      "[276/01173] train_loss: 0.012873\n",
      "[276/01223] train_loss: 0.012170\n",
      "[277/00047] train_loss: 0.013341\n",
      "[277/00097] train_loss: 0.012145\n",
      "[277/00147] train_loss: 0.013174\n",
      "[277/00197] train_loss: 0.012577\n",
      "[277/00247] train_loss: 0.012406\n",
      "[277/00297] train_loss: 0.011785\n",
      "[277/00347] train_loss: 0.012004\n",
      "[277/00397] train_loss: 0.011928\n",
      "[277/00447] train_loss: 0.012265\n",
      "[277/00497] train_loss: 0.012115\n",
      "[277/00547] train_loss: 0.011841\n",
      "[277/00597] train_loss: 0.011756\n",
      "[277/00647] train_loss: 0.011721\n",
      "[277/00697] train_loss: 0.012195\n",
      "[277/00747] train_loss: 0.012082\n",
      "[277/00797] train_loss: 0.011966\n",
      "[277/00847] train_loss: 0.012092\n",
      "[277/00897] train_loss: 0.012102\n",
      "[277/00947] train_loss: 0.012418\n",
      "[277/00997] train_loss: 0.012589\n",
      "[277/01047] train_loss: 0.012111\n",
      "[277/01097] train_loss: 0.012530\n",
      "[277/01147] train_loss: 0.012182\n",
      "[277/01197] train_loss: 0.012351\n",
      "[278/00021] train_loss: 0.012296\n",
      "[278/00071] train_loss: 0.013010\n",
      "[278/00121] train_loss: 0.012648\n",
      "[278/00171] train_loss: 0.012287\n",
      "[278/00221] train_loss: 0.012905\n",
      "[278/00271] train_loss: 0.013018\n",
      "[278/00321] train_loss: 0.012016\n",
      "[278/00371] train_loss: 0.012230\n",
      "[278/00421] train_loss: 0.012256\n",
      "[278/00471] train_loss: 0.011861\n",
      "[278/00521] train_loss: 0.012435\n",
      "[278/00571] train_loss: 0.011929\n",
      "[278/00621] train_loss: 0.011874\n",
      "[278/00671] train_loss: 0.011666\n",
      "[278/00721] train_loss: 0.012452\n",
      "[278/00771] train_loss: 0.011670\n",
      "[278/00821] train_loss: 0.012187\n",
      "[278/00871] train_loss: 0.012398\n",
      "[278/00921] train_loss: 0.012420\n",
      "[278/00971] train_loss: 0.012207\n",
      "[278/01021] train_loss: 0.012561\n",
      "[278/01071] train_loss: 0.012118\n",
      "[278/01121] train_loss: 0.011495\n",
      "[278/01171] train_loss: 0.011724\n",
      "[278/01221] train_loss: 0.012255\n",
      "[279/00045] train_loss: 0.013383\n",
      "[279/00095] train_loss: 0.013148\n",
      "[279/00145] train_loss: 0.012857\n",
      "[279/00195] train_loss: 0.011998\n",
      "[279/00245] train_loss: 0.013576\n",
      "[279/00295] train_loss: 0.012508\n",
      "[279/00345] train_loss: 0.012714\n",
      "[279/00395] train_loss: 0.012038\n",
      "[279/00445] train_loss: 0.012056\n",
      "[279/00495] train_loss: 0.011571\n",
      "[279/00545] train_loss: 0.011859\n",
      "[279/00595] train_loss: 0.012198\n",
      "[279/00645] train_loss: 0.012086\n",
      "[279/00695] train_loss: 0.011926\n",
      "[279/00745] train_loss: 0.011416\n",
      "[279/00795] train_loss: 0.012805\n",
      "[279/00845] train_loss: 0.011624\n",
      "[279/00895] train_loss: 0.011694\n",
      "[279/00945] train_loss: 0.012432\n",
      "[279/00995] train_loss: 0.011252\n",
      "[279/01045] train_loss: 0.011759\n",
      "[279/01095] train_loss: 0.012141\n",
      "[279/01145] train_loss: 0.012015\n",
      "[279/01195] train_loss: 0.011895\n",
      "[280/00019] train_loss: 0.011880\n",
      "[280/00069] train_loss: 0.012821\n",
      "[280/00119] train_loss: 0.012046\n",
      "[280/00169] train_loss: 0.012125\n",
      "[280/00219] train_loss: 0.011957\n",
      "[280/00269] train_loss: 0.012633\n",
      "[280/00319] train_loss: 0.012357\n",
      "[280/00369] train_loss: 0.012891\n",
      "[280/00419] train_loss: 0.012009\n",
      "[280/00469] train_loss: 0.012112\n",
      "[280/00519] train_loss: 0.011826\n",
      "[280/00569] train_loss: 0.012095\n",
      "[280/00619] train_loss: 0.012115\n",
      "[280/00669] train_loss: 0.011871\n",
      "[280/00719] train_loss: 0.013096\n",
      "[280/00769] train_loss: 0.011739\n",
      "[280/00819] train_loss: 0.012099\n",
      "[280/00869] train_loss: 0.012611\n",
      "[280/00919] train_loss: 0.011710\n",
      "[280/00969] train_loss: 0.012514\n",
      "[280/01019] train_loss: 0.012380\n",
      "[280/01069] train_loss: 0.011788\n",
      "[280/01119] train_loss: 0.011818\n",
      "[280/01169] train_loss: 0.012341\n",
      "[280/01219] train_loss: 0.012215\n",
      "[281/00043] train_loss: 0.012258\n",
      "[281/00093] train_loss: 0.012996\n",
      "[281/00143] train_loss: 0.012152\n",
      "[281/00193] train_loss: 0.012812\n",
      "[281/00243] train_loss: 0.012843\n",
      "[281/00293] train_loss: 0.012055\n",
      "[281/00343] train_loss: 0.011680\n",
      "[281/00393] train_loss: 0.012591\n",
      "[281/00443] train_loss: 0.012127\n",
      "[281/00493] train_loss: 0.011866\n",
      "[281/00543] train_loss: 0.011242\n",
      "[281/00593] train_loss: 0.012282\n",
      "[281/00643] train_loss: 0.012047\n",
      "[281/00693] train_loss: 0.012340\n",
      "[281/00743] train_loss: 0.011729\n",
      "[281/00793] train_loss: 0.011809\n",
      "[281/00843] train_loss: 0.012449\n",
      "[281/00893] train_loss: 0.011908\n",
      "[281/00943] train_loss: 0.012197\n",
      "[281/00993] train_loss: 0.012228\n",
      "[281/01043] train_loss: 0.012211\n",
      "[281/01093] train_loss: 0.012347\n",
      "[281/01143] train_loss: 0.011991\n",
      "[281/01193] train_loss: 0.012267\n",
      "[282/00017] train_loss: 0.011632\n",
      "[282/00067] train_loss: 0.012363\n",
      "[282/00117] train_loss: 0.012101\n",
      "[282/00167] train_loss: 0.012324\n",
      "[282/00217] train_loss: 0.012700\n",
      "[282/00267] train_loss: 0.012085\n",
      "[282/00317] train_loss: 0.012469\n",
      "[282/00367] train_loss: 0.012080\n",
      "[282/00417] train_loss: 0.011805\n",
      "[282/00467] train_loss: 0.011439\n",
      "[282/00517] train_loss: 0.012040\n",
      "[282/00567] train_loss: 0.012686\n",
      "[282/00617] train_loss: 0.011789\n",
      "[282/00667] train_loss: 0.011681\n",
      "[282/00717] train_loss: 0.012049\n",
      "[282/00767] train_loss: 0.012318\n",
      "[282/00817] train_loss: 0.012973\n",
      "[282/00867] train_loss: 0.011855\n",
      "[282/00917] train_loss: 0.012324\n",
      "[282/00967] train_loss: 0.011885\n",
      "[282/01017] train_loss: 0.012271\n",
      "[282/01067] train_loss: 0.012546\n",
      "[282/01117] train_loss: 0.012146\n",
      "[282/01167] train_loss: 0.011888\n",
      "[282/01217] train_loss: 0.011125\n",
      "[283/00041] train_loss: 0.012281\n",
      "[283/00091] train_loss: 0.013357\n",
      "[283/00141] train_loss: 0.012356\n",
      "[283/00191] train_loss: 0.011802\n",
      "[283/00241] train_loss: 0.012293\n",
      "[283/00291] train_loss: 0.011909\n",
      "[283/00341] train_loss: 0.012389\n",
      "[283/00391] train_loss: 0.011712\n",
      "[283/00441] train_loss: 0.012252\n",
      "[283/00491] train_loss: 0.012858\n",
      "[283/00541] train_loss: 0.011436\n",
      "[283/00591] train_loss: 0.012341\n",
      "[283/00641] train_loss: 0.012208\n",
      "[283/00691] train_loss: 0.012267\n",
      "[283/00741] train_loss: 0.011830\n",
      "[283/00791] train_loss: 0.011394\n",
      "[283/00841] train_loss: 0.012335\n",
      "[283/00891] train_loss: 0.012006\n",
      "[283/00941] train_loss: 0.012220\n",
      "[283/00991] train_loss: 0.011923\n",
      "[283/01041] train_loss: 0.011089\n",
      "[283/01091] train_loss: 0.011569\n",
      "[283/01141] train_loss: 0.012252\n",
      "[283/01191] train_loss: 0.012528\n",
      "[284/00015] train_loss: 0.012199\n",
      "[284/00065] train_loss: 0.012339\n",
      "[284/00115] train_loss: 0.012730\n",
      "[284/00165] train_loss: 0.012462\n",
      "[284/00215] train_loss: 0.012327\n",
      "[284/00265] train_loss: 0.012165\n",
      "[284/00315] train_loss: 0.012332\n",
      "[284/00365] train_loss: 0.012531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[284/00415] train_loss: 0.012475\n",
      "[284/00465] train_loss: 0.012862\n",
      "[284/00515] train_loss: 0.012927\n",
      "[284/00565] train_loss: 0.011820\n",
      "[284/00615] train_loss: 0.012004\n",
      "[284/00665] train_loss: 0.012334\n",
      "[284/00715] train_loss: 0.012730\n",
      "[284/00765] train_loss: 0.012330\n",
      "[284/00815] train_loss: 0.011965\n",
      "[284/00865] train_loss: 0.012379\n",
      "[284/00915] train_loss: 0.011339\n",
      "[284/00965] train_loss: 0.012106\n",
      "[284/01015] train_loss: 0.011446\n",
      "[284/01065] train_loss: 0.011467\n",
      "[284/01115] train_loss: 0.011747\n",
      "[284/01165] train_loss: 0.011913\n",
      "[284/01215] train_loss: 0.011752\n",
      "[285/00039] train_loss: 0.012953\n",
      "[285/00089] train_loss: 0.012330\n",
      "[285/00139] train_loss: 0.012229\n",
      "[285/00189] train_loss: 0.011527\n",
      "[285/00239] train_loss: 0.012176\n",
      "[285/00289] train_loss: 0.012065\n",
      "[285/00339] train_loss: 0.012335\n",
      "[285/00389] train_loss: 0.011566\n",
      "[285/00439] train_loss: 0.011867\n",
      "[285/00489] train_loss: 0.011949\n",
      "[285/00539] train_loss: 0.012277\n",
      "[285/00589] train_loss: 0.011532\n",
      "[285/00639] train_loss: 0.012006\n",
      "[285/00689] train_loss: 0.012561\n",
      "[285/00739] train_loss: 0.011651\n",
      "[285/00789] train_loss: 0.012867\n",
      "[285/00839] train_loss: 0.012425\n",
      "[285/00889] train_loss: 0.011884\n",
      "[285/00939] train_loss: 0.012174\n",
      "[285/00989] train_loss: 0.012112\n",
      "[285/01039] train_loss: 0.012170\n",
      "[285/01089] train_loss: 0.012468\n",
      "[285/01139] train_loss: 0.013220\n",
      "[285/01189] train_loss: 0.011952\n",
      "[286/00013] train_loss: 0.012088\n",
      "[286/00063] train_loss: 0.012930\n",
      "[286/00113] train_loss: 0.012961\n",
      "[286/00163] train_loss: 0.012265\n",
      "[286/00213] train_loss: 0.012348\n",
      "[286/00263] train_loss: 0.013360\n",
      "[286/00313] train_loss: 0.011846\n",
      "[286/00363] train_loss: 0.011868\n",
      "[286/00413] train_loss: 0.012716\n",
      "[286/00463] train_loss: 0.012389\n",
      "[286/00513] train_loss: 0.012078\n",
      "[286/00563] train_loss: 0.010570\n",
      "[286/00613] train_loss: 0.011677\n",
      "[286/00663] train_loss: 0.011515\n",
      "[286/00713] train_loss: 0.012015\n",
      "[286/00763] train_loss: 0.012744\n",
      "[286/00813] train_loss: 0.011713\n",
      "[286/00863] train_loss: 0.011148\n",
      "[286/00913] train_loss: 0.012132\n",
      "[286/00963] train_loss: 0.011684\n",
      "[286/01013] train_loss: 0.011672\n",
      "[286/01063] train_loss: 0.012321\n",
      "[286/01113] train_loss: 0.011696\n",
      "[286/01163] train_loss: 0.011411\n",
      "[286/01213] train_loss: 0.012013\n",
      "[287/00037] train_loss: 0.012813\n",
      "[287/00087] train_loss: 0.012639\n",
      "[287/00137] train_loss: 0.012162\n",
      "[287/00187] train_loss: 0.012270\n",
      "[287/00237] train_loss: 0.012162\n",
      "[287/00287] train_loss: 0.011684\n",
      "[287/00337] train_loss: 0.012010\n",
      "[287/00387] train_loss: 0.012232\n",
      "[287/00437] train_loss: 0.011974\n",
      "[287/00487] train_loss: 0.011746\n",
      "[287/00537] train_loss: 0.011500\n",
      "[287/00587] train_loss: 0.011443\n",
      "[287/00637] train_loss: 0.012425\n",
      "[287/00687] train_loss: 0.011508\n",
      "[287/00737] train_loss: 0.012123\n",
      "[287/00787] train_loss: 0.012584\n",
      "[287/00837] train_loss: 0.011126\n",
      "[287/00887] train_loss: 0.012098\n",
      "[287/00937] train_loss: 0.012217\n",
      "[287/00987] train_loss: 0.012103\n",
      "[287/01037] train_loss: 0.011978\n",
      "[287/01087] train_loss: 0.011284\n",
      "[287/01137] train_loss: 0.012142\n",
      "[287/01187] train_loss: 0.012506\n",
      "[288/00011] train_loss: 0.011815\n",
      "[288/00061] train_loss: 0.012698\n",
      "[288/00111] train_loss: 0.012625\n",
      "[288/00161] train_loss: 0.012424\n",
      "[288/00211] train_loss: 0.012630\n",
      "[288/00261] train_loss: 0.012087\n",
      "[288/00311] train_loss: 0.012567\n",
      "[288/00361] train_loss: 0.012123\n",
      "[288/00411] train_loss: 0.012166\n",
      "[288/00461] train_loss: 0.011603\n",
      "[288/00511] train_loss: 0.011795\n",
      "[288/00561] train_loss: 0.011445\n",
      "[288/00611] train_loss: 0.011948\n",
      "[288/00661] train_loss: 0.011593\n",
      "[288/00711] train_loss: 0.012141\n",
      "[288/00761] train_loss: 0.011893\n",
      "[288/00811] train_loss: 0.012248\n",
      "[288/00861] train_loss: 0.011922\n",
      "[288/00911] train_loss: 0.012669\n",
      "[288/00961] train_loss: 0.011845\n",
      "[288/01011] train_loss: 0.012026\n",
      "[288/01061] train_loss: 0.011444\n",
      "[288/01111] train_loss: 0.012177\n",
      "[288/01161] train_loss: 0.012197\n",
      "[288/01211] train_loss: 0.011831\n",
      "[289/00035] train_loss: 0.012336\n",
      "[289/00085] train_loss: 0.012373\n",
      "[289/00135] train_loss: 0.012348\n",
      "[289/00185] train_loss: 0.011912\n",
      "[289/00235] train_loss: 0.012597\n",
      "[289/00285] train_loss: 0.011620\n",
      "[289/00335] train_loss: 0.012575\n",
      "[289/00385] train_loss: 0.011957\n",
      "[289/00435] train_loss: 0.011891\n",
      "[289/00485] train_loss: 0.011956\n",
      "[289/00535] train_loss: 0.012164\n",
      "[289/00585] train_loss: 0.011710\n",
      "[289/00635] train_loss: 0.012135\n",
      "[289/00685] train_loss: 0.011589\n",
      "[289/00735] train_loss: 0.011965\n",
      "[289/00785] train_loss: 0.011963\n",
      "[289/00835] train_loss: 0.012418\n",
      "[289/00885] train_loss: 0.012376\n",
      "[289/00935] train_loss: 0.011596\n",
      "[289/00985] train_loss: 0.012669\n",
      "[289/01035] train_loss: 0.011975\n",
      "[289/01085] train_loss: 0.011801\n",
      "[289/01135] train_loss: 0.011644\n",
      "[289/01185] train_loss: 0.012180\n",
      "[290/00009] train_loss: 0.012773\n",
      "[290/00059] train_loss: 0.012205\n",
      "[290/00109] train_loss: 0.013279\n",
      "[290/00159] train_loss: 0.012605\n",
      "[290/00209] train_loss: 0.012550\n",
      "[290/00259] train_loss: 0.011794\n",
      "[290/00309] train_loss: 0.011642\n",
      "[290/00359] train_loss: 0.012102\n",
      "[290/00409] train_loss: 0.011571\n",
      "[290/00459] train_loss: 0.011427\n",
      "[290/00509] train_loss: 0.011756\n",
      "[290/00559] train_loss: 0.011920\n",
      "[290/00609] train_loss: 0.011719\n",
      "[290/00659] train_loss: 0.012009\n",
      "[290/00709] train_loss: 0.011994\n",
      "[290/00759] train_loss: 0.011839\n",
      "[290/00809] train_loss: 0.012132\n",
      "[290/00859] train_loss: 0.011576\n",
      "[290/00909] train_loss: 0.011898\n",
      "[290/00959] train_loss: 0.012511\n",
      "[290/01009] train_loss: 0.012465\n",
      "[290/01059] train_loss: 0.011740\n",
      "[290/01109] train_loss: 0.013299\n",
      "[290/01159] train_loss: 0.011296\n",
      "[290/01209] train_loss: 0.011659\n",
      "[291/00033] train_loss: 0.012959\n",
      "[291/00083] train_loss: 0.011583\n",
      "[291/00133] train_loss: 0.012845\n",
      "[291/00183] train_loss: 0.011970\n",
      "[291/00233] train_loss: 0.012377\n",
      "[291/00283] train_loss: 0.012606\n",
      "[291/00333] train_loss: 0.012894\n",
      "[291/00383] train_loss: 0.012092\n",
      "[291/00433] train_loss: 0.012746\n",
      "[291/00483] train_loss: 0.011656\n",
      "[291/00533] train_loss: 0.011679\n",
      "[291/00583] train_loss: 0.012010\n",
      "[291/00633] train_loss: 0.013070\n",
      "[291/00683] train_loss: 0.012010\n",
      "[291/00733] train_loss: 0.012035\n",
      "[291/00783] train_loss: 0.011930\n",
      "[291/00833] train_loss: 0.011272\n",
      "[291/00883] train_loss: 0.011635\n",
      "[291/00933] train_loss: 0.011541\n",
      "[291/00983] train_loss: 0.011764\n",
      "[291/01033] train_loss: 0.011489\n",
      "[291/01083] train_loss: 0.011861\n",
      "[291/01133] train_loss: 0.012178\n",
      "[291/01183] train_loss: 0.012289\n",
      "[292/00007] train_loss: 0.011573\n",
      "[292/00057] train_loss: 0.012456\n",
      "[292/00107] train_loss: 0.012890\n",
      "[292/00157] train_loss: 0.012526\n",
      "[292/00207] train_loss: 0.011752\n",
      "[292/00257] train_loss: 0.012163\n",
      "[292/00307] train_loss: 0.011875\n",
      "[292/00357] train_loss: 0.011973\n",
      "[292/00407] train_loss: 0.012307\n",
      "[292/00457] train_loss: 0.012409\n",
      "[292/00507] train_loss: 0.012341\n",
      "[292/00557] train_loss: 0.012036\n",
      "[292/00607] train_loss: 0.011620\n",
      "[292/00657] train_loss: 0.012691\n",
      "[292/00707] train_loss: 0.012212\n",
      "[292/00757] train_loss: 0.012825\n",
      "[292/00807] train_loss: 0.011263\n",
      "[292/00857] train_loss: 0.012341\n",
      "[292/00907] train_loss: 0.011793\n",
      "[292/00957] train_loss: 0.012346\n",
      "[292/01007] train_loss: 0.011742\n",
      "[292/01057] train_loss: 0.011809\n",
      "[292/01107] train_loss: 0.011757\n",
      "[292/01157] train_loss: 0.012141\n",
      "[292/01207] train_loss: 0.011899\n",
      "[293/00031] train_loss: 0.012427\n",
      "[293/00081] train_loss: 0.012557\n",
      "[293/00131] train_loss: 0.011956\n",
      "[293/00181] train_loss: 0.012050\n",
      "[293/00231] train_loss: 0.012117\n",
      "[293/00281] train_loss: 0.012822\n",
      "[293/00331] train_loss: 0.012994\n",
      "[293/00381] train_loss: 0.011954\n",
      "[293/00431] train_loss: 0.011621\n",
      "[293/00481] train_loss: 0.012201\n",
      "[293/00531] train_loss: 0.011682\n",
      "[293/00581] train_loss: 0.011692\n",
      "[293/00631] train_loss: 0.011715\n",
      "[293/00681] train_loss: 0.012338\n",
      "[293/00731] train_loss: 0.011395\n",
      "[293/00781] train_loss: 0.011642\n",
      "[293/00831] train_loss: 0.012365\n",
      "[293/00881] train_loss: 0.012018\n",
      "[293/00931] train_loss: 0.011530\n",
      "[293/00981] train_loss: 0.012374\n",
      "[293/01031] train_loss: 0.012439\n",
      "[293/01081] train_loss: 0.011908\n",
      "[293/01131] train_loss: 0.012253\n",
      "[293/01181] train_loss: 0.012265\n",
      "[294/00005] train_loss: 0.011917\n",
      "[294/00055] train_loss: 0.012629\n",
      "[294/00105] train_loss: 0.012372\n",
      "[294/00155] train_loss: 0.012279\n",
      "[294/00205] train_loss: 0.012114\n",
      "[294/00255] train_loss: 0.012496\n",
      "[294/00305] train_loss: 0.012672\n",
      "[294/00355] train_loss: 0.012213\n",
      "[294/00405] train_loss: 0.012741\n",
      "[294/00455] train_loss: 0.011642\n",
      "[294/00505] train_loss: 0.012638\n",
      "[294/00555] train_loss: 0.012339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[294/00605] train_loss: 0.011711\n",
      "[294/00655] train_loss: 0.011597\n",
      "[294/00705] train_loss: 0.012109\n",
      "[294/00755] train_loss: 0.012292\n",
      "[294/00805] train_loss: 0.011757\n",
      "[294/00855] train_loss: 0.011799\n",
      "[294/00905] train_loss: 0.011699\n",
      "[294/00955] train_loss: 0.011840\n",
      "[294/01005] train_loss: 0.012273\n",
      "[294/01055] train_loss: 0.011894\n",
      "[294/01105] train_loss: 0.012141\n",
      "[294/01155] train_loss: 0.011033\n",
      "[294/01205] train_loss: 0.012181\n",
      "[295/00029] train_loss: 0.011931\n",
      "[295/00079] train_loss: 0.011708\n",
      "[295/00129] train_loss: 0.013477\n",
      "[295/00179] train_loss: 0.013087\n",
      "[295/00229] train_loss: 0.011972\n",
      "[295/00279] train_loss: 0.011721\n",
      "[295/00329] train_loss: 0.012055\n",
      "[295/00379] train_loss: 0.011796\n",
      "[295/00429] train_loss: 0.011711\n",
      "[295/00479] train_loss: 0.011627\n",
      "[295/00529] train_loss: 0.012322\n",
      "[295/00579] train_loss: 0.012112\n",
      "[295/00629] train_loss: 0.011523\n",
      "[295/00679] train_loss: 0.011861\n",
      "[295/00729] train_loss: 0.013001\n",
      "[295/00779] train_loss: 0.011514\n",
      "[295/00829] train_loss: 0.012334\n",
      "[295/00879] train_loss: 0.011649\n",
      "[295/00929] train_loss: 0.011455\n",
      "[295/00979] train_loss: 0.012103\n",
      "[295/01029] train_loss: 0.012927\n",
      "[295/01079] train_loss: 0.012372\n",
      "[295/01129] train_loss: 0.011472\n",
      "[295/01179] train_loss: 0.011350\n",
      "[296/00003] train_loss: 0.012097\n",
      "[296/00053] train_loss: 0.012885\n",
      "[296/00103] train_loss: 0.012529\n",
      "[296/00153] train_loss: 0.012552\n",
      "[296/00203] train_loss: 0.011842\n",
      "[296/00253] train_loss: 0.012512\n",
      "[296/00303] train_loss: 0.012157\n",
      "[296/00353] train_loss: 0.012201\n",
      "[296/00403] train_loss: 0.011702\n",
      "[296/00453] train_loss: 0.012077\n",
      "[296/00503] train_loss: 0.012679\n",
      "[296/00553] train_loss: 0.012486\n",
      "[296/00603] train_loss: 0.011334\n",
      "[296/00653] train_loss: 0.011590\n",
      "[296/00703] train_loss: 0.011675\n",
      "[296/00753] train_loss: 0.011620\n",
      "[296/00803] train_loss: 0.012774\n",
      "[296/00853] train_loss: 0.012066\n",
      "[296/00903] train_loss: 0.011966\n",
      "[296/00953] train_loss: 0.012076\n",
      "[296/01003] train_loss: 0.011638\n",
      "[296/01053] train_loss: 0.010923\n",
      "[296/01103] train_loss: 0.011622\n",
      "[296/01153] train_loss: 0.012052\n",
      "[296/01203] train_loss: 0.012455\n",
      "[297/00027] train_loss: 0.012360\n",
      "[297/00077] train_loss: 0.012366\n",
      "[297/00127] train_loss: 0.012639\n",
      "[297/00177] train_loss: 0.012354\n",
      "[297/00227] train_loss: 0.011955\n",
      "[297/00277] train_loss: 0.011636\n",
      "[297/00327] train_loss: 0.011367\n",
      "[297/00377] train_loss: 0.012040\n",
      "[297/00427] train_loss: 0.012711\n",
      "[297/00477] train_loss: 0.011764\n",
      "[297/00527] train_loss: 0.012025\n",
      "[297/00577] train_loss: 0.011653\n",
      "[297/00627] train_loss: 0.012526\n",
      "[297/00677] train_loss: 0.012144\n",
      "[297/00727] train_loss: 0.011821\n",
      "[297/00777] train_loss: 0.011834\n",
      "[297/00827] train_loss: 0.012340\n",
      "[297/00877] train_loss: 0.011787\n",
      "[297/00927] train_loss: 0.011633\n",
      "[297/00977] train_loss: 0.012003\n",
      "[297/01027] train_loss: 0.011494\n",
      "[297/01077] train_loss: 0.011207\n",
      "[297/01127] train_loss: 0.011396\n",
      "[297/01177] train_loss: 0.012488\n",
      "[298/00001] train_loss: 0.012194\n",
      "[298/00051] train_loss: 0.012719\n",
      "[298/00101] train_loss: 0.012309\n",
      "[298/00151] train_loss: 0.012236\n",
      "[298/00201] train_loss: 0.012276\n",
      "[298/00251] train_loss: 0.011998\n",
      "[298/00301] train_loss: 0.012328\n",
      "[298/00351] train_loss: 0.012236\n",
      "[298/00401] train_loss: 0.011915\n",
      "[298/00451] train_loss: 0.011627\n",
      "[298/00501] train_loss: 0.012129\n",
      "[298/00551] train_loss: 0.011835\n",
      "[298/00601] train_loss: 0.011969\n",
      "[298/00651] train_loss: 0.012123\n",
      "[298/00701] train_loss: 0.012211\n",
      "[298/00751] train_loss: 0.011701\n",
      "[298/00801] train_loss: 0.011374\n",
      "[298/00851] train_loss: 0.011705\n",
      "[298/00901] train_loss: 0.011484\n",
      "[298/00951] train_loss: 0.012525\n",
      "[298/01001] train_loss: 0.013374\n",
      "[298/01051] train_loss: 0.011929\n",
      "[298/01101] train_loss: 0.011988\n",
      "[298/01151] train_loss: 0.011469\n",
      "[298/01201] train_loss: 0.012416\n",
      "[299/00025] train_loss: 0.012279\n",
      "[299/00075] train_loss: 0.012140\n",
      "[299/00125] train_loss: 0.011690\n",
      "[299/00175] train_loss: 0.012642\n",
      "[299/00225] train_loss: 0.011843\n",
      "[299/00275] train_loss: 0.011453\n",
      "[299/00325] train_loss: 0.012054\n",
      "[299/00375] train_loss: 0.011346\n",
      "[299/00425] train_loss: 0.012519\n",
      "[299/00475] train_loss: 0.012411\n",
      "[299/00525] train_loss: 0.012234\n",
      "[299/00575] train_loss: 0.012308\n",
      "[299/00625] train_loss: 0.012026\n",
      "[299/00675] train_loss: 0.012009\n",
      "[299/00725] train_loss: 0.012152\n",
      "[299/00775] train_loss: 0.011715\n",
      "[299/00825] train_loss: 0.011435\n",
      "[299/00875] train_loss: 0.012298\n",
      "[299/00925] train_loss: 0.011701\n",
      "[299/00975] train_loss: 0.011744\n",
      "[299/01025] train_loss: 0.012372\n",
      "[299/01075] train_loss: 0.012505\n",
      "[299/01125] train_loss: 0.011803\n",
      "[299/01175] train_loss: 0.011383\n",
      "[299/01225] train_loss: 0.012113\n",
      "[300/00049] train_loss: 0.012588\n",
      "[300/00099] train_loss: 0.011857\n",
      "[300/00149] train_loss: 0.012035\n",
      "[300/00199] train_loss: 0.012261\n",
      "[300/00249] train_loss: 0.011730\n",
      "[300/00299] train_loss: 0.012712\n",
      "[300/00349] train_loss: 0.012471\n",
      "[300/00399] train_loss: 0.011747\n",
      "[300/00449] train_loss: 0.011975\n",
      "[300/00499] train_loss: 0.011921\n",
      "[300/00549] train_loss: 0.012084\n",
      "[300/00599] train_loss: 0.012155\n",
      "[300/00649] train_loss: 0.011903\n",
      "[300/00699] train_loss: 0.011698\n",
      "[300/00749] train_loss: 0.012272\n",
      "[300/00799] train_loss: 0.011753\n",
      "[300/00849] train_loss: 0.011751\n",
      "[300/00899] train_loss: 0.011996\n",
      "[300/00949] train_loss: 0.011954\n",
      "[300/00999] train_loss: 0.012290\n",
      "[300/01049] train_loss: 0.011426\n",
      "[300/01099] train_loss: 0.012406\n",
      "[300/01149] train_loss: 0.011774\n",
      "[300/01199] train_loss: 0.011805\n",
      "[301/00023] train_loss: 0.011417\n",
      "[301/00073] train_loss: 0.012440\n",
      "[301/00123] train_loss: 0.012345\n",
      "[301/00173] train_loss: 0.011667\n",
      "[301/00223] train_loss: 0.011843\n",
      "[301/00273] train_loss: 0.011510\n",
      "[301/00323] train_loss: 0.012174\n",
      "[301/00373] train_loss: 0.012243\n",
      "[301/00423] train_loss: 0.011898\n",
      "[301/00473] train_loss: 0.012276\n",
      "[301/00523] train_loss: 0.012234\n",
      "[301/00573] train_loss: 0.011792\n",
      "[301/00623] train_loss: 0.011676\n",
      "[301/00673] train_loss: 0.013241\n",
      "[301/00723] train_loss: 0.012158\n",
      "[301/00773] train_loss: 0.013340\n",
      "[301/00823] train_loss: 0.011775\n",
      "[301/00873] train_loss: 0.012203\n",
      "[301/00923] train_loss: 0.011906\n",
      "[301/00973] train_loss: 0.011984\n",
      "[301/01023] train_loss: 0.011009\n",
      "[301/01073] train_loss: 0.011297\n",
      "[301/01123] train_loss: 0.011656\n",
      "[301/01173] train_loss: 0.011605\n",
      "[301/01223] train_loss: 0.012320\n",
      "[302/00047] train_loss: 0.012172\n",
      "[302/00097] train_loss: 0.012176\n",
      "[302/00147] train_loss: 0.012096\n",
      "[302/00197] train_loss: 0.012168\n",
      "[302/00247] train_loss: 0.012006\n",
      "[302/00297] train_loss: 0.012305\n",
      "[302/00347] train_loss: 0.011652\n",
      "[302/00397] train_loss: 0.011687\n",
      "[302/00447] train_loss: 0.012971\n",
      "[302/00497] train_loss: 0.011490\n",
      "[302/00547] train_loss: 0.012311\n",
      "[302/00597] train_loss: 0.011610\n",
      "[302/00647] train_loss: 0.011843\n",
      "[302/00697] train_loss: 0.011486\n",
      "[302/00747] train_loss: 0.011710\n",
      "[302/00797] train_loss: 0.011995\n",
      "[302/00847] train_loss: 0.011810\n",
      "[302/00897] train_loss: 0.012386\n",
      "[302/00947] train_loss: 0.011924\n",
      "[302/00997] train_loss: 0.011773\n",
      "[302/01047] train_loss: 0.012536\n",
      "[302/01097] train_loss: 0.011765\n",
      "[302/01147] train_loss: 0.012284\n",
      "[302/01197] train_loss: 0.011623\n",
      "[303/00021] train_loss: 0.012264\n",
      "[303/00071] train_loss: 0.013116\n",
      "[303/00121] train_loss: 0.012332\n",
      "[303/00171] train_loss: 0.012001\n",
      "[303/00221] train_loss: 0.012614\n",
      "[303/00271] train_loss: 0.012099\n",
      "[303/00321] train_loss: 0.012017\n",
      "[303/00371] train_loss: 0.011375\n",
      "[303/00421] train_loss: 0.012272\n",
      "[303/00471] train_loss: 0.011594\n",
      "[303/00521] train_loss: 0.011966\n",
      "[303/00571] train_loss: 0.011684\n",
      "[303/00621] train_loss: 0.012351\n",
      "[303/00671] train_loss: 0.011514\n",
      "[303/00721] train_loss: 0.010942\n",
      "[303/00771] train_loss: 0.012259\n",
      "[303/00821] train_loss: 0.012630\n",
      "[303/00871] train_loss: 0.012331\n",
      "[303/00921] train_loss: 0.011629\n",
      "[303/00971] train_loss: 0.011618\n",
      "[303/01021] train_loss: 0.011612\n",
      "[303/01071] train_loss: 0.011370\n",
      "[303/01121] train_loss: 0.012692\n",
      "[303/01171] train_loss: 0.011518\n",
      "[303/01221] train_loss: 0.010728\n",
      "[304/00045] train_loss: 0.012798\n",
      "[304/00095] train_loss: 0.012997\n",
      "[304/00145] train_loss: 0.012460\n",
      "[304/00195] train_loss: 0.011821\n",
      "[304/00245] train_loss: 0.012082\n",
      "[304/00295] train_loss: 0.012198\n",
      "[304/00345] train_loss: 0.011939\n",
      "[304/00395] train_loss: 0.011996\n",
      "[304/00445] train_loss: 0.011933\n",
      "[304/00495] train_loss: 0.012737\n",
      "[304/00545] train_loss: 0.011744\n",
      "[304/00595] train_loss: 0.011595\n",
      "[304/00645] train_loss: 0.011647\n",
      "[304/00695] train_loss: 0.012881\n",
      "[304/00745] train_loss: 0.012033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[304/00795] train_loss: 0.011543\n",
      "[304/00845] train_loss: 0.011802\n",
      "[304/00895] train_loss: 0.011526\n",
      "[304/00945] train_loss: 0.011688\n",
      "[304/00995] train_loss: 0.011486\n",
      "[304/01045] train_loss: 0.011516\n",
      "[304/01095] train_loss: 0.011247\n",
      "[304/01145] train_loss: 0.012255\n",
      "[304/01195] train_loss: 0.011302\n",
      "[305/00019] train_loss: 0.012368\n",
      "[305/00069] train_loss: 0.012411\n",
      "[305/00119] train_loss: 0.012307\n",
      "[305/00169] train_loss: 0.012825\n",
      "[305/00219] train_loss: 0.012903\n",
      "[305/00269] train_loss: 0.012140\n",
      "[305/00319] train_loss: 0.012968\n",
      "[305/00369] train_loss: 0.012282\n",
      "[305/00419] train_loss: 0.012302\n",
      "[305/00469] train_loss: 0.011688\n",
      "[305/00519] train_loss: 0.012131\n",
      "[305/00569] train_loss: 0.012445\n",
      "[305/00619] train_loss: 0.011566\n",
      "[305/00669] train_loss: 0.011954\n",
      "[305/00719] train_loss: 0.011820\n",
      "[305/00769] train_loss: 0.011998\n",
      "[305/00819] train_loss: 0.011750\n",
      "[305/00869] train_loss: 0.011962\n",
      "[305/00919] train_loss: 0.011763\n",
      "[305/00969] train_loss: 0.011611\n",
      "[305/01019] train_loss: 0.011684\n",
      "[305/01069] train_loss: 0.011209\n",
      "[305/01119] train_loss: 0.011831\n",
      "[305/01169] train_loss: 0.011817\n",
      "[305/01219] train_loss: 0.011705\n",
      "[306/00043] train_loss: 0.012758\n",
      "[306/00093] train_loss: 0.013059\n",
      "[306/00143] train_loss: 0.011647\n",
      "[306/00193] train_loss: 0.012068\n",
      "[306/00243] train_loss: 0.011670\n",
      "[306/00293] train_loss: 0.011858\n",
      "[306/00343] train_loss: 0.011886\n",
      "[306/00393] train_loss: 0.011762\n",
      "[306/00443] train_loss: 0.011580\n",
      "[306/00493] train_loss: 0.012203\n",
      "[306/00543] train_loss: 0.011721\n",
      "[306/00593] train_loss: 0.012323\n",
      "[306/00643] train_loss: 0.011761\n",
      "[306/00693] train_loss: 0.011824\n",
      "[306/00743] train_loss: 0.012154\n",
      "[306/00793] train_loss: 0.011689\n",
      "[306/00843] train_loss: 0.011758\n",
      "[306/00893] train_loss: 0.010998\n",
      "[306/00943] train_loss: 0.012063\n",
      "[306/00993] train_loss: 0.011882\n",
      "[306/01043] train_loss: 0.012050\n",
      "[306/01093] train_loss: 0.012363\n",
      "[306/01143] train_loss: 0.012364\n",
      "[306/01193] train_loss: 0.011077\n",
      "[307/00017] train_loss: 0.011631\n",
      "[307/00067] train_loss: 0.012567\n",
      "[307/00117] train_loss: 0.011689\n",
      "[307/00167] train_loss: 0.012059\n",
      "[307/00217] train_loss: 0.011550\n",
      "[307/00267] train_loss: 0.012334\n",
      "[307/00317] train_loss: 0.011811\n",
      "[307/00367] train_loss: 0.012264\n",
      "[307/00417] train_loss: 0.011984\n",
      "[307/00467] train_loss: 0.011667\n",
      "[307/00517] train_loss: 0.011912\n",
      "[307/00567] train_loss: 0.012671\n",
      "[307/00617] train_loss: 0.012766\n",
      "[307/00667] train_loss: 0.012563\n",
      "[307/00717] train_loss: 0.011731\n",
      "[307/00767] train_loss: 0.011844\n",
      "[307/00817] train_loss: 0.011868\n",
      "[307/00867] train_loss: 0.011824\n",
      "[307/00917] train_loss: 0.012451\n",
      "[307/00967] train_loss: 0.012189\n",
      "[307/01017] train_loss: 0.012060\n",
      "[307/01067] train_loss: 0.011292\n",
      "[307/01117] train_loss: 0.011876\n",
      "[307/01167] train_loss: 0.011687\n",
      "[307/01217] train_loss: 0.011935\n",
      "[308/00041] train_loss: 0.012525\n",
      "[308/00091] train_loss: 0.012480\n",
      "[308/00141] train_loss: 0.012469\n",
      "[308/00191] train_loss: 0.011883\n",
      "[308/00241] train_loss: 0.011599\n",
      "[308/00291] train_loss: 0.012543\n",
      "[308/00341] train_loss: 0.011786\n",
      "[308/00391] train_loss: 0.011722\n",
      "[308/00441] train_loss: 0.011384\n",
      "[308/00491] train_loss: 0.011935\n",
      "[308/00541] train_loss: 0.012204\n",
      "[308/00591] train_loss: 0.012102\n",
      "[308/00641] train_loss: 0.011842\n",
      "[308/00691] train_loss: 0.011120\n",
      "[308/00741] train_loss: 0.011709\n",
      "[308/00791] train_loss: 0.012097\n",
      "[308/00841] train_loss: 0.011203\n",
      "[308/00891] train_loss: 0.011723\n",
      "[308/00941] train_loss: 0.011360\n",
      "[308/00991] train_loss: 0.012203\n",
      "[308/01041] train_loss: 0.012601\n",
      "[308/01091] train_loss: 0.011995\n",
      "[308/01141] train_loss: 0.012036\n",
      "[308/01191] train_loss: 0.011153\n",
      "[309/00015] train_loss: 0.012532\n",
      "[309/00065] train_loss: 0.012206\n",
      "[309/00115] train_loss: 0.012707\n",
      "[309/00165] train_loss: 0.012107\n",
      "[309/00215] train_loss: 0.011537\n",
      "[309/00265] train_loss: 0.012300\n",
      "[309/00315] train_loss: 0.012213\n",
      "[309/00365] train_loss: 0.012948\n",
      "[309/00415] train_loss: 0.011569\n",
      "[309/00465] train_loss: 0.011516\n",
      "[309/00515] train_loss: 0.011509\n",
      "[309/00565] train_loss: 0.012142\n",
      "[309/00615] train_loss: 0.012264\n",
      "[309/00665] train_loss: 0.011708\n",
      "[309/00715] train_loss: 0.012383\n",
      "[309/00765] train_loss: 0.012032\n",
      "[309/00815] train_loss: 0.012162\n",
      "[309/00865] train_loss: 0.011516\n",
      "[309/00915] train_loss: 0.011252\n",
      "[309/00965] train_loss: 0.012491\n",
      "[309/01015] train_loss: 0.012588\n",
      "[309/01065] train_loss: 0.011912\n",
      "[309/01115] train_loss: 0.011849\n",
      "[309/01165] train_loss: 0.012565\n",
      "[309/01215] train_loss: 0.011744\n",
      "[310/00039] train_loss: 0.011750\n",
      "[310/00089] train_loss: 0.011872\n",
      "[310/00139] train_loss: 0.012324\n",
      "[310/00189] train_loss: 0.012635\n",
      "[310/00239] train_loss: 0.012017\n",
      "[310/00289] train_loss: 0.011351\n",
      "[310/00339] train_loss: 0.011861\n",
      "[310/00389] train_loss: 0.011803\n",
      "[310/00439] train_loss: 0.012322\n",
      "[310/00489] train_loss: 0.011601\n",
      "[310/00539] train_loss: 0.012897\n",
      "[310/00589] train_loss: 0.011837\n",
      "[310/00639] train_loss: 0.011471\n",
      "[310/00689] train_loss: 0.011754\n",
      "[310/00739] train_loss: 0.011218\n",
      "[310/00789] train_loss: 0.011757\n",
      "[310/00839] train_loss: 0.011826\n",
      "[310/00889] train_loss: 0.011356\n",
      "[310/00939] train_loss: 0.011410\n",
      "[310/00989] train_loss: 0.012270\n",
      "[310/01039] train_loss: 0.012115\n",
      "[310/01089] train_loss: 0.011857\n",
      "[310/01139] train_loss: 0.011684\n",
      "[310/01189] train_loss: 0.011927\n",
      "[311/00013] train_loss: 0.011944\n",
      "[311/00063] train_loss: 0.012498\n",
      "[311/00113] train_loss: 0.012873\n",
      "[311/00163] train_loss: 0.012616\n",
      "[311/00213] train_loss: 0.012183\n",
      "[311/00263] train_loss: 0.012755\n",
      "[311/00313] train_loss: 0.011413\n",
      "[311/00363] train_loss: 0.011842\n",
      "[311/00413] train_loss: 0.011736\n",
      "[311/00463] train_loss: 0.012143\n",
      "[311/00513] train_loss: 0.011800\n",
      "[311/00563] train_loss: 0.012654\n",
      "[311/00613] train_loss: 0.011341\n",
      "[311/00663] train_loss: 0.012169\n",
      "[311/00713] train_loss: 0.011552\n",
      "[311/00763] train_loss: 0.012282\n",
      "[311/00813] train_loss: 0.011614\n",
      "[311/00863] train_loss: 0.011574\n",
      "[311/00913] train_loss: 0.012375\n",
      "[311/00963] train_loss: 0.011695\n",
      "[311/01013] train_loss: 0.011730\n",
      "[311/01063] train_loss: 0.011839\n",
      "[311/01113] train_loss: 0.011721\n",
      "[311/01163] train_loss: 0.012584\n",
      "[311/01213] train_loss: 0.011808\n",
      "[312/00037] train_loss: 0.012426\n",
      "[312/00087] train_loss: 0.012427\n",
      "[312/00137] train_loss: 0.011779\n",
      "[312/00187] train_loss: 0.011886\n",
      "[312/00237] train_loss: 0.012095\n",
      "[312/00287] train_loss: 0.012366\n",
      "[312/00337] train_loss: 0.011961\n",
      "[312/00387] train_loss: 0.011493\n",
      "[312/00437] train_loss: 0.012446\n",
      "[312/00487] train_loss: 0.011786\n",
      "[312/00537] train_loss: 0.011524\n",
      "[312/00587] train_loss: 0.012604\n",
      "[312/00637] train_loss: 0.011938\n",
      "[312/00687] train_loss: 0.011854\n",
      "[312/00737] train_loss: 0.011989\n",
      "[312/00787] train_loss: 0.012406\n",
      "[312/00837] train_loss: 0.011231\n",
      "[312/00887] train_loss: 0.011629\n",
      "[312/00937] train_loss: 0.011627\n",
      "[312/00987] train_loss: 0.011412\n",
      "[312/01037] train_loss: 0.012379\n",
      "[312/01087] train_loss: 0.011610\n",
      "[312/01137] train_loss: 0.012273\n",
      "[312/01187] train_loss: 0.012110\n",
      "[313/00011] train_loss: 0.012037\n",
      "[313/00061] train_loss: 0.011979\n",
      "[313/00111] train_loss: 0.012574\n",
      "[313/00161] train_loss: 0.012473\n",
      "[313/00211] train_loss: 0.011980\n",
      "[313/00261] train_loss: 0.011971\n",
      "[313/00311] train_loss: 0.011738\n",
      "[313/00361] train_loss: 0.011995\n",
      "[313/00411] train_loss: 0.012143\n",
      "[313/00461] train_loss: 0.012501\n",
      "[313/00511] train_loss: 0.012202\n",
      "[313/00561] train_loss: 0.012673\n",
      "[313/00611] train_loss: 0.011751\n",
      "[313/00661] train_loss: 0.011618\n",
      "[313/00711] train_loss: 0.011975\n",
      "[313/00761] train_loss: 0.011977\n",
      "[313/00811] train_loss: 0.011771\n",
      "[313/00861] train_loss: 0.011859\n",
      "[313/00911] train_loss: 0.012096\n",
      "[313/00961] train_loss: 0.012251\n",
      "[313/01011] train_loss: 0.012143\n",
      "[313/01061] train_loss: 0.011706\n",
      "[313/01111] train_loss: 0.012069\n",
      "[313/01161] train_loss: 0.012320\n",
      "[313/01211] train_loss: 0.012236\n",
      "[314/00035] train_loss: 0.011895\n",
      "[314/00085] train_loss: 0.011815\n",
      "[314/00135] train_loss: 0.011614\n",
      "[314/00185] train_loss: 0.012405\n",
      "[314/00235] train_loss: 0.012598\n",
      "[314/00285] train_loss: 0.012437\n",
      "[314/00335] train_loss: 0.011791\n",
      "[314/00385] train_loss: 0.011708\n",
      "[314/00435] train_loss: 0.011333\n",
      "[314/00485] train_loss: 0.012095\n",
      "[314/00535] train_loss: 0.012292\n",
      "[314/00585] train_loss: 0.011888\n",
      "[314/00635] train_loss: 0.011919\n",
      "[314/00685] train_loss: 0.011365\n",
      "[314/00735] train_loss: 0.011849\n",
      "[314/00785] train_loss: 0.011665\n",
      "[314/00835] train_loss: 0.011916\n",
      "[314/00885] train_loss: 0.011545\n",
      "[314/00935] train_loss: 0.011491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[314/00985] train_loss: 0.011790\n",
      "[314/01035] train_loss: 0.012290\n",
      "[314/01085] train_loss: 0.011878\n",
      "[314/01135] train_loss: 0.011293\n",
      "[314/01185] train_loss: 0.012364\n",
      "[315/00009] train_loss: 0.011486\n",
      "[315/00059] train_loss: 0.012573\n",
      "[315/00109] train_loss: 0.011706\n",
      "[315/00159] train_loss: 0.012696\n",
      "[315/00209] train_loss: 0.012195\n",
      "[315/00259] train_loss: 0.012946\n",
      "[315/00309] train_loss: 0.012132\n",
      "[315/00359] train_loss: 0.012283\n",
      "[315/00409] train_loss: 0.012134\n",
      "[315/00459] train_loss: 0.012590\n",
      "[315/00509] train_loss: 0.011515\n",
      "[315/00559] train_loss: 0.011829\n",
      "[315/00609] train_loss: 0.012263\n",
      "[315/00659] train_loss: 0.012276\n",
      "[315/00709] train_loss: 0.011167\n",
      "[315/00759] train_loss: 0.012541\n",
      "[315/00809] train_loss: 0.012124\n",
      "[315/00859] train_loss: 0.011094\n",
      "[315/00909] train_loss: 0.011519\n",
      "[315/00959] train_loss: 0.011916\n",
      "[315/01009] train_loss: 0.012479\n",
      "[315/01059] train_loss: 0.011363\n",
      "[315/01109] train_loss: 0.011566\n",
      "[315/01159] train_loss: 0.011615\n",
      "[315/01209] train_loss: 0.011176\n",
      "[316/00033] train_loss: 0.011978\n",
      "[316/00083] train_loss: 0.013441\n",
      "[316/00133] train_loss: 0.012233\n",
      "[316/00183] train_loss: 0.012070\n",
      "[316/00233] train_loss: 0.011596\n",
      "[316/00283] train_loss: 0.012208\n",
      "[316/00333] train_loss: 0.011823\n",
      "[316/00383] train_loss: 0.011910\n",
      "[316/00433] train_loss: 0.011844\n",
      "[316/00483] train_loss: 0.011778\n",
      "[316/00533] train_loss: 0.012238\n",
      "[316/00583] train_loss: 0.011997\n",
      "[316/00633] train_loss: 0.011806\n",
      "[316/00683] train_loss: 0.012141\n",
      "[316/00733] train_loss: 0.010683\n",
      "[316/00783] train_loss: 0.011549\n",
      "[316/00833] train_loss: 0.012089\n",
      "[316/00883] train_loss: 0.011970\n",
      "[316/00933] train_loss: 0.011558\n",
      "[316/00983] train_loss: 0.012138\n",
      "[316/01033] train_loss: 0.011033\n",
      "[316/01083] train_loss: 0.010989\n",
      "[316/01133] train_loss: 0.012145\n",
      "[316/01183] train_loss: 0.012002\n",
      "[317/00007] train_loss: 0.011482\n",
      "[317/00057] train_loss: 0.012043\n",
      "[317/00107] train_loss: 0.011793\n",
      "[317/00157] train_loss: 0.011841\n",
      "[317/00207] train_loss: 0.012586\n",
      "[317/00257] train_loss: 0.012826\n",
      "[317/00307] train_loss: 0.011389\n",
      "[317/00357] train_loss: 0.011978\n",
      "[317/00407] train_loss: 0.012784\n",
      "[317/00457] train_loss: 0.011681\n",
      "[317/00507] train_loss: 0.011729\n",
      "[317/00557] train_loss: 0.012336\n",
      "[317/00607] train_loss: 0.011898\n",
      "[317/00657] train_loss: 0.012154\n",
      "[317/00707] train_loss: 0.012466\n",
      "[317/00757] train_loss: 0.011403\n",
      "[317/00807] train_loss: 0.011829\n",
      "[317/00857] train_loss: 0.012141\n",
      "[317/00907] train_loss: 0.011565\n",
      "[317/00957] train_loss: 0.012227\n",
      "[317/01007] train_loss: 0.012334\n",
      "[317/01057] train_loss: 0.011538\n",
      "[317/01107] train_loss: 0.011159\n",
      "[317/01157] train_loss: 0.012164\n",
      "[317/01207] train_loss: 0.011600\n",
      "[318/00031] train_loss: 0.011607\n",
      "[318/00081] train_loss: 0.012208\n",
      "[318/00131] train_loss: 0.012461\n",
      "[318/00181] train_loss: 0.011687\n",
      "[318/00231] train_loss: 0.012892\n",
      "[318/00281] train_loss: 0.011550\n",
      "[318/00331] train_loss: 0.011873\n",
      "[318/00381] train_loss: 0.011934\n",
      "[318/00431] train_loss: 0.011703\n",
      "[318/00481] train_loss: 0.012403\n",
      "[318/00531] train_loss: 0.011937\n",
      "[318/00581] train_loss: 0.011358\n",
      "[318/00631] train_loss: 0.012097\n",
      "[318/00681] train_loss: 0.012171\n",
      "[318/00731] train_loss: 0.011683\n",
      "[318/00781] train_loss: 0.012062\n",
      "[318/00831] train_loss: 0.011657\n",
      "[318/00881] train_loss: 0.011682\n",
      "[318/00931] train_loss: 0.011584\n",
      "[318/00981] train_loss: 0.011907\n",
      "[318/01031] train_loss: 0.011641\n",
      "[318/01081] train_loss: 0.011673\n",
      "[318/01131] train_loss: 0.011399\n",
      "[318/01181] train_loss: 0.012115\n",
      "[319/00005] train_loss: 0.011261\n",
      "[319/00055] train_loss: 0.012302\n",
      "[319/00105] train_loss: 0.012425\n",
      "[319/00155] train_loss: 0.012290\n",
      "[319/00205] train_loss: 0.012520\n",
      "[319/00255] train_loss: 0.012791\n",
      "[319/00305] train_loss: 0.011772\n",
      "[319/00355] train_loss: 0.011702\n",
      "[319/00405] train_loss: 0.011980\n",
      "[319/00455] train_loss: 0.011881\n",
      "[319/00505] train_loss: 0.011457\n",
      "[319/00555] train_loss: 0.011853\n",
      "[319/00605] train_loss: 0.011966\n",
      "[319/00655] train_loss: 0.011563\n",
      "[319/00705] train_loss: 0.011775\n",
      "[319/00755] train_loss: 0.012325\n",
      "[319/00805] train_loss: 0.011916\n",
      "[319/00855] train_loss: 0.012076\n",
      "[319/00905] train_loss: 0.012009\n",
      "[319/00955] train_loss: 0.011828\n",
      "[319/01005] train_loss: 0.011784\n",
      "[319/01055] train_loss: 0.011946\n",
      "[319/01105] train_loss: 0.011641\n",
      "[319/01155] train_loss: 0.011506\n",
      "[319/01205] train_loss: 0.011073\n",
      "[320/00029] train_loss: 0.011817\n",
      "[320/00079] train_loss: 0.012408\n",
      "[320/00129] train_loss: 0.012195\n",
      "[320/00179] train_loss: 0.011863\n",
      "[320/00229] train_loss: 0.011899\n",
      "[320/00279] train_loss: 0.012726\n",
      "[320/00329] train_loss: 0.012583\n",
      "[320/00379] train_loss: 0.011198\n",
      "[320/00429] train_loss: 0.011638\n",
      "[320/00479] train_loss: 0.012527\n",
      "[320/00529] train_loss: 0.011713\n",
      "[320/00579] train_loss: 0.011626\n",
      "[320/00629] train_loss: 0.011385\n",
      "[320/00679] train_loss: 0.011410\n",
      "[320/00729] train_loss: 0.011880\n",
      "[320/00779] train_loss: 0.011933\n",
      "[320/00829] train_loss: 0.011557\n",
      "[320/00879] train_loss: 0.011938\n",
      "[320/00929] train_loss: 0.011669\n",
      "[320/00979] train_loss: 0.011461\n",
      "[320/01029] train_loss: 0.012047\n",
      "[320/01079] train_loss: 0.011850\n",
      "[320/01129] train_loss: 0.011320\n",
      "[320/01179] train_loss: 0.012184\n",
      "[321/00003] train_loss: 0.011724\n",
      "[321/00053] train_loss: 0.012404\n",
      "[321/00103] train_loss: 0.012130\n",
      "[321/00153] train_loss: 0.011789\n",
      "[321/00203] train_loss: 0.012255\n",
      "[321/00253] train_loss: 0.011651\n",
      "[321/00303] train_loss: 0.011847\n",
      "[321/00353] train_loss: 0.012437\n",
      "[321/00403] train_loss: 0.011940\n",
      "[321/00453] train_loss: 0.011400\n",
      "[321/00503] train_loss: 0.011969\n",
      "[321/00553] train_loss: 0.012119\n",
      "[321/00603] train_loss: 0.012151\n",
      "[321/00653] train_loss: 0.012636\n",
      "[321/00703] train_loss: 0.012010\n",
      "[321/00753] train_loss: 0.012043\n",
      "[321/00803] train_loss: 0.011654\n",
      "[321/00853] train_loss: 0.011475\n",
      "[321/00903] train_loss: 0.011440\n",
      "[321/00953] train_loss: 0.011899\n",
      "[321/01003] train_loss: 0.012007\n",
      "[321/01053] train_loss: 0.011839\n",
      "[321/01103] train_loss: 0.011236\n",
      "[321/01153] train_loss: 0.011661\n",
      "[321/01203] train_loss: 0.011564\n",
      "[322/00027] train_loss: 0.011923\n",
      "[322/00077] train_loss: 0.011951\n",
      "[322/00127] train_loss: 0.011634\n",
      "[322/00177] train_loss: 0.012118\n",
      "[322/00227] train_loss: 0.012369\n",
      "[322/00277] train_loss: 0.011062\n",
      "[322/00327] train_loss: 0.011890\n",
      "[322/00377] train_loss: 0.011197\n",
      "[322/00427] train_loss: 0.011525\n",
      "[322/00477] train_loss: 0.011450\n",
      "[322/00527] train_loss: 0.011968\n",
      "[322/00577] train_loss: 0.012115\n",
      "[322/00627] train_loss: 0.011855\n",
      "[322/00677] train_loss: 0.011502\n",
      "[322/00727] train_loss: 0.011468\n",
      "[322/00777] train_loss: 0.011083\n",
      "[322/00827] train_loss: 0.011173\n",
      "[322/00877] train_loss: 0.012003\n",
      "[322/00927] train_loss: 0.012253\n",
      "[322/00977] train_loss: 0.011935\n",
      "[322/01027] train_loss: 0.011650\n",
      "[322/01077] train_loss: 0.012033\n",
      "[322/01127] train_loss: 0.011960\n",
      "[322/01177] train_loss: 0.011793\n",
      "[323/00001] train_loss: 0.011723\n",
      "[323/00051] train_loss: 0.012214\n",
      "[323/00101] train_loss: 0.013248\n",
      "[323/00151] train_loss: 0.012025\n",
      "[323/00201] train_loss: 0.012053\n",
      "[323/00251] train_loss: 0.012091\n",
      "[323/00301] train_loss: 0.012403\n",
      "[323/00351] train_loss: 0.012175\n",
      "[323/00401] train_loss: 0.011645\n",
      "[323/00451] train_loss: 0.012329\n",
      "[323/00501] train_loss: 0.011650\n",
      "[323/00551] train_loss: 0.012091\n",
      "[323/00601] train_loss: 0.011429\n",
      "[323/00651] train_loss: 0.011828\n",
      "[323/00701] train_loss: 0.011443\n",
      "[323/00751] train_loss: 0.011710\n",
      "[323/00801] train_loss: 0.011891\n",
      "[323/00851] train_loss: 0.012019\n",
      "[323/00901] train_loss: 0.012117\n",
      "[323/00951] train_loss: 0.011882\n",
      "[323/01001] train_loss: 0.011437\n",
      "[323/01051] train_loss: 0.011794\n",
      "[323/01101] train_loss: 0.011608\n",
      "[323/01151] train_loss: 0.011383\n",
      "[323/01201] train_loss: 0.011808\n",
      "[324/00025] train_loss: 0.011437\n",
      "[324/00075] train_loss: 0.011862\n",
      "[324/00125] train_loss: 0.012245\n",
      "[324/00175] train_loss: 0.011603\n",
      "[324/00225] train_loss: 0.012275\n",
      "[324/00275] train_loss: 0.011725\n",
      "[324/00325] train_loss: 0.011207\n",
      "[324/00375] train_loss: 0.011485\n",
      "[324/00425] train_loss: 0.011879\n",
      "[324/00475] train_loss: 0.012804\n",
      "[324/00525] train_loss: 0.011861\n",
      "[324/00575] train_loss: 0.011790\n",
      "[324/00625] train_loss: 0.011669\n",
      "[324/00675] train_loss: 0.011239\n",
      "[324/00725] train_loss: 0.011327\n",
      "[324/00775] train_loss: 0.011474\n",
      "[324/00825] train_loss: 0.011409\n",
      "[324/00875] train_loss: 0.011910\n",
      "[324/00925] train_loss: 0.012270\n",
      "[324/00975] train_loss: 0.011946\n",
      "[324/01025] train_loss: 0.012653\n",
      "[324/01075] train_loss: 0.011609\n",
      "[324/01125] train_loss: 0.011562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[324/01175] train_loss: 0.011639\n",
      "[324/01225] train_loss: 0.011187\n",
      "[325/00049] train_loss: 0.012204\n",
      "[325/00099] train_loss: 0.012290\n",
      "[325/00149] train_loss: 0.012775\n",
      "[325/00199] train_loss: 0.012474\n",
      "[325/00249] train_loss: 0.011746\n",
      "[325/00299] train_loss: 0.012564\n",
      "[325/00349] train_loss: 0.012364\n",
      "[325/00399] train_loss: 0.011588\n",
      "[325/00449] train_loss: 0.011820\n",
      "[325/00499] train_loss: 0.011988\n",
      "[325/00549] train_loss: 0.012109\n",
      "[325/00599] train_loss: 0.011138\n",
      "[325/00649] train_loss: 0.011848\n",
      "[325/00699] train_loss: 0.011986\n",
      "[325/00749] train_loss: 0.012253\n",
      "[325/00799] train_loss: 0.012918\n",
      "[325/00849] train_loss: 0.012260\n",
      "[325/00899] train_loss: 0.011186\n",
      "[325/00949] train_loss: 0.011916\n",
      "[325/00999] train_loss: 0.012287\n",
      "[325/01049] train_loss: 0.012064\n",
      "[325/01099] train_loss: 0.010675\n",
      "[325/01149] train_loss: 0.011733\n",
      "[325/01199] train_loss: 0.011277\n",
      "[326/00023] train_loss: 0.012308\n",
      "[326/00073] train_loss: 0.011750\n",
      "[326/00123] train_loss: 0.012143\n",
      "[326/00173] train_loss: 0.012143\n",
      "[326/00223] train_loss: 0.012327\n",
      "[326/00273] train_loss: 0.012027\n",
      "[326/00323] train_loss: 0.011237\n",
      "[326/00373] train_loss: 0.011821\n",
      "[326/00423] train_loss: 0.011796\n",
      "[326/00473] train_loss: 0.011309\n",
      "[326/00523] train_loss: 0.012279\n",
      "[326/00573] train_loss: 0.011813\n",
      "[326/00623] train_loss: 0.011948\n",
      "[326/00673] train_loss: 0.011882\n",
      "[326/00723] train_loss: 0.011759\n",
      "[326/00773] train_loss: 0.011664\n",
      "[326/00823] train_loss: 0.011352\n",
      "[326/00873] train_loss: 0.011990\n",
      "[326/00923] train_loss: 0.011483\n",
      "[326/00973] train_loss: 0.011649\n",
      "[326/01023] train_loss: 0.011436\n",
      "[326/01073] train_loss: 0.011681\n",
      "[326/01123] train_loss: 0.011308\n",
      "[326/01173] train_loss: 0.011868\n",
      "[326/01223] train_loss: 0.012157\n",
      "[327/00047] train_loss: 0.012630\n",
      "[327/00097] train_loss: 0.012501\n",
      "[327/00147] train_loss: 0.011563\n",
      "[327/00197] train_loss: 0.012343\n",
      "[327/00247] train_loss: 0.012275\n",
      "[327/00297] train_loss: 0.012255\n",
      "[327/00347] train_loss: 0.011874\n",
      "[327/00397] train_loss: 0.011836\n",
      "[327/00447] train_loss: 0.012050\n",
      "[327/00497] train_loss: 0.011971\n",
      "[327/00547] train_loss: 0.011737\n",
      "[327/00597] train_loss: 0.011880\n",
      "[327/00647] train_loss: 0.012063\n",
      "[327/00697] train_loss: 0.011835\n",
      "[327/00747] train_loss: 0.012295\n",
      "[327/00797] train_loss: 0.011237\n",
      "[327/00847] train_loss: 0.011723\n",
      "[327/00897] train_loss: 0.012059\n",
      "[327/00947] train_loss: 0.011521\n",
      "[327/00997] train_loss: 0.012083\n",
      "[327/01047] train_loss: 0.011346\n",
      "[327/01097] train_loss: 0.011293\n",
      "[327/01147] train_loss: 0.011323\n",
      "[327/01197] train_loss: 0.011937\n",
      "[328/00021] train_loss: 0.012160\n",
      "[328/00071] train_loss: 0.012255\n",
      "[328/00121] train_loss: 0.011896\n",
      "[328/00171] train_loss: 0.012241\n",
      "[328/00221] train_loss: 0.012447\n",
      "[328/00271] train_loss: 0.011911\n",
      "[328/00321] train_loss: 0.011770\n",
      "[328/00371] train_loss: 0.011735\n",
      "[328/00421] train_loss: 0.011736\n",
      "[328/00471] train_loss: 0.012154\n",
      "[328/00521] train_loss: 0.011760\n",
      "[328/00571] train_loss: 0.010838\n",
      "[328/00621] train_loss: 0.012126\n",
      "[328/00671] train_loss: 0.011769\n",
      "[328/00721] train_loss: 0.011071\n",
      "[328/00771] train_loss: 0.012088\n",
      "[328/00821] train_loss: 0.011464\n",
      "[328/00871] train_loss: 0.011239\n",
      "[328/00921] train_loss: 0.011738\n",
      "[328/00971] train_loss: 0.011759\n",
      "[328/01021] train_loss: 0.012389\n",
      "[328/01071] train_loss: 0.011277\n",
      "[328/01121] train_loss: 0.012317\n",
      "[328/01171] train_loss: 0.011382\n",
      "[328/01221] train_loss: 0.011665\n",
      "[329/00045] train_loss: 0.011708\n",
      "[329/00095] train_loss: 0.013288\n",
      "[329/00145] train_loss: 0.012375\n",
      "[329/00195] train_loss: 0.012476\n",
      "[329/00245] train_loss: 0.011963\n",
      "[329/00295] train_loss: 0.012580\n",
      "[329/00345] train_loss: 0.011355\n",
      "[329/00395] train_loss: 0.011557\n",
      "[329/00445] train_loss: 0.012202\n",
      "[329/00495] train_loss: 0.011175\n",
      "[329/00545] train_loss: 0.012030\n",
      "[329/00595] train_loss: 0.012417\n",
      "[329/00645] train_loss: 0.012254\n",
      "[329/00695] train_loss: 0.012031\n",
      "[329/00745] train_loss: 0.011712\n",
      "[329/00795] train_loss: 0.011871\n",
      "[329/00845] train_loss: 0.011218\n",
      "[329/00895] train_loss: 0.012162\n",
      "[329/00945] train_loss: 0.012661\n",
      "[329/00995] train_loss: 0.011789\n",
      "[329/01045] train_loss: 0.011389\n",
      "[329/01095] train_loss: 0.011021\n",
      "[329/01145] train_loss: 0.011376\n",
      "[329/01195] train_loss: 0.011855\n",
      "[330/00019] train_loss: 0.011911\n",
      "[330/00069] train_loss: 0.012149\n",
      "[330/00119] train_loss: 0.012515\n",
      "[330/00169] train_loss: 0.012580\n",
      "[330/00219] train_loss: 0.012481\n",
      "[330/00269] train_loss: 0.012268\n",
      "[330/00319] train_loss: 0.011582\n",
      "[330/00369] train_loss: 0.011941\n",
      "[330/00419] train_loss: 0.011030\n",
      "[330/00469] train_loss: 0.011822\n",
      "[330/00519] train_loss: 0.011497\n",
      "[330/00569] train_loss: 0.011909\n",
      "[330/00619] train_loss: 0.012366\n",
      "[330/00669] train_loss: 0.011772\n",
      "[330/00719] train_loss: 0.011892\n",
      "[330/00769] train_loss: 0.011841\n",
      "[330/00819] train_loss: 0.011139\n",
      "[330/00869] train_loss: 0.010897\n",
      "[330/00919] train_loss: 0.011935\n",
      "[330/00969] train_loss: 0.011978\n",
      "[330/01019] train_loss: 0.011377\n",
      "[330/01069] train_loss: 0.011877\n",
      "[330/01119] train_loss: 0.011673\n",
      "[330/01169] train_loss: 0.011317\n",
      "[330/01219] train_loss: 0.011432\n",
      "[331/00043] train_loss: 0.011990\n",
      "[331/00093] train_loss: 0.011767\n",
      "[331/00143] train_loss: 0.011958\n",
      "[331/00193] train_loss: 0.012421\n",
      "[331/00243] train_loss: 0.012449\n",
      "[331/00293] train_loss: 0.011743\n",
      "[331/00343] train_loss: 0.012406\n",
      "[331/00393] train_loss: 0.011606\n",
      "[331/00443] train_loss: 0.011543\n",
      "[331/00493] train_loss: 0.011487\n",
      "[331/00543] train_loss: 0.011970\n",
      "[331/00593] train_loss: 0.011061\n",
      "[331/00643] train_loss: 0.012115\n",
      "[331/00693] train_loss: 0.012096\n",
      "[331/00743] train_loss: 0.012465\n",
      "[331/00793] train_loss: 0.011799\n",
      "[331/00843] train_loss: 0.011998\n",
      "[331/00893] train_loss: 0.011532\n",
      "[331/00943] train_loss: 0.012067\n",
      "[331/00993] train_loss: 0.011651\n",
      "[331/01043] train_loss: 0.012131\n",
      "[331/01093] train_loss: 0.011452\n",
      "[331/01143] train_loss: 0.011835\n",
      "[331/01193] train_loss: 0.011772\n",
      "[332/00017] train_loss: 0.011639\n",
      "[332/00067] train_loss: 0.011992\n",
      "[332/00117] train_loss: 0.012163\n",
      "[332/00167] train_loss: 0.012229\n",
      "[332/00217] train_loss: 0.011735\n",
      "[332/00267] train_loss: 0.011891\n",
      "[332/00317] train_loss: 0.012870\n",
      "[332/00367] train_loss: 0.011745\n",
      "[332/00417] train_loss: 0.012000\n",
      "[332/00467] train_loss: 0.012258\n",
      "[332/00517] train_loss: 0.011473\n",
      "[332/00567] train_loss: 0.011806\n",
      "[332/00617] train_loss: 0.012069\n",
      "[332/00667] train_loss: 0.011037\n",
      "[332/00717] train_loss: 0.011834\n",
      "[332/00767] train_loss: 0.011425\n",
      "[332/00817] train_loss: 0.011081\n",
      "[332/00867] train_loss: 0.010924\n",
      "[332/00917] train_loss: 0.011637\n",
      "[332/00967] train_loss: 0.011629\n",
      "[332/01017] train_loss: 0.011455\n",
      "[332/01067] train_loss: 0.011513\n",
      "[332/01117] train_loss: 0.010933\n",
      "[332/01167] train_loss: 0.011205\n",
      "[332/01217] train_loss: 0.011643\n",
      "[333/00041] train_loss: 0.012167\n",
      "[333/00091] train_loss: 0.012367\n",
      "[333/00141] train_loss: 0.011668\n",
      "[333/00191] train_loss: 0.011865\n",
      "[333/00241] train_loss: 0.012035\n",
      "[333/00291] train_loss: 0.012380\n",
      "[333/00341] train_loss: 0.012351\n",
      "[333/00391] train_loss: 0.011243\n",
      "[333/00441] train_loss: 0.012090\n",
      "[333/00491] train_loss: 0.012268\n",
      "[333/00541] train_loss: 0.012050\n",
      "[333/00591] train_loss: 0.011824\n",
      "[333/00641] train_loss: 0.011224\n",
      "[333/00691] train_loss: 0.012139\n",
      "[333/00741] train_loss: 0.011586\n",
      "[333/00791] train_loss: 0.012072\n",
      "[333/00841] train_loss: 0.011392\n",
      "[333/00891] train_loss: 0.011615\n",
      "[333/00941] train_loss: 0.011702\n",
      "[333/00991] train_loss: 0.011379\n",
      "[333/01041] train_loss: 0.011313\n",
      "[333/01091] train_loss: 0.012012\n",
      "[333/01141] train_loss: 0.012275\n",
      "[333/01191] train_loss: 0.011287\n",
      "[334/00015] train_loss: 0.011453\n",
      "[334/00065] train_loss: 0.012042\n",
      "[334/00115] train_loss: 0.012072\n",
      "[334/00165] train_loss: 0.011841\n",
      "[334/00215] train_loss: 0.011388\n",
      "[334/00265] train_loss: 0.012228\n",
      "[334/00315] train_loss: 0.011994\n",
      "[334/00365] train_loss: 0.011185\n",
      "[334/00415] train_loss: 0.011921\n",
      "[334/00465] train_loss: 0.011057\n",
      "[334/00515] train_loss: 0.012012\n",
      "[334/00565] train_loss: 0.011730\n",
      "[334/00615] train_loss: 0.011476\n",
      "[334/00665] train_loss: 0.012095\n",
      "[334/00715] train_loss: 0.010777\n",
      "[334/00765] train_loss: 0.011628\n",
      "[334/00815] train_loss: 0.011790\n",
      "[334/00865] train_loss: 0.011603\n",
      "[334/00915] train_loss: 0.011472\n",
      "[334/00965] train_loss: 0.011614\n",
      "[334/01015] train_loss: 0.012468\n",
      "[334/01065] train_loss: 0.011343\n",
      "[334/01115] train_loss: 0.011648\n",
      "[334/01165] train_loss: 0.011801\n",
      "[334/01215] train_loss: 0.012224\n",
      "[335/00039] train_loss: 0.012203\n",
      "[335/00089] train_loss: 0.012396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[335/00139] train_loss: 0.012794\n",
      "[335/00189] train_loss: 0.012577\n",
      "[335/00239] train_loss: 0.011871\n",
      "[335/00289] train_loss: 0.011684\n",
      "[335/00339] train_loss: 0.011729\n",
      "[335/00389] train_loss: 0.011637\n",
      "[335/00439] train_loss: 0.011879\n",
      "[335/00489] train_loss: 0.012376\n",
      "[335/00539] train_loss: 0.010989\n",
      "[335/00589] train_loss: 0.011737\n",
      "[335/00639] train_loss: 0.011180\n",
      "[335/00689] train_loss: 0.012767\n",
      "[335/00739] train_loss: 0.011652\n",
      "[335/00789] train_loss: 0.012509\n",
      "[335/00839] train_loss: 0.011406\n",
      "[335/00889] train_loss: 0.011611\n",
      "[335/00939] train_loss: 0.012077\n",
      "[335/00989] train_loss: 0.011941\n",
      "[335/01039] train_loss: 0.012244\n",
      "[335/01089] train_loss: 0.011480\n",
      "[335/01139] train_loss: 0.012023\n",
      "[335/01189] train_loss: 0.011710\n",
      "[336/00013] train_loss: 0.011592\n",
      "[336/00063] train_loss: 0.012533\n",
      "[336/00113] train_loss: 0.011294\n",
      "[336/00163] train_loss: 0.011690\n",
      "[336/00213] train_loss: 0.011699\n",
      "[336/00263] train_loss: 0.012272\n",
      "[336/00313] train_loss: 0.012267\n",
      "[336/00363] train_loss: 0.011802\n",
      "[336/00413] train_loss: 0.012557\n",
      "[336/00463] train_loss: 0.012205\n",
      "[336/00513] train_loss: 0.011636\n",
      "[336/00563] train_loss: 0.011167\n",
      "[336/00613] train_loss: 0.011940\n",
      "[336/00663] train_loss: 0.011562\n",
      "[336/00713] train_loss: 0.012143\n",
      "[336/00763] train_loss: 0.011916\n",
      "[336/00813] train_loss: 0.011640\n",
      "[336/00863] train_loss: 0.012031\n",
      "[336/00913] train_loss: 0.010916\n",
      "[336/00963] train_loss: 0.011373\n",
      "[336/01013] train_loss: 0.011529\n",
      "[336/01063] train_loss: 0.011459\n",
      "[336/01113] train_loss: 0.011435\n",
      "[336/01163] train_loss: 0.011829\n",
      "[336/01213] train_loss: 0.011569\n",
      "[337/00037] train_loss: 0.012406\n",
      "[337/00087] train_loss: 0.011589\n",
      "[337/00137] train_loss: 0.012137\n",
      "[337/00187] train_loss: 0.012061\n",
      "[337/00237] train_loss: 0.011865\n",
      "[337/00287] train_loss: 0.011917\n",
      "[337/00337] train_loss: 0.011701\n",
      "[337/00387] train_loss: 0.011893\n",
      "[337/00437] train_loss: 0.011969\n",
      "[337/00487] train_loss: 0.012080\n",
      "[337/00537] train_loss: 0.012315\n",
      "[337/00587] train_loss: 0.011662\n",
      "[337/00637] train_loss: 0.011697\n",
      "[337/00687] train_loss: 0.011438\n",
      "[337/00737] train_loss: 0.011397\n",
      "[337/00787] train_loss: 0.012034\n",
      "[337/00837] train_loss: 0.012499\n",
      "[337/00887] train_loss: 0.011580\n",
      "[337/00937] train_loss: 0.011726\n",
      "[337/00987] train_loss: 0.011283\n",
      "[337/01037] train_loss: 0.011621\n",
      "[337/01087] train_loss: 0.011749\n",
      "[337/01137] train_loss: 0.012539\n",
      "[337/01187] train_loss: 0.011740\n",
      "[338/00011] train_loss: 0.012205\n",
      "[338/00061] train_loss: 0.012284\n",
      "[338/00111] train_loss: 0.012390\n",
      "[338/00161] train_loss: 0.012287\n",
      "[338/00211] train_loss: 0.011701\n",
      "[338/00261] train_loss: 0.012125\n",
      "[338/00311] train_loss: 0.012246\n",
      "[338/00361] train_loss: 0.011554\n",
      "[338/00411] train_loss: 0.012365\n",
      "[338/00461] train_loss: 0.011567\n",
      "[338/00511] train_loss: 0.012474\n",
      "[338/00561] train_loss: 0.011265\n",
      "[338/00611] train_loss: 0.012223\n",
      "[338/00661] train_loss: 0.011053\n",
      "[338/00711] train_loss: 0.011602\n",
      "[338/00761] train_loss: 0.011887\n",
      "[338/00811] train_loss: 0.011619\n",
      "[338/00861] train_loss: 0.010811\n",
      "[338/00911] train_loss: 0.011842\n",
      "[338/00961] train_loss: 0.011374\n",
      "[338/01011] train_loss: 0.011210\n",
      "[338/01061] train_loss: 0.011671\n",
      "[338/01111] train_loss: 0.011253\n",
      "[338/01161] train_loss: 0.011659\n",
      "[338/01211] train_loss: 0.011458\n",
      "[339/00035] train_loss: 0.011725\n",
      "[339/00085] train_loss: 0.011834\n",
      "[339/00135] train_loss: 0.012482\n",
      "[339/00185] train_loss: 0.011575\n",
      "[339/00235] train_loss: 0.012456\n",
      "[339/00285] train_loss: 0.011548\n",
      "[339/00335] train_loss: 0.011554\n",
      "[339/00385] train_loss: 0.012164\n",
      "[339/00435] train_loss: 0.012060\n",
      "[339/00485] train_loss: 0.011878\n",
      "[339/00535] train_loss: 0.011977\n",
      "[339/00585] train_loss: 0.011603\n",
      "[339/00635] train_loss: 0.011507\n",
      "[339/00685] train_loss: 0.011666\n",
      "[339/00735] train_loss: 0.011116\n",
      "[339/00785] train_loss: 0.011571\n",
      "[339/00835] train_loss: 0.012156\n",
      "[339/00885] train_loss: 0.011431\n",
      "[339/00935] train_loss: 0.011944\n",
      "[339/00985] train_loss: 0.011841\n",
      "[339/01035] train_loss: 0.011517\n",
      "[339/01085] train_loss: 0.011849\n",
      "[339/01135] train_loss: 0.012535\n",
      "[339/01185] train_loss: 0.011523\n",
      "[340/00009] train_loss: 0.011631\n",
      "[340/00059] train_loss: 0.012393\n",
      "[340/00109] train_loss: 0.011871\n",
      "[340/00159] train_loss: 0.011977\n",
      "[340/00209] train_loss: 0.011038\n",
      "[340/00259] train_loss: 0.012059\n",
      "[340/00309] train_loss: 0.012006\n",
      "[340/00359] train_loss: 0.011540\n",
      "[340/00409] train_loss: 0.011866\n",
      "[340/00459] train_loss: 0.011805\n",
      "[340/00509] train_loss: 0.011733\n",
      "[340/00559] train_loss: 0.011446\n",
      "[340/00609] train_loss: 0.012108\n",
      "[340/00659] train_loss: 0.011387\n",
      "[340/00709] train_loss: 0.012036\n",
      "[340/00759] train_loss: 0.011628\n",
      "[340/00809] train_loss: 0.012073\n",
      "[340/00859] train_loss: 0.012110\n",
      "[340/00909] train_loss: 0.011313\n",
      "[340/00959] train_loss: 0.011618\n",
      "[340/01009] train_loss: 0.011206\n",
      "[340/01059] train_loss: 0.012279\n",
      "[340/01109] train_loss: 0.011120\n",
      "[340/01159] train_loss: 0.011278\n",
      "[340/01209] train_loss: 0.011013\n",
      "[341/00033] train_loss: 0.012563\n",
      "[341/00083] train_loss: 0.012219\n",
      "[341/00133] train_loss: 0.011606\n",
      "[341/00183] train_loss: 0.011789\n",
      "[341/00233] train_loss: 0.012174\n",
      "[341/00283] train_loss: 0.011823\n",
      "[341/00333] train_loss: 0.011397\n",
      "[341/00383] train_loss: 0.012799\n",
      "[341/00433] train_loss: 0.011430\n",
      "[341/00483] train_loss: 0.012239\n",
      "[341/00533] train_loss: 0.011495\n",
      "[341/00583] train_loss: 0.011905\n",
      "[341/00633] train_loss: 0.011519\n",
      "[341/00683] train_loss: 0.012711\n",
      "[341/00733] train_loss: 0.011378\n",
      "[341/00783] train_loss: 0.011859\n",
      "[341/00833] train_loss: 0.011893\n",
      "[341/00883] train_loss: 0.012459\n",
      "[341/00933] train_loss: 0.012221\n",
      "[341/00983] train_loss: 0.012107\n",
      "[341/01033] train_loss: 0.011661\n",
      "[341/01083] train_loss: 0.011984\n",
      "[341/01133] train_loss: 0.011749\n",
      "[341/01183] train_loss: 0.011351\n",
      "[342/00007] train_loss: 0.010958\n",
      "[342/00057] train_loss: 0.012290\n",
      "[342/00107] train_loss: 0.011857\n",
      "[342/00157] train_loss: 0.011587\n",
      "[342/00207] train_loss: 0.012409\n",
      "[342/00257] train_loss: 0.012274\n",
      "[342/00307] train_loss: 0.012210\n",
      "[342/00357] train_loss: 0.011337\n",
      "[342/00407] train_loss: 0.011858\n",
      "[342/00457] train_loss: 0.011306\n",
      "[342/00507] train_loss: 0.011404\n",
      "[342/00557] train_loss: 0.012022\n",
      "[342/00607] train_loss: 0.011062\n",
      "[342/00657] train_loss: 0.011222\n",
      "[342/00707] train_loss: 0.011877\n",
      "[342/00757] train_loss: 0.011400\n",
      "[342/00807] train_loss: 0.011674\n",
      "[342/00857] train_loss: 0.011234\n",
      "[342/00907] train_loss: 0.011465\n",
      "[342/00957] train_loss: 0.012014\n",
      "[342/01007] train_loss: 0.012150\n",
      "[342/01057] train_loss: 0.011516\n",
      "[342/01107] train_loss: 0.011624\n",
      "[342/01157] train_loss: 0.011602\n",
      "[342/01207] train_loss: 0.012051\n",
      "[343/00031] train_loss: 0.011289\n",
      "[343/00081] train_loss: 0.012312\n",
      "[343/00131] train_loss: 0.012641\n",
      "[343/00181] train_loss: 0.011690\n",
      "[343/00231] train_loss: 0.011875\n",
      "[343/00281] train_loss: 0.011867\n",
      "[343/00331] train_loss: 0.011857\n",
      "[343/00381] train_loss: 0.012052\n",
      "[343/00431] train_loss: 0.012090\n",
      "[343/00481] train_loss: 0.011849\n",
      "[343/00531] train_loss: 0.011452\n",
      "[343/00581] train_loss: 0.011558\n",
      "[343/00631] train_loss: 0.011283\n",
      "[343/00681] train_loss: 0.011662\n",
      "[343/00731] train_loss: 0.011868\n",
      "[343/00781] train_loss: 0.012185\n",
      "[343/00831] train_loss: 0.011678\n",
      "[343/00881] train_loss: 0.011669\n",
      "[343/00931] train_loss: 0.011487\n",
      "[343/00981] train_loss: 0.011543\n",
      "[343/01031] train_loss: 0.011359\n",
      "[343/01081] train_loss: 0.012156\n",
      "[343/01131] train_loss: 0.011400\n",
      "[343/01181] train_loss: 0.011668\n",
      "[344/00005] train_loss: 0.011731\n",
      "[344/00055] train_loss: 0.011645\n",
      "[344/00105] train_loss: 0.011728\n",
      "[344/00155] train_loss: 0.012202\n",
      "[344/00205] train_loss: 0.011548\n",
      "[344/00255] train_loss: 0.012240\n",
      "[344/00305] train_loss: 0.011962\n",
      "[344/00355] train_loss: 0.012390\n",
      "[344/00405] train_loss: 0.011465\n",
      "[344/00455] train_loss: 0.011827\n",
      "[344/00505] train_loss: 0.012166\n",
      "[344/00555] train_loss: 0.012026\n",
      "[344/00605] train_loss: 0.011450\n",
      "[344/00655] train_loss: 0.012428\n",
      "[344/00705] train_loss: 0.011871\n",
      "[344/00755] train_loss: 0.012134\n",
      "[344/00805] train_loss: 0.011574\n",
      "[344/00855] train_loss: 0.011192\n",
      "[344/00905] train_loss: 0.011336\n",
      "[344/00955] train_loss: 0.011823\n",
      "[344/01005] train_loss: 0.011249\n",
      "[344/01055] train_loss: 0.011809\n",
      "[344/01105] train_loss: 0.011573\n",
      "[344/01155] train_loss: 0.011048\n",
      "[344/01205] train_loss: 0.012123\n",
      "[345/00029] train_loss: 0.011757\n",
      "[345/00079] train_loss: 0.012944\n",
      "[345/00129] train_loss: 0.011511\n",
      "[345/00179] train_loss: 0.011197\n",
      "[345/00229] train_loss: 0.011953\n",
      "[345/00279] train_loss: 0.012053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[345/00329] train_loss: 0.012377\n",
      "[345/00379] train_loss: 0.012369\n",
      "[345/00429] train_loss: 0.011793\n",
      "[345/00479] train_loss: 0.011746\n",
      "[345/00529] train_loss: 0.011384\n",
      "[345/00579] train_loss: 0.011439\n",
      "[345/00629] train_loss: 0.012408\n",
      "[345/00679] train_loss: 0.011648\n",
      "[345/00729] train_loss: 0.011533\n",
      "[345/00779] train_loss: 0.011311\n",
      "[345/00829] train_loss: 0.011497\n",
      "[345/00879] train_loss: 0.011552\n",
      "[345/00929] train_loss: 0.011199\n",
      "[345/00979] train_loss: 0.011636\n",
      "[345/01029] train_loss: 0.011525\n",
      "[345/01079] train_loss: 0.011394\n",
      "[345/01129] train_loss: 0.011676\n",
      "[345/01179] train_loss: 0.012180\n",
      "[346/00003] train_loss: 0.011563\n",
      "[346/00053] train_loss: 0.012327\n",
      "[346/00103] train_loss: 0.011370\n",
      "[346/00153] train_loss: 0.011453\n",
      "[346/00203] train_loss: 0.012441\n",
      "[346/00253] train_loss: 0.012909\n",
      "[346/00303] train_loss: 0.011727\n",
      "[346/00353] train_loss: 0.011735\n",
      "[346/00403] train_loss: 0.012692\n",
      "[346/00453] train_loss: 0.011554\n",
      "[346/00503] train_loss: 0.012330\n",
      "[346/00553] train_loss: 0.011312\n",
      "[346/00603] train_loss: 0.011429\n",
      "[346/00653] train_loss: 0.011801\n",
      "[346/00703] train_loss: 0.012009\n",
      "[346/00753] train_loss: 0.011061\n",
      "[346/00803] train_loss: 0.011638\n",
      "[346/00853] train_loss: 0.011465\n",
      "[346/00903] train_loss: 0.012347\n",
      "[346/00953] train_loss: 0.011098\n",
      "[346/01003] train_loss: 0.011599\n",
      "[346/01053] train_loss: 0.011143\n",
      "[346/01103] train_loss: 0.012076\n",
      "[346/01153] train_loss: 0.011535\n",
      "[346/01203] train_loss: 0.011604\n",
      "[347/00027] train_loss: 0.011816\n",
      "[347/00077] train_loss: 0.012116\n",
      "[347/00127] train_loss: 0.012282\n",
      "[347/00177] train_loss: 0.011436\n",
      "[347/00227] train_loss: 0.012073\n",
      "[347/00277] train_loss: 0.011670\n",
      "[347/00327] train_loss: 0.012264\n",
      "[347/00377] train_loss: 0.011216\n",
      "[347/00427] train_loss: 0.012080\n",
      "[347/00477] train_loss: 0.011282\n",
      "[347/00527] train_loss: 0.010904\n",
      "[347/00577] train_loss: 0.011685\n",
      "[347/00627] train_loss: 0.012312\n",
      "[347/00677] train_loss: 0.011274\n",
      "[347/00727] train_loss: 0.012222\n",
      "[347/00777] train_loss: 0.011697\n",
      "[347/00827] train_loss: 0.012532\n",
      "[347/00877] train_loss: 0.011541\n",
      "[347/00927] train_loss: 0.011146\n",
      "[347/00977] train_loss: 0.011536\n",
      "[347/01027] train_loss: 0.011074\n",
      "[347/01077] train_loss: 0.012008\n",
      "[347/01127] train_loss: 0.011611\n",
      "[347/01177] train_loss: 0.011299\n",
      "[348/00001] train_loss: 0.011625\n",
      "[348/00051] train_loss: 0.012449\n",
      "[348/00101] train_loss: 0.012578\n",
      "[348/00151] train_loss: 0.012447\n",
      "[348/00201] train_loss: 0.012438\n",
      "[348/00251] train_loss: 0.012328\n",
      "[348/00301] train_loss: 0.012157\n",
      "[348/00351] train_loss: 0.011615\n",
      "[348/00401] train_loss: 0.012336\n",
      "[348/00451] train_loss: 0.011830\n",
      "[348/00501] train_loss: 0.011726\n",
      "[348/00551] train_loss: 0.012130\n",
      "[348/00601] train_loss: 0.011415\n",
      "[348/00651] train_loss: 0.011626\n",
      "[348/00701] train_loss: 0.011066\n",
      "[348/00751] train_loss: 0.011705\n",
      "[348/00801] train_loss: 0.010885\n",
      "[348/00851] train_loss: 0.011867\n",
      "[348/00901] train_loss: 0.011651\n",
      "[348/00951] train_loss: 0.012232\n",
      "[348/01001] train_loss: 0.011160\n",
      "[348/01051] train_loss: 0.011260\n",
      "[348/01101] train_loss: 0.011492\n",
      "[348/01151] train_loss: 0.011455\n",
      "[348/01201] train_loss: 0.011493\n",
      "[349/00025] train_loss: 0.011723\n",
      "[349/00075] train_loss: 0.012922\n",
      "[349/00125] train_loss: 0.012037\n",
      "[349/00175] train_loss: 0.011754\n",
      "[349/00225] train_loss: 0.011398\n",
      "[349/00275] train_loss: 0.011572\n",
      "[349/00325] train_loss: 0.012044\n",
      "[349/00375] train_loss: 0.011300\n",
      "[349/00425] train_loss: 0.011307\n",
      "[349/00475] train_loss: 0.012207\n",
      "[349/00525] train_loss: 0.011395\n",
      "[349/00575] train_loss: 0.011760\n",
      "[349/00625] train_loss: 0.012357\n",
      "[349/00675] train_loss: 0.011748\n",
      "[349/00725] train_loss: 0.012178\n",
      "[349/00775] train_loss: 0.011529\n",
      "[349/00825] train_loss: 0.011123\n",
      "[349/00875] train_loss: 0.011290\n",
      "[349/00925] train_loss: 0.011583\n",
      "[349/00975] train_loss: 0.011799\n",
      "[349/01025] train_loss: 0.011937\n",
      "[349/01075] train_loss: 0.011698\n",
      "[349/01125] train_loss: 0.011539\n",
      "[349/01175] train_loss: 0.011264\n",
      "[349/01225] train_loss: 0.011716\n",
      "[350/00049] train_loss: 0.012194\n",
      "[350/00099] train_loss: 0.011820\n",
      "[350/00149] train_loss: 0.011476\n",
      "[350/00199] train_loss: 0.012376\n",
      "[350/00249] train_loss: 0.010973\n",
      "[350/00299] train_loss: 0.011759\n",
      "[350/00349] train_loss: 0.012013\n",
      "[350/00399] train_loss: 0.011591\n",
      "[350/00449] train_loss: 0.011131\n",
      "[350/00499] train_loss: 0.011658\n",
      "[350/00549] train_loss: 0.011208\n",
      "[350/00599] train_loss: 0.011429\n",
      "[350/00649] train_loss: 0.011458\n",
      "[350/00699] train_loss: 0.011589\n",
      "[350/00749] train_loss: 0.012701\n",
      "[350/00799] train_loss: 0.011065\n",
      "[350/00849] train_loss: 0.011662\n",
      "[350/00899] train_loss: 0.011411\n",
      "[350/00949] train_loss: 0.011794\n",
      "[350/00999] train_loss: 0.010749\n",
      "[350/01049] train_loss: 0.011332\n",
      "[350/01099] train_loss: 0.011544\n",
      "[350/01149] train_loss: 0.011666\n",
      "[350/01199] train_loss: 0.012410\n",
      "[351/00023] train_loss: 0.012323\n",
      "[351/00073] train_loss: 0.011741\n",
      "[351/00123] train_loss: 0.011792\n",
      "[351/00173] train_loss: 0.012485\n",
      "[351/00223] train_loss: 0.012435\n",
      "[351/00273] train_loss: 0.012086\n",
      "[351/00323] train_loss: 0.011568\n",
      "[351/00373] train_loss: 0.011769\n",
      "[351/00423] train_loss: 0.012117\n",
      "[351/00473] train_loss: 0.012190\n",
      "[351/00523] train_loss: 0.010947\n",
      "[351/00573] train_loss: 0.011872\n",
      "[351/00623] train_loss: 0.011695\n",
      "[351/00673] train_loss: 0.011998\n",
      "[351/00723] train_loss: 0.011926\n",
      "[351/00773] train_loss: 0.012083\n",
      "[351/00823] train_loss: 0.012145\n",
      "[351/00873] train_loss: 0.011498\n",
      "[351/00923] train_loss: 0.011157\n",
      "[351/00973] train_loss: 0.011568\n",
      "[351/01023] train_loss: 0.011746\n",
      "[351/01073] train_loss: 0.011323\n",
      "[351/01123] train_loss: 0.012349\n",
      "[351/01173] train_loss: 0.011540\n",
      "[351/01223] train_loss: 0.011783\n",
      "[352/00047] train_loss: 0.012251\n",
      "[352/00097] train_loss: 0.011775\n",
      "[352/00147] train_loss: 0.012513\n",
      "[352/00197] train_loss: 0.011624\n",
      "[352/00247] train_loss: 0.011765\n",
      "[352/00297] train_loss: 0.012685\n",
      "[352/00347] train_loss: 0.011733\n",
      "[352/00397] train_loss: 0.011812\n",
      "[352/00447] train_loss: 0.011889\n",
      "[352/00497] train_loss: 0.011493\n",
      "[352/00547] train_loss: 0.011506\n",
      "[352/00597] train_loss: 0.012095\n",
      "[352/00647] train_loss: 0.011749\n",
      "[352/00697] train_loss: 0.011183\n",
      "[352/00747] train_loss: 0.011371\n",
      "[352/00797] train_loss: 0.011516\n",
      "[352/00847] train_loss: 0.011466\n",
      "[352/00897] train_loss: 0.011509\n",
      "[352/00947] train_loss: 0.011289\n",
      "[352/00997] train_loss: 0.011225\n",
      "[352/01047] train_loss: 0.011623\n",
      "[352/01097] train_loss: 0.010679\n",
      "[352/01147] train_loss: 0.012197\n",
      "[352/01197] train_loss: 0.011655\n",
      "[353/00021] train_loss: 0.012283\n",
      "[353/00071] train_loss: 0.011820\n",
      "[353/00121] train_loss: 0.012004\n",
      "[353/00171] train_loss: 0.012667\n",
      "[353/00221] train_loss: 0.012176\n",
      "[353/00271] train_loss: 0.012319\n",
      "[353/00321] train_loss: 0.011362\n",
      "[353/00371] train_loss: 0.011757\n",
      "[353/00421] train_loss: 0.012079\n",
      "[353/00471] train_loss: 0.011494\n",
      "[353/00521] train_loss: 0.011764\n",
      "[353/00571] train_loss: 0.011984\n",
      "[353/00621] train_loss: 0.012071\n",
      "[353/00671] train_loss: 0.010997\n",
      "[353/00721] train_loss: 0.011797\n",
      "[353/00771] train_loss: 0.011104\n",
      "[353/00821] train_loss: 0.011513\n",
      "[353/00871] train_loss: 0.011732\n",
      "[353/00921] train_loss: 0.011999\n",
      "[353/00971] train_loss: 0.011798\n",
      "[353/01021] train_loss: 0.011881\n",
      "[353/01071] train_loss: 0.011717\n",
      "[353/01121] train_loss: 0.011534\n",
      "[353/01171] train_loss: 0.011180\n",
      "[353/01221] train_loss: 0.011476\n",
      "[354/00045] train_loss: 0.012863\n",
      "[354/00095] train_loss: 0.011680\n",
      "[354/00145] train_loss: 0.011967\n",
      "[354/00195] train_loss: 0.012104\n",
      "[354/00245] train_loss: 0.012389\n",
      "[354/00295] train_loss: 0.012124\n",
      "[354/00345] train_loss: 0.011216\n",
      "[354/00395] train_loss: 0.011074\n",
      "[354/00445] train_loss: 0.011501\n",
      "[354/00495] train_loss: 0.011492\n",
      "[354/00545] train_loss: 0.010909\n",
      "[354/00595] train_loss: 0.011291\n",
      "[354/00645] train_loss: 0.011411\n",
      "[354/00695] train_loss: 0.012098\n",
      "[354/00745] train_loss: 0.011198\n",
      "[354/00795] train_loss: 0.011921\n",
      "[354/00845] train_loss: 0.011976\n",
      "[354/00895] train_loss: 0.011333\n",
      "[354/00945] train_loss: 0.011204\n",
      "[354/00995] train_loss: 0.012046\n",
      "[354/01045] train_loss: 0.011686\n",
      "[354/01095] train_loss: 0.011209\n",
      "[354/01145] train_loss: 0.011506\n",
      "[354/01195] train_loss: 0.011721\n",
      "[355/00019] train_loss: 0.011368\n",
      "[355/00069] train_loss: 0.012456\n",
      "[355/00119] train_loss: 0.011773\n",
      "[355/00169] train_loss: 0.012037\n",
      "[355/00219] train_loss: 0.012098\n",
      "[355/00269] train_loss: 0.011502\n",
      "[355/00319] train_loss: 0.010899\n",
      "[355/00369] train_loss: 0.011927\n",
      "[355/00419] train_loss: 0.011776\n",
      "[355/00469] train_loss: 0.011891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[355/00519] train_loss: 0.011802\n",
      "[355/00569] train_loss: 0.011422\n",
      "[355/00619] train_loss: 0.011869\n",
      "[355/00669] train_loss: 0.011650\n",
      "[355/00719] train_loss: 0.012222\n",
      "[355/00769] train_loss: 0.011553\n",
      "[355/00819] train_loss: 0.010887\n",
      "[355/00869] train_loss: 0.011290\n",
      "[355/00919] train_loss: 0.011304\n",
      "[355/00969] train_loss: 0.011691\n",
      "[355/01019] train_loss: 0.011407\n",
      "[355/01069] train_loss: 0.012271\n",
      "[355/01119] train_loss: 0.011631\n",
      "[355/01169] train_loss: 0.011456\n",
      "[355/01219] train_loss: 0.011364\n",
      "[356/00043] train_loss: 0.011803\n",
      "[356/00093] train_loss: 0.012015\n",
      "[356/00143] train_loss: 0.011517\n",
      "[356/00193] train_loss: 0.012120\n",
      "[356/00243] train_loss: 0.011490\n",
      "[356/00293] train_loss: 0.011779\n",
      "[356/00343] train_loss: 0.011496\n",
      "[356/00393] train_loss: 0.011084\n",
      "[356/00443] train_loss: 0.011369\n",
      "[356/00493] train_loss: 0.011770\n",
      "[356/00543] train_loss: 0.011609\n",
      "[356/00593] train_loss: 0.011097\n",
      "[356/00643] train_loss: 0.011834\n",
      "[356/00693] train_loss: 0.011099\n",
      "[356/00743] train_loss: 0.011155\n",
      "[356/00793] train_loss: 0.011342\n",
      "[356/00843] train_loss: 0.011685\n",
      "[356/00893] train_loss: 0.011959\n",
      "[356/00943] train_loss: 0.012260\n",
      "[356/00993] train_loss: 0.011653\n",
      "[356/01043] train_loss: 0.011901\n",
      "[356/01093] train_loss: 0.011443\n",
      "[356/01143] train_loss: 0.011358\n",
      "[356/01193] train_loss: 0.011380\n",
      "[357/00017] train_loss: 0.011425\n",
      "[357/00067] train_loss: 0.011769\n",
      "[357/00117] train_loss: 0.012995\n",
      "[357/00167] train_loss: 0.011991\n",
      "[357/00217] train_loss: 0.011567\n",
      "[357/00267] train_loss: 0.011519\n",
      "[357/00317] train_loss: 0.012346\n",
      "[357/00367] train_loss: 0.012012\n",
      "[357/00417] train_loss: 0.012030\n",
      "[357/00467] train_loss: 0.011990\n",
      "[357/00517] train_loss: 0.011450\n",
      "[357/00567] train_loss: 0.011656\n",
      "[357/00617] train_loss: 0.011453\n",
      "[357/00667] train_loss: 0.011830\n",
      "[357/00717] train_loss: 0.011480\n",
      "[357/00767] train_loss: 0.012497\n",
      "[357/00817] train_loss: 0.011906\n",
      "[357/00867] train_loss: 0.011143\n",
      "[357/00917] train_loss: 0.011587\n",
      "[357/00967] train_loss: 0.011160\n",
      "[357/01017] train_loss: 0.011825\n",
      "[357/01067] train_loss: 0.011588\n",
      "[357/01117] train_loss: 0.011641\n",
      "[357/01167] train_loss: 0.011980\n",
      "[357/01217] train_loss: 0.012780\n",
      "[358/00041] train_loss: 0.012397\n",
      "[358/00091] train_loss: 0.012487\n",
      "[358/00141] train_loss: 0.011498\n",
      "[358/00191] train_loss: 0.011315\n",
      "[358/00241] train_loss: 0.011208\n",
      "[358/00291] train_loss: 0.012817\n",
      "[358/00341] train_loss: 0.011258\n",
      "[358/00391] train_loss: 0.011153\n",
      "[358/00441] train_loss: 0.011194\n",
      "[358/00491] train_loss: 0.011862\n",
      "[358/00541] train_loss: 0.010965\n",
      "[358/00591] train_loss: 0.011706\n",
      "[358/00641] train_loss: 0.011991\n",
      "[358/00691] train_loss: 0.011397\n",
      "[358/00741] train_loss: 0.011362\n",
      "[358/00791] train_loss: 0.011184\n",
      "[358/00841] train_loss: 0.011496\n",
      "[358/00891] train_loss: 0.011395\n",
      "[358/00941] train_loss: 0.011681\n",
      "[358/00991] train_loss: 0.011136\n",
      "[358/01041] train_loss: 0.011642\n",
      "[358/01091] train_loss: 0.011878\n",
      "[358/01141] train_loss: 0.011805\n",
      "[358/01191] train_loss: 0.011679\n",
      "[359/00015] train_loss: 0.012221\n",
      "[359/00065] train_loss: 0.012208\n",
      "[359/00115] train_loss: 0.011714\n",
      "[359/00165] train_loss: 0.012682\n",
      "[359/00215] train_loss: 0.012037\n",
      "[359/00265] train_loss: 0.012963\n",
      "[359/00315] train_loss: 0.011494\n",
      "[359/00365] train_loss: 0.011701\n",
      "[359/00415] train_loss: 0.011735\n",
      "[359/00465] train_loss: 0.011931\n",
      "[359/00515] train_loss: 0.011552\n",
      "[359/00565] train_loss: 0.011772\n",
      "[359/00615] train_loss: 0.011882\n",
      "[359/00665] train_loss: 0.011058\n",
      "[359/00715] train_loss: 0.010941\n",
      "[359/00765] train_loss: 0.012649\n",
      "[359/00815] train_loss: 0.011404\n",
      "[359/00865] train_loss: 0.011566\n",
      "[359/00915] train_loss: 0.011437\n",
      "[359/00965] train_loss: 0.011822\n",
      "[359/01015] train_loss: 0.011511\n",
      "[359/01065] train_loss: 0.012092\n",
      "[359/01115] train_loss: 0.011686\n",
      "[359/01165] train_loss: 0.011365\n",
      "[359/01215] train_loss: 0.011292\n",
      "[360/00039] train_loss: 0.012254\n",
      "[360/00089] train_loss: 0.011781\n",
      "[360/00139] train_loss: 0.012211\n",
      "[360/00189] train_loss: 0.011678\n",
      "[360/00239] train_loss: 0.011409\n",
      "[360/00289] train_loss: 0.011786\n",
      "[360/00339] train_loss: 0.011808\n",
      "[360/00389] train_loss: 0.011563\n",
      "[360/00439] train_loss: 0.011907\n",
      "[360/00489] train_loss: 0.011665\n",
      "[360/00539] train_loss: 0.011414\n",
      "[360/00589] train_loss: 0.011733\n",
      "[360/00639] train_loss: 0.011221\n",
      "[360/00689] train_loss: 0.012518\n",
      "[360/00739] train_loss: 0.011429\n",
      "[360/00789] train_loss: 0.010850\n",
      "[360/00839] train_loss: 0.011481\n",
      "[360/00889] train_loss: 0.011086\n",
      "[360/00939] train_loss: 0.012059\n",
      "[360/00989] train_loss: 0.011286\n",
      "[360/01039] train_loss: 0.011185\n",
      "[360/01089] train_loss: 0.011326\n",
      "[360/01139] train_loss: 0.012526\n",
      "[360/01189] train_loss: 0.011333\n",
      "[361/00013] train_loss: 0.012356\n",
      "[361/00063] train_loss: 0.011722\n",
      "[361/00113] train_loss: 0.011427\n",
      "[361/00163] train_loss: 0.011957\n",
      "[361/00213] train_loss: 0.011796\n",
      "[361/00263] train_loss: 0.012120\n",
      "[361/00313] train_loss: 0.011624\n",
      "[361/00363] train_loss: 0.011734\n",
      "[361/00413] train_loss: 0.012439\n",
      "[361/00463] train_loss: 0.011537\n",
      "[361/00513] train_loss: 0.011310\n",
      "[361/00563] train_loss: 0.012095\n",
      "[361/00613] train_loss: 0.011577\n",
      "[361/00663] train_loss: 0.011434\n",
      "[361/00713] train_loss: 0.011956\n",
      "[361/00763] train_loss: 0.012292\n",
      "[361/00813] train_loss: 0.011879\n",
      "[361/00863] train_loss: 0.011851\n",
      "[361/00913] train_loss: 0.011060\n",
      "[361/00963] train_loss: 0.011919\n",
      "[361/01013] train_loss: 0.011668\n",
      "[361/01063] train_loss: 0.011914\n",
      "[361/01113] train_loss: 0.011676\n",
      "[361/01163] train_loss: 0.010750\n",
      "[361/01213] train_loss: 0.011327\n",
      "[362/00037] train_loss: 0.011920\n",
      "[362/00087] train_loss: 0.012363\n",
      "[362/00137] train_loss: 0.011127\n",
      "[362/00187] train_loss: 0.011988\n",
      "[362/00237] train_loss: 0.011920\n",
      "[362/00287] train_loss: 0.012153\n",
      "[362/00337] train_loss: 0.012033\n",
      "[362/00387] train_loss: 0.011778\n",
      "[362/00437] train_loss: 0.011641\n",
      "[362/00487] train_loss: 0.011416\n",
      "[362/00537] train_loss: 0.011904\n",
      "[362/00587] train_loss: 0.011393\n",
      "[362/00637] train_loss: 0.012242\n",
      "[362/00687] train_loss: 0.011144\n",
      "[362/00737] train_loss: 0.011127\n",
      "[362/00787] train_loss: 0.011618\n",
      "[362/00837] train_loss: 0.011789\n",
      "[362/00887] train_loss: 0.011392\n",
      "[362/00937] train_loss: 0.011433\n",
      "[362/00987] train_loss: 0.011169\n",
      "[362/01037] train_loss: 0.010636\n",
      "[362/01087] train_loss: 0.011605\n",
      "[362/01137] train_loss: 0.011385\n",
      "[362/01187] train_loss: 0.011296\n",
      "[363/00011] train_loss: 0.011364\n",
      "[363/00061] train_loss: 0.012298\n",
      "[363/00111] train_loss: 0.012058\n",
      "[363/00161] train_loss: 0.012338\n",
      "[363/00211] train_loss: 0.012016\n",
      "[363/00261] train_loss: 0.011969\n",
      "[363/00311] train_loss: 0.011079\n",
      "[363/00361] train_loss: 0.011816\n",
      "[363/00411] train_loss: 0.012056\n",
      "[363/00461] train_loss: 0.012324\n",
      "[363/00511] train_loss: 0.011557\n",
      "[363/00561] train_loss: 0.010838\n",
      "[363/00611] train_loss: 0.011382\n",
      "[363/00661] train_loss: 0.011827\n",
      "[363/00711] train_loss: 0.011558\n",
      "[363/00761] train_loss: 0.011493\n",
      "[363/00811] train_loss: 0.011856\n",
      "[363/00861] train_loss: 0.011679\n",
      "[363/00911] train_loss: 0.011548\n",
      "[363/00961] train_loss: 0.011852\n",
      "[363/01011] train_loss: 0.012234\n",
      "[363/01061] train_loss: 0.011186\n",
      "[363/01111] train_loss: 0.011793\n",
      "[363/01161] train_loss: 0.011770\n",
      "[363/01211] train_loss: 0.011482\n",
      "[364/00035] train_loss: 0.012393\n",
      "[364/00085] train_loss: 0.012083\n",
      "[364/00135] train_loss: 0.011418\n",
      "[364/00185] train_loss: 0.012399\n",
      "[364/00235] train_loss: 0.012103\n",
      "[364/00285] train_loss: 0.011098\n",
      "[364/00335] train_loss: 0.011613\n",
      "[364/00385] train_loss: 0.011997\n",
      "[364/00435] train_loss: 0.011503\n",
      "[364/00485] train_loss: 0.011323\n",
      "[364/00535] train_loss: 0.011865\n",
      "[364/00585] train_loss: 0.011422\n",
      "[364/00635] train_loss: 0.011119\n",
      "[364/00685] train_loss: 0.011952\n",
      "[364/00735] train_loss: 0.010612\n",
      "[364/00785] train_loss: 0.010980\n",
      "[364/00835] train_loss: 0.012251\n",
      "[364/00885] train_loss: 0.010751\n",
      "[364/00935] train_loss: 0.011428\n",
      "[364/00985] train_loss: 0.011704\n",
      "[364/01035] train_loss: 0.011333\n",
      "[364/01085] train_loss: 0.011273\n",
      "[364/01135] train_loss: 0.011172\n",
      "[364/01185] train_loss: 0.011653\n",
      "[365/00009] train_loss: 0.012021\n",
      "[365/00059] train_loss: 0.011989\n",
      "[365/00109] train_loss: 0.012073\n",
      "[365/00159] train_loss: 0.012697\n",
      "[365/00209] train_loss: 0.011897\n",
      "[365/00259] train_loss: 0.012062\n",
      "[365/00309] train_loss: 0.012336\n",
      "[365/00359] train_loss: 0.012178\n",
      "[365/00409] train_loss: 0.011515\n",
      "[365/00459] train_loss: 0.011776\n",
      "[365/00509] train_loss: 0.011954\n",
      "[365/00559] train_loss: 0.012435\n",
      "[365/00609] train_loss: 0.011318\n",
      "[365/00659] train_loss: 0.011529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[365/00709] train_loss: 0.011703\n",
      "[365/00759] train_loss: 0.011414\n",
      "[365/00809] train_loss: 0.011725\n",
      "[365/00859] train_loss: 0.012325\n",
      "[365/00909] train_loss: 0.011925\n",
      "[365/00959] train_loss: 0.011611\n",
      "[365/01009] train_loss: 0.011329\n",
      "[365/01059] train_loss: 0.011509\n",
      "[365/01109] train_loss: 0.011648\n",
      "[365/01159] train_loss: 0.011022\n",
      "[365/01209] train_loss: 0.011087\n",
      "[366/00033] train_loss: 0.011970\n",
      "[366/00083] train_loss: 0.011889\n",
      "[366/00133] train_loss: 0.011722\n",
      "[366/00183] train_loss: 0.011152\n",
      "[366/00233] train_loss: 0.011834\n",
      "[366/00283] train_loss: 0.011198\n",
      "[366/00333] train_loss: 0.011830\n",
      "[366/00383] train_loss: 0.012070\n",
      "[366/00433] train_loss: 0.011847\n",
      "[366/00483] train_loss: 0.010895\n",
      "[366/00533] train_loss: 0.011287\n",
      "[366/00583] train_loss: 0.011136\n",
      "[366/00633] train_loss: 0.011932\n",
      "[366/00683] train_loss: 0.011465\n",
      "[366/00733] train_loss: 0.011217\n",
      "[366/00783] train_loss: 0.011657\n",
      "[366/00833] train_loss: 0.011574\n",
      "[366/00883] train_loss: 0.011583\n",
      "[366/00933] train_loss: 0.011636\n",
      "[366/00983] train_loss: 0.011309\n",
      "[366/01033] train_loss: 0.012032\n",
      "[366/01083] train_loss: 0.011195\n",
      "[366/01133] train_loss: 0.011479\n",
      "[366/01183] train_loss: 0.010679\n",
      "[367/00007] train_loss: 0.011718\n",
      "[367/00057] train_loss: 0.012609\n",
      "[367/00107] train_loss: 0.012225\n",
      "[367/00157] train_loss: 0.011642\n",
      "[367/00207] train_loss: 0.011507\n",
      "[367/00257] train_loss: 0.012041\n",
      "[367/00307] train_loss: 0.012413\n",
      "[367/00357] train_loss: 0.012280\n",
      "[367/00407] train_loss: 0.011713\n",
      "[367/00457] train_loss: 0.011860\n",
      "[367/00507] train_loss: 0.011403\n",
      "[367/00557] train_loss: 0.010856\n",
      "[367/00607] train_loss: 0.011487\n",
      "[367/00657] train_loss: 0.012091\n",
      "[367/00707] train_loss: 0.011852\n",
      "[367/00757] train_loss: 0.011382\n",
      "[367/00807] train_loss: 0.011664\n",
      "[367/00857] train_loss: 0.011353\n",
      "[367/00907] train_loss: 0.011221\n",
      "[367/00957] train_loss: 0.011885\n",
      "[367/01007] train_loss: 0.011625\n",
      "[367/01057] train_loss: 0.010814\n",
      "[367/01107] train_loss: 0.012125\n",
      "[367/01157] train_loss: 0.012012\n",
      "[367/01207] train_loss: 0.011899\n",
      "[368/00031] train_loss: 0.012220\n",
      "[368/00081] train_loss: 0.011854\n",
      "[368/00131] train_loss: 0.012302\n",
      "[368/00181] train_loss: 0.011328\n",
      "[368/00231] train_loss: 0.011900\n",
      "[368/00281] train_loss: 0.011839\n",
      "[368/00331] train_loss: 0.011294\n",
      "[368/00381] train_loss: 0.010907\n",
      "[368/00431] train_loss: 0.011534\n",
      "[368/00481] train_loss: 0.011279\n",
      "[368/00531] train_loss: 0.011508\n",
      "[368/00581] train_loss: 0.011774\n",
      "[368/00631] train_loss: 0.011539\n",
      "[368/00681] train_loss: 0.011967\n",
      "[368/00731] train_loss: 0.010686\n",
      "[368/00781] train_loss: 0.011280\n",
      "[368/00831] train_loss: 0.010974\n",
      "[368/00881] train_loss: 0.011597\n",
      "[368/00931] train_loss: 0.011746\n",
      "[368/00981] train_loss: 0.011405\n",
      "[368/01031] train_loss: 0.011480\n",
      "[368/01081] train_loss: 0.011550\n",
      "[368/01131] train_loss: 0.011958\n",
      "[368/01181] train_loss: 0.011425\n",
      "[369/00005] train_loss: 0.011583\n",
      "[369/00055] train_loss: 0.012034\n",
      "[369/00105] train_loss: 0.012496\n",
      "[369/00155] train_loss: 0.011352\n",
      "[369/00205] train_loss: 0.011402\n",
      "[369/00255] train_loss: 0.011511\n",
      "[369/00305] train_loss: 0.011658\n",
      "[369/00355] train_loss: 0.011543\n",
      "[369/00405] train_loss: 0.011063\n",
      "[369/00455] train_loss: 0.011514\n",
      "[369/00505] train_loss: 0.011345\n",
      "[369/00555] train_loss: 0.012561\n",
      "[369/00605] train_loss: 0.011445\n",
      "[369/00655] train_loss: 0.011758\n",
      "[369/00705] train_loss: 0.011942\n",
      "[369/00755] train_loss: 0.011702\n",
      "[369/00805] train_loss: 0.011473\n",
      "[369/00855] train_loss: 0.011665\n",
      "[369/00905] train_loss: 0.011348\n",
      "[369/00955] train_loss: 0.011191\n",
      "[369/01005] train_loss: 0.012586\n",
      "[369/01055] train_loss: 0.011465\n",
      "[369/01105] train_loss: 0.011479\n",
      "[369/01155] train_loss: 0.011624\n",
      "[369/01205] train_loss: 0.011401\n",
      "[370/00029] train_loss: 0.011374\n",
      "[370/00079] train_loss: 0.010790\n",
      "[370/00129] train_loss: 0.011167\n",
      "[370/00179] train_loss: 0.011912\n",
      "[370/00229] train_loss: 0.012037\n",
      "[370/00279] train_loss: 0.011499\n",
      "[370/00329] train_loss: 0.011503\n",
      "[370/00379] train_loss: 0.012018\n",
      "[370/00429] train_loss: 0.011155\n",
      "[370/00479] train_loss: 0.011752\n",
      "[370/00529] train_loss: 0.011649\n",
      "[370/00579] train_loss: 0.012013\n",
      "[370/00629] train_loss: 0.011933\n",
      "[370/00679] train_loss: 0.011326\n",
      "[370/00729] train_loss: 0.011770\n",
      "[370/00779] train_loss: 0.011517\n",
      "[370/00829] train_loss: 0.011336\n",
      "[370/00879] train_loss: 0.011662\n",
      "[370/00929] train_loss: 0.010606\n",
      "[370/00979] train_loss: 0.011568\n",
      "[370/01029] train_loss: 0.011312\n",
      "[370/01079] train_loss: 0.011815\n",
      "[370/01129] train_loss: 0.011350\n",
      "[370/01179] train_loss: 0.011825\n",
      "[371/00003] train_loss: 0.011589\n",
      "[371/00053] train_loss: 0.012135\n",
      "[371/00103] train_loss: 0.012082\n",
      "[371/00153] train_loss: 0.012596\n",
      "[371/00203] train_loss: 0.012650\n",
      "[371/00253] train_loss: 0.011630\n",
      "[371/00303] train_loss: 0.010613\n",
      "[371/00353] train_loss: 0.011578\n",
      "[371/00403] train_loss: 0.012707\n",
      "[371/00453] train_loss: 0.011979\n",
      "[371/00503] train_loss: 0.011074\n",
      "[371/00553] train_loss: 0.011832\n",
      "[371/00603] train_loss: 0.011340\n",
      "[371/00653] train_loss: 0.011309\n",
      "[371/00703] train_loss: 0.011361\n",
      "[371/00753] train_loss: 0.011897\n",
      "[371/00803] train_loss: 0.011288\n",
      "[371/00853] train_loss: 0.010946\n",
      "[371/00903] train_loss: 0.011466\n",
      "[371/00953] train_loss: 0.011240\n",
      "[371/01003] train_loss: 0.011693\n",
      "[371/01053] train_loss: 0.011594\n",
      "[371/01103] train_loss: 0.011401\n",
      "[371/01153] train_loss: 0.011089\n",
      "[371/01203] train_loss: 0.011500\n",
      "[372/00027] train_loss: 0.011251\n",
      "[372/00077] train_loss: 0.011360\n",
      "[372/00127] train_loss: 0.011341\n",
      "[372/00177] train_loss: 0.011556\n",
      "[372/00227] train_loss: 0.012570\n",
      "[372/00277] train_loss: 0.011678\n",
      "[372/00327] train_loss: 0.011834\n",
      "[372/00377] train_loss: 0.011475\n",
      "[372/00427] train_loss: 0.011574\n",
      "[372/00477] train_loss: 0.011851\n",
      "[372/00527] train_loss: 0.010766\n",
      "[372/00577] train_loss: 0.011663\n",
      "[372/00627] train_loss: 0.010997\n",
      "[372/00677] train_loss: 0.011470\n",
      "[372/00727] train_loss: 0.011802\n",
      "[372/00777] train_loss: 0.011628\n",
      "[372/00827] train_loss: 0.011834\n",
      "[372/00877] train_loss: 0.011231\n",
      "[372/00927] train_loss: 0.012205\n",
      "[372/00977] train_loss: 0.011340\n",
      "[372/01027] train_loss: 0.011665\n",
      "[372/01077] train_loss: 0.011136\n",
      "[372/01127] train_loss: 0.012177\n",
      "[372/01177] train_loss: 0.011258\n",
      "[373/00001] train_loss: 0.011778\n",
      "[373/00051] train_loss: 0.011774\n",
      "[373/00101] train_loss: 0.011949\n",
      "[373/00151] train_loss: 0.012205\n",
      "[373/00201] train_loss: 0.012316\n",
      "[373/00251] train_loss: 0.010795\n",
      "[373/00301] train_loss: 0.011495\n",
      "[373/00351] train_loss: 0.011141\n",
      "[373/00401] train_loss: 0.012344\n",
      "[373/00451] train_loss: 0.011897\n",
      "[373/00501] train_loss: 0.011778\n",
      "[373/00551] train_loss: 0.010969\n",
      "[373/00601] train_loss: 0.011600\n",
      "[373/00651] train_loss: 0.012099\n",
      "[373/00701] train_loss: 0.011669\n",
      "[373/00751] train_loss: 0.011677\n",
      "[373/00801] train_loss: 0.011892\n",
      "[373/00851] train_loss: 0.011680\n",
      "[373/00901] train_loss: 0.011660\n",
      "[373/00951] train_loss: 0.012173\n",
      "[373/01001] train_loss: 0.011347\n",
      "[373/01051] train_loss: 0.010795\n",
      "[373/01101] train_loss: 0.011473\n",
      "[373/01151] train_loss: 0.011314\n",
      "[373/01201] train_loss: 0.011225\n",
      "[374/00025] train_loss: 0.012031\n",
      "[374/00075] train_loss: 0.011959\n",
      "[374/00125] train_loss: 0.011722\n",
      "[374/00175] train_loss: 0.011969\n",
      "[374/00225] train_loss: 0.011632\n",
      "[374/00275] train_loss: 0.011584\n",
      "[374/00325] train_loss: 0.011295\n",
      "[374/00375] train_loss: 0.011699\n",
      "[374/00425] train_loss: 0.011443\n",
      "[374/00475] train_loss: 0.011323\n",
      "[374/00525] train_loss: 0.011331\n",
      "[374/00575] train_loss: 0.011602\n",
      "[374/00625] train_loss: 0.011122\n",
      "[374/00675] train_loss: 0.011545\n",
      "[374/00725] train_loss: 0.011384\n",
      "[374/00775] train_loss: 0.010673\n",
      "[374/00825] train_loss: 0.012280\n",
      "[374/00875] train_loss: 0.010812\n",
      "[374/00925] train_loss: 0.011932\n",
      "[374/00975] train_loss: 0.011519\n",
      "[374/01025] train_loss: 0.011385\n",
      "[374/01075] train_loss: 0.011662\n",
      "[374/01125] train_loss: 0.011845\n",
      "[374/01175] train_loss: 0.011293\n",
      "[374/01225] train_loss: 0.011640\n",
      "[375/00049] train_loss: 0.012561\n",
      "[375/00099] train_loss: 0.011686\n",
      "[375/00149] train_loss: 0.012436\n",
      "[375/00199] train_loss: 0.011653\n",
      "[375/00249] train_loss: 0.012021\n",
      "[375/00299] train_loss: 0.011974\n",
      "[375/00349] train_loss: 0.011663\n",
      "[375/00399] train_loss: 0.011501\n",
      "[375/00449] train_loss: 0.012181\n",
      "[375/00499] train_loss: 0.011445\n",
      "[375/00549] train_loss: 0.011663\n",
      "[375/00599] train_loss: 0.011337\n",
      "[375/00649] train_loss: 0.011952\n",
      "[375/00699] train_loss: 0.011631\n",
      "[375/00749] train_loss: 0.011218\n",
      "[375/00799] train_loss: 0.011458\n",
      "[375/00849] train_loss: 0.011122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[375/00899] train_loss: 0.011363\n",
      "[375/00949] train_loss: 0.011355\n",
      "[375/00999] train_loss: 0.012287\n",
      "[375/01049] train_loss: 0.011172\n",
      "[375/01099] train_loss: 0.010681\n",
      "[375/01149] train_loss: 0.011842\n",
      "[375/01199] train_loss: 0.011581\n",
      "[376/00023] train_loss: 0.011920\n",
      "[376/00073] train_loss: 0.012170\n",
      "[376/00123] train_loss: 0.011650\n",
      "[376/00173] train_loss: 0.011767\n",
      "[376/00223] train_loss: 0.011235\n",
      "[376/00273] train_loss: 0.011266\n",
      "[376/00323] train_loss: 0.011850\n",
      "[376/00373] train_loss: 0.011534\n",
      "[376/00423] train_loss: 0.011806\n",
      "[376/00473] train_loss: 0.011926\n",
      "[376/00523] train_loss: 0.010984\n",
      "[376/00573] train_loss: 0.011598\n",
      "[376/00623] train_loss: 0.011754\n",
      "[376/00673] train_loss: 0.011446\n",
      "[376/00723] train_loss: 0.011565\n",
      "[376/00773] train_loss: 0.011228\n",
      "[376/00823] train_loss: 0.011123\n",
      "[376/00873] train_loss: 0.011707\n",
      "[376/00923] train_loss: 0.011790\n",
      "[376/00973] train_loss: 0.012104\n",
      "[376/01023] train_loss: 0.010866\n",
      "[376/01073] train_loss: 0.011713\n",
      "[376/01123] train_loss: 0.012227\n",
      "[376/01173] train_loss: 0.011188\n",
      "[376/01223] train_loss: 0.011557\n",
      "[377/00047] train_loss: 0.012455\n",
      "[377/00097] train_loss: 0.012225\n",
      "[377/00147] train_loss: 0.012519\n",
      "[377/00197] train_loss: 0.011118\n",
      "[377/00247] train_loss: 0.011617\n",
      "[377/00297] train_loss: 0.011705\n",
      "[377/00347] train_loss: 0.011774\n",
      "[377/00397] train_loss: 0.011487\n",
      "[377/00447] train_loss: 0.011599\n",
      "[377/00497] train_loss: 0.011349\n",
      "[377/00547] train_loss: 0.011925\n",
      "[377/00597] train_loss: 0.011879\n",
      "[377/00647] train_loss: 0.011189\n",
      "[377/00697] train_loss: 0.011051\n",
      "[377/00747] train_loss: 0.011280\n",
      "[377/00797] train_loss: 0.011209\n",
      "[377/00847] train_loss: 0.011810\n",
      "[377/00897] train_loss: 0.011544\n",
      "[377/00947] train_loss: 0.011804\n",
      "[377/00997] train_loss: 0.011156\n",
      "[377/01047] train_loss: 0.011630\n",
      "[377/01097] train_loss: 0.010741\n",
      "[377/01147] train_loss: 0.011315\n",
      "[377/01197] train_loss: 0.011357\n",
      "[378/00021] train_loss: 0.011378\n",
      "[378/00071] train_loss: 0.011783\n",
      "[378/00121] train_loss: 0.012120\n",
      "[378/00171] train_loss: 0.011820\n",
      "[378/00221] train_loss: 0.011261\n",
      "[378/00271] train_loss: 0.010946\n",
      "[378/00321] train_loss: 0.011912\n",
      "[378/00371] train_loss: 0.011294\n",
      "[378/00421] train_loss: 0.011490\n",
      "[378/00471] train_loss: 0.011810\n",
      "[378/00521] train_loss: 0.012352\n",
      "[378/00571] train_loss: 0.011440\n",
      "[378/00621] train_loss: 0.011418\n",
      "[378/00671] train_loss: 0.011364\n",
      "[378/00721] train_loss: 0.011162\n",
      "[378/00771] train_loss: 0.011203\n",
      "[378/00821] train_loss: 0.012142\n",
      "[378/00871] train_loss: 0.010993\n",
      "[378/00921] train_loss: 0.011202\n",
      "[378/00971] train_loss: 0.011246\n",
      "[378/01021] train_loss: 0.011292\n",
      "[378/01071] train_loss: 0.011646\n",
      "[378/01121] train_loss: 0.010998\n",
      "[378/01171] train_loss: 0.011952\n",
      "[378/01221] train_loss: 0.011921\n",
      "[379/00045] train_loss: 0.011808\n",
      "[379/00095] train_loss: 0.011592\n",
      "[379/00145] train_loss: 0.011795\n",
      "[379/00195] train_loss: 0.012136\n",
      "[379/00245] train_loss: 0.011629\n",
      "[379/00295] train_loss: 0.011894\n",
      "[379/00345] train_loss: 0.011608\n",
      "[379/00395] train_loss: 0.011439\n",
      "[379/00445] train_loss: 0.012184\n",
      "[379/00495] train_loss: 0.011876\n",
      "[379/00545] train_loss: 0.011444\n",
      "[379/00595] train_loss: 0.011338\n",
      "[379/00645] train_loss: 0.011060\n",
      "[379/00695] train_loss: 0.011353\n",
      "[379/00745] train_loss: 0.011731\n",
      "[379/00795] train_loss: 0.011830\n",
      "[379/00845] train_loss: 0.011619\n",
      "[379/00895] train_loss: 0.011806\n",
      "[379/00945] train_loss: 0.011666\n",
      "[379/00995] train_loss: 0.010751\n",
      "[379/01045] train_loss: 0.011334\n",
      "[379/01095] train_loss: 0.011799\n",
      "[379/01145] train_loss: 0.011955\n",
      "[379/01195] train_loss: 0.011599\n",
      "[380/00019] train_loss: 0.012258\n",
      "[380/00069] train_loss: 0.012109\n",
      "[380/00119] train_loss: 0.011679\n",
      "[380/00169] train_loss: 0.011767\n",
      "[380/00219] train_loss: 0.011891\n",
      "[380/00269] train_loss: 0.012467\n",
      "[380/00319] train_loss: 0.011753\n",
      "[380/00369] train_loss: 0.011585\n",
      "[380/00419] train_loss: 0.011243\n",
      "[380/00469] train_loss: 0.011750\n",
      "[380/00519] train_loss: 0.011499\n",
      "[380/00569] train_loss: 0.011682\n",
      "[380/00619] train_loss: 0.011262\n",
      "[380/00669] train_loss: 0.011932\n",
      "[380/00719] train_loss: 0.011488\n",
      "[380/00769] train_loss: 0.011576\n",
      "[380/00819] train_loss: 0.011557\n",
      "[380/00869] train_loss: 0.011284\n",
      "[380/00919] train_loss: 0.011270\n",
      "[380/00969] train_loss: 0.011035\n",
      "[380/01019] train_loss: 0.011959\n",
      "[380/01069] train_loss: 0.010874\n",
      "[380/01119] train_loss: 0.011770\n",
      "[380/01169] train_loss: 0.011771\n",
      "[380/01219] train_loss: 0.011154\n",
      "[381/00043] train_loss: 0.012202\n",
      "[381/00093] train_loss: 0.011999\n",
      "[381/00143] train_loss: 0.011591\n",
      "[381/00193] train_loss: 0.012332\n",
      "[381/00243] train_loss: 0.012266\n",
      "[381/00293] train_loss: 0.011314\n",
      "[381/00343] train_loss: 0.011866\n",
      "[381/00393] train_loss: 0.011592\n",
      "[381/00443] train_loss: 0.011127\n",
      "[381/00493] train_loss: 0.011358\n",
      "[381/00543] train_loss: 0.011198\n",
      "[381/00593] train_loss: 0.011928\n",
      "[381/00643] train_loss: 0.011452\n",
      "[381/00693] train_loss: 0.011620\n",
      "[381/00743] train_loss: 0.011478\n",
      "[381/00793] train_loss: 0.011576\n",
      "[381/00843] train_loss: 0.011388\n",
      "[381/00893] train_loss: 0.011374\n",
      "[381/00943] train_loss: 0.011503\n",
      "[381/00993] train_loss: 0.011688\n",
      "[381/01043] train_loss: 0.011458\n",
      "[381/01093] train_loss: 0.011406\n",
      "[381/01143] train_loss: 0.011849\n",
      "[381/01193] train_loss: 0.011529\n",
      "[382/00017] train_loss: 0.011455\n",
      "[382/00067] train_loss: 0.011881\n",
      "[382/00117] train_loss: 0.012505\n",
      "[382/00167] train_loss: 0.012007\n",
      "[382/00217] train_loss: 0.011900\n",
      "[382/00267] train_loss: 0.011436\n",
      "[382/00317] train_loss: 0.011580\n",
      "[382/00367] train_loss: 0.011572\n",
      "[382/00417] train_loss: 0.011305\n",
      "[382/00467] train_loss: 0.011750\n",
      "[382/00517] train_loss: 0.011408\n",
      "[382/00567] train_loss: 0.011587\n",
      "[382/00617] train_loss: 0.011186\n",
      "[382/00667] train_loss: 0.011327\n",
      "[382/00717] train_loss: 0.011174\n",
      "[382/00767] train_loss: 0.011511\n",
      "[382/00817] train_loss: 0.011762\n",
      "[382/00867] train_loss: 0.011582\n",
      "[382/00917] train_loss: 0.010868\n",
      "[382/00967] train_loss: 0.011379\n",
      "[382/01017] train_loss: 0.011752\n",
      "[382/01067] train_loss: 0.011325\n",
      "[382/01117] train_loss: 0.010906\n",
      "[382/01167] train_loss: 0.011047\n",
      "[382/01217] train_loss: 0.011495\n",
      "[383/00041] train_loss: 0.011196\n",
      "[383/00091] train_loss: 0.012041\n",
      "[383/00141] train_loss: 0.012047\n",
      "[383/00191] train_loss: 0.012110\n",
      "[383/00241] train_loss: 0.012111\n",
      "[383/00291] train_loss: 0.011913\n",
      "[383/00341] train_loss: 0.011726\n",
      "[383/00391] train_loss: 0.011956\n",
      "[383/00441] train_loss: 0.012087\n",
      "[383/00491] train_loss: 0.011736\n",
      "[383/00541] train_loss: 0.011300\n",
      "[383/00591] train_loss: 0.011032\n",
      "[383/00641] train_loss: 0.011449\n",
      "[383/00691] train_loss: 0.011566\n",
      "[383/00741] train_loss: 0.011588\n",
      "[383/00791] train_loss: 0.011583\n",
      "[383/00841] train_loss: 0.011491\n",
      "[383/00891] train_loss: 0.011719\n",
      "[383/00941] train_loss: 0.011357\n",
      "[383/00991] train_loss: 0.011468\n",
      "[383/01041] train_loss: 0.011215\n",
      "[383/01091] train_loss: 0.011261\n",
      "[383/01141] train_loss: 0.011044\n",
      "[383/01191] train_loss: 0.011340\n",
      "[384/00015] train_loss: 0.011695\n",
      "[384/00065] train_loss: 0.011342\n",
      "[384/00115] train_loss: 0.012126\n",
      "[384/00165] train_loss: 0.011113\n",
      "[384/00215] train_loss: 0.011078\n",
      "[384/00265] train_loss: 0.011799\n",
      "[384/00315] train_loss: 0.011801\n",
      "[384/00365] train_loss: 0.010964\n",
      "[384/00415] train_loss: 0.011558\n",
      "[384/00465] train_loss: 0.010663\n",
      "[384/00515] train_loss: 0.012040\n",
      "[384/00565] train_loss: 0.011110\n",
      "[384/00615] train_loss: 0.012013\n",
      "[384/00665] train_loss: 0.011694\n",
      "[384/00715] train_loss: 0.012463\n",
      "[384/00765] train_loss: 0.011388\n",
      "[384/00815] train_loss: 0.011176\n",
      "[384/00865] train_loss: 0.011952\n",
      "[384/00915] train_loss: 0.010810\n",
      "[384/00965] train_loss: 0.011747\n",
      "[384/01015] train_loss: 0.011232\n",
      "[384/01065] train_loss: 0.011492\n",
      "[384/01115] train_loss: 0.011154\n",
      "[384/01165] train_loss: 0.011412\n",
      "[384/01215] train_loss: 0.012069\n",
      "[385/00039] train_loss: 0.011654\n",
      "[385/00089] train_loss: 0.011738\n",
      "[385/00139] train_loss: 0.011808\n",
      "[385/00189] train_loss: 0.011065\n",
      "[385/00239] train_loss: 0.012136\n",
      "[385/00289] train_loss: 0.011483\n",
      "[385/00339] train_loss: 0.011551\n",
      "[385/00389] train_loss: 0.011204\n",
      "[385/00439] train_loss: 0.011820\n",
      "[385/00489] train_loss: 0.012485\n",
      "[385/00539] train_loss: 0.011636\n",
      "[385/00589] train_loss: 0.011632\n",
      "[385/00639] train_loss: 0.011903\n",
      "[385/00689] train_loss: 0.011752\n",
      "[385/00739] train_loss: 0.011276\n",
      "[385/00789] train_loss: 0.011397\n",
      "[385/00839] train_loss: 0.010696\n",
      "[385/00889] train_loss: 0.012423\n",
      "[385/00939] train_loss: 0.011008\n",
      "[385/00989] train_loss: 0.011701\n",
      "[385/01039] train_loss: 0.010571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[385/01089] train_loss: 0.011168\n",
      "[385/01139] train_loss: 0.011336\n",
      "[385/01189] train_loss: 0.011547\n",
      "[386/00013] train_loss: 0.011685\n",
      "[386/00063] train_loss: 0.011682\n",
      "[386/00113] train_loss: 0.012069\n",
      "[386/00163] train_loss: 0.011653\n",
      "[386/00213] train_loss: 0.011195\n",
      "[386/00263] train_loss: 0.011662\n",
      "[386/00313] train_loss: 0.011712\n",
      "[386/00363] train_loss: 0.011076\n",
      "[386/00413] train_loss: 0.011656\n",
      "[386/00463] train_loss: 0.011507\n",
      "[386/00513] train_loss: 0.012055\n",
      "[386/00563] train_loss: 0.011315\n",
      "[386/00613] train_loss: 0.011882\n",
      "[386/00663] train_loss: 0.012126\n",
      "[386/00713] train_loss: 0.012121\n",
      "[386/00763] train_loss: 0.012066\n",
      "[386/00813] train_loss: 0.011089\n",
      "[386/00863] train_loss: 0.011273\n",
      "[386/00913] train_loss: 0.010940\n",
      "[386/00963] train_loss: 0.011519\n",
      "[386/01013] train_loss: 0.011621\n",
      "[386/01063] train_loss: 0.011562\n",
      "[386/01113] train_loss: 0.011177\n",
      "[386/01163] train_loss: 0.010996\n",
      "[386/01213] train_loss: 0.011463\n",
      "[387/00037] train_loss: 0.011055\n",
      "[387/00087] train_loss: 0.011447\n",
      "[387/00137] train_loss: 0.011865\n",
      "[387/00187] train_loss: 0.012102\n",
      "[387/00237] train_loss: 0.011271\n",
      "[387/00287] train_loss: 0.011365\n",
      "[387/00337] train_loss: 0.011862\n",
      "[387/00387] train_loss: 0.011841\n",
      "[387/00437] train_loss: 0.012273\n",
      "[387/00487] train_loss: 0.012178\n",
      "[387/00537] train_loss: 0.011677\n",
      "[387/00587] train_loss: 0.011243\n",
      "[387/00637] train_loss: 0.010945\n",
      "[387/00687] train_loss: 0.011435\n",
      "[387/00737] train_loss: 0.011041\n",
      "[387/00787] train_loss: 0.012000\n",
      "[387/00837] train_loss: 0.011738\n",
      "[387/00887] train_loss: 0.012214\n",
      "[387/00937] train_loss: 0.011138\n",
      "[387/00987] train_loss: 0.011670\n",
      "[387/01037] train_loss: 0.010933\n",
      "[387/01087] train_loss: 0.011906\n",
      "[387/01137] train_loss: 0.010821\n",
      "[387/01187] train_loss: 0.011553\n",
      "[388/00011] train_loss: 0.010915\n",
      "[388/00061] train_loss: 0.011944\n",
      "[388/00111] train_loss: 0.011809\n",
      "[388/00161] train_loss: 0.011673\n",
      "[388/00211] train_loss: 0.011791\n",
      "[388/00261] train_loss: 0.011636\n",
      "[388/00311] train_loss: 0.011359\n",
      "[388/00361] train_loss: 0.011350\n",
      "[388/00411] train_loss: 0.011927\n",
      "[388/00461] train_loss: 0.011540\n",
      "[388/00511] train_loss: 0.011201\n",
      "[388/00561] train_loss: 0.012080\n",
      "[388/00611] train_loss: 0.011557\n",
      "[388/00661] train_loss: 0.011556\n",
      "[388/00711] train_loss: 0.011136\n",
      "[388/00761] train_loss: 0.011427\n",
      "[388/00811] train_loss: 0.011860\n",
      "[388/00861] train_loss: 0.010884\n",
      "[388/00911] train_loss: 0.010744\n",
      "[388/00961] train_loss: 0.012129\n",
      "[388/01011] train_loss: 0.011155\n",
      "[388/01061] train_loss: 0.011067\n",
      "[388/01111] train_loss: 0.011560\n",
      "[388/01161] train_loss: 0.010979\n",
      "[388/01211] train_loss: 0.011596\n",
      "[389/00035] train_loss: 0.011556\n",
      "[389/00085] train_loss: 0.012348\n",
      "[389/00135] train_loss: 0.012036\n",
      "[389/00185] train_loss: 0.011670\n",
      "[389/00235] train_loss: 0.011727\n",
      "[389/00285] train_loss: 0.012209\n",
      "[389/00335] train_loss: 0.011666\n",
      "[389/00385] train_loss: 0.011614\n",
      "[389/00435] train_loss: 0.011883\n",
      "[389/00485] train_loss: 0.011494\n",
      "[389/00535] train_loss: 0.010952\n",
      "[389/00585] train_loss: 0.011556\n",
      "[389/00635] train_loss: 0.011640\n",
      "[389/00685] train_loss: 0.011806\n",
      "[389/00735] train_loss: 0.011734\n",
      "[389/00785] train_loss: 0.010816\n",
      "[389/00835] train_loss: 0.011478\n",
      "[389/00885] train_loss: 0.010835\n",
      "[389/00935] train_loss: 0.011077\n",
      "[389/00985] train_loss: 0.011982\n",
      "[389/01035] train_loss: 0.011625\n",
      "[389/01085] train_loss: 0.011987\n",
      "[389/01135] train_loss: 0.011453\n",
      "[389/01185] train_loss: 0.011480\n",
      "[390/00009] train_loss: 0.011115\n",
      "[390/00059] train_loss: 0.012038\n",
      "[390/00109] train_loss: 0.011936\n",
      "[390/00159] train_loss: 0.011829\n",
      "[390/00209] train_loss: 0.011910\n",
      "[390/00259] train_loss: 0.011499\n",
      "[390/00309] train_loss: 0.010813\n",
      "[390/00359] train_loss: 0.011549\n",
      "[390/00409] train_loss: 0.010923\n",
      "[390/00459] train_loss: 0.011179\n",
      "[390/00509] train_loss: 0.011654\n",
      "[390/00559] train_loss: 0.011227\n",
      "[390/00609] train_loss: 0.011870\n",
      "[390/00659] train_loss: 0.011658\n",
      "[390/00709] train_loss: 0.011850\n",
      "[390/00759] train_loss: 0.011101\n",
      "[390/00809] train_loss: 0.011636\n",
      "[390/00859] train_loss: 0.011295\n",
      "[390/00909] train_loss: 0.012165\n",
      "[390/00959] train_loss: 0.011114\n",
      "[390/01009] train_loss: 0.011092\n",
      "[390/01059] train_loss: 0.010962\n",
      "[390/01109] train_loss: 0.010851\n",
      "[390/01159] train_loss: 0.011360\n",
      "[390/01209] train_loss: 0.011375\n",
      "[391/00033] train_loss: 0.011760\n",
      "[391/00083] train_loss: 0.012024\n",
      "[391/00133] train_loss: 0.011626\n",
      "[391/00183] train_loss: 0.011672\n",
      "[391/00233] train_loss: 0.011621\n",
      "[391/00283] train_loss: 0.011778\n",
      "[391/00333] train_loss: 0.011833\n",
      "[391/00383] train_loss: 0.011288\n",
      "[391/00433] train_loss: 0.011357\n",
      "[391/00483] train_loss: 0.011493\n",
      "[391/00533] train_loss: 0.011090\n",
      "[391/00583] train_loss: 0.011352\n",
      "[391/00633] train_loss: 0.012209\n",
      "[391/00683] train_loss: 0.011549\n",
      "[391/00733] train_loss: 0.011424\n",
      "[391/00783] train_loss: 0.011318\n",
      "[391/00833] train_loss: 0.011905\n",
      "[391/00883] train_loss: 0.011289\n",
      "[391/00933] train_loss: 0.011231\n",
      "[391/00983] train_loss: 0.011889\n",
      "[391/01033] train_loss: 0.011215\n",
      "[391/01083] train_loss: 0.011482\n",
      "[391/01133] train_loss: 0.012008\n",
      "[391/01183] train_loss: 0.011849\n",
      "[392/00007] train_loss: 0.011169\n",
      "[392/00057] train_loss: 0.011218\n",
      "[392/00107] train_loss: 0.011844\n",
      "[392/00157] train_loss: 0.011391\n",
      "[392/00207] train_loss: 0.011409\n",
      "[392/00257] train_loss: 0.011140\n",
      "[392/00307] train_loss: 0.011166\n",
      "[392/00357] train_loss: 0.011648\n",
      "[392/00407] train_loss: 0.010949\n",
      "[392/00457] train_loss: 0.012152\n",
      "[392/00507] train_loss: 0.011755\n",
      "[392/00557] train_loss: 0.011265\n",
      "[392/00607] train_loss: 0.011101\n",
      "[392/00657] train_loss: 0.011492\n",
      "[392/00707] train_loss: 0.011683\n",
      "[392/00757] train_loss: 0.011760\n",
      "[392/00807] train_loss: 0.011904\n",
      "[392/00857] train_loss: 0.011080\n",
      "[392/00907] train_loss: 0.011601\n",
      "[392/00957] train_loss: 0.011206\n",
      "[392/01007] train_loss: 0.010379\n",
      "[392/01057] train_loss: 0.011475\n",
      "[392/01107] train_loss: 0.011788\n",
      "[392/01157] train_loss: 0.010912\n",
      "[392/01207] train_loss: 0.011097\n",
      "[393/00031] train_loss: 0.012935\n",
      "[393/00081] train_loss: 0.011992\n",
      "[393/00131] train_loss: 0.012005\n",
      "[393/00181] train_loss: 0.011466\n",
      "[393/00231] train_loss: 0.012093\n",
      "[393/00281] train_loss: 0.011727\n",
      "[393/00331] train_loss: 0.011904\n",
      "[393/00381] train_loss: 0.011472\n",
      "[393/00431] train_loss: 0.011586\n",
      "[393/00481] train_loss: 0.011207\n",
      "[393/00531] train_loss: 0.011296\n",
      "[393/00581] train_loss: 0.011194\n",
      "[393/00631] train_loss: 0.010835\n",
      "[393/00681] train_loss: 0.011469\n",
      "[393/00731] train_loss: 0.011385\n",
      "[393/00781] train_loss: 0.011626\n",
      "[393/00831] train_loss: 0.011549\n",
      "[393/00881] train_loss: 0.011608\n",
      "[393/00931] train_loss: 0.011599\n",
      "[393/00981] train_loss: 0.011123\n",
      "[393/01031] train_loss: 0.011690\n",
      "[393/01081] train_loss: 0.011241\n",
      "[393/01131] train_loss: 0.011009\n",
      "[393/01181] train_loss: 0.010611\n",
      "[394/00005] train_loss: 0.011169\n",
      "[394/00055] train_loss: 0.011803\n",
      "[394/00105] train_loss: 0.012491\n",
      "[394/00155] train_loss: 0.011729\n",
      "[394/00205] train_loss: 0.011223\n",
      "[394/00255] train_loss: 0.011168\n",
      "[394/00305] train_loss: 0.011321\n",
      "[394/00355] train_loss: 0.011775\n",
      "[394/00405] train_loss: 0.012174\n",
      "[394/00455] train_loss: 0.011086\n",
      "[394/00505] train_loss: 0.011078\n",
      "[394/00555] train_loss: 0.011173\n",
      "[394/00605] train_loss: 0.011350\n",
      "[394/00655] train_loss: 0.011534\n",
      "[394/00705] train_loss: 0.011368\n",
      "[394/00755] train_loss: 0.011374\n",
      "[394/00805] train_loss: 0.011354\n",
      "[394/00855] train_loss: 0.011518\n",
      "[394/00905] train_loss: 0.011736\n",
      "[394/00955] train_loss: 0.011715\n",
      "[394/01005] train_loss: 0.011096\n",
      "[394/01055] train_loss: 0.011268\n",
      "[394/01105] train_loss: 0.011323\n",
      "[394/01155] train_loss: 0.011895\n",
      "[394/01205] train_loss: 0.011313\n",
      "[395/00029] train_loss: 0.011641\n",
      "[395/00079] train_loss: 0.012549\n",
      "[395/00129] train_loss: 0.011966\n",
      "[395/00179] train_loss: 0.011753\n",
      "[395/00229] train_loss: 0.011922\n",
      "[395/00279] train_loss: 0.011618\n",
      "[395/00329] train_loss: 0.012506\n",
      "[395/00379] train_loss: 0.011075\n",
      "[395/00429] train_loss: 0.011201\n",
      "[395/00479] train_loss: 0.011677\n",
      "[395/00529] train_loss: 0.011078\n",
      "[395/00579] train_loss: 0.011578\n",
      "[395/00629] train_loss: 0.011208\n",
      "[395/00679] train_loss: 0.010630\n",
      "[395/00729] train_loss: 0.011434\n",
      "[395/00779] train_loss: 0.011712\n",
      "[395/00829] train_loss: 0.011202\n",
      "[395/00879] train_loss: 0.010584\n",
      "[395/00929] train_loss: 0.011394\n",
      "[395/00979] train_loss: 0.011384\n",
      "[395/01029] train_loss: 0.010587\n",
      "[395/01079] train_loss: 0.011849\n",
      "[395/01129] train_loss: 0.010675\n",
      "[395/01179] train_loss: 0.011446\n",
      "[396/00003] train_loss: 0.011967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[396/00053] train_loss: 0.011723\n",
      "[396/00103] train_loss: 0.011976\n",
      "[396/00153] train_loss: 0.011595\n",
      "[396/00203] train_loss: 0.011399\n",
      "[396/00253] train_loss: 0.011355\n",
      "[396/00303] train_loss: 0.011380\n",
      "[396/00353] train_loss: 0.011785\n",
      "[396/00403] train_loss: 0.011582\n",
      "[396/00453] train_loss: 0.011739\n",
      "[396/00503] train_loss: 0.011756\n",
      "[396/00553] train_loss: 0.011256\n",
      "[396/00603] train_loss: 0.011207\n",
      "[396/00653] train_loss: 0.011763\n",
      "[396/00703] train_loss: 0.011901\n",
      "[396/00753] train_loss: 0.011283\n",
      "[396/00803] train_loss: 0.011454\n",
      "[396/00853] train_loss: 0.010624\n",
      "[396/00903] train_loss: 0.011266\n",
      "[396/00953] train_loss: 0.011198\n",
      "[396/01003] train_loss: 0.011327\n",
      "[396/01053] train_loss: 0.011442\n",
      "[396/01103] train_loss: 0.011550\n",
      "[396/01153] train_loss: 0.011706\n",
      "[396/01203] train_loss: 0.010064\n",
      "[397/00027] train_loss: 0.011551\n",
      "[397/00077] train_loss: 0.011710\n",
      "[397/00127] train_loss: 0.012742\n",
      "[397/00177] train_loss: 0.011710\n",
      "[397/00227] train_loss: 0.010685\n",
      "[397/00277] train_loss: 0.011880\n",
      "[397/00327] train_loss: 0.011344\n",
      "[397/00377] train_loss: 0.011214\n",
      "[397/00427] train_loss: 0.012018\n",
      "[397/00477] train_loss: 0.011677\n",
      "[397/00527] train_loss: 0.011077\n",
      "[397/00577] train_loss: 0.011293\n",
      "[397/00627] train_loss: 0.011019\n",
      "[397/00677] train_loss: 0.011998\n",
      "[397/00727] train_loss: 0.011223\n",
      "[397/00777] train_loss: 0.011611\n",
      "[397/00827] train_loss: 0.012039\n",
      "[397/00877] train_loss: 0.010847\n",
      "[397/00927] train_loss: 0.011295\n",
      "[397/00977] train_loss: 0.012501\n",
      "[397/01027] train_loss: 0.011478\n",
      "[397/01077] train_loss: 0.011634\n",
      "[397/01127] train_loss: 0.011556\n",
      "[397/01177] train_loss: 0.010833\n",
      "[398/00001] train_loss: 0.011229\n",
      "[398/00051] train_loss: 0.012098\n",
      "[398/00101] train_loss: 0.011674\n",
      "[398/00151] train_loss: 0.012021\n",
      "[398/00201] train_loss: 0.011231\n",
      "[398/00251] train_loss: 0.011085\n",
      "[398/00301] train_loss: 0.011618\n",
      "[398/00351] train_loss: 0.011149\n",
      "[398/00401] train_loss: 0.011125\n",
      "[398/00451] train_loss: 0.011128\n",
      "[398/00501] train_loss: 0.011659\n",
      "[398/00551] train_loss: 0.011356\n",
      "[398/00601] train_loss: 0.011520\n",
      "[398/00651] train_loss: 0.011296\n",
      "[398/00701] train_loss: 0.011089\n",
      "[398/00751] train_loss: 0.010947\n",
      "[398/00801] train_loss: 0.011249\n",
      "[398/00851] train_loss: 0.011103\n",
      "[398/00901] train_loss: 0.011788\n",
      "[398/00951] train_loss: 0.011492\n",
      "[398/01001] train_loss: 0.012080\n",
      "[398/01051] train_loss: 0.011028\n",
      "[398/01101] train_loss: 0.011689\n",
      "[398/01151] train_loss: 0.011385\n",
      "[398/01201] train_loss: 0.010967\n",
      "[399/00025] train_loss: 0.011691\n",
      "[399/00075] train_loss: 0.012758\n",
      "[399/00125] train_loss: 0.011471\n",
      "[399/00175] train_loss: 0.011881\n",
      "[399/00225] train_loss: 0.011427\n",
      "[399/00275] train_loss: 0.011306\n",
      "[399/00325] train_loss: 0.011636\n",
      "[399/00375] train_loss: 0.011717\n",
      "[399/00425] train_loss: 0.011386\n",
      "[399/00475] train_loss: 0.011495\n",
      "[399/00525] train_loss: 0.010770\n",
      "[399/00575] train_loss: 0.011906\n",
      "[399/00625] train_loss: 0.011430\n",
      "[399/00675] train_loss: 0.011550\n",
      "[399/00725] train_loss: 0.011396\n",
      "[399/00775] train_loss: 0.011640\n",
      "[399/00825] train_loss: 0.011691\n",
      "[399/00875] train_loss: 0.010934\n",
      "[399/00925] train_loss: 0.011684\n",
      "[399/00975] train_loss: 0.011612\n",
      "[399/01025] train_loss: 0.011273\n",
      "[399/01075] train_loss: 0.010969\n",
      "[399/01125] train_loss: 0.011346\n",
      "[399/01175] train_loss: 0.011267\n",
      "[399/01225] train_loss: 0.011544\n",
      "[400/00049] train_loss: 0.012100\n",
      "[400/00099] train_loss: 0.011795\n",
      "[400/00149] train_loss: 0.012175\n",
      "[400/00199] train_loss: 0.011611\n",
      "[400/00249] train_loss: 0.012346\n",
      "[400/00299] train_loss: 0.011555\n",
      "[400/00349] train_loss: 0.012185\n",
      "[400/00399] train_loss: 0.011312\n",
      "[400/00449] train_loss: 0.011390\n",
      "[400/00499] train_loss: 0.011241\n",
      "[400/00549] train_loss: 0.011532\n",
      "[400/00599] train_loss: 0.011829\n",
      "[400/00649] train_loss: 0.011153\n",
      "[400/00699] train_loss: 0.011110\n",
      "[400/00749] train_loss: 0.011424\n",
      "[400/00799] train_loss: 0.010704\n",
      "[400/00849] train_loss: 0.011495\n",
      "[400/00899] train_loss: 0.011424\n",
      "[400/00949] train_loss: 0.011537\n",
      "[400/00999] train_loss: 0.011558\n",
      "[400/01049] train_loss: 0.011070\n",
      "[400/01099] train_loss: 0.011100\n",
      "[400/01149] train_loss: 0.011492\n",
      "[400/01199] train_loss: 0.011493\n",
      "[401/00023] train_loss: 0.010878\n",
      "[401/00073] train_loss: 0.012159\n",
      "[401/00123] train_loss: 0.012020\n",
      "[401/00173] train_loss: 0.011169\n",
      "[401/00223] train_loss: 0.011568\n",
      "[401/00273] train_loss: 0.011585\n",
      "[401/00323] train_loss: 0.011615\n",
      "[401/00373] train_loss: 0.011761\n",
      "[401/00423] train_loss: 0.011104\n",
      "[401/00473] train_loss: 0.011611\n",
      "[401/00523] train_loss: 0.011198\n",
      "[401/00573] train_loss: 0.011980\n",
      "[401/00623] train_loss: 0.011482\n",
      "[401/00673] train_loss: 0.010834\n",
      "[401/00723] train_loss: 0.011676\n",
      "[401/00773] train_loss: 0.011472\n",
      "[401/00823] train_loss: 0.010950\n",
      "[401/00873] train_loss: 0.011486\n",
      "[401/00923] train_loss: 0.011798\n",
      "[401/00973] train_loss: 0.011440\n",
      "[401/01023] train_loss: 0.011174\n",
      "[401/01073] train_loss: 0.011751\n",
      "[401/01123] train_loss: 0.011392\n",
      "[401/01173] train_loss: 0.011222\n",
      "[401/01223] train_loss: 0.011000\n",
      "[402/00047] train_loss: 0.011935\n",
      "[402/00097] train_loss: 0.011882\n",
      "[402/00147] train_loss: 0.011285\n",
      "[402/00197] train_loss: 0.011318\n",
      "[402/00247] train_loss: 0.012346\n",
      "[402/00297] train_loss: 0.011544\n",
      "[402/00347] train_loss: 0.011544\n",
      "[402/00397] train_loss: 0.011510\n",
      "[402/00447] train_loss: 0.011347\n",
      "[402/00497] train_loss: 0.011334\n",
      "[402/00547] train_loss: 0.012119\n",
      "[402/00597] train_loss: 0.011169\n",
      "[402/00647] train_loss: 0.011961\n",
      "[402/00697] train_loss: 0.011049\n",
      "[402/00747] train_loss: 0.011206\n",
      "[402/00797] train_loss: 0.011219\n",
      "[402/00847] train_loss: 0.011634\n",
      "[402/00897] train_loss: 0.011156\n",
      "[402/00947] train_loss: 0.011088\n",
      "[402/00997] train_loss: 0.010983\n",
      "[402/01047] train_loss: 0.011378\n",
      "[402/01097] train_loss: 0.010870\n",
      "[402/01147] train_loss: 0.011083\n",
      "[402/01197] train_loss: 0.011291\n",
      "[403/00021] train_loss: 0.011674\n",
      "[403/00071] train_loss: 0.011787\n",
      "[403/00121] train_loss: 0.011779\n",
      "[403/00171] train_loss: 0.011765\n",
      "[403/00221] train_loss: 0.011462\n",
      "[403/00271] train_loss: 0.011160\n",
      "[403/00321] train_loss: 0.010608\n",
      "[403/00371] train_loss: 0.011533\n",
      "[403/00421] train_loss: 0.011158\n",
      "[403/00471] train_loss: 0.011627\n",
      "[403/00521] train_loss: 0.011104\n",
      "[403/00571] train_loss: 0.011878\n",
      "[403/00621] train_loss: 0.012141\n",
      "[403/00671] train_loss: 0.012293\n",
      "[403/00721] train_loss: 0.011826\n",
      "[403/00771] train_loss: 0.011388\n",
      "[403/00821] train_loss: 0.010807\n",
      "[403/00871] train_loss: 0.011264\n",
      "[403/00921] train_loss: 0.012129\n",
      "[403/00971] train_loss: 0.011120\n",
      "[403/01021] train_loss: 0.011116\n",
      "[403/01071] train_loss: 0.011531\n",
      "[403/01121] train_loss: 0.011365\n",
      "[403/01171] train_loss: 0.010785\n",
      "[403/01221] train_loss: 0.010997\n",
      "[404/00045] train_loss: 0.011914\n",
      "[404/00095] train_loss: 0.012044\n",
      "[404/00145] train_loss: 0.011783\n",
      "[404/00195] train_loss: 0.012121\n",
      "[404/00245] train_loss: 0.010966\n",
      "[404/00295] train_loss: 0.010815\n",
      "[404/00345] train_loss: 0.011223\n",
      "[404/00395] train_loss: 0.010969\n",
      "[404/00445] train_loss: 0.011672\n",
      "[404/00495] train_loss: 0.011434\n",
      "[404/00545] train_loss: 0.011456\n",
      "[404/00595] train_loss: 0.011623\n",
      "[404/00645] train_loss: 0.011484\n",
      "[404/00695] train_loss: 0.012311\n",
      "[404/00745] train_loss: 0.010639\n",
      "[404/00795] train_loss: 0.012108\n",
      "[404/00845] train_loss: 0.011250\n",
      "[404/00895] train_loss: 0.011355\n",
      "[404/00945] train_loss: 0.010657\n",
      "[404/00995] train_loss: 0.011443\n",
      "[404/01045] train_loss: 0.012066\n",
      "[404/01095] train_loss: 0.011616\n",
      "[404/01145] train_loss: 0.011470\n",
      "[404/01195] train_loss: 0.011263\n",
      "[405/00019] train_loss: 0.011036\n",
      "[405/00069] train_loss: 0.011659\n",
      "[405/00119] train_loss: 0.011167\n",
      "[405/00169] train_loss: 0.012062\n",
      "[405/00219] train_loss: 0.011809\n",
      "[405/00269] train_loss: 0.011853\n",
      "[405/00319] train_loss: 0.011277\n",
      "[405/00369] train_loss: 0.011576\n",
      "[405/00419] train_loss: 0.011564\n",
      "[405/00469] train_loss: 0.010922\n",
      "[405/00519] train_loss: 0.010985\n",
      "[405/00569] train_loss: 0.011353\n",
      "[405/00619] train_loss: 0.011349\n",
      "[405/00669] train_loss: 0.011635\n",
      "[405/00719] train_loss: 0.011851\n",
      "[405/00769] train_loss: 0.012174\n",
      "[405/00819] train_loss: 0.011514\n",
      "[405/00869] train_loss: 0.011792\n",
      "[405/00919] train_loss: 0.011980\n",
      "[405/00969] train_loss: 0.011164\n",
      "[405/01019] train_loss: 0.011093\n",
      "[405/01069] train_loss: 0.011418\n",
      "[405/01119] train_loss: 0.010876\n",
      "[405/01169] train_loss: 0.011144\n",
      "[405/01219] train_loss: 0.010832\n",
      "[406/00043] train_loss: 0.011647\n",
      "[406/00093] train_loss: 0.011228\n",
      "[406/00143] train_loss: 0.011461\n",
      "[406/00193] train_loss: 0.011503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[406/00243] train_loss: 0.011541\n",
      "[406/00293] train_loss: 0.011403\n",
      "[406/00343] train_loss: 0.010941\n",
      "[406/00393] train_loss: 0.011402\n",
      "[406/00443] train_loss: 0.011857\n",
      "[406/00493] train_loss: 0.011470\n",
      "[406/00543] train_loss: 0.011333\n",
      "[406/00593] train_loss: 0.011783\n",
      "[406/00643] train_loss: 0.011732\n",
      "[406/00693] train_loss: 0.011134\n",
      "[406/00743] train_loss: 0.011107\n",
      "[406/00793] train_loss: 0.011427\n",
      "[406/00843] train_loss: 0.011138\n",
      "[406/00893] train_loss: 0.011057\n",
      "[406/00943] train_loss: 0.010960\n",
      "[406/00993] train_loss: 0.010859\n",
      "[406/01043] train_loss: 0.011119\n",
      "[406/01093] train_loss: 0.011240\n",
      "[406/01143] train_loss: 0.012091\n",
      "[406/01193] train_loss: 0.011131\n",
      "[407/00017] train_loss: 0.011412\n",
      "[407/00067] train_loss: 0.011847\n",
      "[407/00117] train_loss: 0.011777\n",
      "[407/00167] train_loss: 0.011679\n",
      "[407/00217] train_loss: 0.011144\n",
      "[407/00267] train_loss: 0.011520\n",
      "[407/00317] train_loss: 0.011134\n",
      "[407/00367] train_loss: 0.012116\n",
      "[407/00417] train_loss: 0.010857\n",
      "[407/00467] train_loss: 0.012053\n",
      "[407/00517] train_loss: 0.011169\n",
      "[407/00567] train_loss: 0.011262\n",
      "[407/00617] train_loss: 0.011342\n",
      "[407/00667] train_loss: 0.011557\n",
      "[407/00717] train_loss: 0.010629\n",
      "[407/00767] train_loss: 0.011895\n",
      "[407/00817] train_loss: 0.011578\n",
      "[407/00867] train_loss: 0.012161\n",
      "[407/00917] train_loss: 0.012770\n",
      "[407/00967] train_loss: 0.010677\n",
      "[407/01017] train_loss: 0.010915\n",
      "[407/01067] train_loss: 0.011223\n",
      "[407/01117] train_loss: 0.011173\n",
      "[407/01167] train_loss: 0.011349\n",
      "[407/01217] train_loss: 0.011172\n",
      "[408/00041] train_loss: 0.012377\n",
      "[408/00091] train_loss: 0.012000\n",
      "[408/00141] train_loss: 0.011490\n",
      "[408/00191] train_loss: 0.011162\n",
      "[408/00241] train_loss: 0.011812\n",
      "[408/00291] train_loss: 0.011335\n",
      "[408/00341] train_loss: 0.011263\n",
      "[408/00391] train_loss: 0.011423\n",
      "[408/00441] train_loss: 0.011292\n",
      "[408/00491] train_loss: 0.011703\n",
      "[408/00541] train_loss: 0.010971\n",
      "[408/00591] train_loss: 0.011288\n",
      "[408/00641] train_loss: 0.011549\n",
      "[408/00691] train_loss: 0.011609\n",
      "[408/00741] train_loss: 0.011086\n",
      "[408/00791] train_loss: 0.011259\n",
      "[408/00841] train_loss: 0.011600\n",
      "[408/00891] train_loss: 0.011647\n",
      "[408/00941] train_loss: 0.011184\n",
      "[408/00991] train_loss: 0.011523\n",
      "[408/01041] train_loss: 0.011346\n",
      "[408/01091] train_loss: 0.010484\n",
      "[408/01141] train_loss: 0.011387\n",
      "[408/01191] train_loss: 0.011517\n",
      "[409/00015] train_loss: 0.010756\n",
      "[409/00065] train_loss: 0.011897\n",
      "[409/00115] train_loss: 0.011457\n",
      "[409/00165] train_loss: 0.011119\n",
      "[409/00215] train_loss: 0.012030\n",
      "[409/00265] train_loss: 0.011235\n",
      "[409/00315] train_loss: 0.011728\n",
      "[409/00365] train_loss: 0.011615\n",
      "[409/00415] train_loss: 0.012273\n",
      "[409/00465] train_loss: 0.011395\n",
      "[409/00515] train_loss: 0.011178\n",
      "[409/00565] train_loss: 0.010718\n",
      "[409/00615] train_loss: 0.011946\n",
      "[409/00665] train_loss: 0.011766\n",
      "[409/00715] train_loss: 0.011205\n",
      "[409/00765] train_loss: 0.011276\n",
      "[409/00815] train_loss: 0.011373\n",
      "[409/00865] train_loss: 0.011135\n",
      "[409/00915] train_loss: 0.011838\n",
      "[409/00965] train_loss: 0.011322\n",
      "[409/01015] train_loss: 0.011075\n",
      "[409/01065] train_loss: 0.011836\n",
      "[409/01115] train_loss: 0.011812\n",
      "[409/01165] train_loss: 0.010996\n",
      "[409/01215] train_loss: 0.011285\n",
      "[410/00039] train_loss: 0.011990\n",
      "[410/00089] train_loss: 0.011821\n",
      "[410/00139] train_loss: 0.012127\n",
      "[410/00189] train_loss: 0.011679\n",
      "[410/00239] train_loss: 0.011674\n",
      "[410/00289] train_loss: 0.010898\n",
      "[410/00339] train_loss: 0.011265\n",
      "[410/00389] train_loss: 0.011867\n",
      "[410/00439] train_loss: 0.011401\n",
      "[410/00489] train_loss: 0.012028\n",
      "[410/00539] train_loss: 0.011184\n",
      "[410/00589] train_loss: 0.011402\n",
      "[410/00639] train_loss: 0.011622\n",
      "[410/00689] train_loss: 0.011993\n",
      "[410/00739] train_loss: 0.011179\n",
      "[410/00789] train_loss: 0.011345\n",
      "[410/00839] train_loss: 0.011407\n",
      "[410/00889] train_loss: 0.011608\n",
      "[410/00939] train_loss: 0.010770\n",
      "[410/00989] train_loss: 0.010734\n",
      "[410/01039] train_loss: 0.010895\n",
      "[410/01089] train_loss: 0.011162\n",
      "[410/01139] train_loss: 0.011953\n",
      "[410/01189] train_loss: 0.010867\n",
      "[411/00013] train_loss: 0.011639\n",
      "[411/00063] train_loss: 0.012874\n",
      "[411/00113] train_loss: 0.011545\n",
      "[411/00163] train_loss: 0.011733\n",
      "[411/00213] train_loss: 0.011327\n",
      "[411/00263] train_loss: 0.010853\n",
      "[411/00313] train_loss: 0.011167\n",
      "[411/00363] train_loss: 0.011209\n",
      "[411/00413] train_loss: 0.011980\n",
      "[411/00463] train_loss: 0.011324\n",
      "[411/00513] train_loss: 0.011360\n",
      "[411/00563] train_loss: 0.011110\n",
      "[411/00613] train_loss: 0.011616\n",
      "[411/00663] train_loss: 0.011358\n",
      "[411/00713] train_loss: 0.011966\n",
      "[411/00763] train_loss: 0.011992\n",
      "[411/00813] train_loss: 0.010888\n",
      "[411/00863] train_loss: 0.011294\n",
      "[411/00913] train_loss: 0.011476\n",
      "[411/00963] train_loss: 0.011095\n",
      "[411/01013] train_loss: 0.011556\n",
      "[411/01063] train_loss: 0.011055\n",
      "[411/01113] train_loss: 0.011564\n",
      "[411/01163] train_loss: 0.011336\n",
      "[411/01213] train_loss: 0.011276\n",
      "[412/00037] train_loss: 0.011673\n",
      "[412/00087] train_loss: 0.011738\n",
      "[412/00137] train_loss: 0.011785\n",
      "[412/00187] train_loss: 0.011665\n",
      "[412/00237] train_loss: 0.011860\n",
      "[412/00287] train_loss: 0.011574\n",
      "[412/00337] train_loss: 0.011564\n",
      "[412/00387] train_loss: 0.011739\n",
      "[412/00437] train_loss: 0.011484\n",
      "[412/00487] train_loss: 0.010999\n",
      "[412/00537] train_loss: 0.010981\n",
      "[412/00587] train_loss: 0.011532\n",
      "[412/00637] train_loss: 0.012051\n",
      "[412/00687] train_loss: 0.011253\n",
      "[412/00737] train_loss: 0.011583\n",
      "[412/00787] train_loss: 0.011147\n",
      "[412/00837] train_loss: 0.010968\n",
      "[412/00887] train_loss: 0.011411\n",
      "[412/00937] train_loss: 0.011342\n",
      "[412/00987] train_loss: 0.010941\n",
      "[412/01037] train_loss: 0.011401\n",
      "[412/01087] train_loss: 0.011229\n",
      "[412/01137] train_loss: 0.011018\n",
      "[412/01187] train_loss: 0.011391\n",
      "[413/00011] train_loss: 0.011449\n",
      "[413/00061] train_loss: 0.011541\n",
      "[413/00111] train_loss: 0.012219\n",
      "[413/00161] train_loss: 0.011659\n",
      "[413/00211] train_loss: 0.011438\n",
      "[413/00261] train_loss: 0.011217\n",
      "[413/00311] train_loss: 0.011493\n",
      "[413/00361] train_loss: 0.011391\n",
      "[413/00411] train_loss: 0.011064\n",
      "[413/00461] train_loss: 0.011325\n",
      "[413/00511] train_loss: 0.011425\n",
      "[413/00561] train_loss: 0.011495\n",
      "[413/00611] train_loss: 0.011268\n",
      "[413/00661] train_loss: 0.011403\n",
      "[413/00711] train_loss: 0.010856\n",
      "[413/00761] train_loss: 0.011418\n",
      "[413/00811] train_loss: 0.011288\n",
      "[413/00861] train_loss: 0.011664\n",
      "[413/00911] train_loss: 0.011548\n",
      "[413/00961] train_loss: 0.010975\n",
      "[413/01011] train_loss: 0.011479\n",
      "[413/01061] train_loss: 0.011620\n",
      "[413/01111] train_loss: 0.010896\n",
      "[413/01161] train_loss: 0.011481\n",
      "[413/01211] train_loss: 0.011370\n",
      "[414/00035] train_loss: 0.011913\n",
      "[414/00085] train_loss: 0.011508\n",
      "[414/00135] train_loss: 0.011681\n",
      "[414/00185] train_loss: 0.011594\n",
      "[414/00235] train_loss: 0.011545\n",
      "[414/00285] train_loss: 0.010722\n",
      "[414/00335] train_loss: 0.011763\n",
      "[414/00385] train_loss: 0.011374\n",
      "[414/00435] train_loss: 0.011209\n",
      "[414/00485] train_loss: 0.011231\n",
      "[414/00535] train_loss: 0.011890\n",
      "[414/00585] train_loss: 0.010928\n",
      "[414/00635] train_loss: 0.011333\n",
      "[414/00685] train_loss: 0.012153\n",
      "[414/00735] train_loss: 0.011991\n",
      "[414/00785] train_loss: 0.012269\n",
      "[414/00835] train_loss: 0.011775\n",
      "[414/00885] train_loss: 0.010848\n",
      "[414/00935] train_loss: 0.011020\n",
      "[414/00985] train_loss: 0.011013\n",
      "[414/01035] train_loss: 0.010830\n",
      "[414/01085] train_loss: 0.011226\n",
      "[414/01135] train_loss: 0.010947\n",
      "[414/01185] train_loss: 0.011449\n",
      "[415/00009] train_loss: 0.010933\n",
      "[415/00059] train_loss: 0.011754\n",
      "[415/00109] train_loss: 0.011850\n",
      "[415/00159] train_loss: 0.011734\n",
      "[415/00209] train_loss: 0.011229\n",
      "[415/00259] train_loss: 0.011841\n",
      "[415/00309] train_loss: 0.010935\n",
      "[415/00359] train_loss: 0.011443\n",
      "[415/00409] train_loss: 0.011368\n",
      "[415/00459] train_loss: 0.011264\n",
      "[415/00509] train_loss: 0.011037\n",
      "[415/00559] train_loss: 0.011721\n",
      "[415/00609] train_loss: 0.011154\n",
      "[415/00659] train_loss: 0.011845\n",
      "[415/00709] train_loss: 0.010828\n",
      "[415/00759] train_loss: 0.011488\n",
      "[415/00809] train_loss: 0.012118\n",
      "[415/00859] train_loss: 0.011160\n",
      "[415/00909] train_loss: 0.011295\n",
      "[415/00959] train_loss: 0.011185\n",
      "[415/01009] train_loss: 0.010795\n",
      "[415/01059] train_loss: 0.011889\n",
      "[415/01109] train_loss: 0.011322\n",
      "[415/01159] train_loss: 0.011281\n",
      "[415/01209] train_loss: 0.011329\n",
      "[416/00033] train_loss: 0.011992\n",
      "[416/00083] train_loss: 0.012427\n",
      "[416/00133] train_loss: 0.011544\n",
      "[416/00183] train_loss: 0.010927\n",
      "[416/00233] train_loss: 0.011197\n",
      "[416/00283] train_loss: 0.011775\n",
      "[416/00333] train_loss: 0.011812\n",
      "[416/00383] train_loss: 0.010900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[416/00433] train_loss: 0.011993\n",
      "[416/00483] train_loss: 0.011514\n",
      "[416/00533] train_loss: 0.011631\n",
      "[416/00583] train_loss: 0.011128\n",
      "[416/00633] train_loss: 0.011082\n",
      "[416/00683] train_loss: 0.010780\n",
      "[416/00733] train_loss: 0.010963\n",
      "[416/00783] train_loss: 0.011583\n",
      "[416/00833] train_loss: 0.011703\n",
      "[416/00883] train_loss: 0.011515\n",
      "[416/00933] train_loss: 0.011241\n",
      "[416/00983] train_loss: 0.011607\n",
      "[416/01033] train_loss: 0.010072\n",
      "[416/01083] train_loss: 0.011049\n",
      "[416/01133] train_loss: 0.011479\n",
      "[416/01183] train_loss: 0.011625\n",
      "[417/00007] train_loss: 0.011449\n",
      "[417/00057] train_loss: 0.011631\n",
      "[417/00107] train_loss: 0.011135\n",
      "[417/00157] train_loss: 0.011608\n",
      "[417/00207] train_loss: 0.010895\n",
      "[417/00257] train_loss: 0.011533\n",
      "[417/00307] train_loss: 0.011942\n",
      "[417/00357] train_loss: 0.012066\n",
      "[417/00407] train_loss: 0.010953\n",
      "[417/00457] train_loss: 0.011632\n",
      "[417/00507] train_loss: 0.011981\n",
      "[417/00557] train_loss: 0.010863\n",
      "[417/00607] train_loss: 0.011341\n",
      "[417/00657] train_loss: 0.011730\n",
      "[417/00707] train_loss: 0.011522\n",
      "[417/00757] train_loss: 0.011370\n",
      "[417/00807] train_loss: 0.011525\n",
      "[417/00857] train_loss: 0.011135\n",
      "[417/00907] train_loss: 0.010376\n",
      "[417/00957] train_loss: 0.011722\n",
      "[417/01007] train_loss: 0.011235\n",
      "[417/01057] train_loss: 0.011839\n",
      "[417/01107] train_loss: 0.011180\n",
      "[417/01157] train_loss: 0.011231\n",
      "[417/01207] train_loss: 0.012060\n",
      "[418/00031] train_loss: 0.011559\n",
      "[418/00081] train_loss: 0.011061\n",
      "[418/00131] train_loss: 0.011119\n",
      "[418/00181] train_loss: 0.010893\n",
      "[418/00231] train_loss: 0.011117\n",
      "[418/00281] train_loss: 0.012177\n",
      "[418/00331] train_loss: 0.011069\n",
      "[418/00381] train_loss: 0.011152\n",
      "[418/00431] train_loss: 0.010978\n",
      "[418/00481] train_loss: 0.011985\n",
      "[418/00531] train_loss: 0.010842\n",
      "[418/00581] train_loss: 0.011016\n",
      "[418/00631] train_loss: 0.011423\n",
      "[418/00681] train_loss: 0.011201\n",
      "[418/00731] train_loss: 0.011243\n",
      "[418/00781] train_loss: 0.010877\n",
      "[418/00831] train_loss: 0.010845\n",
      "[418/00881] train_loss: 0.011266\n",
      "[418/00931] train_loss: 0.011668\n",
      "[418/00981] train_loss: 0.011191\n",
      "[418/01031] train_loss: 0.011836\n",
      "[418/01081] train_loss: 0.011706\n",
      "[418/01131] train_loss: 0.011445\n",
      "[418/01181] train_loss: 0.011493\n",
      "[419/00005] train_loss: 0.011434\n",
      "[419/00055] train_loss: 0.011467\n",
      "[419/00105] train_loss: 0.012128\n",
      "[419/00155] train_loss: 0.011024\n",
      "[419/00205] train_loss: 0.011532\n",
      "[419/00255] train_loss: 0.011697\n",
      "[419/00305] train_loss: 0.011794\n",
      "[419/00355] train_loss: 0.010753\n",
      "[419/00405] train_loss: 0.010801\n",
      "[419/00455] train_loss: 0.011653\n",
      "[419/00505] train_loss: 0.011851\n",
      "[419/00555] train_loss: 0.011055\n",
      "[419/00605] train_loss: 0.011740\n",
      "[419/00655] train_loss: 0.012506\n",
      "[419/00705] train_loss: 0.011341\n",
      "[419/00755] train_loss: 0.011018\n",
      "[419/00805] train_loss: 0.011920\n",
      "[419/00855] train_loss: 0.011613\n",
      "[419/00905] train_loss: 0.011950\n",
      "[419/00955] train_loss: 0.011449\n",
      "[419/01005] train_loss: 0.011462\n",
      "[419/01055] train_loss: 0.011042\n",
      "[419/01105] train_loss: 0.011191\n",
      "[419/01155] train_loss: 0.010949\n",
      "[419/01205] train_loss: 0.011578\n",
      "[420/00029] train_loss: 0.012635\n",
      "[420/00079] train_loss: 0.011333\n",
      "[420/00129] train_loss: 0.011807\n",
      "[420/00179] train_loss: 0.011668\n",
      "[420/00229] train_loss: 0.011465\n",
      "[420/00279] train_loss: 0.012155\n",
      "[420/00329] train_loss: 0.011404\n",
      "[420/00379] train_loss: 0.011158\n",
      "[420/00429] train_loss: 0.011671\n",
      "[420/00479] train_loss: 0.011479\n",
      "[420/00529] train_loss: 0.010673\n",
      "[420/00579] train_loss: 0.011398\n",
      "[420/00629] train_loss: 0.011957\n",
      "[420/00679] train_loss: 0.010787\n",
      "[420/00729] train_loss: 0.011002\n",
      "[420/00779] train_loss: 0.010735\n",
      "[420/00829] train_loss: 0.011962\n",
      "[420/00879] train_loss: 0.010689\n",
      "[420/00929] train_loss: 0.010671\n",
      "[420/00979] train_loss: 0.011389\n",
      "[420/01029] train_loss: 0.010875\n",
      "[420/01079] train_loss: 0.011288\n",
      "[420/01129] train_loss: 0.011584\n",
      "[420/01179] train_loss: 0.011028\n",
      "[421/00003] train_loss: 0.011547\n",
      "[421/00053] train_loss: 0.011815\n",
      "[421/00103] train_loss: 0.012152\n",
      "[421/00153] train_loss: 0.011283\n",
      "[421/00203] train_loss: 0.011583\n",
      "[421/00253] train_loss: 0.011165\n",
      "[421/00303] train_loss: 0.011170\n",
      "[421/00353] train_loss: 0.011414\n",
      "[421/00403] train_loss: 0.011819\n",
      "[421/00453] train_loss: 0.011207\n",
      "[421/00503] train_loss: 0.011898\n",
      "[421/00553] train_loss: 0.011767\n",
      "[421/00603] train_loss: 0.011504\n",
      "[421/00653] train_loss: 0.011446\n",
      "[421/00703] train_loss: 0.011400\n",
      "[421/00753] train_loss: 0.011042\n",
      "[421/00803] train_loss: 0.011253\n",
      "[421/00853] train_loss: 0.011683\n",
      "[421/00903] train_loss: 0.010826\n",
      "[421/00953] train_loss: 0.011438\n",
      "[421/01003] train_loss: 0.011900\n",
      "[421/01053] train_loss: 0.011171\n",
      "[421/01103] train_loss: 0.011141\n",
      "[421/01153] train_loss: 0.010735\n",
      "[421/01203] train_loss: 0.010937\n",
      "[422/00027] train_loss: 0.010605\n",
      "[422/00077] train_loss: 0.012084\n",
      "[422/00127] train_loss: 0.011297\n",
      "[422/00177] train_loss: 0.011943\n",
      "[422/00227] train_loss: 0.010949\n",
      "[422/00277] train_loss: 0.012055\n",
      "[422/00327] train_loss: 0.011726\n",
      "[422/00377] train_loss: 0.012197\n",
      "[422/00427] train_loss: 0.011030\n",
      "[422/00477] train_loss: 0.010924\n",
      "[422/00527] train_loss: 0.011395\n",
      "[422/00577] train_loss: 0.011117\n",
      "[422/00627] train_loss: 0.010877\n",
      "[422/00677] train_loss: 0.011804\n",
      "[422/00727] train_loss: 0.011068\n",
      "[422/00777] train_loss: 0.010866\n",
      "[422/00827] train_loss: 0.010923\n",
      "[422/00877] train_loss: 0.012002\n",
      "[422/00927] train_loss: 0.010524\n",
      "[422/00977] train_loss: 0.011045\n",
      "[422/01027] train_loss: 0.011287\n",
      "[422/01077] train_loss: 0.011305\n",
      "[422/01127] train_loss: 0.011647\n",
      "[422/01177] train_loss: 0.011729\n",
      "[423/00001] train_loss: 0.011471\n",
      "[423/00051] train_loss: 0.010952\n",
      "[423/00101] train_loss: 0.011805\n",
      "[423/00151] train_loss: 0.011938\n",
      "[423/00201] train_loss: 0.011508\n",
      "[423/00251] train_loss: 0.011248\n",
      "[423/00301] train_loss: 0.011648\n",
      "[423/00351] train_loss: 0.012509\n",
      "[423/00401] train_loss: 0.010885\n",
      "[423/00451] train_loss: 0.011604\n",
      "[423/00501] train_loss: 0.011524\n",
      "[423/00551] train_loss: 0.011018\n",
      "[423/00601] train_loss: 0.011622\n",
      "[423/00651] train_loss: 0.011608\n",
      "[423/00701] train_loss: 0.011403\n",
      "[423/00751] train_loss: 0.011449\n",
      "[423/00801] train_loss: 0.011384\n",
      "[423/00851] train_loss: 0.011248\n",
      "[423/00901] train_loss: 0.011323\n",
      "[423/00951] train_loss: 0.011403\n",
      "[423/01001] train_loss: 0.011391\n",
      "[423/01051] train_loss: 0.010707\n",
      "[423/01101] train_loss: 0.011280\n",
      "[423/01151] train_loss: 0.011424\n",
      "[423/01201] train_loss: 0.011258\n",
      "[424/00025] train_loss: 0.012121\n",
      "[424/00075] train_loss: 0.011481\n",
      "[424/00125] train_loss: 0.011276\n",
      "[424/00175] train_loss: 0.011835\n",
      "[424/00225] train_loss: 0.011153\n",
      "[424/00275] train_loss: 0.011464\n",
      "[424/00325] train_loss: 0.011552\n",
      "[424/00375] train_loss: 0.012447\n",
      "[424/00425] train_loss: 0.012433\n",
      "[424/00475] train_loss: 0.011261\n",
      "[424/00525] train_loss: 0.010525\n",
      "[424/00575] train_loss: 0.010766\n",
      "[424/00625] train_loss: 0.011377\n",
      "[424/00675] train_loss: 0.010965\n",
      "[424/00725] train_loss: 0.011663\n",
      "[424/00775] train_loss: 0.010846\n",
      "[424/00825] train_loss: 0.011665\n",
      "[424/00875] train_loss: 0.011236\n",
      "[424/00925] train_loss: 0.011384\n",
      "[424/00975] train_loss: 0.010836\n",
      "[424/01025] train_loss: 0.011458\n",
      "[424/01075] train_loss: 0.011539\n",
      "[424/01125] train_loss: 0.010911\n",
      "[424/01175] train_loss: 0.010720\n",
      "[424/01225] train_loss: 0.010900\n",
      "[425/00049] train_loss: 0.012283\n",
      "[425/00099] train_loss: 0.011824\n",
      "[425/00149] train_loss: 0.011980\n",
      "[425/00199] train_loss: 0.011657\n",
      "[425/00249] train_loss: 0.011323\n",
      "[425/00299] train_loss: 0.011830\n",
      "[425/00349] train_loss: 0.011067\n",
      "[425/00399] train_loss: 0.011911\n",
      "[425/00449] train_loss: 0.011462\n",
      "[425/00499] train_loss: 0.011567\n",
      "[425/00549] train_loss: 0.011053\n",
      "[425/00599] train_loss: 0.011483\n",
      "[425/00649] train_loss: 0.011875\n",
      "[425/00699] train_loss: 0.011200\n",
      "[425/00749] train_loss: 0.011727\n",
      "[425/00799] train_loss: 0.011749\n",
      "[425/00849] train_loss: 0.010959\n",
      "[425/00899] train_loss: 0.011068\n",
      "[425/00949] train_loss: 0.010504\n",
      "[425/00999] train_loss: 0.011662\n",
      "[425/01049] train_loss: 0.010759\n",
      "[425/01099] train_loss: 0.011171\n",
      "[425/01149] train_loss: 0.011110\n",
      "[425/01199] train_loss: 0.010837\n",
      "[426/00023] train_loss: 0.011380\n",
      "[426/00073] train_loss: 0.012010\n",
      "[426/00123] train_loss: 0.011633\n",
      "[426/00173] train_loss: 0.011901\n",
      "[426/00223] train_loss: 0.011588\n",
      "[426/00273] train_loss: 0.011023\n",
      "[426/00323] train_loss: 0.010823\n",
      "[426/00373] train_loss: 0.011234\n",
      "[426/00423] train_loss: 0.011089\n",
      "[426/00473] train_loss: 0.011376\n",
      "[426/00523] train_loss: 0.010949\n",
      "[426/00573] train_loss: 0.011605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[426/00623] train_loss: 0.011769\n",
      "[426/00673] train_loss: 0.011803\n",
      "[426/00723] train_loss: 0.011273\n",
      "[426/00773] train_loss: 0.011936\n",
      "[426/00823] train_loss: 0.011331\n",
      "[426/00873] train_loss: 0.011004\n",
      "[426/00923] train_loss: 0.011165\n",
      "[426/00973] train_loss: 0.011027\n",
      "[426/01023] train_loss: 0.011065\n",
      "[426/01073] train_loss: 0.011693\n",
      "[426/01123] train_loss: 0.010876\n",
      "[426/01173] train_loss: 0.010854\n",
      "[426/01223] train_loss: 0.010943\n",
      "[427/00047] train_loss: 0.011546\n",
      "[427/00097] train_loss: 0.011661\n",
      "[427/00147] train_loss: 0.011881\n",
      "[427/00197] train_loss: 0.011959\n",
      "[427/00247] train_loss: 0.011555\n",
      "[427/00297] train_loss: 0.011413\n",
      "[427/00347] train_loss: 0.011315\n",
      "[427/00397] train_loss: 0.011240\n",
      "[427/00447] train_loss: 0.011664\n",
      "[427/00497] train_loss: 0.011254\n",
      "[427/00547] train_loss: 0.011250\n",
      "[427/00597] train_loss: 0.011874\n",
      "[427/00647] train_loss: 0.011242\n",
      "[427/00697] train_loss: 0.011454\n",
      "[427/00747] train_loss: 0.012126\n",
      "[427/00797] train_loss: 0.011146\n",
      "[427/00847] train_loss: 0.011285\n",
      "[427/00897] train_loss: 0.010803\n",
      "[427/00947] train_loss: 0.010747\n",
      "[427/00997] train_loss: 0.011317\n",
      "[427/01047] train_loss: 0.010749\n",
      "[427/01097] train_loss: 0.010569\n",
      "[427/01147] train_loss: 0.011586\n",
      "[427/01197] train_loss: 0.010632\n",
      "[428/00021] train_loss: 0.011818\n",
      "[428/00071] train_loss: 0.011919\n",
      "[428/00121] train_loss: 0.011512\n",
      "[428/00171] train_loss: 0.011629\n",
      "[428/00221] train_loss: 0.010915\n",
      "[428/00271] train_loss: 0.011523\n",
      "[428/00321] train_loss: 0.011555\n",
      "[428/00371] train_loss: 0.011052\n",
      "[428/00421] train_loss: 0.011692\n",
      "[428/00471] train_loss: 0.011494\n",
      "[428/00521] train_loss: 0.012027\n",
      "[428/00571] train_loss: 0.011782\n",
      "[428/00621] train_loss: 0.010720\n",
      "[428/00671] train_loss: 0.011139\n",
      "[428/00721] train_loss: 0.011376\n",
      "[428/00771] train_loss: 0.011407\n",
      "[428/00821] train_loss: 0.010616\n",
      "[428/00871] train_loss: 0.011941\n",
      "[428/00921] train_loss: 0.011354\n",
      "[428/00971] train_loss: 0.010795\n",
      "[428/01021] train_loss: 0.011782\n",
      "[428/01071] train_loss: 0.011531\n",
      "[428/01121] train_loss: 0.010907\n",
      "[428/01171] train_loss: 0.011568\n",
      "[428/01221] train_loss: 0.010804\n",
      "[429/00045] train_loss: 0.011578\n",
      "[429/00095] train_loss: 0.011521\n",
      "[429/00145] train_loss: 0.011996\n",
      "[429/00195] train_loss: 0.012161\n",
      "[429/00245] train_loss: 0.011209\n",
      "[429/00295] train_loss: 0.011508\n",
      "[429/00345] train_loss: 0.011602\n",
      "[429/00395] train_loss: 0.011714\n",
      "[429/00445] train_loss: 0.011363\n",
      "[429/00495] train_loss: 0.010820\n",
      "[429/00545] train_loss: 0.011529\n",
      "[429/00595] train_loss: 0.010687\n",
      "[429/00645] train_loss: 0.010873\n",
      "[429/00695] train_loss: 0.011146\n",
      "[429/00745] train_loss: 0.011656\n",
      "[429/00795] train_loss: 0.010913\n",
      "[429/00845] train_loss: 0.011180\n",
      "[429/00895] train_loss: 0.010631\n",
      "[429/00945] train_loss: 0.011159\n",
      "[429/00995] train_loss: 0.010963\n",
      "[429/01045] train_loss: 0.011196\n",
      "[429/01095] train_loss: 0.011281\n",
      "[429/01145] train_loss: 0.010988\n",
      "[429/01195] train_loss: 0.011499\n",
      "[430/00019] train_loss: 0.011302\n",
      "[430/00069] train_loss: 0.011036\n",
      "[430/00119] train_loss: 0.011135\n",
      "[430/00169] train_loss: 0.011331\n",
      "[430/00219] train_loss: 0.012216\n",
      "[430/00269] train_loss: 0.010627\n",
      "[430/00319] train_loss: 0.011753\n",
      "[430/00369] train_loss: 0.011133\n",
      "[430/00419] train_loss: 0.011578\n",
      "[430/00469] train_loss: 0.011327\n",
      "[430/00519] train_loss: 0.011751\n",
      "[430/00569] train_loss: 0.011781\n",
      "[430/00619] train_loss: 0.011490\n",
      "[430/00669] train_loss: 0.011068\n",
      "[430/00719] train_loss: 0.011108\n",
      "[430/00769] train_loss: 0.011102\n",
      "[430/00819] train_loss: 0.010842\n",
      "[430/00869] train_loss: 0.011673\n",
      "[430/00919] train_loss: 0.011092\n",
      "[430/00969] train_loss: 0.011490\n",
      "[430/01019] train_loss: 0.011010\n",
      "[430/01069] train_loss: 0.012393\n",
      "[430/01119] train_loss: 0.010392\n",
      "[430/01169] train_loss: 0.011496\n",
      "[430/01219] train_loss: 0.011588\n",
      "[431/00043] train_loss: 0.011428\n",
      "[431/00093] train_loss: 0.010875\n",
      "[431/00143] train_loss: 0.011576\n",
      "[431/00193] train_loss: 0.010709\n",
      "[431/00243] train_loss: 0.011154\n",
      "[431/00293] train_loss: 0.012129\n",
      "[431/00343] train_loss: 0.011681\n",
      "[431/00393] train_loss: 0.011476\n",
      "[431/00443] train_loss: 0.011108\n",
      "[431/00493] train_loss: 0.010969\n",
      "[431/00543] train_loss: 0.012157\n",
      "[431/00593] train_loss: 0.011373\n",
      "[431/00643] train_loss: 0.011373\n",
      "[431/00693] train_loss: 0.011712\n",
      "[431/00743] train_loss: 0.011447\n",
      "[431/00793] train_loss: 0.011258\n",
      "[431/00843] train_loss: 0.010991\n",
      "[431/00893] train_loss: 0.010984\n",
      "[431/00943] train_loss: 0.011451\n",
      "[431/00993] train_loss: 0.011397\n",
      "[431/01043] train_loss: 0.011216\n",
      "[431/01093] train_loss: 0.012040\n",
      "[431/01143] train_loss: 0.011852\n",
      "[431/01193] train_loss: 0.011431\n",
      "[432/00017] train_loss: 0.011257\n",
      "[432/00067] train_loss: 0.010795\n",
      "[432/00117] train_loss: 0.011715\n",
      "[432/00167] train_loss: 0.011654\n",
      "[432/00217] train_loss: 0.011267\n",
      "[432/00267] train_loss: 0.011284\n",
      "[432/00317] train_loss: 0.011346\n",
      "[432/00367] train_loss: 0.011171\n",
      "[432/00417] train_loss: 0.012156\n",
      "[432/00467] train_loss: 0.011797\n",
      "[432/00517] train_loss: 0.010819\n",
      "[432/00567] train_loss: 0.011381\n",
      "[432/00617] train_loss: 0.011852\n",
      "[432/00667] train_loss: 0.011094\n",
      "[432/00717] train_loss: 0.012059\n",
      "[432/00767] train_loss: 0.011809\n",
      "[432/00817] train_loss: 0.010856\n",
      "[432/00867] train_loss: 0.011282\n",
      "[432/00917] train_loss: 0.011539\n",
      "[432/00967] train_loss: 0.010399\n",
      "[432/01017] train_loss: 0.010945\n",
      "[432/01067] train_loss: 0.011102\n",
      "[432/01117] train_loss: 0.011579\n",
      "[432/01167] train_loss: 0.011653\n",
      "[432/01217] train_loss: 0.011706\n",
      "[433/00041] train_loss: 0.011927\n",
      "[433/00091] train_loss: 0.011607\n",
      "[433/00141] train_loss: 0.011634\n",
      "[433/00191] train_loss: 0.011191\n",
      "[433/00241] train_loss: 0.011593\n",
      "[433/00291] train_loss: 0.011043\n",
      "[433/00341] train_loss: 0.011292\n",
      "[433/00391] train_loss: 0.011947\n",
      "[433/00441] train_loss: 0.011591\n",
      "[433/00491] train_loss: 0.011812\n",
      "[433/00541] train_loss: 0.011483\n",
      "[433/00591] train_loss: 0.011016\n",
      "[433/00641] train_loss: 0.010957\n",
      "[433/00691] train_loss: 0.011107\n",
      "[433/00741] train_loss: 0.011356\n",
      "[433/00791] train_loss: 0.011538\n",
      "[433/00841] train_loss: 0.011261\n",
      "[433/00891] train_loss: 0.011751\n",
      "[433/00941] train_loss: 0.011232\n",
      "[433/00991] train_loss: 0.011046\n",
      "[433/01041] train_loss: 0.011752\n",
      "[433/01091] train_loss: 0.011064\n",
      "[433/01141] train_loss: 0.010653\n",
      "[433/01191] train_loss: 0.010577\n",
      "[434/00015] train_loss: 0.011361\n",
      "[434/00065] train_loss: 0.011431\n",
      "[434/00115] train_loss: 0.012153\n",
      "[434/00165] train_loss: 0.011906\n",
      "[434/00215] train_loss: 0.011684\n",
      "[434/00265] train_loss: 0.011269\n",
      "[434/00315] train_loss: 0.011568\n",
      "[434/00365] train_loss: 0.011249\n",
      "[434/00415] train_loss: 0.012299\n",
      "[434/00465] train_loss: 0.011357\n",
      "[434/00515] train_loss: 0.011055\n",
      "[434/00565] train_loss: 0.011073\n",
      "[434/00615] train_loss: 0.010948\n",
      "[434/00665] train_loss: 0.010803\n",
      "[434/00715] train_loss: 0.011041\n",
      "[434/00765] train_loss: 0.011221\n",
      "[434/00815] train_loss: 0.010687\n",
      "[434/00865] train_loss: 0.011593\n",
      "[434/00915] train_loss: 0.010687\n",
      "[434/00965] train_loss: 0.011449\n",
      "[434/01015] train_loss: 0.010850\n",
      "[434/01065] train_loss: 0.011380\n",
      "[434/01115] train_loss: 0.011091\n",
      "[434/01165] train_loss: 0.011451\n",
      "[434/01215] train_loss: 0.010763\n",
      "[435/00039] train_loss: 0.011965\n",
      "[435/00089] train_loss: 0.011480\n",
      "[435/00139] train_loss: 0.011445\n",
      "[435/00189] train_loss: 0.011746\n",
      "[435/00239] train_loss: 0.011019\n",
      "[435/00289] train_loss: 0.011089\n",
      "[435/00339] train_loss: 0.010914\n",
      "[435/00389] train_loss: 0.010921\n",
      "[435/00439] train_loss: 0.011772\n",
      "[435/00489] train_loss: 0.011000\n",
      "[435/00539] train_loss: 0.011815\n",
      "[435/00589] train_loss: 0.011229\n",
      "[435/00639] train_loss: 0.011738\n",
      "[435/00689] train_loss: 0.011341\n",
      "[435/00739] train_loss: 0.011213\n",
      "[435/00789] train_loss: 0.011551\n",
      "[435/00839] train_loss: 0.011010\n",
      "[435/00889] train_loss: 0.011166\n",
      "[435/00939] train_loss: 0.010937\n",
      "[435/00989] train_loss: 0.011727\n",
      "[435/01039] train_loss: 0.011715\n",
      "[435/01089] train_loss: 0.010882\n",
      "[435/01139] train_loss: 0.010949\n",
      "[435/01189] train_loss: 0.010574\n",
      "[436/00013] train_loss: 0.011350\n",
      "[436/00063] train_loss: 0.011377\n",
      "[436/00113] train_loss: 0.011482\n",
      "[436/00163] train_loss: 0.011314\n",
      "[436/00213] train_loss: 0.011656\n",
      "[436/00263] train_loss: 0.011110\n",
      "[436/00313] train_loss: 0.011117\n",
      "[436/00363] train_loss: 0.011169\n",
      "[436/00413] train_loss: 0.011195\n",
      "[436/00463] train_loss: 0.011390\n",
      "[436/00513] train_loss: 0.011255\n",
      "[436/00563] train_loss: 0.011282\n",
      "[436/00613] train_loss: 0.011248\n",
      "[436/00663] train_loss: 0.010947\n",
      "[436/00713] train_loss: 0.011307\n",
      "[436/00763] train_loss: 0.012490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[436/00813] train_loss: 0.011794\n",
      "[436/00863] train_loss: 0.011363\n",
      "[436/00913] train_loss: 0.011302\n",
      "[436/00963] train_loss: 0.011420\n",
      "[436/01013] train_loss: 0.011335\n",
      "[436/01063] train_loss: 0.011161\n",
      "[436/01113] train_loss: 0.011210\n",
      "[436/01163] train_loss: 0.010899\n",
      "[436/01213] train_loss: 0.011237\n",
      "[437/00037] train_loss: 0.011951\n",
      "[437/00087] train_loss: 0.011423\n",
      "[437/00137] train_loss: 0.012020\n",
      "[437/00187] train_loss: 0.011697\n",
      "[437/00237] train_loss: 0.011292\n",
      "[437/00287] train_loss: 0.011557\n",
      "[437/00337] train_loss: 0.012056\n",
      "[437/00387] train_loss: 0.011204\n",
      "[437/00437] train_loss: 0.011584\n",
      "[437/00487] train_loss: 0.011223\n",
      "[437/00537] train_loss: 0.011360\n",
      "[437/00587] train_loss: 0.011776\n",
      "[437/00637] train_loss: 0.011303\n",
      "[437/00687] train_loss: 0.011163\n",
      "[437/00737] train_loss: 0.011090\n",
      "[437/00787] train_loss: 0.011135\n",
      "[437/00837] train_loss: 0.011006\n",
      "[437/00887] train_loss: 0.011372\n",
      "[437/00937] train_loss: 0.010811\n",
      "[437/00987] train_loss: 0.011487\n",
      "[437/01037] train_loss: 0.010949\n",
      "[437/01087] train_loss: 0.011127\n",
      "[437/01137] train_loss: 0.010994\n",
      "[437/01187] train_loss: 0.011319\n",
      "[438/00011] train_loss: 0.011225\n",
      "[438/00061] train_loss: 0.011981\n",
      "[438/00111] train_loss: 0.012070\n",
      "[438/00161] train_loss: 0.011423\n",
      "[438/00211] train_loss: 0.011748\n",
      "[438/00261] train_loss: 0.011724\n",
      "[438/00311] train_loss: 0.011169\n",
      "[438/00361] train_loss: 0.011077\n",
      "[438/00411] train_loss: 0.012024\n",
      "[438/00461] train_loss: 0.011189\n",
      "[438/00511] train_loss: 0.010834\n",
      "[438/00561] train_loss: 0.010835\n",
      "[438/00611] train_loss: 0.011417\n",
      "[438/00661] train_loss: 0.010874\n",
      "[438/00711] train_loss: 0.010971\n",
      "[438/00761] train_loss: 0.011569\n",
      "[438/00811] train_loss: 0.011373\n",
      "[438/00861] train_loss: 0.011244\n",
      "[438/00911] train_loss: 0.010785\n",
      "[438/00961] train_loss: 0.011277\n",
      "[438/01011] train_loss: 0.010650\n",
      "[438/01061] train_loss: 0.011716\n",
      "[438/01111] train_loss: 0.011555\n",
      "[438/01161] train_loss: 0.011454\n",
      "[438/01211] train_loss: 0.011662\n",
      "[439/00035] train_loss: 0.011262\n",
      "[439/00085] train_loss: 0.011400\n",
      "[439/00135] train_loss: 0.012007\n",
      "[439/00185] train_loss: 0.010889\n",
      "[439/00235] train_loss: 0.011588\n",
      "[439/00285] train_loss: 0.011665\n",
      "[439/00335] train_loss: 0.011434\n",
      "[439/00385] train_loss: 0.011860\n",
      "[439/00435] train_loss: 0.010821\n",
      "[439/00485] train_loss: 0.011188\n",
      "[439/00535] train_loss: 0.011910\n",
      "[439/00585] train_loss: 0.011650\n",
      "[439/00635] train_loss: 0.011201\n",
      "[439/00685] train_loss: 0.010750\n",
      "[439/00735] train_loss: 0.012086\n",
      "[439/00785] train_loss: 0.011227\n",
      "[439/00835] train_loss: 0.011807\n",
      "[439/00885] train_loss: 0.010695\n",
      "[439/00935] train_loss: 0.010489\n",
      "[439/00985] train_loss: 0.011087\n",
      "[439/01035] train_loss: 0.010956\n",
      "[439/01085] train_loss: 0.010985\n",
      "[439/01135] train_loss: 0.011193\n",
      "[439/01185] train_loss: 0.011697\n",
      "[440/00009] train_loss: 0.011678\n",
      "[440/00059] train_loss: 0.011919\n",
      "[440/00109] train_loss: 0.012144\n",
      "[440/00159] train_loss: 0.011778\n",
      "[440/00209] train_loss: 0.011264\n",
      "[440/00259] train_loss: 0.010413\n",
      "[440/00309] train_loss: 0.011009\n",
      "[440/00359] train_loss: 0.011492\n",
      "[440/00409] train_loss: 0.011360\n",
      "[440/00459] train_loss: 0.011517\n",
      "[440/00509] train_loss: 0.010303\n",
      "[440/00559] train_loss: 0.011344\n",
      "[440/00609] train_loss: 0.011230\n",
      "[440/00659] train_loss: 0.011587\n",
      "[440/00709] train_loss: 0.011381\n",
      "[440/00759] train_loss: 0.011473\n",
      "[440/00809] train_loss: 0.010901\n",
      "[440/00859] train_loss: 0.011359\n",
      "[440/00909] train_loss: 0.011402\n",
      "[440/00959] train_loss: 0.010607\n",
      "[440/01009] train_loss: 0.011272\n",
      "[440/01059] train_loss: 0.010999\n",
      "[440/01109] train_loss: 0.010280\n",
      "[440/01159] train_loss: 0.011444\n",
      "[440/01209] train_loss: 0.011083\n",
      "[441/00033] train_loss: 0.011579\n",
      "[441/00083] train_loss: 0.011336\n",
      "[441/00133] train_loss: 0.011312\n",
      "[441/00183] train_loss: 0.011606\n",
      "[441/00233] train_loss: 0.011645\n",
      "[441/00283] train_loss: 0.011427\n",
      "[441/00333] train_loss: 0.011017\n",
      "[441/00383] train_loss: 0.011215\n",
      "[441/00433] train_loss: 0.011206\n",
      "[441/00483] train_loss: 0.010943\n",
      "[441/00533] train_loss: 0.011063\n",
      "[441/00583] train_loss: 0.011217\n",
      "[441/00633] train_loss: 0.011605\n",
      "[441/00683] train_loss: 0.011567\n",
      "[441/00733] train_loss: 0.011660\n",
      "[441/00783] train_loss: 0.011465\n",
      "[441/00833] train_loss: 0.011427\n",
      "[441/00883] train_loss: 0.011633\n",
      "[441/00933] train_loss: 0.010763\n",
      "[441/00983] train_loss: 0.011149\n",
      "[441/01033] train_loss: 0.011169\n",
      "[441/01083] train_loss: 0.011689\n",
      "[441/01133] train_loss: 0.011453\n",
      "[441/01183] train_loss: 0.010928\n",
      "[442/00007] train_loss: 0.011589\n",
      "[442/00057] train_loss: 0.011645\n",
      "[442/00107] train_loss: 0.011829\n",
      "[442/00157] train_loss: 0.011074\n",
      "[442/00207] train_loss: 0.011127\n",
      "[442/00257] train_loss: 0.011442\n",
      "[442/00307] train_loss: 0.011372\n",
      "[442/00357] train_loss: 0.012071\n",
      "[442/00407] train_loss: 0.011914\n",
      "[442/00457] train_loss: 0.011368\n",
      "[442/00507] train_loss: 0.011996\n",
      "[442/00557] train_loss: 0.011222\n",
      "[442/00607] train_loss: 0.011056\n",
      "[442/00657] train_loss: 0.012463\n",
      "[442/00707] train_loss: 0.010953\n",
      "[442/00757] train_loss: 0.011369\n",
      "[442/00807] train_loss: 0.011251\n",
      "[442/00857] train_loss: 0.011280\n",
      "[442/00907] train_loss: 0.010574\n",
      "[442/00957] train_loss: 0.010802\n",
      "[442/01007] train_loss: 0.011053\n",
      "[442/01057] train_loss: 0.010744\n",
      "[442/01107] train_loss: 0.010629\n",
      "[442/01157] train_loss: 0.011544\n",
      "[442/01207] train_loss: 0.010915\n",
      "[443/00031] train_loss: 0.011634\n",
      "[443/00081] train_loss: 0.011209\n",
      "[443/00131] train_loss: 0.011700\n",
      "[443/00181] train_loss: 0.012260\n",
      "[443/00231] train_loss: 0.011169\n",
      "[443/00281] train_loss: 0.011594\n",
      "[443/00331] train_loss: 0.011508\n",
      "[443/00381] train_loss: 0.010950\n",
      "[443/00431] train_loss: 0.011365\n",
      "[443/00481] train_loss: 0.012113\n",
      "[443/00531] train_loss: 0.011078\n",
      "[443/00581] train_loss: 0.011489\n",
      "[443/00631] train_loss: 0.010620\n",
      "[443/00681] train_loss: 0.011305\n",
      "[443/00731] train_loss: 0.011587\n",
      "[443/00781] train_loss: 0.011725\n",
      "[443/00831] train_loss: 0.011684\n",
      "[443/00881] train_loss: 0.011135\n",
      "[443/00931] train_loss: 0.012512\n",
      "[443/00981] train_loss: 0.011994\n",
      "[443/01031] train_loss: 0.010690\n",
      "[443/01081] train_loss: 0.011240\n",
      "[443/01131] train_loss: 0.011139\n",
      "[443/01181] train_loss: 0.011113\n",
      "[444/00005] train_loss: 0.011012\n",
      "[444/00055] train_loss: 0.012179\n",
      "[444/00105] train_loss: 0.011137\n",
      "[444/00155] train_loss: 0.010747\n",
      "[444/00205] train_loss: 0.011517\n",
      "[444/00255] train_loss: 0.010934\n",
      "[444/00305] train_loss: 0.011056\n",
      "[444/00355] train_loss: 0.011903\n",
      "[444/00405] train_loss: 0.011516\n",
      "[444/00455] train_loss: 0.011263\n",
      "[444/00505] train_loss: 0.010890\n",
      "[444/00555] train_loss: 0.011351\n",
      "[444/00605] train_loss: 0.011348\n",
      "[444/00655] train_loss: 0.011881\n",
      "[444/00705] train_loss: 0.011221\n",
      "[444/00755] train_loss: 0.011541\n",
      "[444/00805] train_loss: 0.011748\n",
      "[444/00855] train_loss: 0.011132\n",
      "[444/00905] train_loss: 0.010884\n",
      "[444/00955] train_loss: 0.011053\n",
      "[444/01005] train_loss: 0.011643\n",
      "[444/01055] train_loss: 0.010703\n",
      "[444/01105] train_loss: 0.010859\n",
      "[444/01155] train_loss: 0.010881\n",
      "[444/01205] train_loss: 0.010507\n",
      "[445/00029] train_loss: 0.011214\n",
      "[445/00079] train_loss: 0.011321\n",
      "[445/00129] train_loss: 0.011011\n",
      "[445/00179] train_loss: 0.011549\n",
      "[445/00229] train_loss: 0.011928\n",
      "[445/00279] train_loss: 0.011214\n",
      "[445/00329] train_loss: 0.011227\n",
      "[445/00379] train_loss: 0.011120\n",
      "[445/00429] train_loss: 0.011341\n",
      "[445/00479] train_loss: 0.012327\n",
      "[445/00529] train_loss: 0.010786\n",
      "[445/00579] train_loss: 0.011173\n",
      "[445/00629] train_loss: 0.011250\n",
      "[445/00679] train_loss: 0.011079\n",
      "[445/00729] train_loss: 0.011541\n",
      "[445/00779] train_loss: 0.011580\n",
      "[445/00829] train_loss: 0.011036\n",
      "[445/00879] train_loss: 0.011282\n",
      "[445/00929] train_loss: 0.011119\n",
      "[445/00979] train_loss: 0.010838\n",
      "[445/01029] train_loss: 0.011426\n",
      "[445/01079] train_loss: 0.011304\n",
      "[445/01129] train_loss: 0.011189\n",
      "[445/01179] train_loss: 0.011897\n",
      "[446/00003] train_loss: 0.011399\n",
      "[446/00053] train_loss: 0.011942\n",
      "[446/00103] train_loss: 0.011144\n",
      "[446/00153] train_loss: 0.011304\n",
      "[446/00203] train_loss: 0.010932\n",
      "[446/00253] train_loss: 0.011883\n",
      "[446/00303] train_loss: 0.011371\n",
      "[446/00353] train_loss: 0.011754\n",
      "[446/00403] train_loss: 0.010846\n",
      "[446/00453] train_loss: 0.011631\n",
      "[446/00503] train_loss: 0.010588\n",
      "[446/00553] train_loss: 0.011849\n",
      "[446/00603] train_loss: 0.011909\n",
      "[446/00653] train_loss: 0.011241\n",
      "[446/00703] train_loss: 0.011485\n",
      "[446/00753] train_loss: 0.011611\n",
      "[446/00803] train_loss: 0.010763\n",
      "[446/00853] train_loss: 0.011011\n",
      "[446/00903] train_loss: 0.010900\n",
      "[446/00953] train_loss: 0.010764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[446/01003] train_loss: 0.011198\n",
      "[446/01053] train_loss: 0.011609\n",
      "[446/01103] train_loss: 0.010938\n",
      "[446/01153] train_loss: 0.011090\n",
      "[446/01203] train_loss: 0.011043\n",
      "[447/00027] train_loss: 0.012183\n",
      "[447/00077] train_loss: 0.012363\n",
      "[447/00127] train_loss: 0.011774\n",
      "[447/00177] train_loss: 0.011542\n",
      "[447/00227] train_loss: 0.011510\n",
      "[447/00277] train_loss: 0.010816\n",
      "[447/00327] train_loss: 0.011214\n",
      "[447/00377] train_loss: 0.011265\n",
      "[447/00427] train_loss: 0.010896\n",
      "[447/00477] train_loss: 0.011287\n",
      "[447/00527] train_loss: 0.011596\n",
      "[447/00577] train_loss: 0.011253\n",
      "[447/00627] train_loss: 0.011606\n",
      "[447/00677] train_loss: 0.011434\n",
      "[447/00727] train_loss: 0.011669\n",
      "[447/00777] train_loss: 0.010594\n",
      "[447/00827] train_loss: 0.010794\n",
      "[447/00877] train_loss: 0.010876\n",
      "[447/00927] train_loss: 0.011321\n",
      "[447/00977] train_loss: 0.011442\n",
      "[447/01027] train_loss: 0.010745\n",
      "[447/01077] train_loss: 0.011394\n",
      "[447/01127] train_loss: 0.011522\n",
      "[447/01177] train_loss: 0.011165\n",
      "[448/00001] train_loss: 0.010914\n",
      "[448/00051] train_loss: 0.011912\n",
      "[448/00101] train_loss: 0.010988\n",
      "[448/00151] train_loss: 0.011997\n",
      "[448/00201] train_loss: 0.011677\n",
      "[448/00251] train_loss: 0.011175\n",
      "[448/00301] train_loss: 0.011427\n",
      "[448/00351] train_loss: 0.011282\n",
      "[448/00401] train_loss: 0.010604\n",
      "[448/00451] train_loss: 0.011734\n",
      "[448/00501] train_loss: 0.011131\n",
      "[448/00551] train_loss: 0.011526\n",
      "[448/00601] train_loss: 0.011377\n",
      "[448/00651] train_loss: 0.011688\n",
      "[448/00701] train_loss: 0.011202\n",
      "[448/00751] train_loss: 0.010899\n",
      "[448/00801] train_loss: 0.011203\n",
      "[448/00851] train_loss: 0.011687\n",
      "[448/00901] train_loss: 0.011128\n",
      "[448/00951] train_loss: 0.010941\n",
      "[448/01001] train_loss: 0.010534\n",
      "[448/01051] train_loss: 0.011055\n",
      "[448/01101] train_loss: 0.011567\n",
      "[448/01151] train_loss: 0.010576\n",
      "[448/01201] train_loss: 0.010987\n",
      "[449/00025] train_loss: 0.011401\n",
      "[449/00075] train_loss: 0.012307\n",
      "[449/00125] train_loss: 0.011614\n",
      "[449/00175] train_loss: 0.011903\n",
      "[449/00225] train_loss: 0.011224\n",
      "[449/00275] train_loss: 0.011171\n",
      "[449/00325] train_loss: 0.011109\n",
      "[449/00375] train_loss: 0.011505\n",
      "[449/00425] train_loss: 0.010826\n",
      "[449/00475] train_loss: 0.011221\n",
      "[449/00525] train_loss: 0.011098\n",
      "[449/00575] train_loss: 0.011156\n",
      "[449/00625] train_loss: 0.011395\n",
      "[449/00675] train_loss: 0.011480\n",
      "[449/00725] train_loss: 0.011042\n",
      "[449/00775] train_loss: 0.011367\n",
      "[449/00825] train_loss: 0.011025\n",
      "[449/00875] train_loss: 0.011380\n",
      "[449/00925] train_loss: 0.011026\n",
      "[449/00975] train_loss: 0.010904\n",
      "[449/01025] train_loss: 0.011154\n",
      "[449/01075] train_loss: 0.011229\n",
      "[449/01125] train_loss: 0.010949\n",
      "[449/01175] train_loss: 0.011250\n",
      "[449/01225] train_loss: 0.010706\n",
      "[450/00049] train_loss: 0.011381\n",
      "[450/00099] train_loss: 0.012799\n",
      "[450/00149] train_loss: 0.011414\n",
      "[450/00199] train_loss: 0.011104\n",
      "[450/00249] train_loss: 0.011509\n",
      "[450/00299] train_loss: 0.010996\n",
      "[450/00349] train_loss: 0.011082\n",
      "[450/00399] train_loss: 0.011330\n",
      "[450/00449] train_loss: 0.010651\n",
      "[450/00499] train_loss: 0.011240\n",
      "[450/00549] train_loss: 0.011417\n",
      "[450/00599] train_loss: 0.011244\n",
      "[450/00649] train_loss: 0.011399\n",
      "[450/00699] train_loss: 0.011268\n",
      "[450/00749] train_loss: 0.010989\n",
      "[450/00799] train_loss: 0.011258\n",
      "[450/00849] train_loss: 0.011532\n",
      "[450/00899] train_loss: 0.011546\n",
      "[450/00949] train_loss: 0.010675\n",
      "[450/00999] train_loss: 0.011504\n",
      "[450/01049] train_loss: 0.011221\n",
      "[450/01099] train_loss: 0.010963\n",
      "[450/01149] train_loss: 0.011138\n",
      "[450/01199] train_loss: 0.010827\n",
      "[451/00023] train_loss: 0.011203\n",
      "[451/00073] train_loss: 0.012266\n",
      "[451/00123] train_loss: 0.011577\n",
      "[451/00173] train_loss: 0.010944\n",
      "[451/00223] train_loss: 0.011631\n",
      "[451/00273] train_loss: 0.010970\n",
      "[451/00323] train_loss: 0.011146\n",
      "[451/00373] train_loss: 0.011719\n",
      "[451/00423] train_loss: 0.011218\n",
      "[451/00473] train_loss: 0.011279\n",
      "[451/00523] train_loss: 0.011490\n",
      "[451/00573] train_loss: 0.010462\n",
      "[451/00623] train_loss: 0.011178\n",
      "[451/00673] train_loss: 0.011300\n",
      "[451/00723] train_loss: 0.011171\n",
      "[451/00773] train_loss: 0.010529\n",
      "[451/00823] train_loss: 0.011732\n",
      "[451/00873] train_loss: 0.011321\n",
      "[451/00923] train_loss: 0.011142\n",
      "[451/00973] train_loss: 0.011708\n",
      "[451/01023] train_loss: 0.011635\n",
      "[451/01073] train_loss: 0.010758\n",
      "[451/01123] train_loss: 0.011238\n",
      "[451/01173] train_loss: 0.011506\n",
      "[451/01223] train_loss: 0.010365\n",
      "[452/00047] train_loss: 0.011918\n",
      "[452/00097] train_loss: 0.011395\n",
      "[452/00147] train_loss: 0.011453\n",
      "[452/00197] train_loss: 0.011594\n",
      "[452/00247] train_loss: 0.011384\n",
      "[452/00297] train_loss: 0.011565\n",
      "[452/00347] train_loss: 0.011324\n",
      "[452/00397] train_loss: 0.011042\n",
      "[452/00447] train_loss: 0.011212\n",
      "[452/00497] train_loss: 0.010573\n",
      "[452/00547] train_loss: 0.011049\n",
      "[452/00597] train_loss: 0.010819\n",
      "[452/00647] train_loss: 0.010738\n",
      "[452/00697] train_loss: 0.011347\n",
      "[452/00747] train_loss: 0.011068\n",
      "[452/00797] train_loss: 0.011206\n",
      "[452/00847] train_loss: 0.011211\n",
      "[452/00897] train_loss: 0.011345\n",
      "[452/00947] train_loss: 0.011642\n",
      "[452/00997] train_loss: 0.010939\n",
      "[452/01047] train_loss: 0.011305\n",
      "[452/01097] train_loss: 0.010723\n",
      "[452/01147] train_loss: 0.011334\n",
      "[452/01197] train_loss: 0.011366\n",
      "[453/00021] train_loss: 0.012071\n",
      "[453/00071] train_loss: 0.011491\n",
      "[453/00121] train_loss: 0.012183\n",
      "[453/00171] train_loss: 0.010929\n",
      "[453/00221] train_loss: 0.010941\n",
      "[453/00271] train_loss: 0.011607\n",
      "[453/00321] train_loss: 0.012116\n",
      "[453/00371] train_loss: 0.011209\n",
      "[453/00421] train_loss: 0.011963\n",
      "[453/00471] train_loss: 0.011802\n",
      "[453/00521] train_loss: 0.011335\n",
      "[453/00571] train_loss: 0.011995\n",
      "[453/00621] train_loss: 0.011602\n",
      "[453/00671] train_loss: 0.010687\n",
      "[453/00721] train_loss: 0.010633\n",
      "[453/00771] train_loss: 0.011219\n",
      "[453/00821] train_loss: 0.011445\n",
      "[453/00871] train_loss: 0.010682\n",
      "[453/00921] train_loss: 0.010901\n",
      "[453/00971] train_loss: 0.010774\n",
      "[453/01021] train_loss: 0.011137\n",
      "[453/01071] train_loss: 0.011041\n",
      "[453/01121] train_loss: 0.011355\n",
      "[453/01171] train_loss: 0.011456\n",
      "[453/01221] train_loss: 0.010796\n",
      "[454/00045] train_loss: 0.011099\n",
      "[454/00095] train_loss: 0.011336\n",
      "[454/00145] train_loss: 0.011538\n",
      "[454/00195] train_loss: 0.011482\n",
      "[454/00245] train_loss: 0.011924\n",
      "[454/00295] train_loss: 0.011933\n",
      "[454/00345] train_loss: 0.010614\n",
      "[454/00395] train_loss: 0.011051\n",
      "[454/00445] train_loss: 0.010574\n",
      "[454/00495] train_loss: 0.010769\n",
      "[454/00545] train_loss: 0.011947\n",
      "[454/00595] train_loss: 0.011151\n",
      "[454/00645] train_loss: 0.011124\n",
      "[454/00695] train_loss: 0.012214\n",
      "[454/00745] train_loss: 0.010568\n",
      "[454/00795] train_loss: 0.010987\n",
      "[454/00845] train_loss: 0.011090\n",
      "[454/00895] train_loss: 0.010707\n",
      "[454/00945] train_loss: 0.011615\n",
      "[454/00995] train_loss: 0.010464\n",
      "[454/01045] train_loss: 0.011595\n",
      "[454/01095] train_loss: 0.011285\n",
      "[454/01145] train_loss: 0.010889\n",
      "[454/01195] train_loss: 0.010772\n",
      "[455/00019] train_loss: 0.011803\n",
      "[455/00069] train_loss: 0.011812\n",
      "[455/00119] train_loss: 0.010754\n",
      "[455/00169] train_loss: 0.011309\n",
      "[455/00219] train_loss: 0.012022\n",
      "[455/00269] train_loss: 0.011270\n",
      "[455/00319] train_loss: 0.011336\n",
      "[455/00369] train_loss: 0.010688\n",
      "[455/00419] train_loss: 0.011862\n",
      "[455/00469] train_loss: 0.010255\n",
      "[455/00519] train_loss: 0.012105\n",
      "[455/00569] train_loss: 0.012092\n",
      "[455/00619] train_loss: 0.011983\n",
      "[455/00669] train_loss: 0.010798\n",
      "[455/00719] train_loss: 0.011398\n",
      "[455/00769] train_loss: 0.011032\n",
      "[455/00819] train_loss: 0.011830\n",
      "[455/00869] train_loss: 0.010825\n",
      "[455/00919] train_loss: 0.011152\n",
      "[455/00969] train_loss: 0.011170\n",
      "[455/01019] train_loss: 0.010925\n",
      "[455/01069] train_loss: 0.011297\n",
      "[455/01119] train_loss: 0.010968\n",
      "[455/01169] train_loss: 0.010121\n",
      "[455/01219] train_loss: 0.011239\n",
      "[456/00043] train_loss: 0.012629\n",
      "[456/00093] train_loss: 0.011561\n",
      "[456/00143] train_loss: 0.010975\n",
      "[456/00193] train_loss: 0.011684\n",
      "[456/00243] train_loss: 0.011791\n",
      "[456/00293] train_loss: 0.011629\n",
      "[456/00343] train_loss: 0.011337\n",
      "[456/00393] train_loss: 0.010938\n",
      "[456/00443] train_loss: 0.011210\n",
      "[456/00493] train_loss: 0.011166\n",
      "[456/00543] train_loss: 0.010786\n",
      "[456/00593] train_loss: 0.010743\n",
      "[456/00643] train_loss: 0.011284\n",
      "[456/00693] train_loss: 0.010883\n",
      "[456/00743] train_loss: 0.011315\n",
      "[456/00793] train_loss: 0.010461\n",
      "[456/00843] train_loss: 0.011294\n",
      "[456/00893] train_loss: 0.011525\n",
      "[456/00943] train_loss: 0.011488\n",
      "[456/00993] train_loss: 0.010933\n",
      "[456/01043] train_loss: 0.011559\n",
      "[456/01093] train_loss: 0.010705\n",
      "[456/01143] train_loss: 0.011521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[456/01193] train_loss: 0.011076\n",
      "[457/00017] train_loss: 0.011209\n",
      "[457/00067] train_loss: 0.010668\n",
      "[457/00117] train_loss: 0.011280\n",
      "[457/00167] train_loss: 0.011639\n",
      "[457/00217] train_loss: 0.010628\n",
      "[457/00267] train_loss: 0.011486\n",
      "[457/00317] train_loss: 0.011361\n",
      "[457/00367] train_loss: 0.011419\n",
      "[457/00417] train_loss: 0.010999\n",
      "[457/00467] train_loss: 0.010909\n",
      "[457/00517] train_loss: 0.011762\n",
      "[457/00567] train_loss: 0.011549\n",
      "[457/00617] train_loss: 0.011510\n",
      "[457/00667] train_loss: 0.011359\n",
      "[457/00717] train_loss: 0.011382\n",
      "[457/00767] train_loss: 0.010971\n",
      "[457/00817] train_loss: 0.011806\n",
      "[457/00867] train_loss: 0.011049\n",
      "[457/00917] train_loss: 0.010730\n",
      "[457/00967] train_loss: 0.011626\n",
      "[457/01017] train_loss: 0.011223\n",
      "[457/01067] train_loss: 0.010833\n",
      "[457/01117] train_loss: 0.011300\n",
      "[457/01167] train_loss: 0.011369\n",
      "[457/01217] train_loss: 0.011576\n",
      "[458/00041] train_loss: 0.011978\n",
      "[458/00091] train_loss: 0.011327\n",
      "[458/00141] train_loss: 0.011099\n",
      "[458/00191] train_loss: 0.011797\n",
      "[458/00241] train_loss: 0.011969\n",
      "[458/00291] train_loss: 0.011203\n",
      "[458/00341] train_loss: 0.011422\n",
      "[458/00391] train_loss: 0.010586\n",
      "[458/00441] train_loss: 0.011497\n",
      "[458/00491] train_loss: 0.011283\n",
      "[458/00541] train_loss: 0.011252\n",
      "[458/00591] train_loss: 0.011338\n",
      "[458/00641] train_loss: 0.010538\n",
      "[458/00691] train_loss: 0.011547\n",
      "[458/00741] train_loss: 0.010953\n",
      "[458/00791] train_loss: 0.011228\n",
      "[458/00841] train_loss: 0.010898\n",
      "[458/00891] train_loss: 0.010921\n",
      "[458/00941] train_loss: 0.010319\n",
      "[458/00991] train_loss: 0.011127\n",
      "[458/01041] train_loss: 0.011302\n",
      "[458/01091] train_loss: 0.011219\n",
      "[458/01141] train_loss: 0.011454\n",
      "[458/01191] train_loss: 0.011440\n",
      "[459/00015] train_loss: 0.011697\n",
      "[459/00065] train_loss: 0.011919\n",
      "[459/00115] train_loss: 0.011873\n",
      "[459/00165] train_loss: 0.011400\n",
      "[459/00215] train_loss: 0.011444\n",
      "[459/00265] train_loss: 0.010965\n",
      "[459/00315] train_loss: 0.011566\n",
      "[459/00365] train_loss: 0.011972\n",
      "[459/00415] train_loss: 0.011295\n",
      "[459/00465] train_loss: 0.011272\n",
      "[459/00515] train_loss: 0.011444\n",
      "[459/00565] train_loss: 0.010819\n",
      "[459/00615] train_loss: 0.010958\n",
      "[459/00665] train_loss: 0.011139\n",
      "[459/00715] train_loss: 0.011116\n",
      "[459/00765] train_loss: 0.010727\n",
      "[459/00815] train_loss: 0.010750\n",
      "[459/00865] train_loss: 0.011633\n",
      "[459/00915] train_loss: 0.010920\n",
      "[459/00965] train_loss: 0.011539\n",
      "[459/01015] train_loss: 0.011222\n",
      "[459/01065] train_loss: 0.010992\n",
      "[459/01115] train_loss: 0.011472\n",
      "[459/01165] train_loss: 0.011095\n",
      "[459/01215] train_loss: 0.011174\n",
      "[460/00039] train_loss: 0.011055\n",
      "[460/00089] train_loss: 0.012189\n",
      "[460/00139] train_loss: 0.010850\n",
      "[460/00189] train_loss: 0.011340\n",
      "[460/00239] train_loss: 0.011813\n",
      "[460/00289] train_loss: 0.011504\n",
      "[460/00339] train_loss: 0.011026\n",
      "[460/00389] train_loss: 0.011051\n",
      "[460/00439] train_loss: 0.010832\n",
      "[460/00489] train_loss: 0.011420\n",
      "[460/00539] train_loss: 0.010858\n",
      "[460/00589] train_loss: 0.010781\n",
      "[460/00639] train_loss: 0.011201\n",
      "[460/00689] train_loss: 0.011371\n",
      "[460/00739] train_loss: 0.010990\n",
      "[460/00789] train_loss: 0.010870\n",
      "[460/00839] train_loss: 0.011132\n",
      "[460/00889] train_loss: 0.011711\n",
      "[460/00939] train_loss: 0.010843\n",
      "[460/00989] train_loss: 0.010887\n",
      "[460/01039] train_loss: 0.010870\n",
      "[460/01089] train_loss: 0.011557\n",
      "[460/01139] train_loss: 0.011650\n",
      "[460/01189] train_loss: 0.011079\n",
      "[461/00013] train_loss: 0.011835\n",
      "[461/00063] train_loss: 0.011322\n",
      "[461/00113] train_loss: 0.011024\n",
      "[461/00163] train_loss: 0.011598\n",
      "[461/00213] train_loss: 0.011339\n",
      "[461/00263] train_loss: 0.011308\n",
      "[461/00313] train_loss: 0.011549\n",
      "[461/00363] train_loss: 0.011312\n",
      "[461/00413] train_loss: 0.011826\n",
      "[461/00463] train_loss: 0.010571\n",
      "[461/00513] train_loss: 0.011026\n",
      "[461/00563] train_loss: 0.011311\n",
      "[461/00613] train_loss: 0.010929\n",
      "[461/00663] train_loss: 0.012119\n",
      "[461/00713] train_loss: 0.010858\n",
      "[461/00763] train_loss: 0.011434\n",
      "[461/00813] train_loss: 0.011242\n",
      "[461/00863] train_loss: 0.010844\n",
      "[461/00913] train_loss: 0.010755\n",
      "[461/00963] train_loss: 0.011018\n",
      "[461/01013] train_loss: 0.011173\n",
      "[461/01063] train_loss: 0.011616\n",
      "[461/01113] train_loss: 0.011077\n",
      "[461/01163] train_loss: 0.010687\n",
      "[461/01213] train_loss: 0.011018\n",
      "[462/00037] train_loss: 0.012382\n",
      "[462/00087] train_loss: 0.010667\n",
      "[462/00137] train_loss: 0.011265\n",
      "[462/00187] train_loss: 0.011255\n",
      "[462/00237] train_loss: 0.011873\n",
      "[462/00287] train_loss: 0.011726\n",
      "[462/00337] train_loss: 0.011709\n",
      "[462/00387] train_loss: 0.011429\n",
      "[462/00437] train_loss: 0.010967\n",
      "[462/00487] train_loss: 0.011573\n",
      "[462/00537] train_loss: 0.011353\n",
      "[462/00587] train_loss: 0.011472\n",
      "[462/00637] train_loss: 0.012107\n",
      "[462/00687] train_loss: 0.010867\n",
      "[462/00737] train_loss: 0.010871\n",
      "[462/00787] train_loss: 0.011098\n",
      "[462/00837] train_loss: 0.010631\n",
      "[462/00887] train_loss: 0.010916\n",
      "[462/00937] train_loss: 0.011014\n",
      "[462/00987] train_loss: 0.010635\n",
      "[462/01037] train_loss: 0.010919\n",
      "[462/01087] train_loss: 0.010578\n",
      "[462/01137] train_loss: 0.011075\n",
      "[462/01187] train_loss: 0.011345\n",
      "[463/00011] train_loss: 0.011512\n",
      "[463/00061] train_loss: 0.011919\n",
      "[463/00111] train_loss: 0.011704\n",
      "[463/00161] train_loss: 0.011572\n",
      "[463/00211] train_loss: 0.010941\n",
      "[463/00261] train_loss: 0.011028\n",
      "[463/00311] train_loss: 0.011075\n",
      "[463/00361] train_loss: 0.011056\n",
      "[463/00411] train_loss: 0.011375\n",
      "[463/00461] train_loss: 0.010796\n",
      "[463/00511] train_loss: 0.010950\n",
      "[463/00561] train_loss: 0.011906\n",
      "[463/00611] train_loss: 0.011675\n",
      "[463/00661] train_loss: 0.010761\n",
      "[463/00711] train_loss: 0.011922\n",
      "[463/00761] train_loss: 0.011132\n",
      "[463/00811] train_loss: 0.010624\n",
      "[463/00861] train_loss: 0.011072\n",
      "[463/00911] train_loss: 0.010106\n",
      "[463/00961] train_loss: 0.011729\n",
      "[463/01011] train_loss: 0.010821\n",
      "[463/01061] train_loss: 0.011270\n",
      "[463/01111] train_loss: 0.011308\n",
      "[463/01161] train_loss: 0.010982\n",
      "[463/01211] train_loss: 0.011122\n",
      "[464/00035] train_loss: 0.011815\n",
      "[464/00085] train_loss: 0.011966\n",
      "[464/00135] train_loss: 0.011735\n",
      "[464/00185] train_loss: 0.011162\n",
      "[464/00235] train_loss: 0.010769\n",
      "[464/00285] train_loss: 0.010655\n",
      "[464/00335] train_loss: 0.011017\n",
      "[464/00385] train_loss: 0.011279\n",
      "[464/00435] train_loss: 0.010821\n",
      "[464/00485] train_loss: 0.011830\n",
      "[464/00535] train_loss: 0.011378\n",
      "[464/00585] train_loss: 0.011154\n",
      "[464/00635] train_loss: 0.011272\n",
      "[464/00685] train_loss: 0.010909\n",
      "[464/00735] train_loss: 0.011243\n",
      "[464/00785] train_loss: 0.011625\n",
      "[464/00835] train_loss: 0.011223\n",
      "[464/00885] train_loss: 0.010852\n",
      "[464/00935] train_loss: 0.011569\n",
      "[464/00985] train_loss: 0.011257\n",
      "[464/01035] train_loss: 0.011003\n",
      "[464/01085] train_loss: 0.010799\n",
      "[464/01135] train_loss: 0.011686\n",
      "[464/01185] train_loss: 0.010608\n",
      "[465/00009] train_loss: 0.010701\n",
      "[465/00059] train_loss: 0.011248\n",
      "[465/00109] train_loss: 0.012138\n",
      "[465/00159] train_loss: 0.010728\n",
      "[465/00209] train_loss: 0.011389\n",
      "[465/00259] train_loss: 0.011439\n",
      "[465/00309] train_loss: 0.012250\n",
      "[465/00359] train_loss: 0.011088\n",
      "[465/00409] train_loss: 0.010521\n",
      "[465/00459] train_loss: 0.011671\n",
      "[465/00509] train_loss: 0.011410\n",
      "[465/00559] train_loss: 0.011029\n",
      "[465/00609] train_loss: 0.011565\n",
      "[465/00659] train_loss: 0.010910\n",
      "[465/00709] train_loss: 0.010651\n",
      "[465/00759] train_loss: 0.011609\n",
      "[465/00809] train_loss: 0.011500\n",
      "[465/00859] train_loss: 0.010873\n",
      "[465/00909] train_loss: 0.010694\n",
      "[465/00959] train_loss: 0.011043\n",
      "[465/01009] train_loss: 0.011366\n",
      "[465/01059] train_loss: 0.011093\n",
      "[465/01109] train_loss: 0.011366\n",
      "[465/01159] train_loss: 0.010472\n",
      "[465/01209] train_loss: 0.010605\n",
      "[466/00033] train_loss: 0.011884\n",
      "[466/00083] train_loss: 0.011073\n",
      "[466/00133] train_loss: 0.011846\n",
      "[466/00183] train_loss: 0.011068\n",
      "[466/00233] train_loss: 0.010655\n",
      "[466/00283] train_loss: 0.011167\n",
      "[466/00333] train_loss: 0.010691\n",
      "[466/00383] train_loss: 0.011149\n",
      "[466/00433] train_loss: 0.011801\n",
      "[466/00483] train_loss: 0.010460\n",
      "[466/00533] train_loss: 0.011034\n",
      "[466/00583] train_loss: 0.011426\n",
      "[466/00633] train_loss: 0.011190\n",
      "[466/00683] train_loss: 0.010767\n",
      "[466/00733] train_loss: 0.011221\n",
      "[466/00783] train_loss: 0.011477\n",
      "[466/00833] train_loss: 0.011766\n",
      "[466/00883] train_loss: 0.011000\n",
      "[466/00933] train_loss: 0.010786\n",
      "[466/00983] train_loss: 0.011489\n",
      "[466/01033] train_loss: 0.011619\n",
      "[466/01083] train_loss: 0.011365\n",
      "[466/01133] train_loss: 0.011481\n",
      "[466/01183] train_loss: 0.010529\n",
      "[467/00007] train_loss: 0.011634\n",
      "[467/00057] train_loss: 0.010793\n",
      "[467/00107] train_loss: 0.011056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[467/00157] train_loss: 0.011307\n",
      "[467/00207] train_loss: 0.011263\n",
      "[467/00257] train_loss: 0.011149\n",
      "[467/00307] train_loss: 0.011350\n",
      "[467/00357] train_loss: 0.011920\n",
      "[467/00407] train_loss: 0.010887\n",
      "[467/00457] train_loss: 0.011300\n",
      "[467/00507] train_loss: 0.012123\n",
      "[467/00557] train_loss: 0.011314\n",
      "[467/00607] train_loss: 0.011263\n",
      "[467/00657] train_loss: 0.010906\n",
      "[467/00707] train_loss: 0.011359\n",
      "[467/00757] train_loss: 0.011175\n",
      "[467/00807] train_loss: 0.011631\n",
      "[467/00857] train_loss: 0.010963\n",
      "[467/00907] train_loss: 0.011495\n",
      "[467/00957] train_loss: 0.010837\n",
      "[467/01007] train_loss: 0.010094\n",
      "[467/01057] train_loss: 0.011457\n",
      "[467/01107] train_loss: 0.011361\n",
      "[467/01157] train_loss: 0.010945\n",
      "[467/01207] train_loss: 0.010889\n",
      "[468/00031] train_loss: 0.010945\n",
      "[468/00081] train_loss: 0.011878\n",
      "[468/00131] train_loss: 0.011659\n",
      "[468/00181] train_loss: 0.011363\n",
      "[468/00231] train_loss: 0.011561\n",
      "[468/00281] train_loss: 0.011841\n",
      "[468/00331] train_loss: 0.010912\n",
      "[468/00381] train_loss: 0.011210\n",
      "[468/00431] train_loss: 0.011226\n",
      "[468/00481] train_loss: 0.011015\n",
      "[468/00531] train_loss: 0.011139\n",
      "[468/00581] train_loss: 0.010328\n",
      "[468/00631] train_loss: 0.010511\n",
      "[468/00681] train_loss: 0.011166\n",
      "[468/00731] train_loss: 0.011200\n",
      "[468/00781] train_loss: 0.011037\n",
      "[468/00831] train_loss: 0.010975\n",
      "[468/00881] train_loss: 0.011494\n",
      "[468/00931] train_loss: 0.011477\n",
      "[468/00981] train_loss: 0.011048\n",
      "[468/01031] train_loss: 0.011256\n",
      "[468/01081] train_loss: 0.011311\n",
      "[468/01131] train_loss: 0.010459\n",
      "[468/01181] train_loss: 0.011349\n",
      "[469/00005] train_loss: 0.011718\n",
      "[469/00055] train_loss: 0.011597\n",
      "[469/00105] train_loss: 0.010964\n",
      "[469/00155] train_loss: 0.011977\n",
      "[469/00205] train_loss: 0.011516\n",
      "[469/00255] train_loss: 0.011511\n",
      "[469/00305] train_loss: 0.012014\n",
      "[469/00355] train_loss: 0.011764\n",
      "[469/00405] train_loss: 0.011850\n",
      "[469/00455] train_loss: 0.011133\n",
      "[469/00505] train_loss: 0.011632\n",
      "[469/00555] train_loss: 0.011034\n",
      "[469/00605] train_loss: 0.011652\n",
      "[469/00655] train_loss: 0.010913\n",
      "[469/00705] train_loss: 0.011130\n",
      "[469/00755] train_loss: 0.010714\n",
      "[469/00805] train_loss: 0.011371\n",
      "[469/00855] train_loss: 0.011080\n",
      "[469/00905] train_loss: 0.010446\n",
      "[469/00955] train_loss: 0.010229\n",
      "[469/01005] train_loss: 0.011541\n",
      "[469/01055] train_loss: 0.010523\n",
      "[469/01105] train_loss: 0.010317\n",
      "[469/01155] train_loss: 0.011063\n",
      "[469/01205] train_loss: 0.010710\n",
      "[470/00029] train_loss: 0.011050\n",
      "[470/00079] train_loss: 0.012157\n",
      "[470/00129] train_loss: 0.010807\n",
      "[470/00179] train_loss: 0.011254\n",
      "[470/00229] train_loss: 0.011623\n",
      "[470/00279] train_loss: 0.010702\n",
      "[470/00329] train_loss: 0.011089\n",
      "[470/00379] train_loss: 0.011005\n",
      "[470/00429] train_loss: 0.011126\n",
      "[470/00479] train_loss: 0.010903\n",
      "[470/00529] train_loss: 0.011693\n",
      "[470/00579] train_loss: 0.012073\n",
      "[470/00629] train_loss: 0.011001\n",
      "[470/00679] train_loss: 0.011942\n",
      "[470/00729] train_loss: 0.010996\n",
      "[470/00779] train_loss: 0.010926\n",
      "[470/00829] train_loss: 0.010665\n",
      "[470/00879] train_loss: 0.010871\n",
      "[470/00929] train_loss: 0.010962\n",
      "[470/00979] train_loss: 0.010942\n",
      "[470/01029] train_loss: 0.010843\n",
      "[470/01079] train_loss: 0.011113\n",
      "[470/01129] train_loss: 0.010864\n",
      "[470/01179] train_loss: 0.011173\n",
      "[471/00003] train_loss: 0.011310\n",
      "[471/00053] train_loss: 0.011080\n",
      "[471/00103] train_loss: 0.011656\n",
      "[471/00153] train_loss: 0.011580\n",
      "[471/00203] train_loss: 0.011971\n",
      "[471/00253] train_loss: 0.011357\n",
      "[471/00303] train_loss: 0.011444\n",
      "[471/00353] train_loss: 0.011736\n",
      "[471/00403] train_loss: 0.011136\n",
      "[471/00453] train_loss: 0.010742\n",
      "[471/00503] train_loss: 0.011149\n",
      "[471/00553] train_loss: 0.011937\n",
      "[471/00603] train_loss: 0.011612\n",
      "[471/00653] train_loss: 0.011153\n",
      "[471/00703] train_loss: 0.011211\n",
      "[471/00753] train_loss: 0.010923\n",
      "[471/00803] train_loss: 0.010388\n",
      "[471/00853] train_loss: 0.010940\n",
      "[471/00903] train_loss: 0.011360\n",
      "[471/00953] train_loss: 0.011528\n",
      "[471/01003] train_loss: 0.011183\n",
      "[471/01053] train_loss: 0.011105\n",
      "[471/01103] train_loss: 0.010506\n",
      "[471/01153] train_loss: 0.010947\n",
      "[471/01203] train_loss: 0.011105\n",
      "[472/00027] train_loss: 0.011503\n",
      "[472/00077] train_loss: 0.011489\n",
      "[472/00127] train_loss: 0.011911\n",
      "[472/00177] train_loss: 0.011759\n",
      "[472/00227] train_loss: 0.011674\n",
      "[472/00277] train_loss: 0.011846\n",
      "[472/00327] train_loss: 0.011437\n",
      "[472/00377] train_loss: 0.011322\n",
      "[472/00427] train_loss: 0.011406\n",
      "[472/00477] train_loss: 0.011018\n",
      "[472/00527] train_loss: 0.011139\n",
      "[472/00577] train_loss: 0.010666\n",
      "[472/00627] train_loss: 0.011091\n",
      "[472/00677] train_loss: 0.010587\n",
      "[472/00727] train_loss: 0.011326\n",
      "[472/00777] train_loss: 0.011434\n",
      "[472/00827] train_loss: 0.010900\n",
      "[472/00877] train_loss: 0.011401\n",
      "[472/00927] train_loss: 0.010836\n",
      "[472/00977] train_loss: 0.010928\n",
      "[472/01027] train_loss: 0.011713\n",
      "[472/01077] train_loss: 0.012049\n",
      "[472/01127] train_loss: 0.011595\n",
      "[472/01177] train_loss: 0.010796\n",
      "[473/00001] train_loss: 0.010948\n",
      "[473/00051] train_loss: 0.011375\n",
      "[473/00101] train_loss: 0.011188\n",
      "[473/00151] train_loss: 0.011627\n",
      "[473/00201] train_loss: 0.011135\n",
      "[473/00251] train_loss: 0.011218\n",
      "[473/00301] train_loss: 0.011011\n",
      "[473/00351] train_loss: 0.011783\n",
      "[473/00401] train_loss: 0.010723\n",
      "[473/00451] train_loss: 0.010535\n",
      "[473/00501] train_loss: 0.011220\n",
      "[473/00551] train_loss: 0.011837\n",
      "[473/00601] train_loss: 0.011805\n",
      "[473/00651] train_loss: 0.010976\n",
      "[473/00701] train_loss: 0.010366\n",
      "[473/00751] train_loss: 0.011235\n",
      "[473/00801] train_loss: 0.011024\n",
      "[473/00851] train_loss: 0.011765\n",
      "[473/00901] train_loss: 0.010827\n",
      "[473/00951] train_loss: 0.011455\n",
      "[473/01001] train_loss: 0.011409\n",
      "[473/01051] train_loss: 0.011617\n",
      "[473/01101] train_loss: 0.010796\n",
      "[473/01151] train_loss: 0.010834\n",
      "[473/01201] train_loss: 0.011244\n",
      "[474/00025] train_loss: 0.011092\n",
      "[474/00075] train_loss: 0.011923\n",
      "[474/00125] train_loss: 0.010805\n",
      "[474/00175] train_loss: 0.011570\n",
      "[474/00225] train_loss: 0.011211\n",
      "[474/00275] train_loss: 0.011705\n",
      "[474/00325] train_loss: 0.011464\n",
      "[474/00375] train_loss: 0.011052\n",
      "[474/00425] train_loss: 0.011228\n",
      "[474/00475] train_loss: 0.010715\n",
      "[474/00525] train_loss: 0.011036\n",
      "[474/00575] train_loss: 0.011305\n",
      "[474/00625] train_loss: 0.011143\n",
      "[474/00675] train_loss: 0.011775\n",
      "[474/00725] train_loss: 0.011148\n",
      "[474/00775] train_loss: 0.011346\n",
      "[474/00825] train_loss: 0.011086\n",
      "[474/00875] train_loss: 0.010834\n",
      "[474/00925] train_loss: 0.010749\n",
      "[474/00975] train_loss: 0.010607\n",
      "[474/01025] train_loss: 0.011444\n",
      "[474/01075] train_loss: 0.010983\n",
      "[474/01125] train_loss: 0.011213\n",
      "[474/01175] train_loss: 0.010885\n",
      "[474/01225] train_loss: 0.011409\n",
      "[475/00049] train_loss: 0.011211\n",
      "[475/00099] train_loss: 0.011237\n",
      "[475/00149] train_loss: 0.010796\n",
      "[475/00199] train_loss: 0.011320\n",
      "[475/00249] train_loss: 0.012032\n",
      "[475/00299] train_loss: 0.011222\n",
      "[475/00349] train_loss: 0.011236\n",
      "[475/00399] train_loss: 0.011273\n",
      "[475/00449] train_loss: 0.011513\n",
      "[475/00499] train_loss: 0.011333\n",
      "[475/00549] train_loss: 0.010701\n",
      "[475/00599] train_loss: 0.010885\n",
      "[475/00649] train_loss: 0.010830\n",
      "[475/00699] train_loss: 0.011404\n",
      "[475/00749] train_loss: 0.010849\n",
      "[475/00799] train_loss: 0.010803\n",
      "[475/00849] train_loss: 0.010934\n",
      "[475/00899] train_loss: 0.010889\n",
      "[475/00949] train_loss: 0.010554\n",
      "[475/00999] train_loss: 0.011188\n",
      "[475/01049] train_loss: 0.011216\n",
      "[475/01099] train_loss: 0.010881\n",
      "[475/01149] train_loss: 0.011609\n",
      "[475/01199] train_loss: 0.011117\n",
      "[476/00023] train_loss: 0.011533\n",
      "[476/00073] train_loss: 0.011638\n",
      "[476/00123] train_loss: 0.011341\n",
      "[476/00173] train_loss: 0.010726\n",
      "[476/00223] train_loss: 0.011120\n",
      "[476/00273] train_loss: 0.011517\n",
      "[476/00323] train_loss: 0.011333\n",
      "[476/00373] train_loss: 0.011176\n",
      "[476/00423] train_loss: 0.012069\n",
      "[476/00473] train_loss: 0.011537\n",
      "[476/00523] train_loss: 0.010748\n",
      "[476/00573] train_loss: 0.011334\n",
      "[476/00623] train_loss: 0.011303\n",
      "[476/00673] train_loss: 0.011265\n",
      "[476/00723] train_loss: 0.011048\n",
      "[476/00773] train_loss: 0.010510\n",
      "[476/00823] train_loss: 0.010850\n",
      "[476/00873] train_loss: 0.010430\n",
      "[476/00923] train_loss: 0.011156\n",
      "[476/00973] train_loss: 0.011341\n",
      "[476/01023] train_loss: 0.010447\n",
      "[476/01073] train_loss: 0.011130\n",
      "[476/01123] train_loss: 0.011369\n",
      "[476/01173] train_loss: 0.010527\n",
      "[476/01223] train_loss: 0.011750\n",
      "[477/00047] train_loss: 0.010856\n",
      "[477/00097] train_loss: 0.011030\n",
      "[477/00147] train_loss: 0.011694\n",
      "[477/00197] train_loss: 0.012266\n",
      "[477/00247] train_loss: 0.011641\n",
      "[477/00297] train_loss: 0.011210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[477/00347] train_loss: 0.011190\n",
      "[477/00397] train_loss: 0.010911\n",
      "[477/00447] train_loss: 0.010902\n",
      "[477/00497] train_loss: 0.011063\n",
      "[477/00547] train_loss: 0.010769\n",
      "[477/00597] train_loss: 0.011798\n",
      "[477/00647] train_loss: 0.011138\n",
      "[477/00697] train_loss: 0.011193\n",
      "[477/00747] train_loss: 0.011192\n",
      "[477/00797] train_loss: 0.011356\n",
      "[477/00847] train_loss: 0.011241\n",
      "[477/00897] train_loss: 0.011194\n",
      "[477/00947] train_loss: 0.010803\n",
      "[477/00997] train_loss: 0.011182\n",
      "[477/01047] train_loss: 0.011121\n",
      "[477/01097] train_loss: 0.011317\n",
      "[477/01147] train_loss: 0.011437\n",
      "[477/01197] train_loss: 0.010185\n",
      "[478/00021] train_loss: 0.010978\n",
      "[478/00071] train_loss: 0.011971\n",
      "[478/00121] train_loss: 0.010953\n",
      "[478/00171] train_loss: 0.011223\n",
      "[478/00221] train_loss: 0.011331\n",
      "[478/00271] train_loss: 0.010466\n",
      "[478/00321] train_loss: 0.010800\n",
      "[478/00371] train_loss: 0.011823\n",
      "[478/00421] train_loss: 0.011248\n",
      "[478/00471] train_loss: 0.011619\n",
      "[478/00521] train_loss: 0.012167\n",
      "[478/00571] train_loss: 0.011425\n",
      "[478/00621] train_loss: 0.010411\n",
      "[478/00671] train_loss: 0.011433\n",
      "[478/00721] train_loss: 0.010605\n",
      "[478/00771] train_loss: 0.011047\n",
      "[478/00821] train_loss: 0.010579\n",
      "[478/00871] train_loss: 0.010878\n",
      "[478/00921] train_loss: 0.010802\n",
      "[478/00971] train_loss: 0.011006\n",
      "[478/01021] train_loss: 0.011760\n",
      "[478/01071] train_loss: 0.011117\n",
      "[478/01121] train_loss: 0.011651\n",
      "[478/01171] train_loss: 0.010558\n",
      "[478/01221] train_loss: 0.010662\n",
      "[479/00045] train_loss: 0.010634\n",
      "[479/00095] train_loss: 0.011028\n",
      "[479/00145] train_loss: 0.011232\n",
      "[479/00195] train_loss: 0.010639\n",
      "[479/00245] train_loss: 0.011090\n",
      "[479/00295] train_loss: 0.011459\n",
      "[479/00345] train_loss: 0.011237\n",
      "[479/00395] train_loss: 0.011140\n",
      "[479/00445] train_loss: 0.010729\n",
      "[479/00495] train_loss: 0.011648\n",
      "[479/00545] train_loss: 0.011749\n",
      "[479/00595] train_loss: 0.010747\n",
      "[479/00645] train_loss: 0.011296\n",
      "[479/00695] train_loss: 0.010862\n",
      "[479/00745] train_loss: 0.011657\n",
      "[479/00795] train_loss: 0.011413\n",
      "[479/00845] train_loss: 0.010842\n",
      "[479/00895] train_loss: 0.011846\n",
      "[479/00945] train_loss: 0.011676\n",
      "[479/00995] train_loss: 0.010657\n",
      "[479/01045] train_loss: 0.010922\n",
      "[479/01095] train_loss: 0.011341\n",
      "[479/01145] train_loss: 0.011653\n",
      "[479/01195] train_loss: 0.010699\n",
      "[480/00019] train_loss: 0.010924\n",
      "[480/00069] train_loss: 0.011814\n",
      "[480/00119] train_loss: 0.011632\n",
      "[480/00169] train_loss: 0.012810\n",
      "[480/00219] train_loss: 0.011190\n",
      "[480/00269] train_loss: 0.011314\n",
      "[480/00319] train_loss: 0.011126\n",
      "[480/00369] train_loss: 0.011133\n",
      "[480/00419] train_loss: 0.011274\n",
      "[480/00469] train_loss: 0.010472\n",
      "[480/00519] train_loss: 0.010689\n",
      "[480/00569] train_loss: 0.010751\n",
      "[480/00619] train_loss: 0.011344\n",
      "[480/00669] train_loss: 0.010642\n",
      "[480/00719] train_loss: 0.010720\n",
      "[480/00769] train_loss: 0.011032\n",
      "[480/00819] train_loss: 0.011317\n",
      "[480/00869] train_loss: 0.011019\n",
      "[480/00919] train_loss: 0.010864\n",
      "[480/00969] train_loss: 0.010884\n",
      "[480/01019] train_loss: 0.011499\n",
      "[480/01069] train_loss: 0.010533\n",
      "[480/01119] train_loss: 0.011242\n",
      "[480/01169] train_loss: 0.011232\n",
      "[480/01219] train_loss: 0.011401\n",
      "[481/00043] train_loss: 0.011535\n",
      "[481/00093] train_loss: 0.011804\n",
      "[481/00143] train_loss: 0.011204\n",
      "[481/00193] train_loss: 0.010869\n",
      "[481/00243] train_loss: 0.012169\n",
      "[481/00293] train_loss: 0.010869\n",
      "[481/00343] train_loss: 0.010861\n",
      "[481/00393] train_loss: 0.011009\n",
      "[481/00443] train_loss: 0.011111\n",
      "[481/00493] train_loss: 0.011226\n",
      "[481/00543] train_loss: 0.011520\n",
      "[481/00593] train_loss: 0.010864\n",
      "[481/00643] train_loss: 0.010532\n",
      "[481/00693] train_loss: 0.011370\n",
      "[481/00743] train_loss: 0.011594\n",
      "[481/00793] train_loss: 0.011508\n",
      "[481/00843] train_loss: 0.010856\n",
      "[481/00893] train_loss: 0.011014\n",
      "[481/00943] train_loss: 0.011449\n",
      "[481/00993] train_loss: 0.011278\n",
      "[481/01043] train_loss: 0.010766\n",
      "[481/01093] train_loss: 0.010593\n",
      "[481/01143] train_loss: 0.011318\n",
      "[481/01193] train_loss: 0.010862\n",
      "[482/00017] train_loss: 0.011984\n",
      "[482/00067] train_loss: 0.012672\n",
      "[482/00117] train_loss: 0.011446\n",
      "[482/00167] train_loss: 0.011406\n",
      "[482/00217] train_loss: 0.011491\n",
      "[482/00267] train_loss: 0.011550\n",
      "[482/00317] train_loss: 0.011374\n",
      "[482/00367] train_loss: 0.011021\n",
      "[482/00417] train_loss: 0.010808\n",
      "[482/00467] train_loss: 0.010770\n",
      "[482/00517] train_loss: 0.011140\n",
      "[482/00567] train_loss: 0.011664\n",
      "[482/00617] train_loss: 0.010937\n",
      "[482/00667] train_loss: 0.010854\n",
      "[482/00717] train_loss: 0.010942\n",
      "[482/00767] train_loss: 0.011333\n",
      "[482/00817] train_loss: 0.010616\n",
      "[482/00867] train_loss: 0.010755\n",
      "[482/00917] train_loss: 0.010971\n",
      "[482/00967] train_loss: 0.011047\n",
      "[482/01017] train_loss: 0.010643\n",
      "[482/01067] train_loss: 0.010756\n",
      "[482/01117] train_loss: 0.011311\n",
      "[482/01167] train_loss: 0.011430\n",
      "[482/01217] train_loss: 0.011475\n",
      "[483/00041] train_loss: 0.011062\n",
      "[483/00091] train_loss: 0.011378\n",
      "[483/00141] train_loss: 0.011397\n",
      "[483/00191] train_loss: 0.010967\n",
      "[483/00241] train_loss: 0.012074\n",
      "[483/00291] train_loss: 0.011214\n",
      "[483/00341] train_loss: 0.011120\n",
      "[483/00391] train_loss: 0.010919\n",
      "[483/00441] train_loss: 0.011148\n",
      "[483/00491] train_loss: 0.011514\n",
      "[483/00541] train_loss: 0.010755\n",
      "[483/00591] train_loss: 0.010871\n",
      "[483/00641] train_loss: 0.010766\n",
      "[483/00691] train_loss: 0.010791\n",
      "[483/00741] train_loss: 0.011366\n",
      "[483/00791] train_loss: 0.011227\n",
      "[483/00841] train_loss: 0.010552\n",
      "[483/00891] train_loss: 0.010784\n",
      "[483/00941] train_loss: 0.011704\n",
      "[483/00991] train_loss: 0.010739\n",
      "[483/01041] train_loss: 0.011314\n",
      "[483/01091] train_loss: 0.010773\n",
      "[483/01141] train_loss: 0.011102\n",
      "[483/01191] train_loss: 0.010557\n",
      "[484/00015] train_loss: 0.011549\n",
      "[484/00065] train_loss: 0.011489\n",
      "[484/00115] train_loss: 0.011416\n",
      "[484/00165] train_loss: 0.011372\n",
      "[484/00215] train_loss: 0.011467\n",
      "[484/00265] train_loss: 0.011273\n",
      "[484/00315] train_loss: 0.012270\n",
      "[484/00365] train_loss: 0.010765\n",
      "[484/00415] train_loss: 0.011952\n",
      "[484/00465] train_loss: 0.011505\n",
      "[484/00515] train_loss: 0.011528\n",
      "[484/00565] train_loss: 0.011561\n",
      "[484/00615] train_loss: 0.010651\n",
      "[484/00665] train_loss: 0.011419\n",
      "[484/00715] train_loss: 0.010890\n",
      "[484/00765] train_loss: 0.011295\n",
      "[484/00815] train_loss: 0.010832\n",
      "[484/00865] train_loss: 0.011165\n",
      "[484/00915] train_loss: 0.010974\n",
      "[484/00965] train_loss: 0.011291\n",
      "[484/01015] train_loss: 0.010639\n",
      "[484/01065] train_loss: 0.011247\n",
      "[484/01115] train_loss: 0.011327\n",
      "[484/01165] train_loss: 0.010600\n",
      "[484/01215] train_loss: 0.010737\n",
      "[485/00039] train_loss: 0.011365\n",
      "[485/00089] train_loss: 0.011700\n",
      "[485/00139] train_loss: 0.011846\n",
      "[485/00189] train_loss: 0.011521\n",
      "[485/00239] train_loss: 0.010448\n",
      "[485/00289] train_loss: 0.011466\n",
      "[485/00339] train_loss: 0.011349\n",
      "[485/00389] train_loss: 0.010893\n",
      "[485/00439] train_loss: 0.011467\n",
      "[485/00489] train_loss: 0.011444\n",
      "[485/00539] train_loss: 0.010741\n",
      "[485/00589] train_loss: 0.010700\n",
      "[485/00639] train_loss: 0.011140\n",
      "[485/00689] train_loss: 0.011394\n",
      "[485/00739] train_loss: 0.010612\n",
      "[485/00789] train_loss: 0.011455\n",
      "[485/00839] train_loss: 0.011108\n",
      "[485/00889] train_loss: 0.010970\n",
      "[485/00939] train_loss: 0.011071\n",
      "[485/00989] train_loss: 0.010489\n",
      "[485/01039] train_loss: 0.010992\n",
      "[485/01089] train_loss: 0.011162\n",
      "[485/01139] train_loss: 0.010772\n",
      "[485/01189] train_loss: 0.010782\n",
      "[486/00013] train_loss: 0.011132\n",
      "[486/00063] train_loss: 0.011672\n",
      "[486/00113] train_loss: 0.011401\n",
      "[486/00163] train_loss: 0.012389\n",
      "[486/00213] train_loss: 0.011738\n",
      "[486/00263] train_loss: 0.011341\n",
      "[486/00313] train_loss: 0.011113\n",
      "[486/00363] train_loss: 0.010969\n",
      "[486/00413] train_loss: 0.011321\n",
      "[486/00463] train_loss: 0.011112\n",
      "[486/00513] train_loss: 0.011586\n",
      "[486/00563] train_loss: 0.010962\n",
      "[486/00613] train_loss: 0.011457\n",
      "[486/00663] train_loss: 0.011246\n",
      "[486/00713] train_loss: 0.011014\n",
      "[486/00763] train_loss: 0.010895\n",
      "[486/00813] train_loss: 0.010972\n",
      "[486/00863] train_loss: 0.011419\n",
      "[486/00913] train_loss: 0.010643\n",
      "[486/00963] train_loss: 0.010525\n",
      "[486/01013] train_loss: 0.010522\n",
      "[486/01063] train_loss: 0.011181\n",
      "[486/01113] train_loss: 0.011505\n",
      "[486/01163] train_loss: 0.011291\n",
      "[486/01213] train_loss: 0.010671\n",
      "[487/00037] train_loss: 0.011289\n",
      "[487/00087] train_loss: 0.010718\n",
      "[487/00137] train_loss: 0.011565\n",
      "[487/00187] train_loss: 0.010881\n",
      "[487/00237] train_loss: 0.011259\n",
      "[487/00287] train_loss: 0.010823\n",
      "[487/00337] train_loss: 0.011275\n",
      "[487/00387] train_loss: 0.010466\n",
      "[487/00437] train_loss: 0.011461\n",
      "[487/00487] train_loss: 0.010917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[487/00537] train_loss: 0.011004\n",
      "[487/00587] train_loss: 0.011584\n",
      "[487/00637] train_loss: 0.011742\n",
      "[487/00687] train_loss: 0.011763\n",
      "[487/00737] train_loss: 0.010268\n",
      "[487/00787] train_loss: 0.011198\n",
      "[487/00837] train_loss: 0.010512\n",
      "[487/00887] train_loss: 0.011239\n",
      "[487/00937] train_loss: 0.011280\n",
      "[487/00987] train_loss: 0.010879\n",
      "[487/01037] train_loss: 0.011173\n",
      "[487/01087] train_loss: 0.011656\n",
      "[487/01137] train_loss: 0.011319\n",
      "[487/01187] train_loss: 0.010881\n",
      "[488/00011] train_loss: 0.010850\n",
      "[488/00061] train_loss: 0.011852\n",
      "[488/00111] train_loss: 0.011843\n",
      "[488/00161] train_loss: 0.011356\n",
      "[488/00211] train_loss: 0.011720\n",
      "[488/00261] train_loss: 0.011427\n",
      "[488/00311] train_loss: 0.011445\n",
      "[488/00361] train_loss: 0.011122\n",
      "[488/00411] train_loss: 0.010939\n",
      "[488/00461] train_loss: 0.011140\n",
      "[488/00511] train_loss: 0.010883\n",
      "[488/00561] train_loss: 0.010890\n",
      "[488/00611] train_loss: 0.011082\n",
      "[488/00661] train_loss: 0.011222\n",
      "[488/00711] train_loss: 0.010779\n",
      "[488/00761] train_loss: 0.011601\n",
      "[488/00811] train_loss: 0.011104\n",
      "[488/00861] train_loss: 0.011284\n",
      "[488/00911] train_loss: 0.010894\n",
      "[488/00961] train_loss: 0.010867\n",
      "[488/01011] train_loss: 0.011147\n",
      "[488/01061] train_loss: 0.010752\n",
      "[488/01111] train_loss: 0.011006\n",
      "[488/01161] train_loss: 0.011737\n",
      "[488/01211] train_loss: 0.011134\n",
      "[489/00035] train_loss: 0.011685\n",
      "[489/00085] train_loss: 0.011592\n",
      "[489/00135] train_loss: 0.011044\n",
      "[489/00185] train_loss: 0.011320\n",
      "[489/00235] train_loss: 0.011160\n",
      "[489/00285] train_loss: 0.011230\n",
      "[489/00335] train_loss: 0.010636\n",
      "[489/00385] train_loss: 0.011372\n",
      "[489/00435] train_loss: 0.011382\n",
      "[489/00485] train_loss: 0.011298\n",
      "[489/00535] train_loss: 0.011009\n",
      "[489/00585] train_loss: 0.010236\n",
      "[489/00635] train_loss: 0.011213\n",
      "[489/00685] train_loss: 0.010748\n",
      "[489/00735] train_loss: 0.011146\n",
      "[489/00785] train_loss: 0.010444\n",
      "[489/00835] train_loss: 0.010582\n",
      "[489/00885] train_loss: 0.011862\n",
      "[489/00935] train_loss: 0.010994\n",
      "[489/00985] train_loss: 0.010349\n",
      "[489/01035] train_loss: 0.010697\n",
      "[489/01085] train_loss: 0.011103\n",
      "[489/01135] train_loss: 0.010799\n",
      "[489/01185] train_loss: 0.010828\n",
      "[490/00009] train_loss: 0.010519\n",
      "[490/00059] train_loss: 0.011333\n",
      "[490/00109] train_loss: 0.010942\n",
      "[490/00159] train_loss: 0.011256\n",
      "[490/00209] train_loss: 0.010933\n",
      "[490/00259] train_loss: 0.011323\n",
      "[490/00309] train_loss: 0.011555\n",
      "[490/00359] train_loss: 0.010623\n",
      "[490/00409] train_loss: 0.011237\n",
      "[490/00459] train_loss: 0.011168\n",
      "[490/00509] train_loss: 0.011050\n",
      "[490/00559] train_loss: 0.011461\n",
      "[490/00609] train_loss: 0.011356\n",
      "[490/00659] train_loss: 0.011343\n",
      "[490/00709] train_loss: 0.010978\n",
      "[490/00759] train_loss: 0.011208\n",
      "[490/00809] train_loss: 0.010802\n",
      "[490/00859] train_loss: 0.011419\n",
      "[490/00909] train_loss: 0.010948\n",
      "[490/00959] train_loss: 0.011274\n",
      "[490/01009] train_loss: 0.011333\n",
      "[490/01059] train_loss: 0.011842\n",
      "[490/01109] train_loss: 0.011203\n",
      "[490/01159] train_loss: 0.010297\n",
      "[490/01209] train_loss: 0.011534\n",
      "[491/00033] train_loss: 0.011540\n",
      "[491/00083] train_loss: 0.011414\n",
      "[491/00133] train_loss: 0.011221\n",
      "[491/00183] train_loss: 0.010732\n",
      "[491/00233] train_loss: 0.011991\n",
      "[491/00283] train_loss: 0.011625\n",
      "[491/00333] train_loss: 0.011388\n",
      "[491/00383] train_loss: 0.011695\n",
      "[491/00433] train_loss: 0.011374\n",
      "[491/00483] train_loss: 0.010631\n",
      "[491/00533] train_loss: 0.010618\n",
      "[491/00583] train_loss: 0.011093\n",
      "[491/00633] train_loss: 0.011030\n",
      "[491/00683] train_loss: 0.010969\n",
      "[491/00733] train_loss: 0.011261\n",
      "[491/00783] train_loss: 0.010675\n",
      "[491/00833] train_loss: 0.010462\n",
      "[491/00883] train_loss: 0.011026\n",
      "[491/00933] train_loss: 0.010625\n",
      "[491/00983] train_loss: 0.010949\n",
      "[491/01033] train_loss: 0.011350\n",
      "[491/01083] train_loss: 0.011082\n",
      "[491/01133] train_loss: 0.010992\n",
      "[491/01183] train_loss: 0.010785\n",
      "[492/00007] train_loss: 0.011372\n",
      "[492/00057] train_loss: 0.011593\n",
      "[492/00107] train_loss: 0.011585\n",
      "[492/00157] train_loss: 0.011475\n",
      "[492/00207] train_loss: 0.011338\n",
      "[492/00257] train_loss: 0.010646\n",
      "[492/00307] train_loss: 0.011368\n",
      "[492/00357] train_loss: 0.011122\n",
      "[492/00407] train_loss: 0.011362\n",
      "[492/00457] train_loss: 0.011052\n",
      "[492/00507] train_loss: 0.011304\n",
      "[492/00557] train_loss: 0.011866\n",
      "[492/00607] train_loss: 0.010922\n",
      "[492/00657] train_loss: 0.011475\n",
      "[492/00707] train_loss: 0.010999\n",
      "[492/00757] train_loss: 0.010831\n",
      "[492/00807] train_loss: 0.011861\n",
      "[492/00857] train_loss: 0.011582\n",
      "[492/00907] train_loss: 0.010601\n",
      "[492/00957] train_loss: 0.011213\n",
      "[492/01007] train_loss: 0.011183\n",
      "[492/01057] train_loss: 0.011053\n",
      "[492/01107] train_loss: 0.011187\n",
      "[492/01157] train_loss: 0.011234\n",
      "[492/01207] train_loss: 0.010644\n",
      "[493/00031] train_loss: 0.010968\n",
      "[493/00081] train_loss: 0.010861\n",
      "[493/00131] train_loss: 0.011283\n",
      "[493/00181] train_loss: 0.010795\n",
      "[493/00231] train_loss: 0.010668\n",
      "[493/00281] train_loss: 0.011187\n",
      "[493/00331] train_loss: 0.011308\n",
      "[493/00381] train_loss: 0.010866\n",
      "[493/00431] train_loss: 0.011324\n",
      "[493/00481] train_loss: 0.012093\n",
      "[493/00531] train_loss: 0.011544\n",
      "[493/00581] train_loss: 0.010780\n",
      "[493/00631] train_loss: 0.010990\n",
      "[493/00681] train_loss: 0.010632\n",
      "[493/00731] train_loss: 0.010397\n",
      "[493/00781] train_loss: 0.011031\n",
      "[493/00831] train_loss: 0.011271\n",
      "[493/00881] train_loss: 0.011346\n",
      "[493/00931] train_loss: 0.011919\n",
      "[493/00981] train_loss: 0.010658\n",
      "[493/01031] train_loss: 0.011316\n",
      "[493/01081] train_loss: 0.010544\n",
      "[493/01131] train_loss: 0.010880\n",
      "[493/01181] train_loss: 0.010962\n",
      "[494/00005] train_loss: 0.011043\n",
      "[494/00055] train_loss: 0.011316\n",
      "[494/00105] train_loss: 0.011383\n",
      "[494/00155] train_loss: 0.011442\n",
      "[494/00205] train_loss: 0.011199\n",
      "[494/00255] train_loss: 0.011960\n",
      "[494/00305] train_loss: 0.011248\n",
      "[494/00355] train_loss: 0.011169\n",
      "[494/00405] train_loss: 0.011289\n",
      "[494/00455] train_loss: 0.011000\n",
      "[494/00505] train_loss: 0.011978\n",
      "[494/00555] train_loss: 0.010532\n",
      "[494/00605] train_loss: 0.011210\n",
      "[494/00655] train_loss: 0.010902\n",
      "[494/00705] train_loss: 0.010952\n",
      "[494/00755] train_loss: 0.011016\n",
      "[494/00805] train_loss: 0.011894\n",
      "[494/00855] train_loss: 0.011054\n",
      "[494/00905] train_loss: 0.010537\n",
      "[494/00955] train_loss: 0.011576\n",
      "[494/01005] train_loss: 0.010744\n",
      "[494/01055] train_loss: 0.010560\n",
      "[494/01105] train_loss: 0.011353\n",
      "[494/01155] train_loss: 0.010512\n",
      "[494/01205] train_loss: 0.011673\n",
      "[495/00029] train_loss: 0.011261\n",
      "[495/00079] train_loss: 0.011169\n",
      "[495/00129] train_loss: 0.010996\n",
      "[495/00179] train_loss: 0.011909\n",
      "[495/00229] train_loss: 0.011687\n",
      "[495/00279] train_loss: 0.010947\n",
      "[495/00329] train_loss: 0.010830\n",
      "[495/00379] train_loss: 0.011312\n",
      "[495/00429] train_loss: 0.011753\n",
      "[495/00479] train_loss: 0.010962\n",
      "[495/00529] train_loss: 0.011028\n",
      "[495/00579] train_loss: 0.010416\n",
      "[495/00629] train_loss: 0.010505\n",
      "[495/00679] train_loss: 0.011216\n",
      "[495/00729] train_loss: 0.010685\n",
      "[495/00779] train_loss: 0.011041\n",
      "[495/00829] train_loss: 0.011395\n",
      "[495/00879] train_loss: 0.011660\n",
      "[495/00929] train_loss: 0.010742\n",
      "[495/00979] train_loss: 0.010757\n",
      "[495/01029] train_loss: 0.010908\n",
      "[495/01079] train_loss: 0.011037\n",
      "[495/01129] train_loss: 0.010977\n",
      "[495/01179] train_loss: 0.011234\n",
      "[496/00003] train_loss: 0.011009\n",
      "[496/00053] train_loss: 0.011529\n",
      "[496/00103] train_loss: 0.011382\n",
      "[496/00153] train_loss: 0.011568\n",
      "[496/00203] train_loss: 0.011188\n",
      "[496/00253] train_loss: 0.012102\n",
      "[496/00303] train_loss: 0.010757\n",
      "[496/00353] train_loss: 0.011570\n",
      "[496/00403] train_loss: 0.011927\n",
      "[496/00453] train_loss: 0.010845\n",
      "[496/00503] train_loss: 0.011488\n",
      "[496/00553] train_loss: 0.011788\n",
      "[496/00603] train_loss: 0.011167\n",
      "[496/00653] train_loss: 0.011347\n",
      "[496/00703] train_loss: 0.011181\n",
      "[496/00753] train_loss: 0.011382\n",
      "[496/00803] train_loss: 0.010286\n",
      "[496/00853] train_loss: 0.010885\n",
      "[496/00903] train_loss: 0.011041\n",
      "[496/00953] train_loss: 0.010859\n",
      "[496/01003] train_loss: 0.011455\n",
      "[496/01053] train_loss: 0.010873\n",
      "[496/01103] train_loss: 0.010562\n",
      "[496/01153] train_loss: 0.011080\n",
      "[496/01203] train_loss: 0.010477\n",
      "[497/00027] train_loss: 0.011062\n",
      "[497/00077] train_loss: 0.011450\n",
      "[497/00127] train_loss: 0.011283\n",
      "[497/00177] train_loss: 0.011502\n",
      "[497/00227] train_loss: 0.011489\n",
      "[497/00277] train_loss: 0.011755\n",
      "[497/00327] train_loss: 0.010637\n",
      "[497/00377] train_loss: 0.011065\n",
      "[497/00427] train_loss: 0.010965\n",
      "[497/00477] train_loss: 0.010880\n",
      "[497/00527] train_loss: 0.010925\n",
      "[497/00577] train_loss: 0.011110\n",
      "[497/00627] train_loss: 0.010331\n",
      "[497/00677] train_loss: 0.011202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[497/00727] train_loss: 0.010970\n",
      "[497/00777] train_loss: 0.011092\n",
      "[497/00827] train_loss: 0.011253\n",
      "[497/00877] train_loss: 0.011080\n",
      "[497/00927] train_loss: 0.010578\n",
      "[497/00977] train_loss: 0.011750\n",
      "[497/01027] train_loss: 0.011280\n",
      "[497/01077] train_loss: 0.010393\n",
      "[497/01127] train_loss: 0.010857\n",
      "[497/01177] train_loss: 0.010790\n",
      "[498/00001] train_loss: 0.010860\n",
      "[498/00051] train_loss: 0.011045\n",
      "[498/00101] train_loss: 0.010873\n",
      "[498/00151] train_loss: 0.011088\n",
      "[498/00201] train_loss: 0.011284\n",
      "[498/00251] train_loss: 0.010970\n",
      "[498/00301] train_loss: 0.011083\n",
      "[498/00351] train_loss: 0.011265\n",
      "[498/00401] train_loss: 0.011405\n",
      "[498/00451] train_loss: 0.010841\n",
      "[498/00501] train_loss: 0.010828\n",
      "[498/00551] train_loss: 0.011215\n",
      "[498/00601] train_loss: 0.011566\n",
      "[498/00651] train_loss: 0.010894\n",
      "[498/00701] train_loss: 0.010866\n",
      "[498/00751] train_loss: 0.010971\n",
      "[498/00801] train_loss: 0.011210\n",
      "[498/00851] train_loss: 0.011246\n",
      "[498/00901] train_loss: 0.011229\n",
      "[498/00951] train_loss: 0.011151\n",
      "[498/01001] train_loss: 0.011736\n",
      "[498/01051] train_loss: 0.010402\n",
      "[498/01101] train_loss: 0.010709\n",
      "[498/01151] train_loss: 0.011271\n",
      "[498/01201] train_loss: 0.011126\n",
      "[499/00025] train_loss: 0.011377\n",
      "[499/00075] train_loss: 0.010481\n",
      "[499/00125] train_loss: 0.011879\n",
      "[499/00175] train_loss: 0.011521\n",
      "[499/00225] train_loss: 0.011326\n",
      "[499/00275] train_loss: 0.010711\n",
      "[499/00325] train_loss: 0.010205\n",
      "[499/00375] train_loss: 0.011841\n",
      "[499/00425] train_loss: 0.010836\n",
      "[499/00475] train_loss: 0.011782\n",
      "[499/00525] train_loss: 0.011717\n",
      "[499/00575] train_loss: 0.011096\n",
      "[499/00625] train_loss: 0.010929\n",
      "[499/00675] train_loss: 0.011096\n",
      "[499/00725] train_loss: 0.011018\n",
      "[499/00775] train_loss: 0.010639\n",
      "[499/00825] train_loss: 0.011028\n",
      "[499/00875] train_loss: 0.011280\n",
      "[499/00925] train_loss: 0.011808\n",
      "[499/00975] train_loss: 0.010991\n",
      "[499/01025] train_loss: 0.011025\n",
      "[499/01075] train_loss: 0.010978\n",
      "[499/01125] train_loss: 0.010660\n",
      "[499/01175] train_loss: 0.010524\n",
      "[499/01225] train_loss: 0.010499\n",
      "[500/00049] train_loss: 0.011566\n",
      "[500/00099] train_loss: 0.011665\n",
      "[500/00149] train_loss: 0.011027\n",
      "[500/00199] train_loss: 0.011214\n",
      "[500/00249] train_loss: 0.011351\n",
      "[500/00299] train_loss: 0.010970\n",
      "[500/00349] train_loss: 0.010757\n",
      "[500/00399] train_loss: 0.010620\n",
      "[500/00449] train_loss: 0.010968\n",
      "[500/00499] train_loss: 0.011716\n",
      "[500/00549] train_loss: 0.010662\n",
      "[500/00599] train_loss: 0.011261\n",
      "[500/00649] train_loss: 0.011254\n",
      "[500/00699] train_loss: 0.010444\n",
      "[500/00749] train_loss: 0.011350\n",
      "[500/00799] train_loss: 0.011093\n",
      "[500/00849] train_loss: 0.011041\n",
      "[500/00899] train_loss: 0.010669\n",
      "[500/00949] train_loss: 0.011013\n",
      "[500/00999] train_loss: 0.010701\n",
      "[500/01049] train_loss: 0.010544\n",
      "[500/01099] train_loss: 0.011112\n",
      "[500/01149] train_loss: 0.010275\n",
      "[500/01199] train_loss: 0.010921\n",
      "[501/00023] train_loss: 0.010667\n",
      "[501/00073] train_loss: 0.009688\n",
      "[501/00123] train_loss: 0.009499\n",
      "[501/00173] train_loss: 0.008872\n",
      "[501/00223] train_loss: 0.009655\n",
      "[501/00273] train_loss: 0.009422\n",
      "[501/00323] train_loss: 0.008763\n",
      "[501/00373] train_loss: 0.009576\n",
      "[501/00423] train_loss: 0.009823\n",
      "[501/00473] train_loss: 0.008803\n",
      "[501/00523] train_loss: 0.009164\n",
      "[501/00573] train_loss: 0.009145\n",
      "[501/00623] train_loss: 0.009449\n",
      "[501/00673] train_loss: 0.009140\n",
      "[501/00723] train_loss: 0.009467\n",
      "[501/00773] train_loss: 0.010027\n",
      "[501/00823] train_loss: 0.009022\n",
      "[501/00873] train_loss: 0.009089\n",
      "[501/00923] train_loss: 0.008736\n",
      "[501/00973] train_loss: 0.009612\n",
      "[501/01023] train_loss: 0.008957\n",
      "[501/01073] train_loss: 0.009454\n",
      "[501/01123] train_loss: 0.010221\n",
      "[501/01173] train_loss: 0.008917\n",
      "[501/01223] train_loss: 0.009973\n",
      "[502/00047] train_loss: 0.009128\n",
      "[502/00097] train_loss: 0.009722\n",
      "[502/00147] train_loss: 0.008878\n",
      "[502/00197] train_loss: 0.009829\n",
      "[502/00247] train_loss: 0.009047\n",
      "[502/00297] train_loss: 0.009102\n",
      "[502/00347] train_loss: 0.008939\n",
      "[502/00397] train_loss: 0.008673\n",
      "[502/00447] train_loss: 0.008919\n",
      "[502/00497] train_loss: 0.009104\n",
      "[502/00547] train_loss: 0.009641\n",
      "[502/00597] train_loss: 0.009442\n",
      "[502/00647] train_loss: 0.008977\n",
      "[502/00697] train_loss: 0.009540\n",
      "[502/00747] train_loss: 0.009494\n",
      "[502/00797] train_loss: 0.008726\n",
      "[502/00847] train_loss: 0.009113\n",
      "[502/00897] train_loss: 0.009387\n",
      "[502/00947] train_loss: 0.009170\n",
      "[502/00997] train_loss: 0.009153\n",
      "[502/01047] train_loss: 0.008467\n",
      "[502/01097] train_loss: 0.008934\n",
      "[502/01147] train_loss: 0.009115\n",
      "[502/01197] train_loss: 0.009186\n",
      "[503/00021] train_loss: 0.009510\n",
      "[503/00071] train_loss: 0.009545\n",
      "[503/00121] train_loss: 0.010000\n",
      "[503/00171] train_loss: 0.009046\n",
      "[503/00221] train_loss: 0.008896\n",
      "[503/00271] train_loss: 0.008991\n",
      "[503/00321] train_loss: 0.009195\n",
      "[503/00371] train_loss: 0.009172\n",
      "[503/00421] train_loss: 0.009317\n",
      "[503/00471] train_loss: 0.009279\n",
      "[503/00521] train_loss: 0.009269\n",
      "[503/00571] train_loss: 0.009225\n",
      "[503/00621] train_loss: 0.009379\n",
      "[503/00671] train_loss: 0.009459\n",
      "[503/00721] train_loss: 0.009497\n",
      "[503/00771] train_loss: 0.009508\n",
      "[503/00821] train_loss: 0.009065\n",
      "[503/00871] train_loss: 0.009432\n",
      "[503/00921] train_loss: 0.008923\n",
      "[503/00971] train_loss: 0.009068\n",
      "[503/01021] train_loss: 0.009250\n",
      "[503/01071] train_loss: 0.008808\n",
      "[503/01121] train_loss: 0.009302\n",
      "[503/01171] train_loss: 0.009270\n",
      "[503/01221] train_loss: 0.009287\n",
      "[504/00045] train_loss: 0.009142\n",
      "[504/00095] train_loss: 0.009235\n",
      "[504/00145] train_loss: 0.009061\n",
      "[504/00195] train_loss: 0.008921\n",
      "[504/00245] train_loss: 0.008851\n",
      "[504/00295] train_loss: 0.009730\n",
      "[504/00345] train_loss: 0.008885\n",
      "[504/00395] train_loss: 0.009356\n",
      "[504/00445] train_loss: 0.009087\n",
      "[504/00495] train_loss: 0.008928\n",
      "[504/00545] train_loss: 0.008532\n",
      "[504/00595] train_loss: 0.008893\n",
      "[504/00645] train_loss: 0.009384\n",
      "[504/00695] train_loss: 0.009031\n",
      "[504/00745] train_loss: 0.009236\n",
      "[504/00795] train_loss: 0.009199\n",
      "[504/00845] train_loss: 0.009598\n",
      "[504/00895] train_loss: 0.009071\n",
      "[504/00945] train_loss: 0.009602\n",
      "[504/00995] train_loss: 0.009536\n",
      "[504/01045] train_loss: 0.009577\n",
      "[504/01095] train_loss: 0.009452\n",
      "[504/01145] train_loss: 0.009433\n",
      "[504/01195] train_loss: 0.009444\n",
      "[505/00019] train_loss: 0.008797\n",
      "[505/00069] train_loss: 0.008997\n",
      "[505/00119] train_loss: 0.009282\n",
      "[505/00169] train_loss: 0.009167\n",
      "[505/00219] train_loss: 0.009008\n",
      "[505/00269] train_loss: 0.009379\n",
      "[505/00319] train_loss: 0.008816\n",
      "[505/00369] train_loss: 0.008877\n",
      "[505/00419] train_loss: 0.009326\n",
      "[505/00469] train_loss: 0.009027\n",
      "[505/00519] train_loss: 0.009287\n",
      "[505/00569] train_loss: 0.008968\n",
      "[505/00619] train_loss: 0.008907\n",
      "[505/00669] train_loss: 0.009390\n",
      "[505/00719] train_loss: 0.009684\n",
      "[505/00769] train_loss: 0.009464\n",
      "[505/00819] train_loss: 0.009462\n",
      "[505/00869] train_loss: 0.009455\n",
      "[505/00919] train_loss: 0.009064\n",
      "[505/00969] train_loss: 0.008845\n",
      "[505/01019] train_loss: 0.009163\n",
      "[505/01069] train_loss: 0.008816\n",
      "[505/01119] train_loss: 0.009504\n",
      "[505/01169] train_loss: 0.009197\n",
      "[505/01219] train_loss: 0.008760\n",
      "[506/00043] train_loss: 0.009449\n",
      "[506/00093] train_loss: 0.008528\n",
      "[506/00143] train_loss: 0.009265\n",
      "[506/00193] train_loss: 0.008811\n",
      "[506/00243] train_loss: 0.008594\n",
      "[506/00293] train_loss: 0.009244\n",
      "[506/00343] train_loss: 0.009343\n",
      "[506/00393] train_loss: 0.008815\n",
      "[506/00443] train_loss: 0.008905\n",
      "[506/00493] train_loss: 0.009855\n",
      "[506/00543] train_loss: 0.008836\n",
      "[506/00593] train_loss: 0.009078\n",
      "[506/00643] train_loss: 0.009303\n",
      "[506/00693] train_loss: 0.009192\n",
      "[506/00743] train_loss: 0.009650\n",
      "[506/00793] train_loss: 0.008774\n",
      "[506/00843] train_loss: 0.009161\n",
      "[506/00893] train_loss: 0.008819\n",
      "[506/00943] train_loss: 0.008911\n",
      "[506/00993] train_loss: 0.008811\n",
      "[506/01043] train_loss: 0.008924\n",
      "[506/01093] train_loss: 0.008895\n",
      "[506/01143] train_loss: 0.009408\n",
      "[506/01193] train_loss: 0.009313\n",
      "[507/00017] train_loss: 0.009058\n",
      "[507/00067] train_loss: 0.009307\n",
      "[507/00117] train_loss: 0.009276\n",
      "[507/00167] train_loss: 0.009248\n",
      "[507/00217] train_loss: 0.008788\n",
      "[507/00267] train_loss: 0.009182\n",
      "[507/00317] train_loss: 0.008622\n",
      "[507/00367] train_loss: 0.009084\n",
      "[507/00417] train_loss: 0.009407\n",
      "[507/00467] train_loss: 0.009274\n",
      "[507/00517] train_loss: 0.009043\n",
      "[507/00567] train_loss: 0.009253\n",
      "[507/00617] train_loss: 0.009193\n",
      "[507/00667] train_loss: 0.008897\n",
      "[507/00717] train_loss: 0.009401\n",
      "[507/00767] train_loss: 0.008734\n",
      "[507/00817] train_loss: 0.008975\n",
      "[507/00867] train_loss: 0.009352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[507/00917] train_loss: 0.009012\n",
      "[507/00967] train_loss: 0.009342\n",
      "[507/01017] train_loss: 0.009238\n",
      "[507/01067] train_loss: 0.008888\n",
      "[507/01117] train_loss: 0.009267\n",
      "[507/01167] train_loss: 0.008799\n",
      "[507/01217] train_loss: 0.009126\n",
      "[508/00041] train_loss: 0.008383\n",
      "[508/00091] train_loss: 0.009544\n",
      "[508/00141] train_loss: 0.009530\n",
      "[508/00191] train_loss: 0.008661\n",
      "[508/00241] train_loss: 0.009287\n",
      "[508/00291] train_loss: 0.009176\n",
      "[508/00341] train_loss: 0.008910\n",
      "[508/00391] train_loss: 0.009413\n",
      "[508/00441] train_loss: 0.008875\n",
      "[508/00491] train_loss: 0.008866\n",
      "[508/00541] train_loss: 0.008710\n",
      "[508/00591] train_loss: 0.009558\n",
      "[508/00641] train_loss: 0.009212\n",
      "[508/00691] train_loss: 0.008911\n",
      "[508/00741] train_loss: 0.009775\n",
      "[508/00791] train_loss: 0.008605\n",
      "[508/00841] train_loss: 0.008904\n",
      "[508/00891] train_loss: 0.009098\n",
      "[508/00941] train_loss: 0.008532\n",
      "[508/00991] train_loss: 0.008613\n",
      "[508/01041] train_loss: 0.009051\n",
      "[508/01091] train_loss: 0.008933\n",
      "[508/01141] train_loss: 0.009197\n",
      "[508/01191] train_loss: 0.009106\n",
      "[509/00015] train_loss: 0.009267\n",
      "[509/00065] train_loss: 0.008843\n",
      "[509/00115] train_loss: 0.008356\n",
      "[509/00165] train_loss: 0.009237\n",
      "[509/00215] train_loss: 0.008919\n",
      "[509/00265] train_loss: 0.008761\n",
      "[509/00315] train_loss: 0.009605\n",
      "[509/00365] train_loss: 0.009725\n",
      "[509/00415] train_loss: 0.008808\n",
      "[509/00465] train_loss: 0.008748\n",
      "[509/00515] train_loss: 0.008704\n",
      "[509/00565] train_loss: 0.008415\n",
      "[509/00615] train_loss: 0.009511\n",
      "[509/00665] train_loss: 0.009050\n",
      "[509/00715] train_loss: 0.008913\n",
      "[509/00765] train_loss: 0.008693\n",
      "[509/00815] train_loss: 0.009515\n",
      "[509/00865] train_loss: 0.009371\n",
      "[509/00915] train_loss: 0.009035\n",
      "[509/00965] train_loss: 0.009013\n",
      "[509/01015] train_loss: 0.008983\n",
      "[509/01065] train_loss: 0.008979\n",
      "[509/01115] train_loss: 0.008957\n",
      "[509/01165] train_loss: 0.009814\n",
      "[509/01215] train_loss: 0.009218\n",
      "[510/00039] train_loss: 0.009716\n",
      "[510/00089] train_loss: 0.009688\n",
      "[510/00139] train_loss: 0.008687\n",
      "[510/00189] train_loss: 0.008803\n",
      "[510/00239] train_loss: 0.009229\n",
      "[510/00289] train_loss: 0.009500\n",
      "[510/00339] train_loss: 0.009423\n",
      "[510/00389] train_loss: 0.008930\n",
      "[510/00439] train_loss: 0.009230\n",
      "[510/00489] train_loss: 0.008760\n",
      "[510/00539] train_loss: 0.008640\n",
      "[510/00589] train_loss: 0.009069\n",
      "[510/00639] train_loss: 0.008605\n",
      "[510/00689] train_loss: 0.009220\n",
      "[510/00739] train_loss: 0.008479\n",
      "[510/00789] train_loss: 0.008953\n",
      "[510/00839] train_loss: 0.009145\n",
      "[510/00889] train_loss: 0.008657\n",
      "[510/00939] train_loss: 0.009304\n",
      "[510/00989] train_loss: 0.008891\n",
      "[510/01039] train_loss: 0.008985\n",
      "[510/01089] train_loss: 0.008925\n",
      "[510/01139] train_loss: 0.009035\n",
      "[510/01189] train_loss: 0.008680\n",
      "[511/00013] train_loss: 0.008930\n",
      "[511/00063] train_loss: 0.008981\n",
      "[511/00113] train_loss: 0.009432\n",
      "[511/00163] train_loss: 0.009448\n",
      "[511/00213] train_loss: 0.009373\n",
      "[511/00263] train_loss: 0.009486\n",
      "[511/00313] train_loss: 0.008768\n",
      "[511/00363] train_loss: 0.009058\n",
      "[511/00413] train_loss: 0.009177\n",
      "[511/00463] train_loss: 0.008534\n",
      "[511/00513] train_loss: 0.009050\n",
      "[511/00563] train_loss: 0.009025\n",
      "[511/00613] train_loss: 0.008597\n",
      "[511/00663] train_loss: 0.009115\n",
      "[511/00713] train_loss: 0.008906\n",
      "[511/00763] train_loss: 0.008622\n",
      "[511/00813] train_loss: 0.009296\n",
      "[511/00863] train_loss: 0.009490\n",
      "[511/00913] train_loss: 0.009077\n",
      "[511/00963] train_loss: 0.008436\n",
      "[511/01013] train_loss: 0.008645\n",
      "[511/01063] train_loss: 0.009433\n",
      "[511/01113] train_loss: 0.009155\n",
      "[511/01163] train_loss: 0.009184\n",
      "[511/01213] train_loss: 0.008598\n",
      "[512/00037] train_loss: 0.009042\n",
      "[512/00087] train_loss: 0.008770\n",
      "[512/00137] train_loss: 0.009055\n",
      "[512/00187] train_loss: 0.008750\n",
      "[512/00237] train_loss: 0.008884\n",
      "[512/00287] train_loss: 0.008955\n",
      "[512/00337] train_loss: 0.009014\n",
      "[512/00387] train_loss: 0.009232\n",
      "[512/00437] train_loss: 0.008419\n",
      "[512/00487] train_loss: 0.009395\n",
      "[512/00537] train_loss: 0.009499\n",
      "[512/00587] train_loss: 0.008563\n",
      "[512/00637] train_loss: 0.008638\n",
      "[512/00687] train_loss: 0.008916\n",
      "[512/00737] train_loss: 0.009208\n",
      "[512/00787] train_loss: 0.008888\n",
      "[512/00837] train_loss: 0.008926\n",
      "[512/00887] train_loss: 0.008724\n",
      "[512/00937] train_loss: 0.009030\n",
      "[512/00987] train_loss: 0.009067\n",
      "[512/01037] train_loss: 0.009102\n",
      "[512/01087] train_loss: 0.008805\n",
      "[512/01137] train_loss: 0.009172\n",
      "[512/01187] train_loss: 0.009682\n",
      "[513/00011] train_loss: 0.008869\n",
      "[513/00061] train_loss: 0.008902\n",
      "[513/00111] train_loss: 0.009109\n",
      "[513/00161] train_loss: 0.009089\n",
      "[513/00211] train_loss: 0.008943\n",
      "[513/00261] train_loss: 0.008764\n",
      "[513/00311] train_loss: 0.009117\n",
      "[513/00361] train_loss: 0.009121\n",
      "[513/00411] train_loss: 0.009339\n",
      "[513/00461] train_loss: 0.009057\n",
      "[513/00511] train_loss: 0.008523\n",
      "[513/00561] train_loss: 0.009285\n",
      "[513/00611] train_loss: 0.009213\n",
      "[513/00661] train_loss: 0.008621\n",
      "[513/00711] train_loss: 0.008413\n",
      "[513/00761] train_loss: 0.009067\n",
      "[513/00811] train_loss: 0.008963\n",
      "[513/00861] train_loss: 0.008773\n",
      "[513/00911] train_loss: 0.009098\n",
      "[513/00961] train_loss: 0.009010\n",
      "[513/01011] train_loss: 0.008814\n",
      "[513/01061] train_loss: 0.008471\n",
      "[513/01111] train_loss: 0.009544\n",
      "[513/01161] train_loss: 0.009359\n",
      "[513/01211] train_loss: 0.008910\n",
      "[514/00035] train_loss: 0.009209\n",
      "[514/00085] train_loss: 0.009120\n",
      "[514/00135] train_loss: 0.008789\n",
      "[514/00185] train_loss: 0.008726\n",
      "[514/00235] train_loss: 0.008723\n",
      "[514/00285] train_loss: 0.008907\n",
      "[514/00335] train_loss: 0.008502\n",
      "[514/00385] train_loss: 0.009064\n",
      "[514/00435] train_loss: 0.009154\n",
      "[514/00485] train_loss: 0.009094\n",
      "[514/00535] train_loss: 0.009724\n",
      "[514/00585] train_loss: 0.009659\n",
      "[514/00635] train_loss: 0.008973\n",
      "[514/00685] train_loss: 0.008981\n",
      "[514/00735] train_loss: 0.009275\n",
      "[514/00785] train_loss: 0.008588\n",
      "[514/00835] train_loss: 0.009130\n",
      "[514/00885] train_loss: 0.009579\n",
      "[514/00935] train_loss: 0.009221\n",
      "[514/00985] train_loss: 0.008591\n",
      "[514/01035] train_loss: 0.008731\n",
      "[514/01085] train_loss: 0.008890\n",
      "[514/01135] train_loss: 0.008940\n",
      "[514/01185] train_loss: 0.008603\n",
      "[515/00009] train_loss: 0.008332\n",
      "[515/00059] train_loss: 0.008165\n",
      "[515/00109] train_loss: 0.008972\n",
      "[515/00159] train_loss: 0.008903\n",
      "[515/00209] train_loss: 0.008819\n",
      "[515/00259] train_loss: 0.009871\n",
      "[515/00309] train_loss: 0.009143\n",
      "[515/00359] train_loss: 0.009030\n",
      "[515/00409] train_loss: 0.009296\n",
      "[515/00459] train_loss: 0.008639\n",
      "[515/00509] train_loss: 0.009277\n",
      "[515/00559] train_loss: 0.009167\n",
      "[515/00609] train_loss: 0.008466\n",
      "[515/00659] train_loss: 0.009202\n",
      "[515/00709] train_loss: 0.009211\n",
      "[515/00759] train_loss: 0.008634\n",
      "[515/00809] train_loss: 0.008939\n",
      "[515/00859] train_loss: 0.009582\n",
      "[515/00909] train_loss: 0.009224\n",
      "[515/00959] train_loss: 0.008898\n",
      "[515/01009] train_loss: 0.008482\n",
      "[515/01059] train_loss: 0.008787\n",
      "[515/01109] train_loss: 0.009116\n",
      "[515/01159] train_loss: 0.008535\n",
      "[515/01209] train_loss: 0.009081\n",
      "[516/00033] train_loss: 0.008920\n",
      "[516/00083] train_loss: 0.008379\n",
      "[516/00133] train_loss: 0.009368\n",
      "[516/00183] train_loss: 0.008829\n",
      "[516/00233] train_loss: 0.008791\n",
      "[516/00283] train_loss: 0.009070\n",
      "[516/00333] train_loss: 0.009019\n",
      "[516/00383] train_loss: 0.009879\n",
      "[516/00433] train_loss: 0.008802\n",
      "[516/00483] train_loss: 0.008898\n",
      "[516/00533] train_loss: 0.008679\n",
      "[516/00583] train_loss: 0.009636\n",
      "[516/00633] train_loss: 0.009031\n",
      "[516/00683] train_loss: 0.008978\n",
      "[516/00733] train_loss: 0.008768\n",
      "[516/00783] train_loss: 0.009129\n",
      "[516/00833] train_loss: 0.008143\n",
      "[516/00883] train_loss: 0.008681\n",
      "[516/00933] train_loss: 0.008937\n",
      "[516/00983] train_loss: 0.008762\n",
      "[516/01033] train_loss: 0.008674\n",
      "[516/01083] train_loss: 0.008553\n",
      "[516/01133] train_loss: 0.008960\n",
      "[516/01183] train_loss: 0.009150\n",
      "[517/00007] train_loss: 0.009284\n",
      "[517/00057] train_loss: 0.008457\n",
      "[517/00107] train_loss: 0.008681\n",
      "[517/00157] train_loss: 0.008730\n",
      "[517/00207] train_loss: 0.008887\n",
      "[517/00257] train_loss: 0.008888\n",
      "[517/00307] train_loss: 0.009595\n",
      "[517/00357] train_loss: 0.009011\n",
      "[517/00407] train_loss: 0.008773\n",
      "[517/00457] train_loss: 0.008772\n",
      "[517/00507] train_loss: 0.008787\n",
      "[517/00557] train_loss: 0.009503\n",
      "[517/00607] train_loss: 0.009025\n",
      "[517/00657] train_loss: 0.008704\n",
      "[517/00707] train_loss: 0.009162\n",
      "[517/00757] train_loss: 0.008670\n",
      "[517/00807] train_loss: 0.009084\n",
      "[517/00857] train_loss: 0.009450\n",
      "[517/00907] train_loss: 0.009014\n",
      "[517/00957] train_loss: 0.008949\n",
      "[517/01007] train_loss: 0.009551\n",
      "[517/01057] train_loss: 0.008891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[517/01107] train_loss: 0.008759\n",
      "[517/01157] train_loss: 0.008662\n",
      "[517/01207] train_loss: 0.008994\n",
      "[518/00031] train_loss: 0.008899\n",
      "[518/00081] train_loss: 0.008687\n",
      "[518/00131] train_loss: 0.008830\n",
      "[518/00181] train_loss: 0.008771\n",
      "[518/00231] train_loss: 0.008882\n",
      "[518/00281] train_loss: 0.009387\n",
      "[518/00331] train_loss: 0.009240\n",
      "[518/00381] train_loss: 0.009464\n",
      "[518/00431] train_loss: 0.008618\n",
      "[518/00481] train_loss: 0.009379\n",
      "[518/00531] train_loss: 0.008917\n",
      "[518/00581] train_loss: 0.008520\n",
      "[518/00631] train_loss: 0.008720\n",
      "[518/00681] train_loss: 0.008832\n",
      "[518/00731] train_loss: 0.009124\n",
      "[518/00781] train_loss: 0.008867\n",
      "[518/00831] train_loss: 0.008715\n",
      "[518/00881] train_loss: 0.008690\n",
      "[518/00931] train_loss: 0.008850\n",
      "[518/00981] train_loss: 0.008758\n",
      "[518/01031] train_loss: 0.009456\n",
      "[518/01081] train_loss: 0.008940\n",
      "[518/01131] train_loss: 0.009049\n",
      "[518/01181] train_loss: 0.008453\n",
      "[519/00005] train_loss: 0.008801\n",
      "[519/00055] train_loss: 0.009121\n",
      "[519/00105] train_loss: 0.008989\n",
      "[519/00155] train_loss: 0.008757\n",
      "[519/00205] train_loss: 0.009158\n",
      "[519/00255] train_loss: 0.008841\n",
      "[519/00305] train_loss: 0.008781\n",
      "[519/00355] train_loss: 0.008956\n",
      "[519/00405] train_loss: 0.009224\n",
      "[519/00455] train_loss: 0.009354\n",
      "[519/00505] train_loss: 0.008822\n",
      "[519/00555] train_loss: 0.008833\n",
      "[519/00605] train_loss: 0.008608\n",
      "[519/00655] train_loss: 0.008480\n",
      "[519/00705] train_loss: 0.009058\n",
      "[519/00755] train_loss: 0.009479\n",
      "[519/00805] train_loss: 0.008563\n",
      "[519/00855] train_loss: 0.008744\n",
      "[519/00905] train_loss: 0.008898\n",
      "[519/00955] train_loss: 0.008886\n",
      "[519/01005] train_loss: 0.008976\n",
      "[519/01055] train_loss: 0.009185\n",
      "[519/01105] train_loss: 0.009484\n",
      "[519/01155] train_loss: 0.008728\n",
      "[519/01205] train_loss: 0.008872\n",
      "[520/00029] train_loss: 0.008536\n",
      "[520/00079] train_loss: 0.008863\n",
      "[520/00129] train_loss: 0.008771\n",
      "[520/00179] train_loss: 0.008729\n",
      "[520/00229] train_loss: 0.008887\n",
      "[520/00279] train_loss: 0.008809\n",
      "[520/00329] train_loss: 0.008773\n",
      "[520/00379] train_loss: 0.008730\n",
      "[520/00429] train_loss: 0.008919\n",
      "[520/00479] train_loss: 0.008808\n",
      "[520/00529] train_loss: 0.009288\n",
      "[520/00579] train_loss: 0.009111\n",
      "[520/00629] train_loss: 0.009110\n",
      "[520/00679] train_loss: 0.008962\n",
      "[520/00729] train_loss: 0.008499\n",
      "[520/00779] train_loss: 0.009333\n",
      "[520/00829] train_loss: 0.008875\n",
      "[520/00879] train_loss: 0.008586\n",
      "[520/00929] train_loss: 0.009117\n",
      "[520/00979] train_loss: 0.009029\n",
      "[520/01029] train_loss: 0.009163\n",
      "[520/01079] train_loss: 0.008983\n",
      "[520/01129] train_loss: 0.008349\n",
      "[520/01179] train_loss: 0.008849\n",
      "[521/00003] train_loss: 0.009106\n",
      "[521/00053] train_loss: 0.009267\n",
      "[521/00103] train_loss: 0.009159\n",
      "[521/00153] train_loss: 0.009047\n",
      "[521/00203] train_loss: 0.009112\n",
      "[521/00253] train_loss: 0.008906\n",
      "[521/00303] train_loss: 0.009494\n",
      "[521/00353] train_loss: 0.009186\n",
      "[521/00403] train_loss: 0.009173\n",
      "[521/00453] train_loss: 0.008860\n",
      "[521/00503] train_loss: 0.008623\n",
      "[521/00553] train_loss: 0.008456\n",
      "[521/00603] train_loss: 0.008375\n",
      "[521/00653] train_loss: 0.009273\n",
      "[521/00703] train_loss: 0.008739\n",
      "[521/00753] train_loss: 0.008851\n",
      "[521/00803] train_loss: 0.009203\n",
      "[521/00853] train_loss: 0.008784\n",
      "[521/00903] train_loss: 0.008916\n",
      "[521/00953] train_loss: 0.008478\n",
      "[521/01003] train_loss: 0.009125\n",
      "[521/01053] train_loss: 0.009352\n",
      "[521/01103] train_loss: 0.008773\n",
      "[521/01153] train_loss: 0.008330\n",
      "[521/01203] train_loss: 0.008497\n",
      "[522/00027] train_loss: 0.008774\n",
      "[522/00077] train_loss: 0.008907\n",
      "[522/00127] train_loss: 0.008634\n",
      "[522/00177] train_loss: 0.008575\n",
      "[522/00227] train_loss: 0.008744\n",
      "[522/00277] train_loss: 0.009256\n",
      "[522/00327] train_loss: 0.008826\n",
      "[522/00377] train_loss: 0.008507\n",
      "[522/00427] train_loss: 0.009736\n",
      "[522/00477] train_loss: 0.008876\n",
      "[522/00527] train_loss: 0.008652\n",
      "[522/00577] train_loss: 0.008773\n",
      "[522/00627] train_loss: 0.009394\n",
      "[522/00677] train_loss: 0.008747\n",
      "[522/00727] train_loss: 0.009385\n",
      "[522/00777] train_loss: 0.008988\n",
      "[522/00827] train_loss: 0.008192\n",
      "[522/00877] train_loss: 0.008600\n",
      "[522/00927] train_loss: 0.008941\n",
      "[522/00977] train_loss: 0.008569\n",
      "[522/01027] train_loss: 0.009323\n",
      "[522/01077] train_loss: 0.009446\n",
      "[522/01127] train_loss: 0.009152\n",
      "[522/01177] train_loss: 0.008528\n",
      "[523/00001] train_loss: 0.008605\n",
      "[523/00051] train_loss: 0.008920\n",
      "[523/00101] train_loss: 0.008887\n",
      "[523/00151] train_loss: 0.008830\n",
      "[523/00201] train_loss: 0.009278\n",
      "[523/00251] train_loss: 0.008927\n",
      "[523/00301] train_loss: 0.008561\n",
      "[523/00351] train_loss: 0.008774\n",
      "[523/00401] train_loss: 0.009050\n",
      "[523/00451] train_loss: 0.008839\n",
      "[523/00501] train_loss: 0.009067\n",
      "[523/00551] train_loss: 0.009282\n",
      "[523/00601] train_loss: 0.008713\n",
      "[523/00651] train_loss: 0.009457\n",
      "[523/00701] train_loss: 0.009198\n",
      "[523/00751] train_loss: 0.009109\n",
      "[523/00801] train_loss: 0.009071\n",
      "[523/00851] train_loss: 0.008983\n",
      "[523/00901] train_loss: 0.008279\n",
      "[523/00951] train_loss: 0.008810\n",
      "[523/01001] train_loss: 0.009100\n",
      "[523/01051] train_loss: 0.009245\n",
      "[523/01101] train_loss: 0.008147\n",
      "[523/01151] train_loss: 0.008983\n",
      "[523/01201] train_loss: 0.009042\n",
      "[524/00025] train_loss: 0.008391\n",
      "[524/00075] train_loss: 0.009020\n",
      "[524/00125] train_loss: 0.009498\n",
      "[524/00175] train_loss: 0.008412\n",
      "[524/00225] train_loss: 0.009199\n",
      "[524/00275] train_loss: 0.008461\n",
      "[524/00325] train_loss: 0.008186\n",
      "[524/00375] train_loss: 0.008901\n",
      "[524/00425] train_loss: 0.009202\n",
      "[524/00475] train_loss: 0.008887\n",
      "[524/00525] train_loss: 0.008912\n",
      "[524/00575] train_loss: 0.008989\n",
      "[524/00625] train_loss: 0.009036\n",
      "[524/00675] train_loss: 0.009081\n",
      "[524/00725] train_loss: 0.008561\n",
      "[524/00775] train_loss: 0.008785\n",
      "[524/00825] train_loss: 0.008973\n",
      "[524/00875] train_loss: 0.008985\n",
      "[524/00925] train_loss: 0.008883\n",
      "[524/00975] train_loss: 0.008535\n",
      "[524/01025] train_loss: 0.008585\n",
      "[524/01075] train_loss: 0.009244\n",
      "[524/01125] train_loss: 0.008216\n",
      "[524/01175] train_loss: 0.009351\n",
      "[524/01225] train_loss: 0.009292\n",
      "[525/00049] train_loss: 0.008662\n",
      "[525/00099] train_loss: 0.009117\n",
      "[525/00149] train_loss: 0.008955\n",
      "[525/00199] train_loss: 0.009076\n",
      "[525/00249] train_loss: 0.009017\n",
      "[525/00299] train_loss: 0.008902\n",
      "[525/00349] train_loss: 0.009822\n",
      "[525/00399] train_loss: 0.009138\n",
      "[525/00449] train_loss: 0.009140\n",
      "[525/00499] train_loss: 0.009084\n",
      "[525/00549] train_loss: 0.008915\n",
      "[525/00599] train_loss: 0.008761\n",
      "[525/00649] train_loss: 0.008830\n",
      "[525/00699] train_loss: 0.008685\n",
      "[525/00749] train_loss: 0.009523\n",
      "[525/00799] train_loss: 0.008912\n",
      "[525/00849] train_loss: 0.008365\n",
      "[525/00899] train_loss: 0.009139\n",
      "[525/00949] train_loss: 0.008455\n",
      "[525/00999] train_loss: 0.008716\n",
      "[525/01049] train_loss: 0.008839\n",
      "[525/01099] train_loss: 0.008885\n",
      "[525/01149] train_loss: 0.009013\n",
      "[525/01199] train_loss: 0.008626\n",
      "[526/00023] train_loss: 0.008664\n",
      "[526/00073] train_loss: 0.009305\n",
      "[526/00123] train_loss: 0.008998\n",
      "[526/00173] train_loss: 0.008666\n",
      "[526/00223] train_loss: 0.008656\n",
      "[526/00273] train_loss: 0.009060\n",
      "[526/00323] train_loss: 0.008783\n",
      "[526/00373] train_loss: 0.008581\n",
      "[526/00423] train_loss: 0.009105\n",
      "[526/00473] train_loss: 0.008741\n",
      "[526/00523] train_loss: 0.009044\n",
      "[526/00573] train_loss: 0.008862\n",
      "[526/00623] train_loss: 0.008842\n",
      "[526/00673] train_loss: 0.008830\n",
      "[526/00723] train_loss: 0.009252\n",
      "[526/00773] train_loss: 0.008406\n",
      "[526/00823] train_loss: 0.008294\n",
      "[526/00873] train_loss: 0.008649\n",
      "[526/00923] train_loss: 0.008872\n",
      "[526/00973] train_loss: 0.008935\n",
      "[526/01023] train_loss: 0.008944\n",
      "[526/01073] train_loss: 0.008531\n",
      "[526/01123] train_loss: 0.008468\n",
      "[526/01173] train_loss: 0.008648\n",
      "[526/01223] train_loss: 0.009110\n",
      "[527/00047] train_loss: 0.009477\n",
      "[527/00097] train_loss: 0.008688\n",
      "[527/00147] train_loss: 0.008149\n",
      "[527/00197] train_loss: 0.009477\n",
      "[527/00247] train_loss: 0.008574\n",
      "[527/00297] train_loss: 0.008889\n",
      "[527/00347] train_loss: 0.009171\n",
      "[527/00397] train_loss: 0.009357\n",
      "[527/00447] train_loss: 0.008732\n",
      "[527/00497] train_loss: 0.009021\n",
      "[527/00547] train_loss: 0.008902\n",
      "[527/00597] train_loss: 0.008604\n",
      "[527/00647] train_loss: 0.008937\n",
      "[527/00697] train_loss: 0.009294\n",
      "[527/00747] train_loss: 0.008873\n",
      "[527/00797] train_loss: 0.008898\n",
      "[527/00847] train_loss: 0.009087\n",
      "[527/00897] train_loss: 0.008468\n",
      "[527/00947] train_loss: 0.009230\n",
      "[527/00997] train_loss: 0.008943\n",
      "[527/01047] train_loss: 0.009027\n",
      "[527/01097] train_loss: 0.009293\n",
      "[527/01147] train_loss: 0.008550\n",
      "[527/01197] train_loss: 0.008676\n",
      "[528/00021] train_loss: 0.008339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[528/00071] train_loss: 0.008457\n",
      "[528/00121] train_loss: 0.008613\n",
      "[528/00171] train_loss: 0.009274\n",
      "[528/00221] train_loss: 0.008897\n",
      "[528/00271] train_loss: 0.009130\n",
      "[528/00321] train_loss: 0.008691\n",
      "[528/00371] train_loss: 0.008576\n",
      "[528/00421] train_loss: 0.008910\n",
      "[528/00471] train_loss: 0.008609\n",
      "[528/00521] train_loss: 0.009143\n",
      "[528/00571] train_loss: 0.008451\n",
      "[528/00621] train_loss: 0.008913\n",
      "[528/00671] train_loss: 0.008268\n",
      "[528/00721] train_loss: 0.009216\n",
      "[528/00771] train_loss: 0.009712\n",
      "[528/00821] train_loss: 0.008801\n",
      "[528/00871] train_loss: 0.008993\n",
      "[528/00921] train_loss: 0.009063\n",
      "[528/00971] train_loss: 0.008623\n",
      "[528/01021] train_loss: 0.009243\n",
      "[528/01071] train_loss: 0.008424\n",
      "[528/01121] train_loss: 0.009145\n",
      "[528/01171] train_loss: 0.008617\n",
      "[528/01221] train_loss: 0.008914\n",
      "[529/00045] train_loss: 0.009072\n",
      "[529/00095] train_loss: 0.009033\n",
      "[529/00145] train_loss: 0.008968\n",
      "[529/00195] train_loss: 0.008678\n",
      "[529/00245] train_loss: 0.009117\n",
      "[529/00295] train_loss: 0.008741\n",
      "[529/00345] train_loss: 0.009055\n",
      "[529/00395] train_loss: 0.009080\n",
      "[529/00445] train_loss: 0.008938\n",
      "[529/00495] train_loss: 0.008322\n",
      "[529/00545] train_loss: 0.008590\n",
      "[529/00595] train_loss: 0.008516\n",
      "[529/00645] train_loss: 0.008820\n",
      "[529/00695] train_loss: 0.008659\n",
      "[529/00745] train_loss: 0.008990\n",
      "[529/00795] train_loss: 0.008875\n",
      "[529/00845] train_loss: 0.008936\n",
      "[529/00895] train_loss: 0.009709\n",
      "[529/00945] train_loss: 0.008968\n",
      "[529/00995] train_loss: 0.008921\n",
      "[529/01045] train_loss: 0.009081\n",
      "[529/01095] train_loss: 0.008632\n",
      "[529/01145] train_loss: 0.008736\n",
      "[529/01195] train_loss: 0.008518\n",
      "[530/00019] train_loss: 0.008679\n",
      "[530/00069] train_loss: 0.008475\n",
      "[530/00119] train_loss: 0.008654\n",
      "[530/00169] train_loss: 0.009180\n",
      "[530/00219] train_loss: 0.009091\n",
      "[530/00269] train_loss: 0.008957\n",
      "[530/00319] train_loss: 0.008708\n",
      "[530/00369] train_loss: 0.009212\n",
      "[530/00419] train_loss: 0.009250\n",
      "[530/00469] train_loss: 0.009165\n",
      "[530/00519] train_loss: 0.008767\n",
      "[530/00569] train_loss: 0.008750\n",
      "[530/00619] train_loss: 0.008281\n",
      "[530/00669] train_loss: 0.008945\n",
      "[530/00719] train_loss: 0.009018\n",
      "[530/00769] train_loss: 0.009043\n",
      "[530/00819] train_loss: 0.008792\n",
      "[530/00869] train_loss: 0.008647\n",
      "[530/00919] train_loss: 0.009117\n",
      "[530/00969] train_loss: 0.008871\n",
      "[530/01019] train_loss: 0.008860\n",
      "[530/01069] train_loss: 0.008912\n",
      "[530/01119] train_loss: 0.008825\n",
      "[530/01169] train_loss: 0.008324\n",
      "[530/01219] train_loss: 0.008902\n",
      "[531/00043] train_loss: 0.008825\n",
      "[531/00093] train_loss: 0.009301\n",
      "[531/00143] train_loss: 0.008914\n",
      "[531/00193] train_loss: 0.009011\n",
      "[531/00243] train_loss: 0.008645\n",
      "[531/00293] train_loss: 0.008863\n",
      "[531/00343] train_loss: 0.008973\n",
      "[531/00393] train_loss: 0.009267\n",
      "[531/00443] train_loss: 0.008838\n",
      "[531/00493] train_loss: 0.008192\n",
      "[531/00543] train_loss: 0.008784\n",
      "[531/00593] train_loss: 0.009296\n",
      "[531/00643] train_loss: 0.009268\n",
      "[531/00693] train_loss: 0.008317\n",
      "[531/00743] train_loss: 0.008654\n",
      "[531/00793] train_loss: 0.009201\n",
      "[531/00843] train_loss: 0.009100\n",
      "[531/00893] train_loss: 0.008729\n",
      "[531/00943] train_loss: 0.008951\n",
      "[531/00993] train_loss: 0.008492\n",
      "[531/01043] train_loss: 0.009573\n",
      "[531/01093] train_loss: 0.008769\n",
      "[531/01143] train_loss: 0.008974\n",
      "[531/01193] train_loss: 0.008583\n",
      "[532/00017] train_loss: 0.008580\n",
      "[532/00067] train_loss: 0.008831\n",
      "[532/00117] train_loss: 0.008685\n",
      "[532/00167] train_loss: 0.009195\n",
      "[532/00217] train_loss: 0.008585\n",
      "[532/00267] train_loss: 0.009334\n",
      "[532/00317] train_loss: 0.008629\n",
      "[532/00367] train_loss: 0.009124\n",
      "[532/00417] train_loss: 0.008520\n",
      "[532/00467] train_loss: 0.008308\n",
      "[532/00517] train_loss: 0.008747\n",
      "[532/00567] train_loss: 0.008776\n",
      "[532/00617] train_loss: 0.008885\n",
      "[532/00667] train_loss: 0.008760\n",
      "[532/00717] train_loss: 0.009239\n",
      "[532/00767] train_loss: 0.009232\n",
      "[532/00817] train_loss: 0.008525\n",
      "[532/00867] train_loss: 0.008449\n",
      "[532/00917] train_loss: 0.009012\n",
      "[532/00967] train_loss: 0.009179\n",
      "[532/01017] train_loss: 0.009327\n",
      "[532/01067] train_loss: 0.008835\n",
      "[532/01117] train_loss: 0.008554\n",
      "[532/01167] train_loss: 0.008592\n",
      "[532/01217] train_loss: 0.008612\n",
      "[533/00041] train_loss: 0.008916\n",
      "[533/00091] train_loss: 0.009394\n",
      "[533/00141] train_loss: 0.009213\n",
      "[533/00191] train_loss: 0.008659\n",
      "[533/00241] train_loss: 0.008411\n",
      "[533/00291] train_loss: 0.008842\n",
      "[533/00341] train_loss: 0.008640\n",
      "[533/00391] train_loss: 0.008793\n",
      "[533/00441] train_loss: 0.008353\n",
      "[533/00491] train_loss: 0.009137\n",
      "[533/00541] train_loss: 0.008639\n",
      "[533/00591] train_loss: 0.008708\n",
      "[533/00641] train_loss: 0.009459\n",
      "[533/00691] train_loss: 0.009186\n",
      "[533/00741] train_loss: 0.008866\n",
      "[533/00791] train_loss: 0.009040\n",
      "[533/00841] train_loss: 0.009031\n",
      "[533/00891] train_loss: 0.008892\n",
      "[533/00941] train_loss: 0.008582\n",
      "[533/00991] train_loss: 0.008749\n",
      "[533/01041] train_loss: 0.008825\n",
      "[533/01091] train_loss: 0.009109\n",
      "[533/01141] train_loss: 0.008547\n",
      "[533/01191] train_loss: 0.008782\n",
      "[534/00015] train_loss: 0.008861\n",
      "[534/00065] train_loss: 0.008191\n",
      "[534/00115] train_loss: 0.008884\n",
      "[534/00165] train_loss: 0.009107\n",
      "[534/00215] train_loss: 0.008972\n",
      "[534/00265] train_loss: 0.009544\n",
      "[534/00315] train_loss: 0.008722\n",
      "[534/00365] train_loss: 0.008860\n",
      "[534/00415] train_loss: 0.008706\n",
      "[534/00465] train_loss: 0.008934\n",
      "[534/00515] train_loss: 0.009275\n",
      "[534/00565] train_loss: 0.008864\n",
      "[534/00615] train_loss: 0.008471\n",
      "[534/00665] train_loss: 0.008907\n",
      "[534/00715] train_loss: 0.008927\n",
      "[534/00765] train_loss: 0.008984\n",
      "[534/00815] train_loss: 0.008465\n",
      "[534/00865] train_loss: 0.008447\n",
      "[534/00915] train_loss: 0.008604\n",
      "[534/00965] train_loss: 0.008565\n",
      "[534/01015] train_loss: 0.009446\n",
      "[534/01065] train_loss: 0.008885\n",
      "[534/01115] train_loss: 0.008681\n",
      "[534/01165] train_loss: 0.008414\n",
      "[534/01215] train_loss: 0.008278\n",
      "[535/00039] train_loss: 0.008925\n",
      "[535/00089] train_loss: 0.008771\n",
      "[535/00139] train_loss: 0.008560\n",
      "[535/00189] train_loss: 0.008877\n",
      "[535/00239] train_loss: 0.009134\n",
      "[535/00289] train_loss: 0.009128\n",
      "[535/00339] train_loss: 0.008994\n",
      "[535/00389] train_loss: 0.008826\n",
      "[535/00439] train_loss: 0.008676\n",
      "[535/00489] train_loss: 0.008569\n",
      "[535/00539] train_loss: 0.008727\n",
      "[535/00589] train_loss: 0.008908\n",
      "[535/00639] train_loss: 0.008668\n",
      "[535/00689] train_loss: 0.008748\n",
      "[535/00739] train_loss: 0.009001\n",
      "[535/00789] train_loss: 0.008860\n",
      "[535/00839] train_loss: 0.008648\n",
      "[535/00889] train_loss: 0.009329\n",
      "[535/00939] train_loss: 0.008926\n",
      "[535/00989] train_loss: 0.008714\n",
      "[535/01039] train_loss: 0.009216\n",
      "[535/01089] train_loss: 0.008972\n",
      "[535/01139] train_loss: 0.008129\n",
      "[535/01189] train_loss: 0.008825\n",
      "[536/00013] train_loss: 0.008661\n",
      "[536/00063] train_loss: 0.009628\n",
      "[536/00113] train_loss: 0.008648\n",
      "[536/00163] train_loss: 0.008609\n",
      "[536/00213] train_loss: 0.008841\n",
      "[536/00263] train_loss: 0.008737\n",
      "[536/00313] train_loss: 0.009185\n",
      "[536/00363] train_loss: 0.008883\n",
      "[536/00413] train_loss: 0.008660\n",
      "[536/00463] train_loss: 0.009005\n",
      "[536/00513] train_loss: 0.008427\n",
      "[536/00563] train_loss: 0.009067\n",
      "[536/00613] train_loss: 0.008670\n",
      "[536/00663] train_loss: 0.008807\n",
      "[536/00713] train_loss: 0.008827\n",
      "[536/00763] train_loss: 0.008820\n",
      "[536/00813] train_loss: 0.009181\n",
      "[536/00863] train_loss: 0.008677\n",
      "[536/00913] train_loss: 0.008818\n",
      "[536/00963] train_loss: 0.008860\n",
      "[536/01013] train_loss: 0.008898\n",
      "[536/01063] train_loss: 0.008457\n",
      "[536/01113] train_loss: 0.008567\n",
      "[536/01163] train_loss: 0.008450\n",
      "[536/01213] train_loss: 0.008971\n",
      "[537/00037] train_loss: 0.008394\n",
      "[537/00087] train_loss: 0.008314\n",
      "[537/00137] train_loss: 0.009114\n",
      "[537/00187] train_loss: 0.008405\n",
      "[537/00237] train_loss: 0.008966\n",
      "[537/00287] train_loss: 0.009306\n",
      "[537/00337] train_loss: 0.008925\n",
      "[537/00387] train_loss: 0.009107\n",
      "[537/00437] train_loss: 0.009054\n",
      "[537/00487] train_loss: 0.009608\n",
      "[537/00537] train_loss: 0.008809\n",
      "[537/00587] train_loss: 0.008440\n",
      "[537/00637] train_loss: 0.008567\n",
      "[537/00687] train_loss: 0.008605\n",
      "[537/00737] train_loss: 0.009073\n",
      "[537/00787] train_loss: 0.009116\n",
      "[537/00837] train_loss: 0.009178\n",
      "[537/00887] train_loss: 0.008959\n",
      "[537/00937] train_loss: 0.008528\n",
      "[537/00987] train_loss: 0.008972\n",
      "[537/01037] train_loss: 0.008830\n",
      "[537/01087] train_loss: 0.009011\n",
      "[537/01137] train_loss: 0.008543\n",
      "[537/01187] train_loss: 0.008960\n",
      "[538/00011] train_loss: 0.008627\n",
      "[538/00061] train_loss: 0.008509\n",
      "[538/00111] train_loss: 0.008644\n",
      "[538/00161] train_loss: 0.009481\n",
      "[538/00211] train_loss: 0.008864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[538/00261] train_loss: 0.008133\n",
      "[538/00311] train_loss: 0.009245\n",
      "[538/00361] train_loss: 0.008809\n",
      "[538/00411] train_loss: 0.008513\n",
      "[538/00461] train_loss: 0.008795\n",
      "[538/00511] train_loss: 0.008909\n",
      "[538/00561] train_loss: 0.008763\n",
      "[538/00611] train_loss: 0.008320\n",
      "[538/00661] train_loss: 0.008787\n",
      "[538/00711] train_loss: 0.008600\n",
      "[538/00761] train_loss: 0.008794\n",
      "[538/00811] train_loss: 0.008721\n",
      "[538/00861] train_loss: 0.008686\n",
      "[538/00911] train_loss: 0.009020\n",
      "[538/00961] train_loss: 0.008828\n",
      "[538/01011] train_loss: 0.008838\n",
      "[538/01061] train_loss: 0.008863\n",
      "[538/01111] train_loss: 0.009115\n",
      "[538/01161] train_loss: 0.009060\n",
      "[538/01211] train_loss: 0.009163\n",
      "[539/00035] train_loss: 0.008771\n",
      "[539/00085] train_loss: 0.009491\n",
      "[539/00135] train_loss: 0.008665\n",
      "[539/00185] train_loss: 0.008603\n",
      "[539/00235] train_loss: 0.008863\n",
      "[539/00285] train_loss: 0.009115\n",
      "[539/00335] train_loss: 0.008509\n",
      "[539/00385] train_loss: 0.008951\n",
      "[539/00435] train_loss: 0.009795\n",
      "[539/00485] train_loss: 0.008988\n",
      "[539/00535] train_loss: 0.008844\n",
      "[539/00585] train_loss: 0.008265\n",
      "[539/00635] train_loss: 0.008745\n",
      "[539/00685] train_loss: 0.008695\n",
      "[539/00735] train_loss: 0.008560\n",
      "[539/00785] train_loss: 0.008783\n",
      "[539/00835] train_loss: 0.008470\n",
      "[539/00885] train_loss: 0.008781\n",
      "[539/00935] train_loss: 0.008813\n",
      "[539/00985] train_loss: 0.008737\n",
      "[539/01035] train_loss: 0.008472\n",
      "[539/01085] train_loss: 0.008684\n",
      "[539/01135] train_loss: 0.009082\n",
      "[539/01185] train_loss: 0.009133\n",
      "[540/00009] train_loss: 0.008536\n",
      "[540/00059] train_loss: 0.008374\n",
      "[540/00109] train_loss: 0.008711\n",
      "[540/00159] train_loss: 0.008676\n",
      "[540/00209] train_loss: 0.008874\n",
      "[540/00259] train_loss: 0.009231\n",
      "[540/00309] train_loss: 0.009185\n",
      "[540/00359] train_loss: 0.008365\n",
      "[540/00409] train_loss: 0.009428\n",
      "[540/00459] train_loss: 0.008888\n",
      "[540/00509] train_loss: 0.008714\n",
      "[540/00559] train_loss: 0.008371\n",
      "[540/00609] train_loss: 0.008552\n",
      "[540/00659] train_loss: 0.008746\n",
      "[540/00709] train_loss: 0.008469\n",
      "[540/00759] train_loss: 0.008683\n",
      "[540/00809] train_loss: 0.008668\n",
      "[540/00859] train_loss: 0.008683\n",
      "[540/00909] train_loss: 0.008521\n",
      "[540/00959] train_loss: 0.008697\n",
      "[540/01009] train_loss: 0.008886\n",
      "[540/01059] train_loss: 0.009192\n",
      "[540/01109] train_loss: 0.008651\n",
      "[540/01159] train_loss: 0.008986\n",
      "[540/01209] train_loss: 0.008703\n",
      "[541/00033] train_loss: 0.009208\n",
      "[541/00083] train_loss: 0.008854\n",
      "[541/00133] train_loss: 0.008827\n",
      "[541/00183] train_loss: 0.008616\n",
      "[541/00233] train_loss: 0.009010\n",
      "[541/00283] train_loss: 0.008460\n",
      "[541/00333] train_loss: 0.008819\n",
      "[541/00383] train_loss: 0.008505\n",
      "[541/00433] train_loss: 0.008643\n",
      "[541/00483] train_loss: 0.008557\n",
      "[541/00533] train_loss: 0.008998\n",
      "[541/00583] train_loss: 0.008404\n",
      "[541/00633] train_loss: 0.008628\n",
      "[541/00683] train_loss: 0.008779\n",
      "[541/00733] train_loss: 0.009308\n",
      "[541/00783] train_loss: 0.008799\n",
      "[541/00833] train_loss: 0.009426\n",
      "[541/00883] train_loss: 0.008515\n",
      "[541/00933] train_loss: 0.009201\n",
      "[541/00983] train_loss: 0.009204\n",
      "[541/01033] train_loss: 0.008544\n",
      "[541/01083] train_loss: 0.008396\n",
      "[541/01133] train_loss: 0.009024\n",
      "[541/01183] train_loss: 0.009548\n",
      "[542/00007] train_loss: 0.008699\n",
      "[542/00057] train_loss: 0.009157\n",
      "[542/00107] train_loss: 0.008749\n",
      "[542/00157] train_loss: 0.008498\n",
      "[542/00207] train_loss: 0.008396\n",
      "[542/00257] train_loss: 0.008940\n",
      "[542/00307] train_loss: 0.008563\n",
      "[542/00357] train_loss: 0.009223\n",
      "[542/00407] train_loss: 0.009098\n",
      "[542/00457] train_loss: 0.008564\n",
      "[542/00507] train_loss: 0.008917\n",
      "[542/00557] train_loss: 0.008712\n",
      "[542/00607] train_loss: 0.009150\n",
      "[542/00657] train_loss: 0.008450\n",
      "[542/00707] train_loss: 0.008804\n",
      "[542/00757] train_loss: 0.008471\n",
      "[542/00807] train_loss: 0.008957\n",
      "[542/00857] train_loss: 0.008891\n",
      "[542/00907] train_loss: 0.008796\n",
      "[542/00957] train_loss: 0.008537\n",
      "[542/01007] train_loss: 0.008356\n",
      "[542/01057] train_loss: 0.008444\n",
      "[542/01107] train_loss: 0.008732\n",
      "[542/01157] train_loss: 0.008898\n",
      "[542/01207] train_loss: 0.008802\n",
      "[543/00031] train_loss: 0.009009\n",
      "[543/00081] train_loss: 0.008572\n",
      "[543/00131] train_loss: 0.008697\n",
      "[543/00181] train_loss: 0.008912\n",
      "[543/00231] train_loss: 0.009024\n",
      "[543/00281] train_loss: 0.008465\n",
      "[543/00331] train_loss: 0.009399\n",
      "[543/00381] train_loss: 0.008785\n",
      "[543/00431] train_loss: 0.009266\n",
      "[543/00481] train_loss: 0.008792\n",
      "[543/00531] train_loss: 0.008489\n",
      "[543/00581] train_loss: 0.008380\n",
      "[543/00631] train_loss: 0.009160\n",
      "[543/00681] train_loss: 0.008629\n",
      "[543/00731] train_loss: 0.008732\n",
      "[543/00781] train_loss: 0.008757\n",
      "[543/00831] train_loss: 0.008333\n",
      "[543/00881] train_loss: 0.008910\n",
      "[543/00931] train_loss: 0.008679\n",
      "[543/00981] train_loss: 0.009262\n",
      "[543/01031] train_loss: 0.008112\n",
      "[543/01081] train_loss: 0.008601\n",
      "[543/01131] train_loss: 0.009270\n",
      "[543/01181] train_loss: 0.008621\n",
      "[544/00005] train_loss: 0.008793\n",
      "[544/00055] train_loss: 0.008763\n",
      "[544/00105] train_loss: 0.009033\n",
      "[544/00155] train_loss: 0.008478\n",
      "[544/00205] train_loss: 0.008693\n",
      "[544/00255] train_loss: 0.008760\n",
      "[544/00305] train_loss: 0.009033\n",
      "[544/00355] train_loss: 0.008887\n",
      "[544/00405] train_loss: 0.009083\n",
      "[544/00455] train_loss: 0.009049\n",
      "[544/00505] train_loss: 0.008670\n",
      "[544/00555] train_loss: 0.008958\n",
      "[544/00605] train_loss: 0.009224\n",
      "[544/00655] train_loss: 0.008441\n",
      "[544/00705] train_loss: 0.008918\n",
      "[544/00755] train_loss: 0.008569\n",
      "[544/00805] train_loss: 0.008867\n",
      "[544/00855] train_loss: 0.008940\n",
      "[544/00905] train_loss: 0.008546\n",
      "[544/00955] train_loss: 0.008727\n",
      "[544/01005] train_loss: 0.008821\n",
      "[544/01055] train_loss: 0.008750\n",
      "[544/01105] train_loss: 0.008701\n",
      "[544/01155] train_loss: 0.009066\n",
      "[544/01205] train_loss: 0.008297\n",
      "[545/00029] train_loss: 0.008820\n",
      "[545/00079] train_loss: 0.008755\n",
      "[545/00129] train_loss: 0.008751\n",
      "[545/00179] train_loss: 0.008488\n",
      "[545/00229] train_loss: 0.008191\n",
      "[545/00279] train_loss: 0.008499\n",
      "[545/00329] train_loss: 0.008736\n",
      "[545/00379] train_loss: 0.008930\n",
      "[545/00429] train_loss: 0.008631\n",
      "[545/00479] train_loss: 0.008752\n",
      "[545/00529] train_loss: 0.009029\n",
      "[545/00579] train_loss: 0.009205\n",
      "[545/00629] train_loss: 0.008810\n",
      "[545/00679] train_loss: 0.009029\n",
      "[545/00729] train_loss: 0.008911\n",
      "[545/00779] train_loss: 0.009696\n",
      "[545/00829] train_loss: 0.008551\n",
      "[545/00879] train_loss: 0.008333\n",
      "[545/00929] train_loss: 0.009195\n",
      "[545/00979] train_loss: 0.008776\n",
      "[545/01029] train_loss: 0.008297\n",
      "[545/01079] train_loss: 0.008959\n",
      "[545/01129] train_loss: 0.008494\n",
      "[545/01179] train_loss: 0.008904\n",
      "[546/00003] train_loss: 0.009056\n",
      "[546/00053] train_loss: 0.008704\n",
      "[546/00103] train_loss: 0.008957\n",
      "[546/00153] train_loss: 0.008946\n",
      "[546/00203] train_loss: 0.008799\n",
      "[546/00253] train_loss: 0.008369\n",
      "[546/00303] train_loss: 0.009086\n",
      "[546/00353] train_loss: 0.008523\n",
      "[546/00403] train_loss: 0.008538\n",
      "[546/00453] train_loss: 0.009045\n",
      "[546/00503] train_loss: 0.008582\n",
      "[546/00553] train_loss: 0.008104\n",
      "[546/00603] train_loss: 0.008985\n",
      "[546/00653] train_loss: 0.008795\n",
      "[546/00703] train_loss: 0.009579\n",
      "[546/00753] train_loss: 0.008877\n",
      "[546/00803] train_loss: 0.008944\n",
      "[546/00853] train_loss: 0.008794\n",
      "[546/00903] train_loss: 0.008729\n",
      "[546/00953] train_loss: 0.008981\n",
      "[546/01003] train_loss: 0.008696\n",
      "[546/01053] train_loss: 0.008739\n",
      "[546/01103] train_loss: 0.008812\n",
      "[546/01153] train_loss: 0.008694\n",
      "[546/01203] train_loss: 0.008391\n",
      "[547/00027] train_loss: 0.008016\n",
      "[547/00077] train_loss: 0.008662\n",
      "[547/00127] train_loss: 0.008594\n",
      "[547/00177] train_loss: 0.008847\n",
      "[547/00227] train_loss: 0.008691\n",
      "[547/00277] train_loss: 0.008878\n",
      "[547/00327] train_loss: 0.009242\n",
      "[547/00377] train_loss: 0.008977\n",
      "[547/00427] train_loss: 0.008551\n",
      "[547/00477] train_loss: 0.008776\n",
      "[547/00527] train_loss: 0.008663\n",
      "[547/00577] train_loss: 0.008456\n",
      "[547/00627] train_loss: 0.008840\n",
      "[547/00677] train_loss: 0.008678\n",
      "[547/00727] train_loss: 0.008823\n",
      "[547/00777] train_loss: 0.008723\n",
      "[547/00827] train_loss: 0.008874\n",
      "[547/00877] train_loss: 0.008831\n",
      "[547/00927] train_loss: 0.008874\n",
      "[547/00977] train_loss: 0.008899\n",
      "[547/01027] train_loss: 0.008638\n",
      "[547/01077] train_loss: 0.008757\n",
      "[547/01127] train_loss: 0.008590\n",
      "[547/01177] train_loss: 0.009395\n",
      "[548/00001] train_loss: 0.008888\n",
      "[548/00051] train_loss: 0.009066\n",
      "[548/00101] train_loss: 0.008822\n",
      "[548/00151] train_loss: 0.009036\n",
      "[548/00201] train_loss: 0.008423\n",
      "[548/00251] train_loss: 0.008863\n",
      "[548/00301] train_loss: 0.008466\n",
      "[548/00351] train_loss: 0.009312\n",
      "[548/00401] train_loss: 0.008366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[548/00451] train_loss: 0.008900\n",
      "[548/00501] train_loss: 0.008719\n",
      "[548/00551] train_loss: 0.008825\n",
      "[548/00601] train_loss: 0.009186\n",
      "[548/00651] train_loss: 0.008537\n",
      "[548/00701] train_loss: 0.008756\n",
      "[548/00751] train_loss: 0.008998\n",
      "[548/00801] train_loss: 0.009125\n",
      "[548/00851] train_loss: 0.008613\n",
      "[548/00901] train_loss: 0.008532\n",
      "[548/00951] train_loss: 0.008414\n",
      "[548/01001] train_loss: 0.009353\n",
      "[548/01051] train_loss: 0.008755\n",
      "[548/01101] train_loss: 0.008564\n",
      "[548/01151] train_loss: 0.008424\n",
      "[548/01201] train_loss: 0.008697\n",
      "[549/00025] train_loss: 0.008847\n",
      "[549/00075] train_loss: 0.008604\n",
      "[549/00125] train_loss: 0.008540\n",
      "[549/00175] train_loss: 0.008285\n",
      "[549/00225] train_loss: 0.008773\n",
      "[549/00275] train_loss: 0.009202\n",
      "[549/00325] train_loss: 0.008691\n",
      "[549/00375] train_loss: 0.008615\n",
      "[549/00425] train_loss: 0.008962\n",
      "[549/00475] train_loss: 0.008932\n",
      "[549/00525] train_loss: 0.009237\n",
      "[549/00575] train_loss: 0.008351\n",
      "[549/00625] train_loss: 0.008194\n",
      "[549/00675] train_loss: 0.008983\n",
      "[549/00725] train_loss: 0.008677\n",
      "[549/00775] train_loss: 0.009329\n",
      "[549/00825] train_loss: 0.008367\n",
      "[549/00875] train_loss: 0.008183\n",
      "[549/00925] train_loss: 0.008750\n",
      "[549/00975] train_loss: 0.009173\n",
      "[549/01025] train_loss: 0.008490\n",
      "[549/01075] train_loss: 0.008902\n",
      "[549/01125] train_loss: 0.008581\n",
      "[549/01175] train_loss: 0.009642\n",
      "[549/01225] train_loss: 0.008725\n",
      "[550/00049] train_loss: 0.008765\n",
      "[550/00099] train_loss: 0.008218\n",
      "[550/00149] train_loss: 0.008679\n",
      "[550/00199] train_loss: 0.009208\n",
      "[550/00249] train_loss: 0.009175\n",
      "[550/00299] train_loss: 0.008981\n",
      "[550/00349] train_loss: 0.008798\n",
      "[550/00399] train_loss: 0.008821\n",
      "[550/00449] train_loss: 0.008702\n",
      "[550/00499] train_loss: 0.008764\n",
      "[550/00549] train_loss: 0.008123\n",
      "[550/00599] train_loss: 0.008902\n",
      "[550/00649] train_loss: 0.008596\n",
      "[550/00699] train_loss: 0.008904\n",
      "[550/00749] train_loss: 0.008794\n",
      "[550/00799] train_loss: 0.008893\n",
      "[550/00849] train_loss: 0.009073\n",
      "[550/00899] train_loss: 0.009280\n",
      "[550/00949] train_loss: 0.008281\n",
      "[550/00999] train_loss: 0.009234\n",
      "[550/01049] train_loss: 0.008890\n",
      "[550/01099] train_loss: 0.008371\n",
      "[550/01149] train_loss: 0.008613\n",
      "[550/01199] train_loss: 0.008473\n",
      "[551/00023] train_loss: 0.008415\n",
      "[551/00073] train_loss: 0.009142\n",
      "[551/00123] train_loss: 0.008135\n",
      "[551/00173] train_loss: 0.009320\n",
      "[551/00223] train_loss: 0.008845\n",
      "[551/00273] train_loss: 0.009004\n",
      "[551/00323] train_loss: 0.008986\n",
      "[551/00373] train_loss: 0.008772\n",
      "[551/00423] train_loss: 0.009032\n",
      "[551/00473] train_loss: 0.009106\n",
      "[551/00523] train_loss: 0.008670\n",
      "[551/00573] train_loss: 0.008704\n",
      "[551/00623] train_loss: 0.009166\n",
      "[551/00673] train_loss: 0.008963\n",
      "[551/00723] train_loss: 0.008465\n",
      "[551/00773] train_loss: 0.008510\n",
      "[551/00823] train_loss: 0.009096\n",
      "[551/00873] train_loss: 0.008656\n",
      "[551/00923] train_loss: 0.008807\n",
      "[551/00973] train_loss: 0.009516\n",
      "[551/01023] train_loss: 0.008586\n",
      "[551/01073] train_loss: 0.008311\n",
      "[551/01123] train_loss: 0.008666\n",
      "[551/01173] train_loss: 0.008366\n",
      "[551/01223] train_loss: 0.009183\n",
      "[552/00047] train_loss: 0.008478\n",
      "[552/00097] train_loss: 0.008367\n",
      "[552/00147] train_loss: 0.008837\n",
      "[552/00197] train_loss: 0.008754\n",
      "[552/00247] train_loss: 0.008615\n",
      "[552/00297] train_loss: 0.009004\n",
      "[552/00347] train_loss: 0.008777\n",
      "[552/00397] train_loss: 0.008811\n",
      "[552/00447] train_loss: 0.009230\n",
      "[552/00497] train_loss: 0.008862\n",
      "[552/00547] train_loss: 0.008350\n",
      "[552/00597] train_loss: 0.009180\n",
      "[552/00647] train_loss: 0.009108\n",
      "[552/00697] train_loss: 0.008125\n",
      "[552/00747] train_loss: 0.008627\n",
      "[552/00797] train_loss: 0.009007\n",
      "[552/00847] train_loss: 0.008830\n",
      "[552/00897] train_loss: 0.008790\n",
      "[552/00947] train_loss: 0.008505\n",
      "[552/00997] train_loss: 0.008966\n",
      "[552/01047] train_loss: 0.007952\n",
      "[552/01097] train_loss: 0.008252\n",
      "[552/01147] train_loss: 0.009050\n",
      "[552/01197] train_loss: 0.008840\n",
      "[553/00021] train_loss: 0.008845\n",
      "[553/00071] train_loss: 0.008255\n",
      "[553/00121] train_loss: 0.008681\n",
      "[553/00171] train_loss: 0.008763\n",
      "[553/00221] train_loss: 0.008496\n",
      "[553/00271] train_loss: 0.008964\n",
      "[553/00321] train_loss: 0.008477\n",
      "[553/00371] train_loss: 0.008511\n",
      "[553/00421] train_loss: 0.008979\n",
      "[553/00471] train_loss: 0.008390\n",
      "[553/00521] train_loss: 0.008675\n",
      "[553/00571] train_loss: 0.008869\n",
      "[553/00621] train_loss: 0.008603\n",
      "[553/00671] train_loss: 0.009004\n",
      "[553/00721] train_loss: 0.008431\n",
      "[553/00771] train_loss: 0.008443\n",
      "[553/00821] train_loss: 0.009204\n",
      "[553/00871] train_loss: 0.009336\n",
      "[553/00921] train_loss: 0.008568\n",
      "[553/00971] train_loss: 0.008626\n",
      "[553/01021] train_loss: 0.008813\n",
      "[553/01071] train_loss: 0.008939\n",
      "[553/01121] train_loss: 0.009248\n",
      "[553/01171] train_loss: 0.008808\n",
      "[553/01221] train_loss: 0.009327\n",
      "[554/00045] train_loss: 0.008852\n",
      "[554/00095] train_loss: 0.008852\n",
      "[554/00145] train_loss: 0.008535\n",
      "[554/00195] train_loss: 0.008664\n",
      "[554/00245] train_loss: 0.008803\n",
      "[554/00295] train_loss: 0.008802\n",
      "[554/00345] train_loss: 0.008836\n",
      "[554/00395] train_loss: 0.008583\n",
      "[554/00445] train_loss: 0.008459\n",
      "[554/00495] train_loss: 0.008707\n",
      "[554/00545] train_loss: 0.008676\n",
      "[554/00595] train_loss: 0.008745\n",
      "[554/00645] train_loss: 0.008560\n",
      "[554/00695] train_loss: 0.008451\n",
      "[554/00745] train_loss: 0.008783\n",
      "[554/00795] train_loss: 0.008879\n",
      "[554/00845] train_loss: 0.008634\n",
      "[554/00895] train_loss: 0.008676\n",
      "[554/00945] train_loss: 0.008894\n",
      "[554/00995] train_loss: 0.008685\n",
      "[554/01045] train_loss: 0.009159\n",
      "[554/01095] train_loss: 0.009346\n",
      "[554/01145] train_loss: 0.008920\n",
      "[554/01195] train_loss: 0.008632\n",
      "[555/00019] train_loss: 0.008776\n",
      "[555/00069] train_loss: 0.008575\n",
      "[555/00119] train_loss: 0.008178\n",
      "[555/00169] train_loss: 0.009176\n",
      "[555/00219] train_loss: 0.009291\n",
      "[555/00269] train_loss: 0.008896\n",
      "[555/00319] train_loss: 0.008702\n",
      "[555/00369] train_loss: 0.008178\n",
      "[555/00419] train_loss: 0.008698\n",
      "[555/00469] train_loss: 0.008811\n",
      "[555/00519] train_loss: 0.008675\n",
      "[555/00569] train_loss: 0.008379\n",
      "[555/00619] train_loss: 0.008700\n",
      "[555/00669] train_loss: 0.009279\n",
      "[555/00719] train_loss: 0.009124\n",
      "[555/00769] train_loss: 0.009281\n",
      "[555/00819] train_loss: 0.009097\n",
      "[555/00869] train_loss: 0.008654\n",
      "[555/00919] train_loss: 0.008650\n",
      "[555/00969] train_loss: 0.009130\n",
      "[555/01019] train_loss: 0.008466\n",
      "[555/01069] train_loss: 0.008582\n",
      "[555/01119] train_loss: 0.008445\n",
      "[555/01169] train_loss: 0.008391\n",
      "[555/01219] train_loss: 0.009099\n",
      "[556/00043] train_loss: 0.008661\n",
      "[556/00093] train_loss: 0.008900\n",
      "[556/00143] train_loss: 0.008655\n",
      "[556/00193] train_loss: 0.009072\n",
      "[556/00243] train_loss: 0.008876\n",
      "[556/00293] train_loss: 0.008642\n",
      "[556/00343] train_loss: 0.008662\n",
      "[556/00393] train_loss: 0.009229\n",
      "[556/00443] train_loss: 0.008801\n",
      "[556/00493] train_loss: 0.008271\n",
      "[556/00543] train_loss: 0.008781\n",
      "[556/00593] train_loss: 0.008819\n",
      "[556/00643] train_loss: 0.008853\n",
      "[556/00693] train_loss: 0.008539\n",
      "[556/00743] train_loss: 0.008740\n",
      "[556/00793] train_loss: 0.008803\n",
      "[556/00843] train_loss: 0.008804\n",
      "[556/00893] train_loss: 0.008297\n",
      "[556/00943] train_loss: 0.008819\n",
      "[556/00993] train_loss: 0.008973\n",
      "[556/01043] train_loss: 0.009076\n",
      "[556/01093] train_loss: 0.008703\n",
      "[556/01143] train_loss: 0.008671\n",
      "[556/01193] train_loss: 0.008315\n",
      "[557/00017] train_loss: 0.008414\n",
      "[557/00067] train_loss: 0.009461\n",
      "[557/00117] train_loss: 0.008452\n",
      "[557/00167] train_loss: 0.008892\n",
      "[557/00217] train_loss: 0.008750\n",
      "[557/00267] train_loss: 0.008253\n",
      "[557/00317] train_loss: 0.008146\n",
      "[557/00367] train_loss: 0.008892\n",
      "[557/00417] train_loss: 0.008796\n",
      "[557/00467] train_loss: 0.008615\n",
      "[557/00517] train_loss: 0.008877\n",
      "[557/00567] train_loss: 0.008417\n",
      "[557/00617] train_loss: 0.007903\n",
      "[557/00667] train_loss: 0.008440\n",
      "[557/00717] train_loss: 0.009054\n",
      "[557/00767] train_loss: 0.008932\n",
      "[557/00817] train_loss: 0.008875\n",
      "[557/00867] train_loss: 0.008838\n",
      "[557/00917] train_loss: 0.008664\n",
      "[557/00967] train_loss: 0.009125\n",
      "[557/01017] train_loss: 0.008919\n",
      "[557/01067] train_loss: 0.008725\n",
      "[557/01117] train_loss: 0.008772\n",
      "[557/01167] train_loss: 0.009619\n",
      "[557/01217] train_loss: 0.008578\n",
      "[558/00041] train_loss: 0.008694\n",
      "[558/00091] train_loss: 0.009036\n",
      "[558/00141] train_loss: 0.008470\n",
      "[558/00191] train_loss: 0.008937\n",
      "[558/00241] train_loss: 0.009037\n",
      "[558/00291] train_loss: 0.008613\n",
      "[558/00341] train_loss: 0.009016\n",
      "[558/00391] train_loss: 0.009001\n",
      "[558/00441] train_loss: 0.008773\n",
      "[558/00491] train_loss: 0.008557\n",
      "[558/00541] train_loss: 0.008492\n",
      "[558/00591] train_loss: 0.008823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[558/00641] train_loss: 0.008484\n",
      "[558/00691] train_loss: 0.008487\n",
      "[558/00741] train_loss: 0.008212\n",
      "[558/00791] train_loss: 0.008843\n",
      "[558/00841] train_loss: 0.009167\n",
      "[558/00891] train_loss: 0.008529\n",
      "[558/00941] train_loss: 0.008876\n",
      "[558/00991] train_loss: 0.008118\n",
      "[558/01041] train_loss: 0.008776\n",
      "[558/01091] train_loss: 0.008582\n",
      "[558/01141] train_loss: 0.008819\n",
      "[558/01191] train_loss: 0.009373\n",
      "[559/00015] train_loss: 0.008362\n",
      "[559/00065] train_loss: 0.008821\n",
      "[559/00115] train_loss: 0.008155\n",
      "[559/00165] train_loss: 0.008439\n",
      "[559/00215] train_loss: 0.008798\n",
      "[559/00265] train_loss: 0.009340\n",
      "[559/00315] train_loss: 0.008959\n",
      "[559/00365] train_loss: 0.008271\n",
      "[559/00415] train_loss: 0.008610\n",
      "[559/00465] train_loss: 0.008728\n",
      "[559/00515] train_loss: 0.008190\n",
      "[559/00565] train_loss: 0.008950\n",
      "[559/00615] train_loss: 0.009697\n",
      "[559/00665] train_loss: 0.008753\n",
      "[559/00715] train_loss: 0.008218\n",
      "[559/00765] train_loss: 0.008920\n",
      "[559/00815] train_loss: 0.009095\n",
      "[559/00865] train_loss: 0.008661\n",
      "[559/00915] train_loss: 0.008852\n",
      "[559/00965] train_loss: 0.008793\n",
      "[559/01015] train_loss: 0.008622\n",
      "[559/01065] train_loss: 0.009559\n",
      "[559/01115] train_loss: 0.008414\n",
      "[559/01165] train_loss: 0.008793\n",
      "[559/01215] train_loss: 0.008887\n",
      "[560/00039] train_loss: 0.008914\n",
      "[560/00089] train_loss: 0.009075\n",
      "[560/00139] train_loss: 0.008481\n",
      "[560/00189] train_loss: 0.008528\n",
      "[560/00239] train_loss: 0.008132\n",
      "[560/00289] train_loss: 0.008744\n",
      "[560/00339] train_loss: 0.008881\n",
      "[560/00389] train_loss: 0.008778\n",
      "[560/00439] train_loss: 0.008343\n",
      "[560/00489] train_loss: 0.008587\n",
      "[560/00539] train_loss: 0.008607\n",
      "[560/00589] train_loss: 0.008999\n",
      "[560/00639] train_loss: 0.008220\n",
      "[560/00689] train_loss: 0.008843\n",
      "[560/00739] train_loss: 0.009176\n",
      "[560/00789] train_loss: 0.008463\n",
      "[560/00839] train_loss: 0.008565\n",
      "[560/00889] train_loss: 0.009105\n",
      "[560/00939] train_loss: 0.008793\n",
      "[560/00989] train_loss: 0.009061\n",
      "[560/01039] train_loss: 0.008693\n",
      "[560/01089] train_loss: 0.008670\n",
      "[560/01139] train_loss: 0.008851\n",
      "[560/01189] train_loss: 0.008599\n",
      "[561/00013] train_loss: 0.008357\n",
      "[561/00063] train_loss: 0.008681\n",
      "[561/00113] train_loss: 0.008841\n",
      "[561/00163] train_loss: 0.008409\n",
      "[561/00213] train_loss: 0.008752\n",
      "[561/00263] train_loss: 0.008128\n",
      "[561/00313] train_loss: 0.009002\n",
      "[561/00363] train_loss: 0.008791\n",
      "[561/00413] train_loss: 0.008872\n",
      "[561/00463] train_loss: 0.008493\n",
      "[561/00513] train_loss: 0.008732\n",
      "[561/00563] train_loss: 0.009222\n",
      "[561/00613] train_loss: 0.008548\n",
      "[561/00663] train_loss: 0.009228\n",
      "[561/00713] train_loss: 0.009022\n",
      "[561/00763] train_loss: 0.009160\n",
      "[561/00813] train_loss: 0.008846\n",
      "[561/00863] train_loss: 0.008536\n",
      "[561/00913] train_loss: 0.008954\n",
      "[561/00963] train_loss: 0.009062\n",
      "[561/01013] train_loss: 0.008747\n",
      "[561/01063] train_loss: 0.008454\n",
      "[561/01113] train_loss: 0.009142\n",
      "[561/01163] train_loss: 0.008827\n",
      "[561/01213] train_loss: 0.008750\n",
      "[562/00037] train_loss: 0.008718\n",
      "[562/00087] train_loss: 0.008237\n",
      "[562/00137] train_loss: 0.009344\n",
      "[562/00187] train_loss: 0.008863\n",
      "[562/00237] train_loss: 0.008291\n",
      "[562/00287] train_loss: 0.009185\n",
      "[562/00337] train_loss: 0.007973\n",
      "[562/00387] train_loss: 0.008825\n",
      "[562/00437] train_loss: 0.008815\n",
      "[562/00487] train_loss: 0.008390\n",
      "[562/00537] train_loss: 0.009400\n",
      "[562/00587] train_loss: 0.008624\n",
      "[562/00637] train_loss: 0.008144\n",
      "[562/00687] train_loss: 0.008809\n",
      "[562/00737] train_loss: 0.008850\n",
      "[562/00787] train_loss: 0.008494\n",
      "[562/00837] train_loss: 0.008550\n",
      "[562/00887] train_loss: 0.008160\n",
      "[562/00937] train_loss: 0.008597\n",
      "[562/00987] train_loss: 0.009232\n",
      "[562/01037] train_loss: 0.009131\n",
      "[562/01087] train_loss: 0.008591\n",
      "[562/01137] train_loss: 0.008885\n",
      "[562/01187] train_loss: 0.008759\n",
      "[563/00011] train_loss: 0.008750\n",
      "[563/00061] train_loss: 0.009004\n",
      "[563/00111] train_loss: 0.008524\n",
      "[563/00161] train_loss: 0.008308\n",
      "[563/00211] train_loss: 0.008788\n",
      "[563/00261] train_loss: 0.008552\n",
      "[563/00311] train_loss: 0.009083\n",
      "[563/00361] train_loss: 0.008390\n",
      "[563/00411] train_loss: 0.009103\n",
      "[563/00461] train_loss: 0.008620\n",
      "[563/00511] train_loss: 0.008565\n",
      "[563/00561] train_loss: 0.008930\n",
      "[563/00611] train_loss: 0.008957\n",
      "[563/00661] train_loss: 0.008728\n",
      "[563/00711] train_loss: 0.008652\n",
      "[563/00761] train_loss: 0.009095\n",
      "[563/00811] train_loss: 0.008519\n",
      "[563/00861] train_loss: 0.008818\n",
      "[563/00911] train_loss: 0.009142\n",
      "[563/00961] train_loss: 0.008464\n",
      "[563/01011] train_loss: 0.008443\n",
      "[563/01061] train_loss: 0.008800\n",
      "[563/01111] train_loss: 0.008536\n",
      "[563/01161] train_loss: 0.008827\n",
      "[563/01211] train_loss: 0.008454\n",
      "[564/00035] train_loss: 0.008817\n",
      "[564/00085] train_loss: 0.008918\n",
      "[564/00135] train_loss: 0.008831\n",
      "[564/00185] train_loss: 0.008365\n",
      "[564/00235] train_loss: 0.008789\n",
      "[564/00285] train_loss: 0.008705\n",
      "[564/00335] train_loss: 0.008961\n",
      "[564/00385] train_loss: 0.008713\n",
      "[564/00435] train_loss: 0.008453\n",
      "[564/00485] train_loss: 0.008886\n",
      "[564/00535] train_loss: 0.008756\n",
      "[564/00585] train_loss: 0.008909\n",
      "[564/00635] train_loss: 0.008767\n",
      "[564/00685] train_loss: 0.008800\n",
      "[564/00735] train_loss: 0.008922\n",
      "[564/00785] train_loss: 0.008598\n",
      "[564/00835] train_loss: 0.008300\n",
      "[564/00885] train_loss: 0.008761\n",
      "[564/00935] train_loss: 0.009173\n",
      "[564/00985] train_loss: 0.008362\n",
      "[564/01035] train_loss: 0.008460\n",
      "[564/01085] train_loss: 0.008468\n",
      "[564/01135] train_loss: 0.008904\n",
      "[564/01185] train_loss: 0.009008\n",
      "[565/00009] train_loss: 0.008544\n",
      "[565/00059] train_loss: 0.009313\n",
      "[565/00109] train_loss: 0.008774\n",
      "[565/00159] train_loss: 0.008223\n",
      "[565/00209] train_loss: 0.008424\n",
      "[565/00259] train_loss: 0.008379\n",
      "[565/00309] train_loss: 0.009587\n",
      "[565/00359] train_loss: 0.008816\n",
      "[565/00409] train_loss: 0.008488\n",
      "[565/00459] train_loss: 0.008589\n",
      "[565/00509] train_loss: 0.008766\n",
      "[565/00559] train_loss: 0.008398\n",
      "[565/00609] train_loss: 0.009271\n",
      "[565/00659] train_loss: 0.008772\n",
      "[565/00709] train_loss: 0.008278\n",
      "[565/00759] train_loss: 0.008499\n",
      "[565/00809] train_loss: 0.008886\n",
      "[565/00859] train_loss: 0.009183\n",
      "[565/00909] train_loss: 0.008781\n",
      "[565/00959] train_loss: 0.008909\n",
      "[565/01009] train_loss: 0.008845\n",
      "[565/01059] train_loss: 0.008453\n",
      "[565/01109] train_loss: 0.008341\n",
      "[565/01159] train_loss: 0.008673\n",
      "[565/01209] train_loss: 0.008952\n",
      "[566/00033] train_loss: 0.009097\n",
      "[566/00083] train_loss: 0.008281\n",
      "[566/00133] train_loss: 0.008362\n",
      "[566/00183] train_loss: 0.008642\n",
      "[566/00233] train_loss: 0.009307\n",
      "[566/00283] train_loss: 0.008525\n",
      "[566/00333] train_loss: 0.008453\n",
      "[566/00383] train_loss: 0.008503\n",
      "[566/00433] train_loss: 0.008817\n",
      "[566/00483] train_loss: 0.008927\n",
      "[566/00533] train_loss: 0.009616\n",
      "[566/00583] train_loss: 0.008899\n",
      "[566/00633] train_loss: 0.008708\n",
      "[566/00683] train_loss: 0.009111\n",
      "[566/00733] train_loss: 0.008594\n",
      "[566/00783] train_loss: 0.008762\n",
      "[566/00833] train_loss: 0.009107\n",
      "[566/00883] train_loss: 0.008507\n",
      "[566/00933] train_loss: 0.008533\n",
      "[566/00983] train_loss: 0.008695\n",
      "[566/01033] train_loss: 0.008425\n",
      "[566/01083] train_loss: 0.008294\n",
      "[566/01133] train_loss: 0.008562\n",
      "[566/01183] train_loss: 0.008226\n",
      "[567/00007] train_loss: 0.008520\n",
      "[567/00057] train_loss: 0.009134\n",
      "[567/00107] train_loss: 0.009022\n",
      "[567/00157] train_loss: 0.008927\n",
      "[567/00207] train_loss: 0.009029\n",
      "[567/00257] train_loss: 0.008595\n",
      "[567/00307] train_loss: 0.008395\n",
      "[567/00357] train_loss: 0.009097\n",
      "[567/00407] train_loss: 0.008561\n",
      "[567/00457] train_loss: 0.008443\n",
      "[567/00507] train_loss: 0.009178\n",
      "[567/00557] train_loss: 0.008468\n",
      "[567/00607] train_loss: 0.009016\n",
      "[567/00657] train_loss: 0.008845\n",
      "[567/00707] train_loss: 0.008910\n",
      "[567/00757] train_loss: 0.008380\n",
      "[567/00807] train_loss: 0.008613\n",
      "[567/00857] train_loss: 0.008832\n",
      "[567/00907] train_loss: 0.008298\n",
      "[567/00957] train_loss: 0.008747\n",
      "[567/01007] train_loss: 0.008189\n",
      "[567/01057] train_loss: 0.008528\n",
      "[567/01107] train_loss: 0.008899\n",
      "[567/01157] train_loss: 0.008616\n",
      "[567/01207] train_loss: 0.009307\n",
      "[568/00031] train_loss: 0.009125\n",
      "[568/00081] train_loss: 0.009030\n",
      "[568/00131] train_loss: 0.009075\n",
      "[568/00181] train_loss: 0.009232\n",
      "[568/00231] train_loss: 0.009148\n",
      "[568/00281] train_loss: 0.008432\n",
      "[568/00331] train_loss: 0.008602\n",
      "[568/00381] train_loss: 0.008332\n",
      "[568/00431] train_loss: 0.008651\n",
      "[568/00481] train_loss: 0.008643\n",
      "[568/00531] train_loss: 0.008472\n",
      "[568/00581] train_loss: 0.008124\n",
      "[568/00631] train_loss: 0.008751\n",
      "[568/00681] train_loss: 0.008922\n",
      "[568/00731] train_loss: 0.008074\n",
      "[568/00781] train_loss: 0.008920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[568/00831] train_loss: 0.008372\n",
      "[568/00881] train_loss: 0.008482\n",
      "[568/00931] train_loss: 0.008224\n",
      "[568/00981] train_loss: 0.008872\n",
      "[568/01031] train_loss: 0.008505\n",
      "[568/01081] train_loss: 0.009151\n",
      "[568/01131] train_loss: 0.009342\n",
      "[568/01181] train_loss: 0.008566\n",
      "[569/00005] train_loss: 0.008306\n",
      "[569/00055] train_loss: 0.009045\n",
      "[569/00105] train_loss: 0.009001\n",
      "[569/00155] train_loss: 0.008390\n",
      "[569/00205] train_loss: 0.008713\n",
      "[569/00255] train_loss: 0.008929\n",
      "[569/00305] train_loss: 0.008273\n",
      "[569/00355] train_loss: 0.008796\n",
      "[569/00405] train_loss: 0.008846\n",
      "[569/00455] train_loss: 0.007996\n",
      "[569/00505] train_loss: 0.008880\n",
      "[569/00555] train_loss: 0.008703\n",
      "[569/00605] train_loss: 0.009190\n",
      "[569/00655] train_loss: 0.008326\n",
      "[569/00705] train_loss: 0.008900\n",
      "[569/00755] train_loss: 0.008394\n",
      "[569/00805] train_loss: 0.008679\n",
      "[569/00855] train_loss: 0.009482\n",
      "[569/00905] train_loss: 0.008852\n",
      "[569/00955] train_loss: 0.008839\n",
      "[569/01005] train_loss: 0.008700\n",
      "[569/01055] train_loss: 0.008843\n",
      "[569/01105] train_loss: 0.008922\n",
      "[569/01155] train_loss: 0.008177\n",
      "[569/01205] train_loss: 0.008272\n",
      "[570/00029] train_loss: 0.009011\n",
      "[570/00079] train_loss: 0.008339\n",
      "[570/00129] train_loss: 0.008834\n",
      "[570/00179] train_loss: 0.009073\n",
      "[570/00229] train_loss: 0.007958\n",
      "[570/00279] train_loss: 0.008908\n",
      "[570/00329] train_loss: 0.008641\n",
      "[570/00379] train_loss: 0.007951\n",
      "[570/00429] train_loss: 0.009086\n",
      "[570/00479] train_loss: 0.008917\n",
      "[570/00529] train_loss: 0.008775\n",
      "[570/00579] train_loss: 0.008362\n",
      "[570/00629] train_loss: 0.009817\n",
      "[570/00679] train_loss: 0.008615\n",
      "[570/00729] train_loss: 0.008729\n",
      "[570/00779] train_loss: 0.008339\n",
      "[570/00829] train_loss: 0.008688\n",
      "[570/00879] train_loss: 0.008145\n",
      "[570/00929] train_loss: 0.008369\n",
      "[570/00979] train_loss: 0.008302\n",
      "[570/01029] train_loss: 0.009390\n",
      "[570/01079] train_loss: 0.008711\n",
      "[570/01129] train_loss: 0.008267\n",
      "[570/01179] train_loss: 0.009275\n",
      "[571/00003] train_loss: 0.008854\n",
      "[571/00053] train_loss: 0.008467\n",
      "[571/00103] train_loss: 0.008638\n",
      "[571/00153] train_loss: 0.008873\n",
      "[571/00203] train_loss: 0.009013\n",
      "[571/00253] train_loss: 0.008398\n",
      "[571/00303] train_loss: 0.008647\n",
      "[571/00353] train_loss: 0.008743\n",
      "[571/00403] train_loss: 0.008288\n",
      "[571/00453] train_loss: 0.008632\n",
      "[571/00503] train_loss: 0.008426\n",
      "[571/00553] train_loss: 0.008497\n",
      "[571/00603] train_loss: 0.009096\n",
      "[571/00653] train_loss: 0.008395\n",
      "[571/00703] train_loss: 0.008805\n",
      "[571/00753] train_loss: 0.008823\n",
      "[571/00803] train_loss: 0.008599\n",
      "[571/00853] train_loss: 0.008750\n",
      "[571/00903] train_loss: 0.008430\n",
      "[571/00953] train_loss: 0.009225\n",
      "[571/01003] train_loss: 0.008855\n",
      "[571/01053] train_loss: 0.009240\n",
      "[571/01103] train_loss: 0.009644\n",
      "[571/01153] train_loss: 0.008192\n",
      "[571/01203] train_loss: 0.008613\n",
      "[572/00027] train_loss: 0.008923\n",
      "[572/00077] train_loss: 0.009136\n",
      "[572/00127] train_loss: 0.008856\n",
      "[572/00177] train_loss: 0.008834\n",
      "[572/00227] train_loss: 0.008384\n",
      "[572/00277] train_loss: 0.008785\n",
      "[572/00327] train_loss: 0.008515\n",
      "[572/00377] train_loss: 0.008171\n",
      "[572/00427] train_loss: 0.009010\n",
      "[572/00477] train_loss: 0.008461\n",
      "[572/00527] train_loss: 0.008635\n",
      "[572/00577] train_loss: 0.008575\n",
      "[572/00627] train_loss: 0.009009\n",
      "[572/00677] train_loss: 0.008824\n",
      "[572/00727] train_loss: 0.008511\n",
      "[572/00777] train_loss: 0.008949\n",
      "[572/00827] train_loss: 0.008850\n",
      "[572/00877] train_loss: 0.008991\n",
      "[572/00927] train_loss: 0.008835\n",
      "[572/00977] train_loss: 0.008671\n",
      "[572/01027] train_loss: 0.008634\n",
      "[572/01077] train_loss: 0.008174\n",
      "[572/01127] train_loss: 0.008641\n",
      "[572/01177] train_loss: 0.008022\n",
      "[573/00001] train_loss: 0.008939\n",
      "[573/00051] train_loss: 0.009490\n",
      "[573/00101] train_loss: 0.008113\n",
      "[573/00151] train_loss: 0.009224\n",
      "[573/00201] train_loss: 0.009480\n",
      "[573/00251] train_loss: 0.008222\n",
      "[573/00301] train_loss: 0.008713\n",
      "[573/00351] train_loss: 0.008492\n",
      "[573/00401] train_loss: 0.008509\n",
      "[573/00451] train_loss: 0.008421\n",
      "[573/00501] train_loss: 0.008785\n",
      "[573/00551] train_loss: 0.008954\n",
      "[573/00601] train_loss: 0.008872\n",
      "[573/00651] train_loss: 0.008746\n",
      "[573/00701] train_loss: 0.008468\n",
      "[573/00751] train_loss: 0.008751\n",
      "[573/00801] train_loss: 0.008468\n",
      "[573/00851] train_loss: 0.008394\n",
      "[573/00901] train_loss: 0.008794\n",
      "[573/00951] train_loss: 0.009102\n",
      "[573/01001] train_loss: 0.008933\n",
      "[573/01051] train_loss: 0.008650\n",
      "[573/01101] train_loss: 0.008795\n",
      "[573/01151] train_loss: 0.008751\n",
      "[573/01201] train_loss: 0.008544\n",
      "[574/00025] train_loss: 0.008564\n",
      "[574/00075] train_loss: 0.008286\n",
      "[574/00125] train_loss: 0.009226\n",
      "[574/00175] train_loss: 0.009325\n",
      "[574/00225] train_loss: 0.009013\n",
      "[574/00275] train_loss: 0.008466\n",
      "[574/00325] train_loss: 0.008202\n",
      "[574/00375] train_loss: 0.008795\n",
      "[574/00425] train_loss: 0.008713\n",
      "[574/00475] train_loss: 0.008665\n",
      "[574/00525] train_loss: 0.008053\n",
      "[574/00575] train_loss: 0.008247\n",
      "[574/00625] train_loss: 0.008867\n",
      "[574/00675] train_loss: 0.008929\n",
      "[574/00725] train_loss: 0.008911\n",
      "[574/00775] train_loss: 0.008884\n",
      "[574/00825] train_loss: 0.008601\n",
      "[574/00875] train_loss: 0.008449\n",
      "[574/00925] train_loss: 0.008170\n",
      "[574/00975] train_loss: 0.008478\n",
      "[574/01025] train_loss: 0.008531\n",
      "[574/01075] train_loss: 0.009413\n",
      "[574/01125] train_loss: 0.008720\n",
      "[574/01175] train_loss: 0.008288\n",
      "[574/01225] train_loss: 0.008736\n",
      "[575/00049] train_loss: 0.008581\n",
      "[575/00099] train_loss: 0.009366\n",
      "[575/00149] train_loss: 0.008647\n",
      "[575/00199] train_loss: 0.009274\n",
      "[575/00249] train_loss: 0.008183\n",
      "[575/00299] train_loss: 0.008186\n",
      "[575/00349] train_loss: 0.008774\n",
      "[575/00399] train_loss: 0.008517\n",
      "[575/00449] train_loss: 0.008897\n",
      "[575/00499] train_loss: 0.008509\n",
      "[575/00549] train_loss: 0.009144\n",
      "[575/00599] train_loss: 0.008953\n",
      "[575/00649] train_loss: 0.008866\n",
      "[575/00699] train_loss: 0.008616\n",
      "[575/00749] train_loss: 0.009395\n",
      "[575/00799] train_loss: 0.008473\n",
      "[575/00849] train_loss: 0.008248\n",
      "[575/00899] train_loss: 0.008631\n",
      "[575/00949] train_loss: 0.008451\n",
      "[575/00999] train_loss: 0.009339\n",
      "[575/01049] train_loss: 0.008735\n",
      "[575/01099] train_loss: 0.008821\n",
      "[575/01149] train_loss: 0.008252\n",
      "[575/01199] train_loss: 0.008647\n",
      "[576/00023] train_loss: 0.008288\n",
      "[576/00073] train_loss: 0.008799\n",
      "[576/00123] train_loss: 0.008607\n",
      "[576/00173] train_loss: 0.008013\n",
      "[576/00223] train_loss: 0.008932\n",
      "[576/00273] train_loss: 0.008963\n",
      "[576/00323] train_loss: 0.008640\n",
      "[576/00373] train_loss: 0.009030\n",
      "[576/00423] train_loss: 0.008510\n",
      "[576/00473] train_loss: 0.009270\n",
      "[576/00523] train_loss: 0.008791\n",
      "[576/00573] train_loss: 0.008285\n",
      "[576/00623] train_loss: 0.008635\n",
      "[576/00673] train_loss: 0.008541\n",
      "[576/00723] train_loss: 0.009143\n",
      "[576/00773] train_loss: 0.008839\n",
      "[576/00823] train_loss: 0.008881\n",
      "[576/00873] train_loss: 0.008406\n",
      "[576/00923] train_loss: 0.009088\n",
      "[576/00973] train_loss: 0.008701\n",
      "[576/01023] train_loss: 0.008571\n",
      "[576/01073] train_loss: 0.008361\n",
      "[576/01123] train_loss: 0.008224\n",
      "[576/01173] train_loss: 0.008076\n",
      "[576/01223] train_loss: 0.009163\n",
      "[577/00047] train_loss: 0.008545\n",
      "[577/00097] train_loss: 0.008820\n",
      "[577/00147] train_loss: 0.009430\n",
      "[577/00197] train_loss: 0.008764\n",
      "[577/00247] train_loss: 0.008426\n",
      "[577/00297] train_loss: 0.008445\n",
      "[577/00347] train_loss: 0.008670\n",
      "[577/00397] train_loss: 0.008605\n",
      "[577/00447] train_loss: 0.008901\n",
      "[577/00497] train_loss: 0.008521\n",
      "[577/00547] train_loss: 0.008470\n",
      "[577/00597] train_loss: 0.008649\n",
      "[577/00647] train_loss: 0.008412\n",
      "[577/00697] train_loss: 0.009163\n",
      "[577/00747] train_loss: 0.008471\n",
      "[577/00797] train_loss: 0.008875\n",
      "[577/00847] train_loss: 0.008679\n",
      "[577/00897] train_loss: 0.008526\n",
      "[577/00947] train_loss: 0.008835\n",
      "[577/00997] train_loss: 0.008691\n",
      "[577/01047] train_loss: 0.008808\n",
      "[577/01097] train_loss: 0.009394\n",
      "[577/01147] train_loss: 0.008610\n",
      "[577/01197] train_loss: 0.008459\n",
      "[578/00021] train_loss: 0.008500\n",
      "[578/00071] train_loss: 0.009138\n",
      "[578/00121] train_loss: 0.008458\n",
      "[578/00171] train_loss: 0.008441\n",
      "[578/00221] train_loss: 0.008329\n",
      "[578/00271] train_loss: 0.009159\n",
      "[578/00321] train_loss: 0.008397\n",
      "[578/00371] train_loss: 0.008829\n",
      "[578/00421] train_loss: 0.008907\n",
      "[578/00471] train_loss: 0.008702\n",
      "[578/00521] train_loss: 0.008785\n",
      "[578/00571] train_loss: 0.008675\n",
      "[578/00621] train_loss: 0.008809\n",
      "[578/00671] train_loss: 0.008589\n",
      "[578/00721] train_loss: 0.008788\n",
      "[578/00771] train_loss: 0.008663\n",
      "[578/00821] train_loss: 0.008717\n",
      "[578/00871] train_loss: 0.008374\n",
      "[578/00921] train_loss: 0.008274\n",
      "[578/00971] train_loss: 0.008774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[578/01021] train_loss: 0.008512\n",
      "[578/01071] train_loss: 0.008928\n",
      "[578/01121] train_loss: 0.009090\n",
      "[578/01171] train_loss: 0.008236\n",
      "[578/01221] train_loss: 0.008397\n",
      "[579/00045] train_loss: 0.008447\n",
      "[579/00095] train_loss: 0.008514\n",
      "[579/00145] train_loss: 0.008723\n",
      "[579/00195] train_loss: 0.008572\n",
      "[579/00245] train_loss: 0.008833\n",
      "[579/00295] train_loss: 0.008629\n",
      "[579/00345] train_loss: 0.008550\n",
      "[579/00395] train_loss: 0.009322\n",
      "[579/00445] train_loss: 0.008346\n",
      "[579/00495] train_loss: 0.008707\n",
      "[579/00545] train_loss: 0.008401\n",
      "[579/00595] train_loss: 0.009316\n",
      "[579/00645] train_loss: 0.008371\n",
      "[579/00695] train_loss: 0.008533\n",
      "[579/00745] train_loss: 0.008020\n",
      "[579/00795] train_loss: 0.008911\n",
      "[579/00845] train_loss: 0.009168\n",
      "[579/00895] train_loss: 0.009075\n",
      "[579/00945] train_loss: 0.008873\n",
      "[579/00995] train_loss: 0.008912\n",
      "[579/01045] train_loss: 0.008632\n",
      "[579/01095] train_loss: 0.009057\n",
      "[579/01145] train_loss: 0.008854\n",
      "[579/01195] train_loss: 0.008447\n",
      "[580/00019] train_loss: 0.008162\n",
      "[580/00069] train_loss: 0.009158\n",
      "[580/00119] train_loss: 0.008218\n",
      "[580/00169] train_loss: 0.008653\n",
      "[580/00219] train_loss: 0.008669\n",
      "[580/00269] train_loss: 0.008589\n",
      "[580/00319] train_loss: 0.008693\n",
      "[580/00369] train_loss: 0.008686\n",
      "[580/00419] train_loss: 0.008778\n",
      "[580/00469] train_loss: 0.008486\n",
      "[580/00519] train_loss: 0.008866\n",
      "[580/00569] train_loss: 0.008210\n",
      "[580/00619] train_loss: 0.008739\n",
      "[580/00669] train_loss: 0.008835\n",
      "[580/00719] train_loss: 0.008896\n",
      "[580/00769] train_loss: 0.008699\n",
      "[580/00819] train_loss: 0.008508\n",
      "[580/00869] train_loss: 0.008509\n",
      "[580/00919] train_loss: 0.008938\n",
      "[580/00969] train_loss: 0.008594\n",
      "[580/01019] train_loss: 0.008577\n",
      "[580/01069] train_loss: 0.008871\n",
      "[580/01119] train_loss: 0.008838\n",
      "[580/01169] train_loss: 0.008425\n",
      "[580/01219] train_loss: 0.008808\n",
      "[581/00043] train_loss: 0.009095\n",
      "[581/00093] train_loss: 0.008555\n",
      "[581/00143] train_loss: 0.008530\n",
      "[581/00193] train_loss: 0.008575\n",
      "[581/00243] train_loss: 0.008793\n",
      "[581/00293] train_loss: 0.008541\n",
      "[581/00343] train_loss: 0.009275\n",
      "[581/00393] train_loss: 0.008648\n",
      "[581/00443] train_loss: 0.008379\n",
      "[581/00493] train_loss: 0.008765\n",
      "[581/00543] train_loss: 0.008303\n",
      "[581/00593] train_loss: 0.008729\n",
      "[581/00643] train_loss: 0.008774\n",
      "[581/00693] train_loss: 0.008658\n",
      "[581/00743] train_loss: 0.008808\n",
      "[581/00793] train_loss: 0.008981\n",
      "[581/00843] train_loss: 0.009149\n",
      "[581/00893] train_loss: 0.008508\n",
      "[581/00943] train_loss: 0.008571\n",
      "[581/00993] train_loss: 0.008284\n",
      "[581/01043] train_loss: 0.008451\n",
      "[581/01093] train_loss: 0.008660\n",
      "[581/01143] train_loss: 0.009197\n",
      "[581/01193] train_loss: 0.008839\n",
      "[582/00017] train_loss: 0.008349\n",
      "[582/00067] train_loss: 0.008471\n",
      "[582/00117] train_loss: 0.008036\n",
      "[582/00167] train_loss: 0.008563\n",
      "[582/00217] train_loss: 0.008537\n",
      "[582/00267] train_loss: 0.008603\n",
      "[582/00317] train_loss: 0.007991\n",
      "[582/00367] train_loss: 0.008947\n",
      "[582/00417] train_loss: 0.008687\n",
      "[582/00467] train_loss: 0.009253\n",
      "[582/00517] train_loss: 0.008383\n",
      "[582/00567] train_loss: 0.008348\n",
      "[582/00617] train_loss: 0.009157\n",
      "[582/00667] train_loss: 0.009034\n",
      "[582/00717] train_loss: 0.008417\n",
      "[582/00767] train_loss: 0.008996\n",
      "[582/00817] train_loss: 0.008675\n",
      "[582/00867] train_loss: 0.008444\n",
      "[582/00917] train_loss: 0.008934\n",
      "[582/00967] train_loss: 0.009057\n",
      "[582/01017] train_loss: 0.009285\n",
      "[582/01067] train_loss: 0.008912\n",
      "[582/01117] train_loss: 0.008435\n",
      "[582/01167] train_loss: 0.008204\n",
      "[582/01217] train_loss: 0.008921\n",
      "[583/00041] train_loss: 0.008302\n",
      "[583/00091] train_loss: 0.008895\n",
      "[583/00141] train_loss: 0.008202\n",
      "[583/00191] train_loss: 0.008498\n",
      "[583/00241] train_loss: 0.008344\n",
      "[583/00291] train_loss: 0.009141\n",
      "[583/00341] train_loss: 0.008453\n",
      "[583/00391] train_loss: 0.008658\n",
      "[583/00441] train_loss: 0.008471\n",
      "[583/00491] train_loss: 0.008060\n",
      "[583/00541] train_loss: 0.008801\n",
      "[583/00591] train_loss: 0.008364\n",
      "[583/00641] train_loss: 0.008618\n",
      "[583/00691] train_loss: 0.008836\n",
      "[583/00741] train_loss: 0.009085\n",
      "[583/00791] train_loss: 0.008876\n",
      "[583/00841] train_loss: 0.009329\n",
      "[583/00891] train_loss: 0.008914\n",
      "[583/00941] train_loss: 0.008755\n",
      "[583/00991] train_loss: 0.008179\n",
      "[583/01041] train_loss: 0.008677\n",
      "[583/01091] train_loss: 0.008828\n",
      "[583/01141] train_loss: 0.008923\n",
      "[583/01191] train_loss: 0.009136\n",
      "[584/00015] train_loss: 0.008666\n",
      "[584/00065] train_loss: 0.008813\n",
      "[584/00115] train_loss: 0.009336\n",
      "[584/00165] train_loss: 0.009016\n",
      "[584/00215] train_loss: 0.008980\n",
      "[584/00265] train_loss: 0.008873\n",
      "[584/00315] train_loss: 0.008585\n",
      "[584/00365] train_loss: 0.008733\n",
      "[584/00415] train_loss: 0.008873\n",
      "[584/00465] train_loss: 0.008591\n",
      "[584/00515] train_loss: 0.008303\n",
      "[584/00565] train_loss: 0.008307\n",
      "[584/00615] train_loss: 0.008388\n",
      "[584/00665] train_loss: 0.009026\n",
      "[584/00715] train_loss: 0.008392\n",
      "[584/00765] train_loss: 0.008683\n",
      "[584/00815] train_loss: 0.008554\n",
      "[584/00865] train_loss: 0.008699\n",
      "[584/00915] train_loss: 0.008662\n",
      "[584/00965] train_loss: 0.008719\n",
      "[584/01015] train_loss: 0.008353\n",
      "[584/01065] train_loss: 0.008841\n",
      "[584/01115] train_loss: 0.008555\n",
      "[584/01165] train_loss: 0.008341\n",
      "[584/01215] train_loss: 0.008563\n",
      "[585/00039] train_loss: 0.008540\n",
      "[585/00089] train_loss: 0.008687\n",
      "[585/00139] train_loss: 0.009036\n",
      "[585/00189] train_loss: 0.008354\n",
      "[585/00239] train_loss: 0.008434\n",
      "[585/00289] train_loss: 0.009078\n",
      "[585/00339] train_loss: 0.008538\n",
      "[585/00389] train_loss: 0.008656\n",
      "[585/00439] train_loss: 0.008963\n",
      "[585/00489] train_loss: 0.008708\n",
      "[585/00539] train_loss: 0.008213\n",
      "[585/00589] train_loss: 0.008496\n",
      "[585/00639] train_loss: 0.008541\n",
      "[585/00689] train_loss: 0.008400\n",
      "[585/00739] train_loss: 0.009049\n",
      "[585/00789] train_loss: 0.008791\n",
      "[585/00839] train_loss: 0.008522\n",
      "[585/00889] train_loss: 0.008772\n",
      "[585/00939] train_loss: 0.009100\n",
      "[585/00989] train_loss: 0.009422\n",
      "[585/01039] train_loss: 0.008596\n",
      "[585/01089] train_loss: 0.008886\n",
      "[585/01139] train_loss: 0.009205\n",
      "[585/01189] train_loss: 0.008230\n",
      "[586/00013] train_loss: 0.008960\n",
      "[586/00063] train_loss: 0.008952\n",
      "[586/00113] train_loss: 0.008765\n",
      "[586/00163] train_loss: 0.008657\n",
      "[586/00213] train_loss: 0.008849\n",
      "[586/00263] train_loss: 0.008605\n",
      "[586/00313] train_loss: 0.008869\n",
      "[586/00363] train_loss: 0.008109\n",
      "[586/00413] train_loss: 0.008539\n",
      "[586/00463] train_loss: 0.008004\n",
      "[586/00513] train_loss: 0.008190\n",
      "[586/00563] train_loss: 0.008747\n",
      "[586/00613] train_loss: 0.008497\n",
      "[586/00663] train_loss: 0.008840\n",
      "[586/00713] train_loss: 0.008624\n",
      "[586/00763] train_loss: 0.008534\n",
      "[586/00813] train_loss: 0.008283\n",
      "[586/00863] train_loss: 0.008688\n",
      "[586/00913] train_loss: 0.008522\n",
      "[586/00963] train_loss: 0.008853\n",
      "[586/01013] train_loss: 0.008707\n",
      "[586/01063] train_loss: 0.008546\n",
      "[586/01113] train_loss: 0.008525\n",
      "[586/01163] train_loss: 0.008831\n",
      "[586/01213] train_loss: 0.008892\n",
      "[587/00037] train_loss: 0.009580\n",
      "[587/00087] train_loss: 0.008756\n",
      "[587/00137] train_loss: 0.008782\n",
      "[587/00187] train_loss: 0.008471\n",
      "[587/00237] train_loss: 0.009032\n",
      "[587/00287] train_loss: 0.008530\n",
      "[587/00337] train_loss: 0.008680\n",
      "[587/00387] train_loss: 0.008623\n",
      "[587/00437] train_loss: 0.008321\n",
      "[587/00487] train_loss: 0.008557\n",
      "[587/00537] train_loss: 0.008095\n",
      "[587/00587] train_loss: 0.008718\n",
      "[587/00637] train_loss: 0.008999\n",
      "[587/00687] train_loss: 0.009134\n",
      "[587/00737] train_loss: 0.008946\n",
      "[587/00787] train_loss: 0.008938\n",
      "[587/00837] train_loss: 0.008594\n",
      "[587/00887] train_loss: 0.008210\n",
      "[587/00937] train_loss: 0.008144\n",
      "[587/00987] train_loss: 0.008194\n",
      "[587/01037] train_loss: 0.008617\n",
      "[587/01087] train_loss: 0.008789\n",
      "[587/01137] train_loss: 0.008372\n",
      "[587/01187] train_loss: 0.008522\n",
      "[588/00011] train_loss: 0.009683\n",
      "[588/00061] train_loss: 0.008907\n",
      "[588/00111] train_loss: 0.008721\n",
      "[588/00161] train_loss: 0.007918\n",
      "[588/00211] train_loss: 0.008814\n",
      "[588/00261] train_loss: 0.009263\n",
      "[588/00311] train_loss: 0.008713\n",
      "[588/00361] train_loss: 0.008390\n",
      "[588/00411] train_loss: 0.008631\n",
      "[588/00461] train_loss: 0.009066\n",
      "[588/00511] train_loss: 0.008725\n",
      "[588/00561] train_loss: 0.008287\n",
      "[588/00611] train_loss: 0.008325\n",
      "[588/00661] train_loss: 0.008803\n",
      "[588/00711] train_loss: 0.008634\n",
      "[588/00761] train_loss: 0.008637\n",
      "[588/00811] train_loss: 0.008308\n",
      "[588/00861] train_loss: 0.008541\n",
      "[588/00911] train_loss: 0.009292\n",
      "[588/00961] train_loss: 0.008561\n",
      "[588/01011] train_loss: 0.008413\n",
      "[588/01061] train_loss: 0.008712\n",
      "[588/01111] train_loss: 0.008133\n",
      "[588/01161] train_loss: 0.008864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[588/01211] train_loss: 0.008289\n",
      "[589/00035] train_loss: 0.008148\n",
      "[589/00085] train_loss: 0.008638\n",
      "[589/00135] train_loss: 0.009395\n",
      "[589/00185] train_loss: 0.009002\n",
      "[589/00235] train_loss: 0.009086\n",
      "[589/00285] train_loss: 0.008674\n",
      "[589/00335] train_loss: 0.008765\n",
      "[589/00385] train_loss: 0.008590\n",
      "[589/00435] train_loss: 0.008641\n",
      "[589/00485] train_loss: 0.008203\n",
      "[589/00535] train_loss: 0.009179\n",
      "[589/00585] train_loss: 0.008163\n",
      "[589/00635] train_loss: 0.008758\n",
      "[589/00685] train_loss: 0.008532\n",
      "[589/00735] train_loss: 0.008829\n",
      "[589/00785] train_loss: 0.009136\n",
      "[589/00835] train_loss: 0.008218\n",
      "[589/00885] train_loss: 0.009149\n",
      "[589/00935] train_loss: 0.008477\n",
      "[589/00985] train_loss: 0.008459\n",
      "[589/01035] train_loss: 0.008821\n",
      "[589/01085] train_loss: 0.008926\n",
      "[589/01135] train_loss: 0.008688\n",
      "[589/01185] train_loss: 0.008365\n",
      "[590/00009] train_loss: 0.008050\n",
      "[590/00059] train_loss: 0.009142\n",
      "[590/00109] train_loss: 0.008321\n",
      "[590/00159] train_loss: 0.008939\n",
      "[590/00209] train_loss: 0.008690\n",
      "[590/00259] train_loss: 0.008645\n",
      "[590/00309] train_loss: 0.008799\n",
      "[590/00359] train_loss: 0.008239\n",
      "[590/00409] train_loss: 0.008377\n",
      "[590/00459] train_loss: 0.008452\n",
      "[590/00509] train_loss: 0.008500\n",
      "[590/00559] train_loss: 0.008680\n",
      "[590/00609] train_loss: 0.008942\n",
      "[590/00659] train_loss: 0.008745\n",
      "[590/00709] train_loss: 0.008263\n",
      "[590/00759] train_loss: 0.008350\n",
      "[590/00809] train_loss: 0.008470\n",
      "[590/00859] train_loss: 0.007928\n",
      "[590/00909] train_loss: 0.009191\n",
      "[590/00959] train_loss: 0.008723\n",
      "[590/01009] train_loss: 0.008788\n",
      "[590/01059] train_loss: 0.008679\n",
      "[590/01109] train_loss: 0.008608\n",
      "[590/01159] train_loss: 0.008829\n",
      "[590/01209] train_loss: 0.008851\n",
      "[591/00033] train_loss: 0.008996\n",
      "[591/00083] train_loss: 0.009019\n",
      "[591/00133] train_loss: 0.008559\n",
      "[591/00183] train_loss: 0.008624\n",
      "[591/00233] train_loss: 0.008747\n",
      "[591/00283] train_loss: 0.008824\n",
      "[591/00333] train_loss: 0.008330\n",
      "[591/00383] train_loss: 0.009195\n",
      "[591/00433] train_loss: 0.008956\n",
      "[591/00483] train_loss: 0.008704\n",
      "[591/00533] train_loss: 0.008115\n",
      "[591/00583] train_loss: 0.008396\n",
      "[591/00633] train_loss: 0.008831\n",
      "[591/00683] train_loss: 0.008792\n",
      "[591/00733] train_loss: 0.008712\n",
      "[591/00783] train_loss: 0.008628\n",
      "[591/00833] train_loss: 0.008359\n",
      "[591/00883] train_loss: 0.009063\n",
      "[591/00933] train_loss: 0.008653\n",
      "[591/00983] train_loss: 0.008175\n",
      "[591/01033] train_loss: 0.008212\n",
      "[591/01083] train_loss: 0.009082\n",
      "[591/01133] train_loss: 0.009064\n",
      "[591/01183] train_loss: 0.008642\n",
      "[592/00007] train_loss: 0.008361\n",
      "[592/00057] train_loss: 0.007801\n",
      "[592/00107] train_loss: 0.009013\n",
      "[592/00157] train_loss: 0.008633\n",
      "[592/00207] train_loss: 0.008697\n",
      "[592/00257] train_loss: 0.008896\n",
      "[592/00307] train_loss: 0.009394\n",
      "[592/00357] train_loss: 0.008798\n",
      "[592/00407] train_loss: 0.008689\n",
      "[592/00457] train_loss: 0.009392\n",
      "[592/00507] train_loss: 0.008319\n",
      "[592/00557] train_loss: 0.008683\n",
      "[592/00607] train_loss: 0.008721\n",
      "[592/00657] train_loss: 0.008583\n",
      "[592/00707] train_loss: 0.008895\n",
      "[592/00757] train_loss: 0.008951\n",
      "[592/00807] train_loss: 0.007688\n",
      "[592/00857] train_loss: 0.008112\n",
      "[592/00907] train_loss: 0.009209\n",
      "[592/00957] train_loss: 0.008656\n",
      "[592/01007] train_loss: 0.008452\n",
      "[592/01057] train_loss: 0.008426\n",
      "[592/01107] train_loss: 0.008210\n",
      "[592/01157] train_loss: 0.008856\n",
      "[592/01207] train_loss: 0.008392\n",
      "[593/00031] train_loss: 0.008928\n",
      "[593/00081] train_loss: 0.009202\n",
      "[593/00131] train_loss: 0.008981\n",
      "[593/00181] train_loss: 0.008773\n",
      "[593/00231] train_loss: 0.009097\n",
      "[593/00281] train_loss: 0.008533\n",
      "[593/00331] train_loss: 0.009208\n",
      "[593/00381] train_loss: 0.007863\n",
      "[593/00431] train_loss: 0.009060\n",
      "[593/00481] train_loss: 0.008546\n",
      "[593/00531] train_loss: 0.008178\n",
      "[593/00581] train_loss: 0.008622\n",
      "[593/00631] train_loss: 0.009035\n",
      "[593/00681] train_loss: 0.008743\n",
      "[593/00731] train_loss: 0.008379\n",
      "[593/00781] train_loss: 0.008313\n",
      "[593/00831] train_loss: 0.008950\n",
      "[593/00881] train_loss: 0.009058\n",
      "[593/00931] train_loss: 0.008691\n",
      "[593/00981] train_loss: 0.008236\n",
      "[593/01031] train_loss: 0.008128\n",
      "[593/01081] train_loss: 0.008997\n",
      "[593/01131] train_loss: 0.008103\n",
      "[593/01181] train_loss: 0.008449\n",
      "[594/00005] train_loss: 0.008735\n",
      "[594/00055] train_loss: 0.008718\n",
      "[594/00105] train_loss: 0.008712\n",
      "[594/00155] train_loss: 0.008434\n",
      "[594/00205] train_loss: 0.008855\n",
      "[594/00255] train_loss: 0.008321\n",
      "[594/00305] train_loss: 0.008965\n",
      "[594/00355] train_loss: 0.008519\n",
      "[594/00405] train_loss: 0.008852\n",
      "[594/00455] train_loss: 0.008130\n",
      "[594/00505] train_loss: 0.008542\n",
      "[594/00555] train_loss: 0.008507\n",
      "[594/00605] train_loss: 0.008205\n",
      "[594/00655] train_loss: 0.008405\n",
      "[594/00705] train_loss: 0.008425\n",
      "[594/00755] train_loss: 0.008168\n",
      "[594/00805] train_loss: 0.008953\n",
      "[594/00855] train_loss: 0.009146\n",
      "[594/00905] train_loss: 0.007943\n",
      "[594/00955] train_loss: 0.008542\n",
      "[594/01005] train_loss: 0.009024\n",
      "[594/01055] train_loss: 0.008955\n",
      "[594/01105] train_loss: 0.008845\n",
      "[594/01155] train_loss: 0.008379\n",
      "[594/01205] train_loss: 0.009169\n",
      "[595/00029] train_loss: 0.008726\n",
      "[595/00079] train_loss: 0.008918\n",
      "[595/00129] train_loss: 0.008467\n",
      "[595/00179] train_loss: 0.008910\n",
      "[595/00229] train_loss: 0.009097\n",
      "[595/00279] train_loss: 0.008939\n",
      "[595/00329] train_loss: 0.008971\n",
      "[595/00379] train_loss: 0.008623\n",
      "[595/00429] train_loss: 0.009065\n",
      "[595/00479] train_loss: 0.008342\n",
      "[595/00529] train_loss: 0.008459\n",
      "[595/00579] train_loss: 0.007998\n",
      "[595/00629] train_loss: 0.008760\n",
      "[595/00679] train_loss: 0.008772\n",
      "[595/00729] train_loss: 0.008620\n",
      "[595/00779] train_loss: 0.008078\n",
      "[595/00829] train_loss: 0.008722\n",
      "[595/00879] train_loss: 0.009066\n",
      "[595/00929] train_loss: 0.008871\n",
      "[595/00979] train_loss: 0.008527\n",
      "[595/01029] train_loss: 0.008585\n",
      "[595/01079] train_loss: 0.008527\n",
      "[595/01129] train_loss: 0.008504\n",
      "[595/01179] train_loss: 0.009154\n",
      "[596/00003] train_loss: 0.008801\n",
      "[596/00053] train_loss: 0.008185\n",
      "[596/00103] train_loss: 0.008541\n",
      "[596/00153] train_loss: 0.008813\n",
      "[596/00203] train_loss: 0.008312\n",
      "[596/00253] train_loss: 0.008916\n",
      "[596/00303] train_loss: 0.009088\n",
      "[596/00353] train_loss: 0.008717\n",
      "[596/00403] train_loss: 0.008456\n",
      "[596/00453] train_loss: 0.008609\n",
      "[596/00503] train_loss: 0.008411\n",
      "[596/00553] train_loss: 0.008530\n",
      "[596/00603] train_loss: 0.008714\n",
      "[596/00653] train_loss: 0.008528\n",
      "[596/00703] train_loss: 0.008357\n",
      "[596/00753] train_loss: 0.008531\n",
      "[596/00803] train_loss: 0.008957\n",
      "[596/00853] train_loss: 0.008336\n",
      "[596/00903] train_loss: 0.008434\n",
      "[596/00953] train_loss: 0.009165\n",
      "[596/01003] train_loss: 0.008122\n",
      "[596/01053] train_loss: 0.008515\n",
      "[596/01103] train_loss: 0.008781\n",
      "[596/01153] train_loss: 0.008496\n",
      "[596/01203] train_loss: 0.008722\n",
      "[597/00027] train_loss: 0.009276\n",
      "[597/00077] train_loss: 0.008521\n",
      "[597/00127] train_loss: 0.009194\n",
      "[597/00177] train_loss: 0.008585\n",
      "[597/00227] train_loss: 0.008874\n",
      "[597/00277] train_loss: 0.008402\n",
      "[597/00327] train_loss: 0.008479\n",
      "[597/00377] train_loss: 0.008556\n",
      "[597/00427] train_loss: 0.008397\n",
      "[597/00477] train_loss: 0.008601\n",
      "[597/00527] train_loss: 0.008363\n",
      "[597/00577] train_loss: 0.008841\n",
      "[597/00627] train_loss: 0.009240\n",
      "[597/00677] train_loss: 0.008557\n",
      "[597/00727] train_loss: 0.008495\n",
      "[597/00777] train_loss: 0.008666\n",
      "[597/00827] train_loss: 0.009152\n",
      "[597/00877] train_loss: 0.008682\n",
      "[597/00927] train_loss: 0.008673\n",
      "[597/00977] train_loss: 0.008347\n",
      "[597/01027] train_loss: 0.008633\n",
      "[597/01077] train_loss: 0.008481\n",
      "[597/01127] train_loss: 0.009168\n",
      "[597/01177] train_loss: 0.008596\n",
      "[598/00001] train_loss: 0.008618\n",
      "[598/00051] train_loss: 0.009336\n",
      "[598/00101] train_loss: 0.008662\n",
      "[598/00151] train_loss: 0.008415\n",
      "[598/00201] train_loss: 0.008240\n",
      "[598/00251] train_loss: 0.008757\n",
      "[598/00301] train_loss: 0.008847\n",
      "[598/00351] train_loss: 0.008267\n",
      "[598/00401] train_loss: 0.008336\n",
      "[598/00451] train_loss: 0.008935\n",
      "[598/00501] train_loss: 0.008618\n",
      "[598/00551] train_loss: 0.008960\n",
      "[598/00601] train_loss: 0.008233\n",
      "[598/00651] train_loss: 0.008164\n",
      "[598/00701] train_loss: 0.008241\n",
      "[598/00751] train_loss: 0.008288\n",
      "[598/00801] train_loss: 0.008523\n",
      "[598/00851] train_loss: 0.008945\n",
      "[598/00901] train_loss: 0.008901\n",
      "[598/00951] train_loss: 0.008291\n",
      "[598/01001] train_loss: 0.008461\n",
      "[598/01051] train_loss: 0.008962\n",
      "[598/01101] train_loss: 0.008794\n",
      "[598/01151] train_loss: 0.009055\n",
      "[598/01201] train_loss: 0.008861\n",
      "[599/00025] train_loss: 0.008795\n",
      "[599/00075] train_loss: 0.008906\n",
      "[599/00125] train_loss: 0.008781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[599/00175] train_loss: 0.008861\n",
      "[599/00225] train_loss: 0.008323\n",
      "[599/00275] train_loss: 0.008227\n",
      "[599/00325] train_loss: 0.008997\n",
      "[599/00375] train_loss: 0.008705\n",
      "[599/00425] train_loss: 0.008689\n",
      "[599/00475] train_loss: 0.008288\n",
      "[599/00525] train_loss: 0.009460\n",
      "[599/00575] train_loss: 0.008981\n",
      "[599/00625] train_loss: 0.008755\n",
      "[599/00675] train_loss: 0.009027\n",
      "[599/00725] train_loss: 0.008802\n",
      "[599/00775] train_loss: 0.008225\n",
      "[599/00825] train_loss: 0.008669\n",
      "[599/00875] train_loss: 0.008529\n",
      "[599/00925] train_loss: 0.008403\n",
      "[599/00975] train_loss: 0.008655\n",
      "[599/01025] train_loss: 0.008320\n",
      "[599/01075] train_loss: 0.008602\n",
      "[599/01125] train_loss: 0.008599\n",
      "[599/01175] train_loss: 0.008770\n",
      "[599/01225] train_loss: 0.008577\n",
      "[600/00049] train_loss: 0.008930\n",
      "[600/00099] train_loss: 0.008912\n",
      "[600/00149] train_loss: 0.008326\n",
      "[600/00199] train_loss: 0.008999\n",
      "[600/00249] train_loss: 0.008671\n",
      "[600/00299] train_loss: 0.008800\n",
      "[600/00349] train_loss: 0.008538\n",
      "[600/00399] train_loss: 0.008933\n",
      "[600/00449] train_loss: 0.007810\n",
      "[600/00499] train_loss: 0.008978\n",
      "[600/00549] train_loss: 0.008678\n",
      "[600/00599] train_loss: 0.009052\n",
      "[600/00649] train_loss: 0.008613\n",
      "[600/00699] train_loss: 0.008479\n",
      "[600/00749] train_loss: 0.008431\n",
      "[600/00799] train_loss: 0.008930\n",
      "[600/00849] train_loss: 0.008354\n",
      "[600/00899] train_loss: 0.008305\n",
      "[600/00949] train_loss: 0.008234\n",
      "[600/00999] train_loss: 0.008260\n",
      "[600/01049] train_loss: 0.008795\n",
      "[600/01099] train_loss: 0.008557\n",
      "[600/01149] train_loss: 0.008515\n",
      "[600/01199] train_loss: 0.008623\n",
      "[601/00023] train_loss: 0.008200\n",
      "[601/00073] train_loss: 0.009535\n",
      "[601/00123] train_loss: 0.008523\n",
      "[601/00173] train_loss: 0.008715\n",
      "[601/00223] train_loss: 0.008446\n",
      "[601/00273] train_loss: 0.008989\n",
      "[601/00323] train_loss: 0.008304\n",
      "[601/00373] train_loss: 0.008637\n",
      "[601/00423] train_loss: 0.008636\n",
      "[601/00473] train_loss: 0.008469\n",
      "[601/00523] train_loss: 0.008456\n",
      "[601/00573] train_loss: 0.008076\n",
      "[601/00623] train_loss: 0.008533\n",
      "[601/00673] train_loss: 0.008509\n",
      "[601/00723] train_loss: 0.008763\n",
      "[601/00773] train_loss: 0.009129\n",
      "[601/00823] train_loss: 0.008422\n",
      "[601/00873] train_loss: 0.009168\n",
      "[601/00923] train_loss: 0.008655\n",
      "[601/00973] train_loss: 0.008584\n",
      "[601/01023] train_loss: 0.008732\n",
      "[601/01073] train_loss: 0.008655\n",
      "[601/01123] train_loss: 0.008263\n",
      "[601/01173] train_loss: 0.009251\n",
      "[601/01223] train_loss: 0.008354\n",
      "[602/00047] train_loss: 0.008321\n",
      "[602/00097] train_loss: 0.008942\n",
      "[602/00147] train_loss: 0.008373\n",
      "[602/00197] train_loss: 0.008556\n",
      "[602/00247] train_loss: 0.008424\n",
      "[602/00297] train_loss: 0.008561\n",
      "[602/00347] train_loss: 0.008628\n",
      "[602/00397] train_loss: 0.008910\n",
      "[602/00447] train_loss: 0.008678\n",
      "[602/00497] train_loss: 0.008288\n",
      "[602/00547] train_loss: 0.008226\n",
      "[602/00597] train_loss: 0.008647\n",
      "[602/00647] train_loss: 0.008786\n",
      "[602/00697] train_loss: 0.008367\n",
      "[602/00747] train_loss: 0.008590\n",
      "[602/00797] train_loss: 0.009201\n",
      "[602/00847] train_loss: 0.008598\n",
      "[602/00897] train_loss: 0.008885\n",
      "[602/00947] train_loss: 0.008630\n",
      "[602/00997] train_loss: 0.009159\n",
      "[602/01047] train_loss: 0.008928\n",
      "[602/01097] train_loss: 0.008883\n",
      "[602/01147] train_loss: 0.008129\n",
      "[602/01197] train_loss: 0.008237\n",
      "[603/00021] train_loss: 0.008469\n",
      "[603/00071] train_loss: 0.009103\n",
      "[603/00121] train_loss: 0.008821\n",
      "[603/00171] train_loss: 0.008903\n",
      "[603/00221] train_loss: 0.008589\n",
      "[603/00271] train_loss: 0.009034\n",
      "[603/00321] train_loss: 0.008357\n",
      "[603/00371] train_loss: 0.008490\n",
      "[603/00421] train_loss: 0.008200\n",
      "[603/00471] train_loss: 0.008581\n",
      "[603/00521] train_loss: 0.008826\n",
      "[603/00571] train_loss: 0.009129\n",
      "[603/00621] train_loss: 0.009101\n",
      "[603/00671] train_loss: 0.008607\n",
      "[603/00721] train_loss: 0.008469\n",
      "[603/00771] train_loss: 0.008421\n",
      "[603/00821] train_loss: 0.008556\n",
      "[603/00871] train_loss: 0.008845\n",
      "[603/00921] train_loss: 0.009047\n",
      "[603/00971] train_loss: 0.009025\n",
      "[603/01021] train_loss: 0.008023\n",
      "[603/01071] train_loss: 0.008333\n",
      "[603/01121] train_loss: 0.008088\n",
      "[603/01171] train_loss: 0.008096\n",
      "[603/01221] train_loss: 0.009141\n",
      "[604/00045] train_loss: 0.008108\n",
      "[604/00095] train_loss: 0.008548\n",
      "[604/00145] train_loss: 0.008283\n",
      "[604/00195] train_loss: 0.008021\n",
      "[604/00245] train_loss: 0.008704\n",
      "[604/00295] train_loss: 0.008564\n",
      "[604/00345] train_loss: 0.008514\n",
      "[604/00395] train_loss: 0.008257\n",
      "[604/00445] train_loss: 0.009051\n",
      "[604/00495] train_loss: 0.009313\n",
      "[604/00545] train_loss: 0.008834\n",
      "[604/00595] train_loss: 0.008385\n",
      "[604/00645] train_loss: 0.008408\n",
      "[604/00695] train_loss: 0.008873\n",
      "[604/00745] train_loss: 0.009749\n",
      "[604/00795] train_loss: 0.008611\n",
      "[604/00845] train_loss: 0.008483\n",
      "[604/00895] train_loss: 0.008479\n",
      "[604/00945] train_loss: 0.008556\n",
      "[604/00995] train_loss: 0.008708\n",
      "[604/01045] train_loss: 0.008836\n",
      "[604/01095] train_loss: 0.008816\n",
      "[604/01145] train_loss: 0.008400\n",
      "[604/01195] train_loss: 0.008295\n",
      "[605/00019] train_loss: 0.008567\n",
      "[605/00069] train_loss: 0.008694\n",
      "[605/00119] train_loss: 0.008663\n",
      "[605/00169] train_loss: 0.008760\n",
      "[605/00219] train_loss: 0.008565\n",
      "[605/00269] train_loss: 0.008569\n",
      "[605/00319] train_loss: 0.009608\n",
      "[605/00369] train_loss: 0.008448\n",
      "[605/00419] train_loss: 0.008291\n",
      "[605/00469] train_loss: 0.008684\n",
      "[605/00519] train_loss: 0.008229\n",
      "[605/00569] train_loss: 0.008585\n",
      "[605/00619] train_loss: 0.009352\n",
      "[605/00669] train_loss: 0.008887\n",
      "[605/00719] train_loss: 0.008809\n",
      "[605/00769] train_loss: 0.008864\n",
      "[605/00819] train_loss: 0.008673\n",
      "[605/00869] train_loss: 0.008326\n",
      "[605/00919] train_loss: 0.008779\n",
      "[605/00969] train_loss: 0.008159\n",
      "[605/01019] train_loss: 0.008169\n",
      "[605/01069] train_loss: 0.008435\n",
      "[605/01119] train_loss: 0.008723\n",
      "[605/01169] train_loss: 0.008544\n",
      "[605/01219] train_loss: 0.009109\n",
      "[606/00043] train_loss: 0.008619\n",
      "[606/00093] train_loss: 0.008313\n",
      "[606/00143] train_loss: 0.008467\n",
      "[606/00193] train_loss: 0.009054\n",
      "[606/00243] train_loss: 0.008470\n",
      "[606/00293] train_loss: 0.009150\n",
      "[606/00343] train_loss: 0.008384\n",
      "[606/00393] train_loss: 0.008622\n",
      "[606/00443] train_loss: 0.008691\n",
      "[606/00493] train_loss: 0.008758\n",
      "[606/00543] train_loss: 0.008352\n",
      "[606/00593] train_loss: 0.008215\n",
      "[606/00643] train_loss: 0.008350\n",
      "[606/00693] train_loss: 0.008279\n",
      "[606/00743] train_loss: 0.009149\n",
      "[606/00793] train_loss: 0.008574\n",
      "[606/00843] train_loss: 0.007888\n",
      "[606/00893] train_loss: 0.008876\n",
      "[606/00943] train_loss: 0.008755\n",
      "[606/00993] train_loss: 0.008248\n",
      "[606/01043] train_loss: 0.008453\n",
      "[606/01093] train_loss: 0.009261\n",
      "[606/01143] train_loss: 0.008512\n",
      "[606/01193] train_loss: 0.008653\n",
      "[607/00017] train_loss: 0.008680\n",
      "[607/00067] train_loss: 0.009090\n",
      "[607/00117] train_loss: 0.008746\n",
      "[607/00167] train_loss: 0.008342\n",
      "[607/00217] train_loss: 0.009153\n",
      "[607/00267] train_loss: 0.008391\n",
      "[607/00317] train_loss: 0.008954\n",
      "[607/00367] train_loss: 0.008319\n",
      "[607/00417] train_loss: 0.008715\n",
      "[607/00467] train_loss: 0.008291\n",
      "[607/00517] train_loss: 0.008403\n",
      "[607/00567] train_loss: 0.008134\n",
      "[607/00617] train_loss: 0.008564\n",
      "[607/00667] train_loss: 0.008681\n",
      "[607/00717] train_loss: 0.009201\n",
      "[607/00767] train_loss: 0.008637\n",
      "[607/00817] train_loss: 0.008756\n",
      "[607/00867] train_loss: 0.008346\n",
      "[607/00917] train_loss: 0.009143\n",
      "[607/00967] train_loss: 0.008517\n",
      "[607/01017] train_loss: 0.008696\n",
      "[607/01067] train_loss: 0.008416\n",
      "[607/01117] train_loss: 0.008906\n",
      "[607/01167] train_loss: 0.008781\n",
      "[607/01217] train_loss: 0.008857\n",
      "[608/00041] train_loss: 0.008662\n",
      "[608/00091] train_loss: 0.008261\n",
      "[608/00141] train_loss: 0.007904\n",
      "[608/00191] train_loss: 0.008534\n",
      "[608/00241] train_loss: 0.008515\n",
      "[608/00291] train_loss: 0.008247\n",
      "[608/00341] train_loss: 0.008700\n",
      "[608/00391] train_loss: 0.008533\n",
      "[608/00441] train_loss: 0.008796\n",
      "[608/00491] train_loss: 0.008930\n",
      "[608/00541] train_loss: 0.008625\n",
      "[608/00591] train_loss: 0.008962\n",
      "[608/00641] train_loss: 0.008358\n",
      "[608/00691] train_loss: 0.008477\n",
      "[608/00741] train_loss: 0.008854\n",
      "[608/00791] train_loss: 0.008899\n",
      "[608/00841] train_loss: 0.008559\n",
      "[608/00891] train_loss: 0.008111\n",
      "[608/00941] train_loss: 0.008850\n",
      "[608/00991] train_loss: 0.008736\n",
      "[608/01041] train_loss: 0.009097\n",
      "[608/01091] train_loss: 0.008402\n",
      "[608/01141] train_loss: 0.008257\n",
      "[608/01191] train_loss: 0.008656\n",
      "[609/00015] train_loss: 0.008771\n",
      "[609/00065] train_loss: 0.008894\n",
      "[609/00115] train_loss: 0.008961\n",
      "[609/00165] train_loss: 0.008602\n",
      "[609/00215] train_loss: 0.009015\n",
      "[609/00265] train_loss: 0.008850\n",
      "[609/00315] train_loss: 0.007922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[609/00365] train_loss: 0.008307\n",
      "[609/00415] train_loss: 0.008228\n",
      "[609/00465] train_loss: 0.009099\n",
      "[609/00515] train_loss: 0.008312\n",
      "[609/00565] train_loss: 0.009279\n",
      "[609/00615] train_loss: 0.008758\n",
      "[609/00665] train_loss: 0.008180\n",
      "[609/00715] train_loss: 0.009129\n",
      "[609/00765] train_loss: 0.008586\n",
      "[609/00815] train_loss: 0.008662\n",
      "[609/00865] train_loss: 0.008225\n",
      "[609/00915] train_loss: 0.008702\n",
      "[609/00965] train_loss: 0.008445\n",
      "[609/01015] train_loss: 0.008697\n",
      "[609/01065] train_loss: 0.008793\n",
      "[609/01115] train_loss: 0.008912\n",
      "[609/01165] train_loss: 0.008579\n",
      "[609/01215] train_loss: 0.009200\n",
      "[610/00039] train_loss: 0.008486\n",
      "[610/00089] train_loss: 0.008844\n",
      "[610/00139] train_loss: 0.008820\n",
      "[610/00189] train_loss: 0.008432\n",
      "[610/00239] train_loss: 0.008148\n",
      "[610/00289] train_loss: 0.008707\n",
      "[610/00339] train_loss: 0.008596\n",
      "[610/00389] train_loss: 0.008477\n",
      "[610/00439] train_loss: 0.008649\n",
      "[610/00489] train_loss: 0.008570\n",
      "[610/00539] train_loss: 0.008868\n",
      "[610/00589] train_loss: 0.008036\n",
      "[610/00639] train_loss: 0.008862\n",
      "[610/00689] train_loss: 0.008624\n",
      "[610/00739] train_loss: 0.008718\n",
      "[610/00789] train_loss: 0.008869\n",
      "[610/00839] train_loss: 0.008308\n",
      "[610/00889] train_loss: 0.008761\n",
      "[610/00939] train_loss: 0.007591\n",
      "[610/00989] train_loss: 0.008657\n",
      "[610/01039] train_loss: 0.008688\n",
      "[610/01089] train_loss: 0.008759\n",
      "[610/01139] train_loss: 0.008004\n",
      "[610/01189] train_loss: 0.008520\n",
      "[611/00013] train_loss: 0.009236\n",
      "[611/00063] train_loss: 0.008795\n",
      "[611/00113] train_loss: 0.008412\n",
      "[611/00163] train_loss: 0.008715\n",
      "[611/00213] train_loss: 0.008627\n",
      "[611/00263] train_loss: 0.008231\n",
      "[611/00313] train_loss: 0.008539\n",
      "[611/00363] train_loss: 0.008921\n",
      "[611/00413] train_loss: 0.007896\n",
      "[611/00463] train_loss: 0.008865\n",
      "[611/00513] train_loss: 0.008429\n",
      "[611/00563] train_loss: 0.008073\n",
      "[611/00613] train_loss: 0.008740\n",
      "[611/00663] train_loss: 0.009198\n",
      "[611/00713] train_loss: 0.008738\n",
      "[611/00763] train_loss: 0.008151\n",
      "[611/00813] train_loss: 0.008866\n",
      "[611/00863] train_loss: 0.009090\n",
      "[611/00913] train_loss: 0.008885\n",
      "[611/00963] train_loss: 0.009124\n",
      "[611/01013] train_loss: 0.008442\n",
      "[611/01063] train_loss: 0.008710\n",
      "[611/01113] train_loss: 0.008619\n",
      "[611/01163] train_loss: 0.008858\n",
      "[611/01213] train_loss: 0.008633\n",
      "[612/00037] train_loss: 0.008149\n",
      "[612/00087] train_loss: 0.008936\n",
      "[612/00137] train_loss: 0.007701\n",
      "[612/00187] train_loss: 0.008550\n",
      "[612/00237] train_loss: 0.008723\n",
      "[612/00287] train_loss: 0.008603\n",
      "[612/00337] train_loss: 0.009028\n",
      "[612/00387] train_loss: 0.008088\n",
      "[612/00437] train_loss: 0.009062\n",
      "[612/00487] train_loss: 0.008605\n",
      "[612/00537] train_loss: 0.008522\n",
      "[612/00587] train_loss: 0.008717\n",
      "[612/00637] train_loss: 0.008917\n",
      "[612/00687] train_loss: 0.008439\n",
      "[612/00737] train_loss: 0.008473\n",
      "[612/00787] train_loss: 0.008118\n",
      "[612/00837] train_loss: 0.008784\n",
      "[612/00887] train_loss: 0.008555\n",
      "[612/00937] train_loss: 0.008844\n",
      "[612/00987] train_loss: 0.008674\n",
      "[612/01037] train_loss: 0.008917\n",
      "[612/01087] train_loss: 0.008514\n",
      "[612/01137] train_loss: 0.008459\n",
      "[612/01187] train_loss: 0.008981\n",
      "[613/00011] train_loss: 0.008694\n",
      "[613/00061] train_loss: 0.008714\n",
      "[613/00111] train_loss: 0.008604\n",
      "[613/00161] train_loss: 0.008527\n",
      "[613/00211] train_loss: 0.008122\n",
      "[613/00261] train_loss: 0.008543\n",
      "[613/00311] train_loss: 0.008549\n",
      "[613/00361] train_loss: 0.008291\n",
      "[613/00411] train_loss: 0.008448\n",
      "[613/00461] train_loss: 0.008532\n",
      "[613/00511] train_loss: 0.008277\n",
      "[613/00561] train_loss: 0.009137\n",
      "[613/00611] train_loss: 0.008740\n",
      "[613/00661] train_loss: 0.008685\n",
      "[613/00711] train_loss: 0.008407\n",
      "[613/00761] train_loss: 0.008562\n",
      "[613/00811] train_loss: 0.009269\n",
      "[613/00861] train_loss: 0.008841\n",
      "[613/00911] train_loss: 0.008621\n",
      "[613/00961] train_loss: 0.008672\n",
      "[613/01011] train_loss: 0.009159\n",
      "[613/01061] train_loss: 0.008918\n",
      "[613/01111] train_loss: 0.008794\n",
      "[613/01161] train_loss: 0.008218\n",
      "[613/01211] train_loss: 0.008493\n",
      "[614/00035] train_loss: 0.008875\n",
      "[614/00085] train_loss: 0.008738\n",
      "[614/00135] train_loss: 0.008290\n",
      "[614/00185] train_loss: 0.008560\n",
      "[614/00235] train_loss: 0.008314\n",
      "[614/00285] train_loss: 0.009148\n",
      "[614/00335] train_loss: 0.008729\n",
      "[614/00385] train_loss: 0.008432\n",
      "[614/00435] train_loss: 0.009469\n",
      "[614/00485] train_loss: 0.008219\n",
      "[614/00535] train_loss: 0.008689\n",
      "[614/00585] train_loss: 0.008661\n",
      "[614/00635] train_loss: 0.008648\n",
      "[614/00685] train_loss: 0.008655\n",
      "[614/00735] train_loss: 0.008557\n",
      "[614/00785] train_loss: 0.008502\n",
      "[614/00835] train_loss: 0.008395\n",
      "[614/00885] train_loss: 0.008396\n",
      "[614/00935] train_loss: 0.008551\n",
      "[614/00985] train_loss: 0.008674\n",
      "[614/01035] train_loss: 0.008964\n",
      "[614/01085] train_loss: 0.008112\n",
      "[614/01135] train_loss: 0.009071\n",
      "[614/01185] train_loss: 0.008526\n",
      "[615/00009] train_loss: 0.007940\n",
      "[615/00059] train_loss: 0.008587\n",
      "[615/00109] train_loss: 0.008567\n",
      "[615/00159] train_loss: 0.009026\n",
      "[615/00209] train_loss: 0.008787\n",
      "[615/00259] train_loss: 0.008197\n",
      "[615/00309] train_loss: 0.009130\n",
      "[615/00359] train_loss: 0.008736\n",
      "[615/00409] train_loss: 0.008740\n",
      "[615/00459] train_loss: 0.009103\n",
      "[615/00509] train_loss: 0.008470\n",
      "[615/00559] train_loss: 0.008400\n",
      "[615/00609] train_loss: 0.008827\n",
      "[615/00659] train_loss: 0.008835\n",
      "[615/00709] train_loss: 0.008763\n",
      "[615/00759] train_loss: 0.008765\n",
      "[615/00809] train_loss: 0.008385\n",
      "[615/00859] train_loss: 0.009033\n",
      "[615/00909] train_loss: 0.008791\n",
      "[615/00959] train_loss: 0.008154\n",
      "[615/01009] train_loss: 0.007678\n",
      "[615/01059] train_loss: 0.008512\n",
      "[615/01109] train_loss: 0.008796\n",
      "[615/01159] train_loss: 0.008378\n",
      "[615/01209] train_loss: 0.008701\n",
      "[616/00033] train_loss: 0.008564\n",
      "[616/00083] train_loss: 0.008313\n",
      "[616/00133] train_loss: 0.008599\n",
      "[616/00183] train_loss: 0.008696\n",
      "[616/00233] train_loss: 0.008689\n",
      "[616/00283] train_loss: 0.008558\n",
      "[616/00333] train_loss: 0.009129\n",
      "[616/00383] train_loss: 0.008817\n",
      "[616/00433] train_loss: 0.008401\n",
      "[616/00483] train_loss: 0.008081\n",
      "[616/00533] train_loss: 0.008930\n",
      "[616/00583] train_loss: 0.008534\n",
      "[616/00633] train_loss: 0.008367\n",
      "[616/00683] train_loss: 0.008780\n",
      "[616/00733] train_loss: 0.008823\n",
      "[616/00783] train_loss: 0.008725\n",
      "[616/00833] train_loss: 0.008507\n",
      "[616/00883] train_loss: 0.008595\n",
      "[616/00933] train_loss: 0.008556\n",
      "[616/00983] train_loss: 0.008378\n",
      "[616/01033] train_loss: 0.008414\n",
      "[616/01083] train_loss: 0.008382\n",
      "[616/01133] train_loss: 0.008508\n",
      "[616/01183] train_loss: 0.008239\n",
      "[617/00007] train_loss: 0.008640\n",
      "[617/00057] train_loss: 0.008385\n",
      "[617/00107] train_loss: 0.008604\n",
      "[617/00157] train_loss: 0.008202\n",
      "[617/00207] train_loss: 0.008805\n",
      "[617/00257] train_loss: 0.008450\n",
      "[617/00307] train_loss: 0.008980\n",
      "[617/00357] train_loss: 0.008268\n",
      "[617/00407] train_loss: 0.008815\n",
      "[617/00457] train_loss: 0.009134\n",
      "[617/00507] train_loss: 0.008540\n",
      "[617/00557] train_loss: 0.008443\n",
      "[617/00607] train_loss: 0.008912\n",
      "[617/00657] train_loss: 0.008936\n",
      "[617/00707] train_loss: 0.009057\n",
      "[617/00757] train_loss: 0.008770\n",
      "[617/00807] train_loss: 0.008961\n",
      "[617/00857] train_loss: 0.008734\n",
      "[617/00907] train_loss: 0.008607\n",
      "[617/00957] train_loss: 0.008261\n",
      "[617/01007] train_loss: 0.008519\n",
      "[617/01057] train_loss: 0.008795\n",
      "[617/01107] train_loss: 0.008891\n",
      "[617/01157] train_loss: 0.008410\n",
      "[617/01207] train_loss: 0.008063\n",
      "[618/00031] train_loss: 0.008378\n",
      "[618/00081] train_loss: 0.009262\n",
      "[618/00131] train_loss: 0.008336\n",
      "[618/00181] train_loss: 0.008120\n",
      "[618/00231] train_loss: 0.008958\n",
      "[618/00281] train_loss: 0.008180\n",
      "[618/00331] train_loss: 0.008305\n",
      "[618/00381] train_loss: 0.008934\n",
      "[618/00431] train_loss: 0.008616\n",
      "[618/00481] train_loss: 0.008625\n",
      "[618/00531] train_loss: 0.008412\n",
      "[618/00581] train_loss: 0.008436\n",
      "[618/00631] train_loss: 0.009024\n",
      "[618/00681] train_loss: 0.008495\n",
      "[618/00731] train_loss: 0.009196\n",
      "[618/00781] train_loss: 0.008845\n",
      "[618/00831] train_loss: 0.008110\n",
      "[618/00881] train_loss: 0.008549\n",
      "[618/00931] train_loss: 0.008620\n",
      "[618/00981] train_loss: 0.008523\n",
      "[618/01031] train_loss: 0.008253\n",
      "[618/01081] train_loss: 0.008553\n",
      "[618/01131] train_loss: 0.008394\n",
      "[618/01181] train_loss: 0.009123\n",
      "[619/00005] train_loss: 0.008739\n",
      "[619/00055] train_loss: 0.008329\n",
      "[619/00105] train_loss: 0.008578\n",
      "[619/00155] train_loss: 0.009093\n",
      "[619/00205] train_loss: 0.008637\n",
      "[619/00255] train_loss: 0.007913\n",
      "[619/00305] train_loss: 0.007978\n",
      "[619/00355] train_loss: 0.008399\n",
      "[619/00405] train_loss: 0.009033\n",
      "[619/00455] train_loss: 0.008939\n",
      "[619/00505] train_loss: 0.008398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[619/00555] train_loss: 0.008890\n",
      "[619/00605] train_loss: 0.008494\n",
      "[619/00655] train_loss: 0.009180\n",
      "[619/00705] train_loss: 0.008708\n",
      "[619/00755] train_loss: 0.009291\n",
      "[619/00805] train_loss: 0.008289\n",
      "[619/00855] train_loss: 0.008239\n",
      "[619/00905] train_loss: 0.008342\n",
      "[619/00955] train_loss: 0.008230\n",
      "[619/01005] train_loss: 0.008733\n",
      "[619/01055] train_loss: 0.008797\n",
      "[619/01105] train_loss: 0.009060\n",
      "[619/01155] train_loss: 0.008373\n",
      "[619/01205] train_loss: 0.008451\n",
      "[620/00029] train_loss: 0.008633\n",
      "[620/00079] train_loss: 0.009065\n",
      "[620/00129] train_loss: 0.008550\n",
      "[620/00179] train_loss: 0.008448\n",
      "[620/00229] train_loss: 0.009191\n",
      "[620/00279] train_loss: 0.008349\n",
      "[620/00329] train_loss: 0.008927\n",
      "[620/00379] train_loss: 0.009046\n",
      "[620/00429] train_loss: 0.009077\n",
      "[620/00479] train_loss: 0.007983\n",
      "[620/00529] train_loss: 0.008575\n",
      "[620/00579] train_loss: 0.008182\n",
      "[620/00629] train_loss: 0.007915\n",
      "[620/00679] train_loss: 0.008675\n",
      "[620/00729] train_loss: 0.008408\n",
      "[620/00779] train_loss: 0.008920\n",
      "[620/00829] train_loss: 0.008593\n",
      "[620/00879] train_loss: 0.008109\n",
      "[620/00929] train_loss: 0.008362\n",
      "[620/00979] train_loss: 0.008036\n",
      "[620/01029] train_loss: 0.008555\n",
      "[620/01079] train_loss: 0.008649\n",
      "[620/01129] train_loss: 0.008872\n",
      "[620/01179] train_loss: 0.008838\n",
      "[621/00003] train_loss: 0.008379\n",
      "[621/00053] train_loss: 0.009131\n",
      "[621/00103] train_loss: 0.008294\n",
      "[621/00153] train_loss: 0.008282\n",
      "[621/00203] train_loss: 0.007932\n",
      "[621/00253] train_loss: 0.008441\n",
      "[621/00303] train_loss: 0.008902\n",
      "[621/00353] train_loss: 0.008222\n",
      "[621/00403] train_loss: 0.008326\n",
      "[621/00453] train_loss: 0.009011\n",
      "[621/00503] train_loss: 0.008846\n",
      "[621/00553] train_loss: 0.008423\n",
      "[621/00603] train_loss: 0.009178\n",
      "[621/00653] train_loss: 0.008769\n",
      "[621/00703] train_loss: 0.008761\n",
      "[621/00753] train_loss: 0.008343\n",
      "[621/00803] train_loss: 0.008687\n",
      "[621/00853] train_loss: 0.008711\n",
      "[621/00903] train_loss: 0.009388\n",
      "[621/00953] train_loss: 0.008872\n",
      "[621/01003] train_loss: 0.008638\n",
      "[621/01053] train_loss: 0.008182\n",
      "[621/01103] train_loss: 0.008413\n",
      "[621/01153] train_loss: 0.008209\n",
      "[621/01203] train_loss: 0.009339\n",
      "[622/00027] train_loss: 0.008651\n",
      "[622/00077] train_loss: 0.008642\n",
      "[622/00127] train_loss: 0.008484\n",
      "[622/00177] train_loss: 0.008702\n",
      "[622/00227] train_loss: 0.008537\n",
      "[622/00277] train_loss: 0.008834\n",
      "[622/00327] train_loss: 0.009201\n",
      "[622/00377] train_loss: 0.009147\n",
      "[622/00427] train_loss: 0.008538\n",
      "[622/00477] train_loss: 0.008591\n",
      "[622/00527] train_loss: 0.008459\n",
      "[622/00577] train_loss: 0.007917\n",
      "[622/00627] train_loss: 0.008512\n",
      "[622/00677] train_loss: 0.008296\n",
      "[622/00727] train_loss: 0.008449\n",
      "[622/00777] train_loss: 0.008391\n",
      "[622/00827] train_loss: 0.008433\n",
      "[622/00877] train_loss: 0.008926\n",
      "[622/00927] train_loss: 0.008762\n",
      "[622/00977] train_loss: 0.008809\n",
      "[622/01027] train_loss: 0.008265\n",
      "[622/01077] train_loss: 0.008778\n",
      "[622/01127] train_loss: 0.008270\n",
      "[622/01177] train_loss: 0.007772\n",
      "[623/00001] train_loss: 0.008458\n",
      "[623/00051] train_loss: 0.008227\n",
      "[623/00101] train_loss: 0.008677\n",
      "[623/00151] train_loss: 0.009122\n",
      "[623/00201] train_loss: 0.009270\n",
      "[623/00251] train_loss: 0.008229\n",
      "[623/00301] train_loss: 0.009008\n",
      "[623/00351] train_loss: 0.009252\n",
      "[623/00401] train_loss: 0.008432\n",
      "[623/00451] train_loss: 0.008175\n",
      "[623/00501] train_loss: 0.008527\n",
      "[623/00551] train_loss: 0.008678\n",
      "[623/00601] train_loss: 0.008065\n",
      "[623/00651] train_loss: 0.007987\n",
      "[623/00701] train_loss: 0.008563\n",
      "[623/00751] train_loss: 0.008449\n",
      "[623/00801] train_loss: 0.008672\n",
      "[623/00851] train_loss: 0.009224\n",
      "[623/00901] train_loss: 0.008692\n",
      "[623/00951] train_loss: 0.008085\n",
      "[623/01001] train_loss: 0.008297\n",
      "[623/01051] train_loss: 0.009070\n",
      "[623/01101] train_loss: 0.008037\n",
      "[623/01151] train_loss: 0.008658\n",
      "[623/01201] train_loss: 0.009169\n",
      "[624/00025] train_loss: 0.008171\n",
      "[624/00075] train_loss: 0.008354\n",
      "[624/00125] train_loss: 0.008266\n",
      "[624/00175] train_loss: 0.008700\n",
      "[624/00225] train_loss: 0.008664\n",
      "[624/00275] train_loss: 0.009637\n",
      "[624/00325] train_loss: 0.008405\n",
      "[624/00375] train_loss: 0.009000\n",
      "[624/00425] train_loss: 0.008424\n",
      "[624/00475] train_loss: 0.008849\n",
      "[624/00525] train_loss: 0.008656\n",
      "[624/00575] train_loss: 0.007705\n",
      "[624/00625] train_loss: 0.008615\n",
      "[624/00675] train_loss: 0.008989\n",
      "[624/00725] train_loss: 0.008041\n",
      "[624/00775] train_loss: 0.008898\n",
      "[624/00825] train_loss: 0.008200\n",
      "[624/00875] train_loss: 0.008315\n",
      "[624/00925] train_loss: 0.008169\n",
      "[624/00975] train_loss: 0.008810\n",
      "[624/01025] train_loss: 0.008390\n",
      "[624/01075] train_loss: 0.008913\n",
      "[624/01125] train_loss: 0.008649\n",
      "[624/01175] train_loss: 0.008689\n",
      "[624/01225] train_loss: 0.008513\n",
      "[625/00049] train_loss: 0.008762\n",
      "[625/00099] train_loss: 0.008676\n",
      "[625/00149] train_loss: 0.008403\n",
      "[625/00199] train_loss: 0.008856\n",
      "[625/00249] train_loss: 0.009085\n",
      "[625/00299] train_loss: 0.008507\n",
      "[625/00349] train_loss: 0.008623\n",
      "[625/00399] train_loss: 0.008430\n",
      "[625/00449] train_loss: 0.008566\n",
      "[625/00499] train_loss: 0.008581\n",
      "[625/00549] train_loss: 0.009287\n",
      "[625/00599] train_loss: 0.008630\n",
      "[625/00649] train_loss: 0.008556\n",
      "[625/00699] train_loss: 0.008187\n",
      "[625/00749] train_loss: 0.008730\n",
      "[625/00799] train_loss: 0.008685\n",
      "[625/00849] train_loss: 0.008664\n",
      "[625/00899] train_loss: 0.008621\n",
      "[625/00949] train_loss: 0.008375\n",
      "[625/00999] train_loss: 0.008603\n",
      "[625/01049] train_loss: 0.008196\n",
      "[625/01099] train_loss: 0.009082\n",
      "[625/01149] train_loss: 0.008218\n",
      "[625/01199] train_loss: 0.008674\n",
      "[626/00023] train_loss: 0.008771\n",
      "[626/00073] train_loss: 0.008716\n",
      "[626/00123] train_loss: 0.008566\n",
      "[626/00173] train_loss: 0.007963\n",
      "[626/00223] train_loss: 0.008100\n",
      "[626/00273] train_loss: 0.008474\n",
      "[626/00323] train_loss: 0.008611\n",
      "[626/00373] train_loss: 0.008459\n",
      "[626/00423] train_loss: 0.008421\n",
      "[626/00473] train_loss: 0.008953\n",
      "[626/00523] train_loss: 0.008801\n",
      "[626/00573] train_loss: 0.009503\n",
      "[626/00623] train_loss: 0.009185\n",
      "[626/00673] train_loss: 0.008305\n",
      "[626/00723] train_loss: 0.008625\n",
      "[626/00773] train_loss: 0.008506\n",
      "[626/00823] train_loss: 0.008292\n",
      "[626/00873] train_loss: 0.008569\n",
      "[626/00923] train_loss: 0.008785\n",
      "[626/00973] train_loss: 0.007941\n",
      "[626/01023] train_loss: 0.009021\n",
      "[626/01073] train_loss: 0.007903\n",
      "[626/01123] train_loss: 0.008385\n",
      "[626/01173] train_loss: 0.008899\n",
      "[626/01223] train_loss: 0.008236\n",
      "[627/00047] train_loss: 0.008867\n",
      "[627/00097] train_loss: 0.008459\n",
      "[627/00147] train_loss: 0.008896\n",
      "[627/00197] train_loss: 0.008033\n",
      "[627/00247] train_loss: 0.009111\n",
      "[627/00297] train_loss: 0.008460\n",
      "[627/00347] train_loss: 0.008818\n",
      "[627/00397] train_loss: 0.008947\n",
      "[627/00447] train_loss: 0.008398\n",
      "[627/00497] train_loss: 0.008173\n",
      "[627/00547] train_loss: 0.008354\n",
      "[627/00597] train_loss: 0.008516\n",
      "[627/00647] train_loss: 0.008563\n",
      "[627/00697] train_loss: 0.008859\n",
      "[627/00747] train_loss: 0.008690\n",
      "[627/00797] train_loss: 0.008676\n"
     ]
    }
   ],
   "source": [
    "from exercise_3.training import train_deepsdf\n",
    "\n",
    "generalization_config = {\n",
    "    'experiment_name': '3_2_deepsdf_generalization',\n",
    "    'device': 'cuda:0',  # run this on a gpu for a reasonable training time\n",
    "    'is_overfit': False,\n",
    "    'num_sample_points': 4096, # you can adjust this such that the model fits on your gpu\n",
    "    'latent_code_length': 256,\n",
    "    'batch_size': 1,\n",
    "    'resume_ckpt': None,\n",
    "    'learning_rate_model': 0.0005,\n",
    "    'learning_rate_code': 0.001,\n",
    "    'lambda_code_regularization': 0.0001,\n",
    "    'max_epochs': 2000,  # not necessary to run for 2000 epochs if you're short on time, at 500 epochs you should start to see reasonable results\n",
    "    'print_every_n': 50,\n",
    "    'visualize_every_n': 5000,\n",
    "}\n",
    "\n",
    "train_deepsdf.main(generalization_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (f) Inference using the trained model on observed SDF values\n",
    "\n",
    "Fill in the inference script `exercise_3/inference/infer_deepsdf.py`. Note that it's not simply a forward pass, but an optimization of the latent code such that we have lowest error on observed SDF values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from exercise_3.inference.infer_deepsdf import InferenceHandlerDeepSDF\n",
    "\n",
    "device = torch.device('cuda:0')  # change this to cpu if you're not using a gpu\n",
    "\n",
    "inference_handler = InferenceHandlerDeepSDF(256, \"exercise_3/runs/3_2_deepsdf_generalization\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we try inference on a shape from validation set, for which we have a complete observation of sdf values. This is an easier problem as compared to shape completion,\n",
    "since we have all the information already in the input.\n",
    "\n",
    "Let's visualize the observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# get observed data\n",
    "points, sdf = ShapeImplicit.get_all_sdf_samples(\"b351e06f5826444c19fb4103277a6b93\")\n",
    "\n",
    "inside_points = points[sdf[:, 0] < 0, :].numpy()\n",
    "outside_points = points[sdf[:, 0] > 0, :].numpy()\n",
    "\n",
    "# visualize observed points; you'll observe that the observations are very complete\n",
    "print('Observations with negative SDF (inside)')\n",
    "visualize_pointcloud(inside_points, 0.025, flip_axes=True)\n",
    "print('Observations with positive SDF (outside)')\n",
    "visualize_pointcloud(outside_points, 0.025, flip_axes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Reconstruction on these observations with the trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct\n",
    "vertices, faces = inference_handler.reconstruct(points, sdf, 800)\n",
    "# visualize\n",
    "visualize_mesh(vertices, faces, flip_axes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can try the shape completion task, i.e., inference on a shape from validation set, for which we do not have a complete observation of sdf values. The observed points are visualized below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# get observed data\n",
    "points, sdf = ShapeImplicit.get_all_sdf_samples(\"b351e06f5826444c19fb4103277a6b93_incomplete\")\n",
    "\n",
    "inside_points = points[sdf[:, 0] < 0, :].numpy()\n",
    "outside_points = points[sdf[:, 0] > 0, :].numpy()\n",
    "\n",
    "# visualize observed points; you'll observe that the observations are incomplete\n",
    "# making this is a shape completion task\n",
    "print('Observations with negative SDF (inside)')\n",
    "visualize_pointcloud(inside_points, 0.025, flip_axes=True)\n",
    "print('Observations with positive SDF (outside)')\n",
    "visualize_pointcloud(outside_points, 0.025, flip_axes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shape completion using the trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct\n",
    "vertices, faces = inference_handler.reconstruct(points, sdf, 800)\n",
    "# visualize\n",
    "visualize_mesh(vertices, faces, flip_axes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (g) Latent space interpolation\n",
    "\n",
    "The latent space learned by DeepSDF is interpolatable, meaning that decoding latent codes from this space produced meaningful shapes. Given two latent codes, a linearly interpolatable latent space will decode\n",
    "each of the intermediate codes to some valid shape. Let's see if this holds for our trained model.\n",
    "\n",
    "We'll pick two shapes from the train set as visualized below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exercise_3.data.shape_implicit import ShapeImplicit\n",
    "from exercise_3.util.visualization import visualize_mesh\n",
    "\n",
    "mesh = ShapeImplicit.get_mesh(\"494fe53da65650b8c358765b76c296\")\n",
    "print('GT Shape A')\n",
    "visualize_mesh(mesh.vertices, mesh.faces, flip_axes=True)\n",
    "\n",
    "mesh = ShapeImplicit.get_mesh(\"5ca1ef55ff5f68501921e7a85cf9da35\")\n",
    "print('GT Shape B')\n",
    "visualize_mesh(mesh.vertices, mesh.faces, flip_axes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Implement the missing parts in `exercise_3/inference/infer_deepsdf.py` such that it interpolates two given latent vectors, and run the code fragement below once done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from exercise_3.inference.infer_deepsdf import InferenceHandlerDeepSDF\n",
    "\n",
    "inference_handler = InferenceHandlerDeepSDF(256, \"exercise_3/runs/3_2_deepsdf_generalization\", torch.device('cuda:0'))\n",
    "# interpolate; also exports interpolated meshes to disk\n",
    "inference_handler.interpolate('494fe53da65650b8c358765b76c296', '5ca1ef55ff5f68501921e7a85cf9da35', 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the interpolation below. If everything works out correctly, you should see a smooth transformation between the shapes, with all intermediate shapes being valid sofas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from exercise_3.util.mesh_collection_to_gif import  meshes_to_gif\n",
    "from exercise_3.util.misc import show_gif\n",
    "\n",
    "# create list of meshes (just exported) to be visualized\n",
    "mesh_paths = sorted([x for x in Path(\"exercise_3/runs/3_2_deepsdf_generalization/interpolation\").iterdir() if int(x.name.split('.')[0].split(\"_\")[1]) == 0], key=lambda x: int(x.name.split('.')[0].split(\"_\")[0]))\n",
    "mesh_paths = mesh_paths + mesh_paths[::-1]\n",
    "\n",
    "# create a visualization of the interpolation process\n",
    "meshes_to_gif(mesh_paths, \"exercise_3/runs/3_2_deepsdf_generalization/latent_interp.gif\", 20)\n",
    "show_gif(\"exercise_3/runs/3_2_deepsdf_generalization/latent_interp.gif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Submission\n",
    "\n",
    "This is the end of exercise 3 🙂. Please create a zip containing all files we provided, everything you modified, your visualization images/gif (no need to submit generated OBJs), including your checkpoints. Name it with your matriculation number(s) as described in exercise 1. Make sure this notebook can be run without problems. Then, submit via Moodle.\n",
    "\n",
    "**Note**: The maximum submission file size limit for Moodle is 100M. You do not need to submit your overfitting checkpoints; however, the generalization checkpoint will be >200M. The easiest way to still be able to submit that one is to split it with zip like this: `zip -s 100M model_best.ckpt.zip model_best.ckpt` which creates a `.zip` and a `.z01`. You can then submit both files alongside another zip containing all your code and outputs.\n",
    "\n",
    "**Submission Deadline**: 09.06.2021, 23:55"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## References\n",
    "\n",
    "[1] Dai, Angela, Charles Ruizhongtai Qi, and Matthias Nießner. \"Shape completion using 3d-encoder-predictor cnns and shape synthesis.\" Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2017.\n",
    "\n",
    "[2] Park, Jeong Joon, et al. \"Deepsdf: Learning continuous signed distance functions for shape representation.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2019."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
